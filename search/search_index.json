{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Hello folks,</p> <p>This is an ongoing practice that I am currently (end of 2022-beginning of 2023) adopting, to build a second brain.</p>"},{"location":"#goal","title":"Goal","text":"<p>One of the things I've learned about myself, is that I value knowledge, and intellectual stimulation. I have been nurturing my intellect for many years with different topics, such as web development, software architecture, psychology, Philosophy, sociology, math, culture dynamics, etc.</p> <p>Yet I've done it constantly, I've done it without a structure, and without making my knowledge somewhat accessible to other people who might be interested on the things I come up with.</p> <p>The goal of this initiative of mine, is to bring a structure, and to be able to create more actionable out of my knowledge, as well as have a pool of knowledge for me to use as reference for any thing I build in the future.</p>"},{"location":"#methods","title":"Methods","text":"<p>This is a personal adaptation of Zettelkasten and P.A.R.A.</p> <p>I've also added some extra folders, such as diagrams-and-media, or reference system, to be able to have a place where I put mind maps, sketches, or sources to books or papers, that I want to have a space for.</p>"},{"location":"#workflow","title":"Workflow","text":""},{"location":"#adding-a-new-note","title":"Adding a new note","text":"<ol> <li>Add a daily note for any new idea, research or so I am doing</li> <li>Within few days, move it to inbox, and process the note, update it, add tags. Let it sink</li> <li>Few days later, move it to any if the other folders (ideas, areas, projects or reference system)</li> </ol>"},{"location":"#producing-an-output","title":"Producing an output","text":"<p>There is nothing I have here, but few ideas I want to try: * Setting up a scheduled time per week to go through the projects, add tasks, and plan the work, so that I deliver something, and close the project</p>"},{"location":"#housekeeping","title":"Housekeeping","text":"<p>Try: Setting up time per week to review notes, clean them up, update categories, etc.</p>"},{"location":"#removing-notes","title":"Removing notes","text":"<p>I am not sure how this works yet, or how I want to do this. Perhaps I could have an archive folder for projects (which is the only folder with 'deadline'?). Or maybe an archive folder for topics I am no longer interested?</p>"},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#tag:actvalues","title":"ACTValues","text":"<ul> <li>            2023 01 07 Living a happier life   Tool    ACT   Values &amp; goals          </li> <li>            2023 02 19   How to craft a harmonius life          </li> </ul>"},{"location":"tags/#tag:ddd","title":"DDD","text":"<ul> <li>            Bounded Context          </li> </ul>"},{"location":"tags/#tag:acttherapy","title":"actTherapy","text":"<ul> <li>            2023 01 07 Living a happier life   Tool    ACT   Values &amp; goals          </li> </ul>"},{"location":"tags/#tag:adr","title":"adr","text":"<ul> <li>            2023 03 03   Notes FAQ with Marc Richards and Neild Ford          </li> </ul>"},{"location":"tags/#tag:architecture","title":"architecture","text":"<ul> <li>            2023 01 18 TIL   domain architecture isomorphism          </li> <li>            2023 02 01   Coupling  &amp; evolve systems          </li> <li>            2023 02 06   Differences EDA vs MSA          </li> <li>            2023 03 03   Notes FAQ with Marc Richards and Neild Ford          </li> <li>            Bounded Context          </li> <li>            Event processor          </li> <li>            Microservice          </li> </ul>"},{"location":"tags/#tag:architecturecharacteristics","title":"architectureCharacteristics","text":"<ul> <li>            2023 03 03   Notes FAQ with Marc Richards and Neild Ford          </li> </ul>"},{"location":"tags/#tag:architecturepatterns","title":"architecturePatterns","text":"<ul> <li>            Event driven architecture          </li> </ul>"},{"location":"tags/#tag:basicconcepts","title":"basicConcepts","text":"<ul> <li>            2023 01 18 TIL   domain architecture isomorphism          </li> <li>            Structure design  Coupling          </li> </ul>"},{"location":"tags/#tag:becomewoman","title":"becomeWoman","text":"<ul> <li>            onLabels          </li> </ul>"},{"location":"tags/#tag:build-for-fun","title":"build-for-fun","text":"<ul> <li>            Draft ideas.md          </li> </ul>"},{"location":"tags/#tag:career","title":"career","text":"<ul> <li>            00  Safari books bookshelf          </li> <li>            2022 10 27   Take home challenge          </li> <li>            2022 10 27   question only interview          </li> <li>            A categorization of goals          </li> <li>            Interview questions          </li> <li>            Notes about Feedback          </li> <li>            Quarterly Self Review   Professional          </li> <li>            What is a software engineer          </li> </ul>"},{"location":"tags/#tag:cloudcomputing","title":"cloudComputing","text":"<ul> <li>            Containerization          </li> <li>            Data Streaming in Cloud Computing          </li> <li>            Data management and Databases          </li> </ul>"},{"location":"tags/#tag:cloudnative","title":"cloudNative","text":"<ul> <li>            Data Streaming in Cloud Computing          </li> <li>            Data management and Databases          </li> <li>            Event driven architecture          </li> </ul>"},{"location":"tags/#tag:communication","title":"communication","text":"<ul> <li>            Communication          </li> <li>            Dealing with a coleric person          </li> <li>            Notes about Feedback          </li> <li>            Receiving challenging feedback          </li> </ul>"},{"location":"tags/#tag:componentapi","title":"componentAPI","text":"<ul> <li>            2023 01 25   Component API          </li> <li>            2023 02 08   how to apply making impossible states impossible to UI components?          </li> </ul>"},{"location":"tags/#tag:components","title":"components","text":"<ul> <li>            2023 01 25   Component API          </li> <li>            2023 02 08   how to apply making impossible states impossible to UI components?          </li> </ul>"},{"location":"tags/#tag:conflictresolution","title":"conflictResolution","text":"<ul> <li>            Solving tech conflict          </li> </ul>"},{"location":"tags/#tag:creativewriting","title":"creativeWriting","text":"<ul> <li>            202208171521   Italo Calvino on how he reads          </li> <li>            2023 02 19   writing with ai          </li> </ul>"},{"location":"tags/#tag:cycleoflearningimproving","title":"cycleOfLearningImproving","text":"<ul> <li>            2023 02 22   Moving to predictable incident management          </li> </ul>"},{"location":"tags/#tag:datamanagement","title":"dataManagement","text":"<ul> <li>            Data management and Databases          </li> </ul>"},{"location":"tags/#tag:datastreaming","title":"dataStreaming","text":"<ul> <li>            Data Streaming in Cloud Computing          </li> </ul>"},{"location":"tags/#tag:database","title":"database","text":"<ul> <li>            Data management and Databases          </li> <li>            Databases          </li> </ul>"},{"location":"tags/#tag:deepthinking","title":"deepThinking","text":"<ul> <li>            2022 10 20   moving on limiting beliefs for diversity in tech          </li> <li>            After sentiers 229   designing without depletion          </li> </ul>"},{"location":"tags/#tag:devops","title":"devOps","text":"<ul> <li>            Containerization          </li> <li>            Databases          </li> <li>            Infrastructure provisioning          </li> </ul>"},{"location":"tags/#tag:developidea","title":"developIdea","text":"<ul> <li>            2023 01 25   Component API          </li> </ul>"},{"location":"tags/#tag:difficultconversation","title":"difficultConversation","text":"<ul> <li>            Difficult Conversations          </li> </ul>"},{"location":"tags/#tag:difficultconversations","title":"difficultConversations","text":"<ul> <li>            Dealing with a coleric person          </li> </ul>"},{"location":"tags/#tag:difficultsituations","title":"difficultSituations","text":"<ul> <li>            Solving tech conflict          </li> </ul>"},{"location":"tags/#tag:diversityintechnology","title":"diversityInTechnology","text":"<ul> <li>            2022 10 20   moving on limiting beliefs for diversity in tech          </li> </ul>"},{"location":"tags/#tag:eventdriven","title":"eventDriven","text":"<ul> <li>            2023 02 06   Differences EDA vs MSA          </li> <li>            Event processor          </li> <li>            Reactive Programming          </li> </ul>"},{"location":"tags/#tag:expectationmanagement","title":"expectationManagement","text":"<ul> <li>            2023 02 07   Role ownership mapped to RACI          </li> </ul>"},{"location":"tags/#tag:feedback","title":"feedback","text":"<ul> <li>            Notes about Feedback          </li> <li>            Receiving challenging feedback          </li> </ul>"},{"location":"tags/#tag:feminism","title":"feminism","text":"<ul> <li>            Feminism          </li> <li>            onLabels          </li> </ul>"},{"location":"tags/#tag:fpterm","title":"fpTerm","text":"<ul> <li>            Maybe type          </li> <li>            Monad          </li> </ul>"},{"location":"tags/#tag:functionaldomainmodelling","title":"functionalDomainModelling","text":"<ul> <li>            2023 02 08   Impossible states Richard Feldman          </li> </ul>"},{"location":"tags/#tag:functionalprogramming","title":"functionalProgramming","text":"<ul> <li>            2023 01 06 Category theory          </li> <li>            2023 02 08   Impossible states Richard Feldman          </li> <li>            Curry &amp; Partial Application          </li> <li>            Functional programming          </li> <li>            Maybe type          </li> <li>            Monad          </li> </ul>"},{"location":"tags/#tag:goals","title":"goals","text":"<ul> <li>            A categorization of goals          </li> </ul>"},{"location":"tags/#tag:harmonious-life-tool","title":"harmonious-life-tool","text":"<ul> <li>            2023 02 19   How to craft a harmonius life          </li> </ul>"},{"location":"tags/#tag:humanetech","title":"humaneTech","text":"<ul> <li>            2022 12 12  What is the story that shapes my path as humane technologist?          </li> <li>            After sentiers 229   designing without depletion          </li> </ul>"},{"location":"tags/#tag:idea","title":"idea","text":"<ul> <li>            2022 10 20   moving on limiting beliefs for diversity in tech          </li> </ul>"},{"location":"tags/#tag:idea-to-refine","title":"idea-to-refine","text":"<ul> <li>            2022 10 20   moving on limiting beliefs for diversity in tech          </li> <li>            Draft ideas.md          </li> </ul>"},{"location":"tags/#tag:impossiblestate","title":"impossibleState","text":"<ul> <li>            2023 01 25   Component API          </li> <li>            2023 02 08   Impossible states Richard Feldman          </li> <li>            2023 02 08   how to apply making impossible states impossible to UI components?          </li> </ul>"},{"location":"tags/#tag:incidentmanagement","title":"incidentManagement","text":"<ul> <li>            2023 02 22   Moving to predictable incident management          </li> </ul>"},{"location":"tags/#tag:infrastructure","title":"infrastructure","text":"<ul> <li>            Databases          </li> </ul>"},{"location":"tags/#tag:infrastructureascode","title":"infrastructureAsCode","text":"<ul> <li>            Infrastructure provisioning          </li> <li>            Tech stack for a real time app          </li> </ul>"},{"location":"tags/#tag:intelectualestimulation","title":"intelectualEstimulation","text":"<ul> <li>            202208171521   Italo Calvino on how he reads          </li> </ul>"},{"location":"tags/#tag:interviewing","title":"interviewing","text":"<ul> <li>            2022 10 27   Take home challenge          </li> <li>            2022 10 27   question only interview          </li> <li>            2022 10 27 Reflection on how I did in a coding chanllenge          </li> <li>            Guide to interviewing and thoughts          </li> <li>            Interview questions          </li> </ul>"},{"location":"tags/#tag:learning","title":"learning","text":"<ul> <li>            00  Safari books bookshelf          </li> </ul>"},{"location":"tags/#tag:math","title":"math","text":"<ul> <li>            2023 01 06 Category theory          </li> </ul>"},{"location":"tags/#tag:microservice","title":"microservice","text":"<ul> <li>            2023 02 06   Differences EDA vs MSA          </li> <li>            Containerization          </li> <li>            Data Streaming in Cloud Computing          </li> <li>            Data management and Databases          </li> <li>            Event driven architecture          </li> <li>            Infrastructure provisioning          </li> <li>            Microservice          </li> </ul>"},{"location":"tags/#tag:monad","title":"monad","text":"<ul> <li>            Maybe type          </li> <li>            Monad          </li> </ul>"},{"location":"tags/#tag:music","title":"music","text":"<ul> <li>            Draft ideas.md          </li> </ul>"},{"location":"tags/#tag:needs-based-crafting","title":"needs-based-crafting","text":"<ul> <li>            2023 02 19   How to craft a harmonius life          </li> </ul>"},{"location":"tags/#tag:newteams","title":"newTeams","text":"<ul> <li>            2023 02 07   Role ownership mapped to RACI          </li> <li>            Questions for new teams          </li> </ul>"},{"location":"tags/#tag:peopletool","title":"peopleTool","text":"<ul> <li>            2023 02 07   Role ownership mapped to RACI          </li> <li>            Communication          </li> <li>            Dealing with a coleric person          </li> </ul>"},{"location":"tags/#tag:pet-project","title":"pet-project","text":"<ul> <li>            Draft ideas.md          </li> </ul>"},{"location":"tags/#tag:principles","title":"principles","text":"<ul> <li>            2023 02 01   Coupling  &amp; evolve systems          </li> </ul>"},{"location":"tags/#tag:programmingparadigm","title":"programmingParadigm","text":"<ul> <li>            Functional programming          </li> <li>            Reactive Programming          </li> </ul>"},{"location":"tags/#tag:reactiveprogramming","title":"reactiveProgramming","text":"<ul> <li>            Event driven architecture          </li> <li>            Reactive Programming          </li> </ul>"},{"location":"tags/#tag:realtime","title":"realTime","text":"<ul> <li>            Containerization          </li> <li>            Reactive Programming          </li> <li>            Tech stack for a real time app          </li> </ul>"},{"location":"tags/#tag:reflection","title":"reflection","text":"<ul> <li>            2022 10 20   moving on limiting beliefs for diversity in tech          </li> <li>            2022 10 27 Reflection on how I did in a coding chanllenge          </li> <li>            2022 12 12  What is the story that shapes my path as humane technologist?          </li> <li>            2023 02 19   How to craft a harmonius life          </li> <li>            Guide to interviewing and thoughts          </li> </ul>"},{"location":"tags/#tag:reminder","title":"reminder","text":"<ul> <li>            Communication          </li> </ul>"},{"location":"tags/#tag:roles","title":"roles","text":"<ul> <li>            What is a software engineer          </li> </ul>"},{"location":"tags/#tag:self-insight","title":"self-insight","text":"<ul> <li>            2022 10 27 Reflection on how I did in a coding chanllenge          </li> <li>            2023 01 07 Living a happier life   Tool    ACT   Values &amp; goals          </li> <li>            2023 01 08 act   finding my values          </li> <li>            2023 02 19   How to craft a harmonius life          </li> <li>            Guide to interviewing and thoughts          </li> <li>            Quarterly Self Review   Professional          </li> <li>            onLabels          </li> </ul>"},{"location":"tags/#tag:softwarearchitecture","title":"softwareArchitecture","text":"<ul> <li>            2023 01 04   Archictecture trade off analysis          </li> <li>            2023 01 16   ADRs &amp; RFCs differences and process          </li> <li>            Databases          </li> <li>            Infrastructure provisioning          </li> <li>            Tech stack for a real time app          </li> </ul>"},{"location":"tags/#tag:softwareconcepts","title":"softwareConcepts","text":"<ul> <li>            Curry &amp; Partial Application          </li> <li>            Structure design  Coupling          </li> </ul>"},{"location":"tags/#tag:softwaredesign","title":"softwareDesign","text":"<ul> <li>            Connascence          </li> <li>            Structure design  Coupling          </li> </ul>"},{"location":"tags/#tag:softwarephylosophy","title":"softwarePhylosophy","text":"<ul> <li>            notes on Programming as Theory Building          </li> </ul>"},{"location":"tags/#tag:sustainability","title":"sustainability","text":"<ul> <li>            After sentiers 229   designing without depletion          </li> </ul>"},{"location":"tags/#tag:sustainabletech","title":"sustainableTech","text":"<ul> <li>            After sentiers 229   designing without depletion          </li> </ul>"},{"location":"tags/#tag:systemdesign","title":"systemDesign","text":"<ul> <li>            2023 01 18 TIL   domain architecture isomorphism          </li> <li>            Bounded Context          </li> </ul>"},{"location":"tags/#tag:systemsdocumentation","title":"systemsDocumentation","text":"<ul> <li>            2023 01 16   ADRs &amp; RFCs differences and process          </li> </ul>"},{"location":"tags/#tag:teambuilding","title":"teamBuilding","text":"<ul> <li>            Questions for new teams          </li> </ul>"},{"location":"tags/#tag:tech","title":"tech","text":"<ul> <li>            00  Safari books bookshelf          </li> </ul>"},{"location":"tags/#tag:techstack","title":"techStack","text":"<ul> <li>            Data management and Databases          </li> </ul>"},{"location":"tags/#tag:technicaldecisions","title":"technicalDecisions","text":"<ul> <li>            2023 03 03   Notes FAQ with Marc Richards and Neild Ford          </li> </ul>"},{"location":"tags/#tag:technicaldocumentation","title":"technicalDocumentation","text":"<ul> <li>            2023 03 03   Notes FAQ with Marc Richards and Neild Ford          </li> </ul>"},{"location":"tags/#tag:technicalwritting","title":"technicalWritting","text":"<ul> <li>            2023 01 16   ADRs &amp; RFCs differences and process          </li> </ul>"},{"location":"tags/#tag:techniques","title":"techniques","text":"<ul> <li>            2023 01 04   Archictecture trade off analysis          </li> </ul>"},{"location":"tags/#tag:thearchitectrole","title":"theArchitectRole","text":"<ul> <li>            2023 03 03   Notes FAQ with Marc Richards and Neild Ford          </li> <li>            The Role of an Architect   Creating a Context for Success through Vision, Standards, and Trade offs          </li> <li>            What is a software engineer          </li> </ul>"},{"location":"tags/#tag:tip","title":"tip","text":"<ul> <li>            Communication          </li> </ul>"},{"location":"tags/#tag:tools","title":"tools","text":"<ul> <li>            Notes about Feedback          </li> <li>            Tech stack for a real time app          </li> </ul>"},{"location":"tags/#tag:tradeoff","title":"tradeOff","text":"<ul> <li>            2023 01 04   Archictecture trade off analysis          </li> </ul>"},{"location":"tags/#tag:understandmyself","title":"understandMyself","text":"<ul> <li>            2023 01 07 Living a happier life   Tool    ACT   Values &amp; goals          </li> <li>            2023 01 08 act   finding my values          </li> <li>            onLabels          </li> </ul>"},{"location":"tags/#tag:web","title":"web","text":"<ul> <li>            2023 01 25   Component API          </li> </ul>"},{"location":"tags/#tag:wip-post","title":"wip-post","text":"<ul> <li>            2023 01 25   Component API          </li> <li>            2023 02 08   how to apply making impossible states impossible to UI components?          </li> </ul>"},{"location":"tags/#tag:writersinspiration","title":"writersInspiration","text":"<ul> <li>            202208171521   Italo Calvino on how he reads          </li> </ul>"},{"location":"tags/#tag:writingwithai","title":"writingWithAI","text":"<ul> <li>            2023 02 19   writing with ai          </li> </ul>"},{"location":"tags/#tag:writtingwithai","title":"writtingWithAI","text":"<ul> <li>            2023 02 19   writing with ai          </li> </ul>"},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-07%20-%20Role%20ownership%20mapped%20to%20RACI/","title":"2023 02 07   Role ownership mapped to RACI","text":"<p>newTeams peopleTool expectationManagement</p>","tags":["newTeams","peopleTool","expectationManagement"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-07%20-%20Role%20ownership%20mapped%20to%20RACI/#what","title":"What?","text":"<p>Usually RACI is a good tool to think of different levels of engagement. However, sometimes is hard to apply it to specific situations.</p> <p>I've found this mapping from the W3C, to levels of ownership and decision making. I find it easier to apply when doing expectation managements.</p> <p>(All the text below is a quote from the original article)</p>","tags":["newTeams","peopleTool","expectationManagement"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-07%20-%20Role%20ownership%20mapped%20to%20RACI/#primary-ownership-accountable","title":"Primary Ownership = \"Accountable\"","text":"<p>Primary ownership aligns most closely with with \"Accountable\" (or \"Approver\" or \"final approving authority\") in a\u00a0RACI matrix.</p> <p>Primary owners typically:</p> <ul> <li>Drive the decision-making process</li> <li>Have direct interaction with the secondary owner(s) discussing issues</li> <li>Delegate the work to other roles or team members (as needed)</li> <li>Lead the task to completion</li> <li>Have final sign-off authority (if/when used)</li> <li>Are ultimately accountable for the outcome of taskpoint or design decisions</li> </ul> <p>The last few points emphasize that the primary role is ultimately accountable. This is why there can only be\u00a0one primary owner for each taskpoint.</p>","tags":["newTeams","peopleTool","expectationManagement"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-07%20-%20Role%20ownership%20mapped%20to%20RACI/#secondary-ownership-responsible","title":"Secondary Ownership = \"Responsible\"","text":"<p>The Secondary role most directly aligns with the\u00a0RACI matrix\u00a0\"Responsible\" (or \"Recommender\"). Unlike RACI, and since Primary owners are also responsible, there can be cases where there are no Secondary owners.</p> <p>Secondary owners:</p> <ul> <li>Directly support the primary owner</li> <li>Are actively involved in the decision-making process</li> <li>Have active interest and participation in the outcomes</li> <li>May work to complete the task</li> <li>(but) Ultimately defer final decisions to primary owner</li> </ul>","tags":["newTeams","peopleTool","expectationManagement"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-07%20-%20Role%20ownership%20mapped%20to%20RACI/#contributor-consulted","title":"Contributor = \"Consulted\"","text":"<p>The Contributor role typically aligns with \"Consulted\" (or \"Consultant\" or \"counsel\") in a\u00a0RACI matrix. In this model, the interaction from a Contributor is typically one-way, but could be two-way as in RACI. Like Secondary ownership, there are often taskpoints with no Contributors.</p> <p>Contributors:</p> <ul> <li>Are not actively involved in the decision-making process</li> <li>Typically provide initial input or requirements</li> <li>May be asked to provide additional information</li> </ul> <p>Contributors may have only limited participation by providing initial design input (such as branding guidelines or business requirements) with little or no subsequent interaction. In those cases the communication may be input only with little or no concern of being \"informed\" of the result (relying on the expertise of other owners).</p> <p>Source</p>","tags":["newTeams","peopleTool","expectationManagement"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-08%20-%20Impossible%20states%20Richard%20Feldman/","title":"2023 02 08   Impossible states Richard Feldman","text":"<p>functionalDomainModelling functionalProgramming impossibleState </p>","tags":["functionalDomainModelling","functionalProgramming","impossibleState"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-08%20-%20Impossible%20states%20Richard%20Feldman/#what-is-an-impossible-state","title":"What is an impossible state?","text":"<p>Impossible states, or nonsense states, states of the system that most likely they are a by-product of how you store your state. The occur when a combination of values in your data model happen, when should not happen. When this happens it means that design our data mode is done in a way that allows for impossible combinations.</p>","tags":["functionalDomainModelling","functionalProgramming","impossibleState"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-08%20-%20Impossible%20states%20Richard%20Feldman/#example-1-a-survey-app-model","title":"Example 1: A survey app model:","text":"<pre><code>{\n  Questions: [a,b,c], -&gt; this can be empty\n  CurrentQuestion: 'a'\n}\n</code></pre> <p>In this case the questions can be empty, and the current question too. Alternative model:</p> <pre><code>{\npreviousQuestions:[]\ncurrentQuestion: 'a', \nremainingQuestions: []\n}\n</code></pre>","tags":["functionalDomainModelling","functionalProgramming","impossibleState"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-08%20-%20Impossible%20states%20Richard%20Feldman/#example-2","title":"Example 2:","text":"<p>Possible states <pre><code>{\nloading: false,\nhasError: false\n}\n</code></pre></p> <pre><code>{\nloading: false,\nhasError: true\n}\n</code></pre> <pre><code>{\n loading: true,\n hasError: false\n}\n</code></pre> <p>Impossible state</p> <pre><code>{\nloading: true,\nhasError: true\n}\n</code></pre>","tags":["functionalDomainModelling","functionalProgramming","impossibleState"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-08%20-%20Impossible%20states%20Richard%20Feldman/#suggestions-to-avoid-impossible-states","title":"Suggestions to avoid impossible states","text":"","tags":["functionalDomainModelling","functionalProgramming","impossibleState"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-08%20-%20Impossible%20states%20Richard%20Feldman/#use-a-union-type-or-an-enum","title":"Use a union type or an enum","text":"<pre><code>type RequestState = 'loading' | 'ok' | 'error'\n\nenum RequestedState = {\nloading = 'loading',\nok = 'ok',\nerror = 'error'\n}\n</code></pre>","tags":["functionalDomainModelling","functionalProgramming","impossibleState"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-08%20-%20Impossible%20states%20Richard%20Feldman/#refactor-models-having-multiple-maybe-types-to-use-enums-or-unions","title":"Refactor models having multiple Maybe types to use enums or unions","text":"<p>A Maybe is a type which value can be something or nothing. In TS:  <pre><code>interface {\n    name?: string;\n}\n/** The same expressed via Generic **/\ntype Maybe&lt;T&gt; = NonNullable&lt;T&gt; | undefined;\n\ntype name: Maybe&lt;string&gt;;\n</code></pre></p> <p>For example, in Elm: <pre><code>type alias Model =  \n    { country : Maybe Country  \n    , city : Maybe City  \n    }\n</code></pre></p> <p>In TypeScript:</p> <pre><code>country?: string\ncity?: string\n</code></pre> <p>Impossible state: a city selected without a country.</p> <pre><code>{ country = Nothing  \n, city = Just \"Paris\"  \n}\n</code></pre> <p>An impossible state in this example is a city being selected without a country. A way to solve this we could write a function to validate that cities must have countries selected, or we could use a Union type.</p> <p>in Elm: <pre><code>type alias Model =  \n { destination : Destination }\n\n type Destination =  \n    NotChosen  \n    | ToCountry Country  \n    | ToCity Country City\n</code></pre></p> <p>In TypeScript: <pre><code>type Country = String;\ntype City = {\n  country: Country,\n  city: string\n};\ntype notChosen = 'notChosen';\ntype Destination = notChosen | toCountry | City\n}\n</code></pre></p> <p>This model makes it impossible to store a city in the data model if there is no country.</p> <p>source example city</p>","tags":["functionalDomainModelling","functionalProgramming","impossibleState"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-08%20-%20Impossible%20states%20Richard%20Feldman/#final-thoughts","title":"Final thoughts","text":"<p>If it is possible to represent states that should be impossible, then rewrite them to make them impossible.    Richard Feldman</p> <p>Avoiding impossible states help making APIs stronger and clearer. In order to achieve this, we need to have a clear data model, preferably that avoids impossible states</p>","tags":["functionalDomainModelling","functionalProgramming","impossibleState"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-08%20-%20Impossible%20states%20Richard%20Feldman/#further-knowledge-on-this","title":"Further knowledge on this","text":"<p>\"Making the Impossible States Impossible\" is just one of the type of so-called business logic errors which is possible to prevent with the help of the type system. But there are others, for example, impossible transitions. When business rules require a specific transition from one state to another. That kind of requirements is not (easily) expressible with the help of the described technique. This task is typically solved with Finite State Machines. I tried to come up with a good example for a system which doesn't allow impossible states, but still can have bugs with the impossible transition and wasn't able to do it right away, so\u00a0take this paragraph with a grain of salt, maybe it is not the whole truth.   \"Making the Impossible States Impossible\" doesn't prevent infinite loops and doesn't prove that all states are reachable. Keep in mind, that this technique will greatly decrease the number of bugs in your application, but this doesn't mean that you\u00a0formally proofed correctness of it. source</p>","tags":["functionalDomainModelling","functionalProgramming","impossibleState"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-08%20-%20Impossible%20states%20Richard%20Feldman/#references","title":"References","text":"<p>Source: # \"Making Impossible States Impossible\" by Richard Feldman source: gist with explanations notes of the talk</p>","tags":["functionalDomainModelling","functionalProgramming","impossibleState"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-08%20-%20how%20to%20apply%20making%20impossible%20states%20impossible%20to%20UI%20components%3F/","title":"2023 02 08   how to apply making impossible states impossible to UI components?","text":"<p>impossibleState wip-post components componentAPI </p>","tags":["impossibleState","wip-post","components","componentAPI"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-19%20-%20How%20to%20craft%20a%20harmonius%20life/","title":"2023 02 19   How to craft a harmonius life","text":"<p>self-insight ACTValues reflection needs-based-crafting harmonious-life-tool</p> <p>Idea: They argue that crafting our life traditionally go around identifying different areas in life, such as: work, relationships, leisure, etc and find a way to function and feel good among all these areas. (1) </p> <p>This area of thought proposes that doing this tend to stay in the theoretical field, because it is hard to put in practice.  That is why they propose to bring up to the center the underlying process: psychological needs satisfaction, and create practices that allow us to identify which are those needs and how can we satisfy them in our day-to-day life. (1) </p>","tags":["self-insight","ACTValues","reflection","needs-based-crafting","harmonious-life-tool"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-19%20-%20How%20to%20craft%20a%20harmonius%20life/#types-of-needs","title":"Types of needs","text":"<ul> <li>Avoidance needs: e.g., need for relaxation, optimal level of mental stimulation/stress, safety</li> <li>Avoidance-focused crafting: e.g., reducing workload</li> <li>Approach needs: e.g., need for competence</li> <li>Approach-focused crafting: e.g., developing new skills, expanding one \u0301s work tasks</li> </ul> <p>The (mis)match between crafting motives and efforts reveal when and why crafting efforts may (not)be effective in achieving optimal functioning... our model postulates that crafting efforts are not equally effective in attaining optimal functioning.To be effective, crafting efforts should target unfulfilled needs</p> <p>We argue that setting up your life in a way that meets your psychological needs (known\u00a0as needs-based crafting), and doing this across all domains, is what\u2019s important. Psychological needs (we\u2019ll come to what these are shortly) lie at the base of human wellbeing and fulfilment. Needs satisfaction has been linked to successfully fulfilling various life roles,\u00a0such as\u00a0parenting, and it may also free new resources to engage in prosocial behaviours, such as helping others, potentially\u00a0leading\u00a0to \u2018virtuous cycles\u2019. Other\u00a0studies\u00a0have shown that people whose needs are fulfilled are more productive and creative at work, more eager to walk the extra mile for their company and help co-workers. The good news is that neither work nor leisure time must satisfy all your psychological needs. Instead, each role in life you have (eg, experienced foreman, loving husband, caring son, dedicated Red Cross volunteer and avid chess player) plays an important part in an orchestra. Coordination of these different roles, and satisfaction of needs via active engagement in these roles, results in what we call \u2018life domain harmony\u2019 \u2013 the symphony of your life.</p> <p> </p>","tags":["self-insight","ACTValues","reflection","needs-based-crafting","harmonious-life-tool"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-19%20-%20How%20to%20craft%20a%20harmonius%20life/#sources","title":"Sources","text":"<p>Phyche magazine: How to craft a harmonious life paper: An identity-based integrative needs model of crafting: Crafting within and across life domains. full text of paper</p> <p>(1) de Bloom J, Vaziri H, Tay L, Kujanp\u00e4\u00e4 M. An identity-based integrative needs model of crafting: Crafting within and across life domains. J Appl Psychol. 2020 Dec;105(12):1423-1446. doi: 10.1037/apl0000495. Epub 2020 Mar 23. PMID: 32202815.</p>","tags":["self-insight","ACTValues","reflection","needs-based-crafting","harmonious-life-tool"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-19%20-%20homework%20learning%20how%20to%20learn/","title":"2023 02 19   homework learning how to learn","text":"<ul> <li> <p>Create a presentation for your parents, friends, and teachers about what you\u2019ve found to be the best tips for learning.</p> </li> <li> <p>Write an article or textbook module about how to broaden your interests and passions\u2014including a description of your own preliminary attempts to go outside your comfort zone in learning or trying something new.</p> </li> <li> <p>Journal your efforts to get a better handle on procrastination and discover (and overcome!) your illusions of competence of learning.</p> </li> <li> <p>Set-up a specialized wiki where students can exchange practical insights on how to learn most effectively.</p> </li> <li> <p>Produce a miniature video documentary that conveys central ideas about learning in a humorous and memorable way.</p> </li> </ul>"},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-19%20-%20learning%20how%20to%20learn%20homework/","title":"2023 02 19   learning how to learn homework","text":"<ul> <li> <p>Create a presentation for your parents, friends, and teachers about what you\u2019ve found to be the best tips for learning.</p> </li> <li> <p>Write an article or textbook module about how to broaden your interests and passions\u2014including a description of your own preliminary attempts to go outside your comfort zone in learning or trying something new.</p> </li> <li> <p>Journal your efforts to get a better handle on procrastination and discover (and overcome!) your illusions of competence of learning.</p> </li> <li> <p>Set-up a specialized wiki where students can exchange practical insights on how to learn most effectively.</p> </li> <li> <p>Produce a miniature video documentary that conveys central ideas about learning in a humorous and memorable way.</p> </li> </ul>"},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-19%20-%20writing%20with%20ai/","title":"2023 02 19   writing with ai","text":"<p>creativeWriting writingWithAI</p> <p>Interesting process on how to use ChatGPT to aid the creative writing process</p> <p>https://every.to/chain-of-thought/writing-essays-with-ai-a-guide</p>","tags":["creativeWriting","writtingWithAI","writingWithAI"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-02-22%20-%20Moving%20to%20predictable%20incident%20management/","title":"2023 02 22   Moving to predictable incident management","text":"<p>incidentManagement cycleOfLearningImproving</p> <p>Companies like Snyk, Stack Overflow, and CircleCI have moved away from reactive, disorganized incident response to proactive, predictable incident management with\u00a0FireHydrant. Here's how:</p> <ul> <li> <p>Automate\u00a0toil, get the right people involved quickly, and codify your organization\u2019s process into turn-by-turn navigation that everyone can follow.</p> </li> <li> <p>Respond\u00a0quickly in a purpose-built workspace for communication that brings your team and tools together in one place.</p> </li> <li> <p>Learn\u00a0from automatically-captured incident activity and a guided, customizable retrospective template.</p> </li> <li> <p>Improve\u00a0reliability with an at-a-glance view of the areas of your system that need investment.</p> </li> </ul>","tags":["incidentManagement","cycleOfLearningImproving"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-03-03%20-%20Notes%20FAQ%20with%20Marc%20Richards%20and%20Neild%20Ford/","title":"2023 03 03   Notes FAQ with Marc Richards and Neild Ford","text":"<p>architecture adr architectureCharacteristics technicalDecisions technicalDocumentation theArchitectRole </p> <p>link: https://www.developertoarchitect.com/foundations-friday-forum.html</p>","tags":["architecture","adr","architectureCharacteristics","technicalDecisions","technicalDocumentation","theArchitectRole"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-03-03%20-%20Notes%20FAQ%20with%20Marc%20Richards%20and%20Neild%20Ford/#intro","title":"Intro","text":"<p>Every first Monday of the month there is an Ask Me Anything about architecture call with Marc Richards and Neil Ford.</p> <p>The session happens every first Monday of the month, from 17:00-18:00 CET, they are free and you can register to attend here</p> <p>I have been learning from them the practice of Software Architecture for a while now, and I have found the sessions to be a fantastic place to learn how the sometimes theoretical knowledge I\u2019ve learned from them, applies to real world situations.</p> <p>The topics covered in each session vary, can be high level things, could be specific architecture things.</p> <p>This time I took some notes on the questions that were asked, and the answers they gave. First for me, and to keep in my second-brain, but also to be able to come back and process the information slower.</p> <p>I am sharing below the notes I took here as an experiment to share with who might find this information interesting.</p>","tags":["architecture","adr","architectureCharacteristics","technicalDecisions","technicalDocumentation","theArchitectRole"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-03-03%20-%20Notes%20FAQ%20with%20Marc%20Richards%20and%20Neild%20Ford/#notes","title":"Notes","text":"<p>Topics covered</p> <p>#ADRs #architectureCharacteristics #technicalDecisions #technicalDocumentation #theArchitectRole</p>","tags":["architecture","adr","architectureCharacteristics","technicalDecisions","technicalDocumentation","theArchitectRole"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-03-03%20-%20Notes%20FAQ%20with%20Marc%20Richards%20and%20Neild%20Ford/#about-technical-decisions-and-how-to-ensure-they-get-followed","title":"About technical decisions and how to \u2018ensure\u2019 they get followed","text":"<p>When I write my architecture decision, I start thinking directly:</p> <p>How will I govern this? What automated process will I put in place to observe and monitor 'violations'?</p> <p>That enables me directly to make the technical decision directly actionable, I measure them, and I create feedback loops that inform me about it.</p>","tags":["architecture","adr","architectureCharacteristics","technicalDecisions","technicalDocumentation","theArchitectRole"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-03-03%20-%20Notes%20FAQ%20with%20Marc%20Richards%20and%20Neild%20Ford/#how-do-i-make-a-decision-that-is-hard-all-the-options-dont-make-me-happy","title":"How do I make a decision that is hard, all the options don't make me happy?","text":"<p>You choose the least worst. And paired with this comes to do a trade off analysis of the options, to find the least worst. Ideally you write an ADR that helps you refine your thinking process on it and get feedback.</p> <p>Even when you are happy with a design, is is handy to get feedback, and one way to do it is write an ADR and get comments from your colleagues to validate your decision.</p> <p>One thing I do often is to set the status for ADRs as: RFC with a particular date. This enables me to get opinions, which is important especially for architecture decisions.</p> <p>They help to set standards across teams and divisions, and also give the justification for that new standard. Especially when you add consequences, it helps you thinking how it will disrupt processes, motivation, throughput.</p> <p>When you highlight this, it helps you rethink if the ADR is the right direction, because you put it under the light of impact, benefits and trade offs. Because enforcing a standard, and adopting it is work.</p> <p>Tech Radar</p> <p>It helps you bring transparency in the enterprise to what technologies are being used, and how collaboration can happen among teams using a similar tool that dont work closely. It also gives visibility about consistency in the organisation.</p> <p>For example the status assess helps you to not jump on the latest new tech, to be able to analyse it, and make it public to the company to learn if other people are doing something and experimenting with it. Which will help making a better decision.</p>","tags":["architecture","adr","architectureCharacteristics","technicalDecisions","technicalDocumentation","theArchitectRole"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-03-03%20-%20Notes%20FAQ%20with%20Marc%20Richards%20and%20Neild%20Ford/#about-enterprise-architecture-as-a-practice-in-an-organisation","title":"About enterprise architecture as a practice in an organisation:","text":"<p>The main goal of an enterprise architecture practice is to facilitate change. All sub goals of it are mainly directed to building consistency in the organisation</p>","tags":["architecture","adr","architectureCharacteristics","technicalDecisions","technicalDocumentation","theArchitectRole"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-03-03%20-%20Notes%20FAQ%20with%20Marc%20Richards%20and%20Neild%20Ford/#what-architecture-documentation-standard-do-you-use","title":"What architecture documentation standard do you use?","text":"<p>I usually start with start with the characteristics, and then go with the standards.</p> <p>Technical documentation is a moving target, architecture characteristics itself keep changing over time, and their definition too.</p> <p>The best way to think about architecture documentation is as an evolutionary document that adapts to your context, team, people, knowledge, time.</p> <p>How do you assign a definition to an architecture characteristic? I usually define it in terms of what I can measure.</p> <p>ie: Reliability:</p> <ul> <li> <p>How many errors</p> </li> <li> <p>Time where system is down/active</p> </li> </ul> <p>We can then have conversations to define our arch characteristics, how can we measure them, and base on that the definition for us.</p> <p>This also helps you to write right away the fitness functions, which will be your feedback loop and will make your engineering practice more mature.</p> <p>In perfect world you aim at immediate feedback, however that is not always happening. Fitness functions should be therefore simple and easy to maintain, so that you maintain them to shorten over time your feedback loops</p>","tags":["architecture","adr","architectureCharacteristics","technicalDecisions","technicalDocumentation","theArchitectRole"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-03-03%20-%20Notes%20FAQ%20with%20Marc%20Richards%20and%20Neild%20Ford/#what-can-architects-do-to-inspire-and-be-positive-drivers-and-how-do-you-spin-the-game-when-the-project-is-going-badly","title":"What can architects do to inspire and be positive drivers, and how do you spin the game when the project is going badly?","text":"<p>One of the expectation for this role is to lead, guide and inspire people through the implementation time.</p> <p>Things going badly is common, because we are human, and maintaining a positive and realistic attitude helps to guide the team through bad paths. It's a balance between everything is all bad and everything is all good.</p> <p>Being realistic is important, and being positive is not synonym of being up beat.</p>","tags":["architecture","adr","architectureCharacteristics","technicalDecisions","technicalDocumentation","theArchitectRole"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-03-03%20-%20Notes%20FAQ%20with%20Marc%20Richards%20and%20Neild%20Ford/#whats-the-difference-between-a-software-architect-and-a-solution-architect","title":"What's the difference between a software architect and a solution architect?","text":"<p>The difference lies on how wide the role spans, and the scope of their responsibilities.</p> <p>Software architect: focuses on one system</p> <p>Solution architect: spans multiple teams, systems, divisions and departments</p> <p>One disclaimer is that every organisation defines their own concept of these roles, so they are organisation specific.</p> <p>Here a link to further explanation of this: https://www.developertoarchitect.com/lessons/lesson151.html</p>","tags":["architecture","adr","architectureCharacteristics","technicalDecisions","technicalDocumentation","theArchitectRole"]},{"location":"00-daily-notes%20%F0%9F%93%85/2023-03-13%20-%20Requirement%20level%20keywords/","title":"2023 03 13   Requirement level keywords","text":"<p>technicalWritting requirementLevels</p> <p>Requirement level keywords \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\" </p> <ol> <li> <p>MUST   This word, or the terms \"REQUIRED\" or \"SHALL\", mean that the    definition is an absolute requirement of the specification.</p> </li> <li> <p>MUST NOT   This phrase, or the phrase \"SHALL NOT\", mean that the    definition is an absolute prohibition of the specification.</p> </li> <li> <p>SHOULD   This word, or the adjective \"RECOMMENDED\", mean that there    may exist valid reasons in particular circumstances to ignore a    particular item, but the full implications must be understood and    carefully weighed before choosing a different course.</p> </li> <li> <p>SHOULD NOT   This phrase, or the phrase \"NOT RECOMMENDED\" mean that    there may exist valid reasons in particular circumstances when the    particular behavior is acceptable or even useful, but the full    implications should be understood and the case carefully weighed    before implementing any behavior described with this label.</p> </li> <li> <p>MAY   This word, or the adjective \"OPTIONAL\", mean that an item is    truly optional.  One vendor may choose to include the item because a    particular marketplace requires it or because the vendor feels that    it enhances the product while another vendor may omit the same item.    An implementation which does not include a particular option MUST be    prepared to interoperate with another implementation which does    include the option, though perhaps with reduced functionality. In the    same vein an implementation which does include a particular option    MUST be prepared to interoperate with another implementation which    does not include the option (except, of course, for the feature the    option provides.)</p> </li> <li> <p>Guidance in the use of these Imperatives</p> </li> </ol> <p>Imperatives of the type defined in this memo must be used with care    and sparingly.  In particular, they MUST only be used where it is    actually required for interoperation or to limit behavior which has    potential for causing harm (e.g., limiting retransmisssions)  For    example, they must not be used to try to impose a particular method    on implementors where the method is not required for    interoperability.</p> <ol> <li>Security Considerations</li> </ol> <p>These terms are frequently used to specify behavior with security    implications.  The effects on security of not implementing a MUST or    SHOULD, or doing something the specification says MUST NOT or SHOULD    NOT be done may be very subtle. Document authors should take the time    to elaborate the security implications of not following    recommendations or requirements as most implementors will not have    had the benefit of the experience and discussion that produced the    specification.</p> <p>Source</p>"},{"location":"00-daily-notes%20%F0%9F%93%85/2023-03-14%20-%20Technical%20decisions%20in%20an%20advice%20focused%20archictecture/","title":"2023 03 14   Technical decisions in an advice focused archictecture","text":"<p>technicalDecisions </p> <p>The process of making a technical decision is at the core of being a software architect, and also evolving the architecture practice.</p> <p>One of the main challenges is to find the sweet spot of: Speed of decision making vs consensus-style decision making (which makes it slower)</p> <p>Decisions might be quick, but this method risks option bias, and often leaves the rest of the company feeling like their voices don\u2019t matter. On the other hand, you can end up with consensus-style decision-making that drags on and on forever, leading to debates that never end, or people who are afraid of speaking up if their opinion is in the minority. Neither process is good for making decisions effectively.</p> <p>Tips * Disagree and commit is a good principle to speed decisions * RFCs and ADRs * Document current process and iterate over it * Encourage phycological safety so people can speak up * Informed captains who make decisions * Embrace conflict</p> <p>An organization without disagreement is either a hive-mind or one where some people have given up on trying to participate.</p> <p>hive mind:   </p> <p>Hive mentality, also known as groupthink, is\u00a0when a person has a strong tendency to fall for group decision-making. If someone has a hive mentality, they may feel invulnerable and morally correct when they're part of a certain group</p> <p>https://github.com/readme/guides/staff-engineers?mc_cid=990aca99f7&amp;mc_eid=3ae5279497</p>"},{"location":"00-daily-notes%20%F0%9F%93%85/2023-07-07%20-skills%20software%20architect/","title":"2023 07 07  skills software architect","text":"<p>friday-forum career </p> <p>The recommended structure is:\u00a0  </p> <p>Skills for solution software/enterprise architect?</p> <ul> <li>Learn about the business, learning about and transforming business capabilities to transfer that to technical solutions</li> <li>Soft skills, negotiation with developers and business people</li> <li>Is less about tech and is more about how to make it happen</li> <li>Is a lot about collaboration and understanding our capabilities</li> <li>marry technical capabilities with business capabilities</li> <li>Important: <ul> <li>Get good at information management! </li> <li>You will have less time, and therefore you need to find a good strategy to find information quickly, and manage your time, organize your things. The more organize you are, the better you can respond to the myriad of things that happen around you, and also prioritize things</li> <li>Time management: Spent X amount of time on the current technology, and spent X amount of time stepping away and learning other technologies. -&gt; This is very important</li> <li>Do your own personal radar.</li> </ul> </li> </ul> <p>Read Residually Theory (interesting take on software architecture) youtube.com/watch?v=0wcUG2EV-7E https://www.sciencedirect.com/science/article/pii/S1877050921007420 about complexity</p> <p>Theory:  we software architects have no idea about what external things influence our architecture and introduce an element of complexity. The stressors change our architecture. check: what are resduals Build your arch in loosely couple residuals, not components, this way the residuals will make the architecture stronger against similar stressors</p>"},{"location":"00-daily-notes%20%F0%9F%93%85/2023-07-11%20-%20idea%20talk%20%2B%20a11y%20proposal%20TR/","title":"2023 07 11   idea talk + a11y proposal TR","text":"<p>In June 2025 there will be the mandate to start compliance for a11y. Banks are included</p> <p>https://www.bmas.de/DE/Service/Presse/Pressemitteilungen/2021/mehr-barrierefreiheit-fuer-deutschland.html</p> <p>Idea: - Write a proposal for:     - What is a11y     - Opportunity in numbers     - Explain the WCAG     - Propose level of compliance     - Propose workflow for:         - Devs         - Designers         - Product</p> <p>References https://dequeuniversity.com/promo/newdqu https://dequeuniversity.com/</p>"},{"location":"00-daily-notes%20%F0%9F%93%85/2023-10-10%20-%20Diagnose%20and%20fix%20problems/","title":"2023 10 10   Diagnose and fix problems","text":"<p>difficultSituations problemSolving</p> <p>Frances Frei's playbook for accelerating excellence in organizations is structured around a weekday calendar. Here's a breakdown of the five steps, from Monday to Friday:</p> <p>Monday - Identify Your Real Problem: Start by identifying the actual underlying problem rather than just addressing the symptoms. It's a day for diagnosis and understanding the root cause.</p> <p>Tuesday - Rebuild Trust: If the problem involves human relationships and trust is broken, focus on rebuilding trust as the core of your solution. Trust is pivotal to effective problem-solving.</p> <p>Wednesday - Make New Friends: To complement your problem-solving efforts, seek out diverse perspectives. Actively engage with people who have different viewpoints. Consider whose perspective is missing and invite them in.</p> <p>Thursday - Storytelling: It's essential to communicate your solutions effectively. Thursday is dedicated to mastering the art of storytelling. Even the best solutions need to be communicated well to have an impact.</p> <p>Friday - Move Fast and Fix Things: Once you've gone through the process of identifying the problem, rebuilding trust, gaining new perspectives, and mastering storytelling, you're now ready to take swift action. Friday represents the day to move quickly and implement your solutions. It's about fixing things efficiently, and this speed is made possible by the thorough work done earlier in the week.</p> <p>This framework emphasizes the importance of a systematic approach to problem-solving, with each day building upon the progress of the previous one. It culminates in the ability to move fast and effectively resolve issues without causing unnecessary disruption.</p> <p>https://www.gsb.stanford.edu/insights/simplify-how-communicate-complex-ideas-simply-effectively</p>"},{"location":"00-daily-notes%20%F0%9F%93%85/2023-10-10%20-%20Persuasion%20past%20present%20future/","title":"2023 10 10   Persuasion past present future","text":"<p>persuation leading</p> <p>Frances Frei's approach to storytelling for persuasion is structured around the past, present, and future framework. Here's a breakdown of how she formulates impactful stories:</p> <p>Past: In the past, it's essential to honor what has happened, both the positive and negative aspects. Acknowledge the history, recognizing that what may have been considered the \"good old days\" for some might not have been the same for others. This historical perspective sets the stage for the need for change.</p> <p>Present: Focus on the present by providing a clear and compelling change mandate. Explain why change is necessary now and why it can't be postponed. Make it evident to your audience why they need to embrace change immediately. This step requires a convincing case for change.</p> <p>Future: Look to the future and describe what the change will lead to. This vision of the future should be both rigorous and optimistic. It should outline a practical, well-thought-out path forward while maintaining a positive and hopeful outlook. This combination of practicality and optimism creates the necessary structure for a persuasive change story.</p> <p>By weaving these elements of the past, present, and future into your storytelling, you can effectively communicate the need for change and inspire others to embrace it. This framework provides a comprehensive narrative that guides your audience from understanding the past to envisioning a brighter future.</p> <p>https://www.gsb.stanford.edu/insights/simplify-how-communicate-complex-ideas-simply-effectively</p>"},{"location":"00-daily-notes%20%F0%9F%93%85/2023-10-10%20-%20Phases%20for%20Inclusion/","title":"2023 10 10   Phases for Inclusion","text":"<p>diversityInTechnology inclusion</p> <p>Frances Frei outlines a four-stage framework for fostering inclusion: safe, welcome, celebrated, and championed. Here's a breakdown of these stages:</p> <ol> <li> <p>Safe: The foundation of inclusion is creating a safe environment where individuals feel secure to express themselves without fear of judgment or discrimination. Safety sets the stage for further progress.</p> </li> <li> <p>Welcome: Once safety is established, the next stage is to make individuals feel genuinely welcomed. This goes beyond mere tolerance; it involves embracing and appreciating the differences that each person brings.</p> </li> <li> <p>Celebrated: Moving beyond welcome, the goal is to celebrate the uniqueness of each individual. Rather than focusing solely on commonalities, this stage encourages recognizing and appreciating the distinct perspectives and experiences that diverse individuals bring to the table.</p> </li> <li> <p>Championed: The final stage involves actively championing individuals. This means advocating for them, especially in situations where their voices may not be heard. It's about supporting and empowering others, both in their presence and absence.</p> </li> </ol> <p>The overarching aim is to advance people up the \"inclusion dial\" without pushing anyone else down. This framework emphasizes the importance of fostering a sense of belonging and value for everyone, recognizing that true inclusion benefits from diversity and should not be achieved at the expense of others. It's a nuanced approach that encourages organizations to navigate the complexities of inclusion effectively.</p> <p>Source: https://www.gsb.stanford.edu/insights/simplify-how-communicate-complex-ideas-simply-effectively</p>"},{"location":"00-daily-notes%20%F0%9F%93%85/2025-08-06-good-bad-goals/","title":"2025 08 06 good bad goals","text":""},{"location":"00-daily-notes%20%F0%9F%93%85/2025-08-06-good-bad-goals/#good-goal-principles","title":"good goal principles","text":"<p>Example: goals regarning \u201cCollaboration Impact,\u201d it should:</p> <p>Be outcome-focused (something tangible exists because of your collaboration)</p> <p>Be in your control (you can produce it without relying on others\u2019 approval or recognition)</p> <p>Encourage the right behaviors (clarity, unblock progress, strengthen team delivery)</p> <p>Be measurable without being purely about vanity metrics</p>"},{"location":"00-daily-notes%20%F0%9F%93%85/2025-08-06-good-bad-goals/#types-of-goals","title":"Types of goals","text":"<p>Goal are everywhere! Goals are linked! There really isn\u2019t a hard boundary between one type of goal and another type of goal: they\u2019re all connected.</p> <p>Learning goals help us focus on what we need to learn</p> <p>Milestones are generally useful constructs (e.g., milestones for decisions, milestones for defining an opportunity, etc.)</p> <p>Delivery goals. Hey, without inputs, you have no outputs :)</p> <p>Initiative goals: the proximate impact of an experiment, initiative, etc.</p> <p>Launch-related goals, where we begin tackling commercialization, adoption, and other related objectives.</p> <p>Input goals, which represent increases/decreases in key, stable, actionable inputs</p> <p>North Star goals\u2014where we want the North Star Metric to be by a certain point in time</p> <p>Annual goals around key (but lagging) business KPIs, customer outcomes, etc.</p> <p>Source https://cutlefish.substack.com/p/tbm-216-good-goalsbad-goals?utm_source=substack&amp;utm_medium=email</p>"},{"location":"00-daily-notes%20%F0%9F%93%85/2025-08-06-good-bad-goals/#good-and-bad-goals-summary","title":"Good and bad goals summary","text":"<p>Here\u2019s a mind map of the blogpost so you can remember the main points at a glance.</p> <p>\ud83c\udf1f What Makes a Good Goal?</p> <p>1. Core Definition</p> <ul> <li>An enabling constraint \u2192 narrows focus + encourages good things to happen</li> <li>Has guardrails \u2192 limits downsides &amp; promotes upsides</li> <li>Not just 1 metric or 1 action</li> </ul> <p>2. Influence &amp; Sustainability</p> <ul> <li>Good: Achievable through actions you control, sustainable results</li> <li>Bad: Not influenceable, or influenceable only by sacrificing long-term health</li> </ul> <p>3. Decision Filtering</p> <ul> <li>Good: More \"good\" yesses, fewer \"bad\" yesses; pushes back on distractions</li> <li>Bad: No weight or bite \u2192 one of many \u201ctop priorities\u201d</li> </ul> <p>4. Context &amp; Purpose</p> <ul> <li>Good: Fits in bigger picture, assumptions clear, adaptable with new info</li> <li>Bad: Exists in isolation, unclear why it matters, zombie goals never change</li> </ul> <p>5. Adaptability</p> <ul> <li>Good: Flexible with changing circumstances, keeps core purpose</li> <li>Bad: Rigid, leads to executing irrelevant plan</li> </ul> <p>6. Reflection &amp; Creativity</p> <ul> <li>Good: Triggers thinking, avoids premature convergence, matches task complexity</li> <li>Bad: Overly simplistic, autopilot thinking, low-leverage outcomes</li> </ul> <p>7. Alignment &amp; Fulfillment</p> <ul> <li>Good: Coherent with values &amp; aspirations, feels significant</li> <li>Bad: Disconnected, disillusioning, bar always rising</li> </ul> <p>8. Team Cohesion</p> <ul> <li>Good: Brings people together, unity, shared purpose</li> <li>Bad: Encourages unhealthy competition, conflicting departmental goals</li> </ul> <p>9. Meaning vs. Measurement</p> <ul> <li>Good: Prioritizes meaningfulness, accepts imperfect measurement</li> <li>Bad: Safe, shallow measures chosen over meaningful impact</li> </ul> <p>10. Tool for the Team</p> <ul> <li>Good: Helps decision-making, reduces risk, improves outcomes</li> <li>Bad: Imposed, performative, you work for the goal instead of the goal working for you</li> </ul> <p>11. Guiding Question</p> <ul> <li>\u201cWhat behaviors will this goal encourage?\u201d</li> <li>Don\u2019t set a goal for everything \u2014 only where it adds value</li> </ul> <p>Source:  https://cutlefish.substack.com/p/tbm-216-good-goalsbad-goals?utm_source=substack&amp;utm_medium=email</p>"},{"location":"01-inbox-wip%20%F0%9F%93%A5/00-readme/","title":"00 readme","text":"<p>First step after processing a daily note. Should go afterwards to one of the 02 &gt; folders</p> <p>Here are things postprocessed and uncategorized</p>"},{"location":"01-inbox-wip%20%F0%9F%93%A5/Notes%20about%20Feedback/","title":"Notes about Feedback","text":"<p>feedback communication </p> <p>as Winston Churchill wisely put it: \u201cCriticism may not be agreeable, but it is necessary. It fulfils the same function as pain in the human body. It calls attention to an unhealthy state of things.\u201d</p> <p>This is the time of the year where most of people is in a self reflecting mode. Setting new year resolutions for our life and work.</p> <p>A part of the habits that I have always have in my career, is to ask for feedback, ever since I started my career in Germany, feedback has been a constant. </p> <p>In most of cases was poorly delivered, and in some cases it harmed my professional confidence and progress. </p> <p>Therefore, for a number of years I have been somewhat being involved on giving or receiving feedback, and I can say that yet I am not a master at giving and receiving feedback, I have collected some knowledge and tools, which I tend to when I want to ask for, give, or receive feedback.</p> <p>Feedback given: common mistakes * Message addressed at the identity of the person * General non actionable feedback * Message that communicates underlying or direct disrespect * Message ambiguous missing a proposal for a solution * Ambiguous or unclear for fear of upsetting the receiver or damaging the relationship * Feedback given in order to fulfill a personal agenda</p> <p>Feedback received: common mistakes * Lack of respect to the person that gives the feedback * Adopt a defensive behaviour * Lack of confidence on yourself to receive feedback openly * Not asking for examples and/or situations where the behaviour was exibited * Not asking for advice on behaviours that would solve it</p> <p>Ideas to have to prepare to give good feedback *   Plan in advance *   Give promptly, right after the event *   Think about what you want to achieve and drive discussion accordingly *   One-on-one feedback is preferable *   Start gently *   Be specific *   Encourage self-reflection *   Be aware of nonverbal clues *   Self-reflect after the feedback session is completed</p> <p>Ideas to have to prepare to receive feedback from an untrained person * If you are given feedback think of yourself as a coach, helping the person to learn on how to give effective feedback * Rephrase into actionable behaviour, or ask for it. * If the person comes with no agenda, or does not state the goal, state it your \"Thank you for being here and open to give me feedback, it is important to me. My goal today is to understand clearly what your persective is, so that I can reflect on it and decide what my actions about it will be\" * If the tone of the conversation builds up: \"we both want to remmember this conversation as a dignified experience for both\" * Ask for clarification * Pause and think before respond, like the stoics</p>","tags":["feedback","communication","tools","career"]},{"location":"01-inbox-wip%20%F0%9F%93%A5/Notes%20about%20Feedback/#links-and-tools-about-this","title":"Links and tools about this","text":"<p>Some old blogpost of me on:</p> <p>give: https://medium.com/@danielavalero/four-steps-to-give-feedback-as-an-act-of-love-and-respect-with-the-other-3000eb0be6e0 receive: https://medium.com/@danielavalero/how-to-receive-feedback-and-not-die-trying-53e7c4cfbcb6</p> <p>A nice PDF short guide on tips to give and receive feedback effectively What I like: Is short, I can scan through it before entering a feedback session as a receiver or giver. https://www.dartmouth.edu/hrs/profldev/performance_management/feedback.pdf</p> <p>Worksheet to use to write down feedback I like: is specific and actionable, helps to frame my thoughts clearly https://docs.google.com/document/d/1KTH4owMH8BA3NWX7i7fTmdt7cBdiLv0PBrnO7vLl4ik/edit</p> <p>Email and form to ask for feedback</p> <p>feedback tools career </p>","tags":["feedback","communication","tools","career"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/2022-10-20%20-%20moving%20on%20limiting%20beliefs%20for%20diversity%20in%20tech/","title":"2022 10 20   moving on limiting beliefs for diversity in tech","text":"<p>deepThinking diversityInTechnology idea reflection idea-to-refine </p>","tags":["deepThinking","diversityInTechnology","idea","reflection","idea-to-refine"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/2022-10-20%20-%20moving%20on%20limiting%20beliefs%20for%20diversity%20in%20tech/#idea_1","title":"Idea:","text":"<ul> <li>Being a person from a minority group, and having 'made it' in Germany, has required a lot of work and time</li> <li>In times I feel the lack of empathy from people who are not or have not been part of minority group, judging me harsh... In contrast, I have got in times lack of empathy to understand where they come from, therefore becomes more difficult for us to find a way to meet in the middle.</li> <li>In technology, there is a stereotype of the developer who programs since they are kids, and all they have done with their life, or private life is to code. If a developer does this, it means they are good and successful. However, the world is more complicated than that</li> <li>Software systems are analogous to the social systems developed by those who are building them. It is as good, and as needed to have in a team a person who can tell you from the brain all the functions available in Array or can traverse a binary tree, as the person who has more intuitive knowledge on it, and has as well social skills.</li> <li>In order to move on the stereotype, as Aristotle said in the quote below, we need to have more people from diffirent backgrounds in technology, and embrace different types of intelligence, compentence and strengths. Doing this, would make it easier for a person in a minority group to move on their own self limiting beliefs, and for the person who is not in a minority group to understand the need and value that others bring to the table.</li> </ul> <p>Aristotle\u00a0wrote about the process of developing the right character traits, or virtues, and he recognised that this could take years of work, supported by immersing oneself in the right sort of community and following the right sort of role models https://psyche.co/guides/how-philosophy-can-help-change-the-beliefs-that-hold-you-back</p>","tags":["deepThinking","diversityInTechnology","idea","reflection","idea-to-refine"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/202208171521%20-%20Italo%20Calvino%20on%20how%20he%20reads/","title":"202208171521   Italo Calvino on how he reads","text":"<p>intelectualEstimulation creativeWriting writersInspiration</p>","tags":["intelectualEstimulation","creativeWriting","writersInspiration"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/202208171521%20-%20Italo%20Calvino%20on%20how%20he%20reads/#tiempo-cero-italo-calvino","title":"Tiempo cero - Italo Calvino","text":"<p>Debo decir a este respecto que no me gusta escoger mis lecturas \u00aben busca de inspiraci\u00f3n\u00bb, no: leo por curiosidad, en oleadas sucesivas -como ocurre a todos los que no hacen un estudio especializado y como creo tambi\u00e9n que ocurre con las lecturas no especializadas de los especialistas-, y salto a menudo de un argumento a otro. Pero mientras dura, por ejemplo, la oleada de la astronom\u00eda, leo libros de astronom\u00eda porque lo que me interesa es la astronom\u00eda, no por que piense servirme de ella en los cuentos que escribir\u00e9.</p>","tags":["intelectualEstimulation","creativeWriting","writersInspiration"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/202208171521%20-%20Italo%20Calvino%20on%20how%20he%20reads/#ideas","title":"Ideas:","text":"<pre><code>* Reading for the sake of reading and enjoying the topic is a form of estimating the intellect\n* Using this mindset could be good as a tool to refocus my mental energy to learn and produce knowledge of some kind of craft, or consume it, to enrich it\n</code></pre>","tags":["intelectualEstimulation","creativeWriting","writersInspiration"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/202208171521%20-%20Italo%20Calvino%20on%20how%20he%20reads/#reminds-me-of","title":"Reminds me of:","text":"<pre><code>* Flow of Mihaly Csikszentmihaly: Who argues that being on the state of flow disconnects you from time. He argues that people who read a lot, and memorizes literature, for example, have inside their own heads the tools to entertain  themselves.\n</code></pre> <p>Recommended by: Abril</p>","tags":["intelectualEstimulation","creativeWriting","writersInspiration"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/2023-01-07%20Living%20a%20happier%20life%20-%20Tool%20--%20ACT%20-%20Values%20%26%20goals/","title":"2023 01 07 Living a happier life   Tool    ACT   Values & goals","text":"<p>self-insight understandMyself ACTValues actTherapy</p>","tags":["self-insight","understandMyself","ACTValues","actTherapy"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/2023-01-07%20Living%20a%20happier%20life%20-%20Tool%20--%20ACT%20-%20Values%20%26%20goals/#inspiration-from","title":"Inspiration from","text":"<p>How to Live By Your\u00a0Values This Year BY\u00a0CASEY ROSENGREN</p>","tags":["self-insight","understandMyself","ACTValues","actTherapy"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/2023-01-07%20Living%20a%20happier%20life%20-%20Tool%20--%20ACT%20-%20Values%20%26%20goals/#idea","title":"Idea","text":"<p>I am 36 and I have achieved all the goals I set for my life when I was a teenager. I have even achieved things that I never thought I would achieve, like making a triathlon.</p> <p>After I achieved all my goals, I felt empty. Setting a new goal could have been the next good thing to do, however I knew that after I achieved that, I would feel empty again, and I might not have the life energy to set and pursue new goals.</p> <p>When I came across the idea that Casey Rosengren is sharing in this post, it resonated with one of the ideas that Mih\u00e1ly Cs\u00edkszentmih\u00e1lyi shares in his book Flow, connecting with the joy of doing something just for the sake of doing it, nurturing one's brain with knowledge and ideas that passionate us, is one of the ways to find more joy in life. Idea also shared by  Martin Seligman in his seminal book Authentic Happiness, where he explains: there are three types of happiness: * The first type, such as getting pleasure out of something, like eating a chocolate. You get the pleasure of it, but the happiness it gives you fades the longer you repeat the action. * The second type, such as doing something you like that involves your brain or/and body, such as programming (in my case), playing an instrument, playing sports, teaching. The core of this type of happiness is that when you do it, you get in the flow, you forget about time and space, you enter in a sort of meditative space where you and the activity only exist. This is a type of happiness that endures more than the first one. * The third type, when you do the activity that gets you into the flow, for a meaning that is bigger than yourself. This type of happiness is more permanent, you might have ups and downs, and independently in the place you are in a given moment, you find meaning on doing the thing you do.</p> <p>Coming back to the idea of Casey Rosengren, she says that having clarity over one's values, is a more sustainable way to come to a happier life. Instead of setting something like doing a triathlon this year, as my north star, I could identify the value behind such as living an adventurous life, or having challenges, or improving my physical and metal health. Decoupling the milestone of the triathlon, from the actual thing that makes me happy. She puts it this way:</p> <p>Since ACT comes from behavioral psychology, it approaches values as\u00a0behaviors. As Jenna Lejeune puts it in her book,\u00a0Values in Therapy, values are about \u201cverbs and adverbs.\u201d To get at a person\u2019s values, you can ask:   *  What would you be doing if you were living meaningfully? (verb)      -   How do you want to show up to whatever you\u2019re doing? (adverb)      ...  Moreover, values are about things we move\u00a0toward, not things we move\u00a0away\u00a0from. \u201cNot being afraid\u201d isn\u2019t a value, but \u201cliving courageously\u201d could be.  ...  Another way we think about values in ACT is as\u00a0meaningful life directions, whereas goals are\u00a0milestones on the path.</p>","tags":["self-insight","understandMyself","ACTValues","actTherapy"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/2023-01-07%20Living%20a%20happier%20life%20-%20Tool%20--%20ACT%20-%20Values%20%26%20goals/#unorganised-research-on-act","title":"Unorganised research on ACT","text":"<p>Acceptance and Commitment Therapy (ACT) is a \u201cthird-wave\u201d cognitive behavioral intervention aimed at enhancing our psychological flexibility (Hayes et al., 2006). Rather than suppress or avoid psychological events, ACT is based on the belief that acceptance and mindfulness are more adaptive responses to the inevitabilities of life.</p> <p>Source: https://positivepsychology.com/act-worksheets/</p>","tags":["self-insight","understandMyself","ACTValues","actTherapy"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/2023-01-07%20Living%20a%20happier%20life%20-%20Tool%20--%20ACT%20-%20Values%20%26%20goals/#worksheets","title":"Worksheets","text":"<p>https://positive.b-cdn.net/wp-content/uploads/2020/11/Personal-Values-Worksheet.pdf https://loving.health/wp-content/uploads/2021/02/ACT-values.pdf https://www.actmindfully.com.au/upimages/2016_Complete_Worksheets_for_Russ_Harris_ACT_Books.pdf</p>","tags":["self-insight","understandMyself","ACTValues","actTherapy"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/2023-01-07%20Living%20a%20happier%20life%20-%20Tool%20--%20ACT%20-%20Values%20%26%20goals/#my-own-funeral-questions","title":"My own funeral questions","text":"<ul> <li>What they would like to have accomplished?</li> <li>What kind of a person would they like to be remembered as?</li> <li>What qualities would be mentioned?</li> <li>How would they have contributed to or shaped others\u2019 lives?</li> </ul>","tags":["self-insight","understandMyself","ACTValues","actTherapy"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/2023-01-07%20Living%20a%20happier%20life%20-%20Tool%20--%20ACT%20-%20Values%20%26%20goals/#resources","title":"Resources","text":"<p>https://portlandpsychotherapy.com/values_exercises/</p>","tags":["self-insight","understandMyself","ACTValues","actTherapy"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/after-sentiers-229%20-%20designing%20without%20depletion/","title":"After sentiers 229   designing without depletion","text":"<p>humaneTech sustainableTech deepThinking sustainability</p> <p>What can we learn from knowledge created in other fields, and adopt in the technology world, so that we adopt mind perspectives that allow us to build technology that integrates in a sustainable manner with us as inviduals, us as societies and within the environment.</p> <p>\"Architects would not design buildings apart from the systems, but rather in the full knowledge of how its impacts reverbarate across the sourcing and contrusctions, and they would not expand their agency to orient the whole for less extraction and more sustainable models\"</p> <p>In order to learn, we need to employ deep thinking strategies, agues the author of this article in sentiers, that lead us to dig further the path where this concept of sustainable products of our practices (in the case of the article is about architects on buildings).</p> <p>\"Spend time thinking deeply about the practice and reinventing it for our current challentes than they do with the 'clasical' tasks of architects\"</p> <p>From the technology perspective, it could mean: how we technologist use our knowledge of practices and computer science, to produce technology products that respect the limits of systemic environment where that product lives, meaning: the world environment (green stuff), the social groups using the actual product, its impact on how they organize themselves, their moral, their priorities, and helping them to go into a direction where they as humans think more in a sustainable manners for themselves and for the world where they live... And from the internal perspective, the teams that build the actual product, what practices or tools do we need to learn, adopt, and promote, so that while we are building this product, we have a more meaningul life, with meaningful connections. </p> <p>So the deep thinking here applies in summary to three areas: the teams that build the product, the individuals using the product, the impact the adoption of the product on societies, and the world environment and amount of natural resources needed in order for that product to operate. The reflection aims to create \"pleasant and liveable environment\".</p> <p>\"this means finding ways to produce more beauty in a way that is much more about the creation of a pleasant and liveable environment...</p> <p>what is core to do this kind of cross disciplinary work is the need to work in teams and networks rather than the idea of the architect as heroic, centralized figure.\"</p> <p>The current social scientific knowledge, across different fields, is pointing to the direction of adopting more collective, well-being, intersectionally diverse and collaborative perspectives produce human environments, products, and impact on environment closer to achieve that sustainable goal that humans nowadays seem to be in the need for.</p>","tags":["humaneTech","sustainableTech","deepThinking","sustainability"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/","title":"lessons Ive learned as EM","text":""},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson","title":"Lesson:","text":"<p>You need to embrace conflict. Conflict will keep happening all through your career as an engineering manager, and with your emotional courage, and a calm attitude towards it, you can lead by example, and guide your team to adopt a culture to embrace conflict in a healthy manner.  </p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_1","title":"Lesson:","text":"<p>You need to stop being an avoider of feedback conversations, and difficult conversations. </p> <p>Your job is to care for the people working with you, and you care about them by giving them feedback. This is important especially if a culture of feedback and learning is not a common lived practice in your organization.</p> <p>You need to build emotional courage, drive the feedback conversation, be comfortable with the messy nature of the conflict.</p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_2","title":"Lesson:","text":"<p>Managing is also teaching people how to change their working habits so that the outcome of their actions gets them to a better place, together. </p> <p>Managing is educating, guiding, and before anything, learning from and with every team member, yourself, and all together as a unit.</p> <p>To be a good manager you need to be a good learner yourself.</p> <p>Communicating efficiently is a skill that you always keep learning</p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_3","title":"Lesson:","text":"<p>If meta-communication is a thing, that\u2019s what you need to be doing all the time.</p> <p>Structure your communication, so that is precise, concise, clear, and from within that precision, it communicates the now of what the direction of the whole team has their purpose.</p> <p>\u2014  </p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_4","title":"Lesson:","text":"<p>The first lesson I have learned is to think tactically before I can think strategically.</p> <p>This does not mean that I forget about strategy, this means that keeping the strategy in mind, keeping the vision of where we are going in mind, I can focus on the tactics, the problems of today.</p> <p>My head is full of unorganized information and it makes me uncomfortable to have it all there unorganized. I feel I am missing something.</p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_5","title":"Lesson:","text":"<p>Communicate progress, current state is better than communicating nothing at all. I don't have to have all the answers so that I communicate things, I don't have to have framed the problem to say something. It is good enough to say: \"Hey I know there is a problem, I am processing it, I don\u2019t have answers yet\"</p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_6","title":"Lesson:","text":"<p>Lead by giving something you never had</p> <p>I never had a good leader, I never had a mentor since I started my career path as an engineering manager.</p> <p>My way to lead therefore is to lead by giving something I never had. Listening to people, guiding them into learning how to do stuff, how to lead, how to navigate this software world.</p> <p>Doing it from a place of love, peace, calmness.</p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_7","title":"Lesson:","text":"<p>Your job is to frame problems, give guidance, give feedback, have difficult conversations, be the lead that you never had.</p> <p>Lesson:</p> <p>The problems you solve as a manager of people are abstract, you never have the full information, there is no science behind it that tells you this is the way to do it.</p> <p>The scope of the problems that you have to solve when being an engineering manager is abstract, undefined, and very often politically driven, especially when powerful people and stakeholders come to play.</p> <p>Therefore as a manager, you have abstract problems, that you start defining, framing, narrowing down.</p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_8","title":"Lesson:","text":"<p>Therefore, onboarding a new manager is abstract. Is a lot of guiding them to how to land, how can they be efficient, how can they come and help you.</p> <p>You have to transfer a bunch of abstract information.</p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_9","title":"Lesson:","text":"<p>You need first to listen to where your team is, understand the context, and walk exactly at their pace. While you do that, you introduce Incremental guided change and guided continuous improvement, so that you, all together go further. Faster does not matter, remember the story of tio conejo y tia tortuga?</p> <p>How do you ensure that the problems that you solve today, the places where you put your energy, are solving the issues that your team has in the long term?</p> <p>How do you give guidance, so that the actions that your team takes, add incrementally to a place where there are solutions?</p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_10","title":"Lesson:","text":"<p>Solve the problems of today, incrementally, and in a guided manner.</p> <p>Dont dream to follow methodologies that have been defined in books. They won't help you 1:1 because they lack context. Remember when you studied all the beautiful practices you do in software engineering, which dont happen in real world? Well, this is the same, but applied to software methodologies and delivery.</p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_11","title":"Lesson:","text":"<p>Your job is creative, the principles and ideas are there, your job is to find creative ways to frame them and communicate them, so that you encourage people.</p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_12","title":"Lesson:","text":"<p>Your next step is to solve the burning problem. You learn what the burning problem is by talking to people and listening what they have to say.</p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_13","title":"Lesson:","text":"<p>Adjust your expectations, being a manager of multiple people, in charge of setting directions and actions, is something that takes time to adapt.</p> <p>Understanding who you are as a manager, how you adapt your style depending on the circumstances, and especially, understanding what the actions are you need to take in order to get your people to walk together into a solution: That is work.</p> <p>\u2014 Lessons:</p> <p>Time management is very important. Keep times in meetings, be on time, keep an agenda, bring back people to the topic at hand, and more importantly: Take breaks. You need to be calm, and in peace so that you can be efficient, be a good leader, and do a good job. If it takes for you to take 2h walk a day, so be it, that\u2019s you.</p> <p>\u2014  </p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_14","title":"Lesson:","text":"<p>Your mental health is the first focus you have. Make it your priority, to be happy and calm, and if your current environment does not allow it, then change it.</p> <p>\u2014  </p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_15","title":"Lesson:","text":"<p>Your job is not your identity. If you can\u2019t stop thinking about work outside working hours, if you can\u2019t disconnect, raise your red flag, and work actively to improve on that.</p> <p>\u2014  </p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/lessons-Ive-learned-as-EM/#lesson_16","title":"Lesson:","text":"<p>People most likely don\u2019t know how to frame problems, you might/will need to help them to do so by asking questions, and once they nailed it, ask them what they will do about it.</p>"},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/notes-on-Programming-as-Theory-Building/","title":"notes on Programming as Theory Building","text":"<p>softwarePhylosophy </p>","tags":["softwarePhylosophy"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/notes-on-Programming-as-Theory-Building/#what","title":"What?","text":"<p>These are notes I've taken out of reading this article: https://blog.ceejbot.com/posts/programming-as-theory-building/</p>","tags":["softwarePhylosophy"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/notes-on-Programming-as-Theory-Building/#notes","title":"Notes","text":"<p>Programming isn\u2019t about writing the code; it\u2019s about understanding the problem and expressing that understanding through code.</p> <p>Coude should:</p> <ul> <li>Explain how the solution relates to the affairs of the world that it helps to handle.</li> <li>Explain why each part of the program is what it is, in other words is able to support the actual program text with a justification of some sort.</li> <li>Respond constructively to any demand for a modification of the program so as to support the affairs of the world in a new manner.</li> </ul> <p>we need to have theories of the systems we build and maintain, as well as theories of the pieces of that system.</p> <p>\u201cthe theory of the program\u201d === \u201ca mental model of the system\u201d</p>","tags":["softwarePhylosophy"]},{"location":"02-ideas%20%F0%9F%97%83%EF%B8%8F/readme/","title":"Readme","text":"<p>a topic or theme of ongoing interest</p>"},{"location":"03-areas%20%F0%9F%A7%BE/readme/","title":"Readme","text":"<p>\u201ca sphere of activity with a standard to be maintained over time.\u201d</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Architecture%20Quantum/","title":"Architecture Quantum","text":""},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Architecture%20Quantum/#quantum-in-physics","title":"Quantum in Physics","text":"<p>the minimum amount of any physical entity involved in an interaction.</p> <p>is the minimum amount of any physical particle (physical property) that has entropy  - Wikipedia</p> <p>A quantum (plural: quanta) is the smallest discrete unit of a phenomenon*. For example, a quantum of light is a photon, and a quantum of electricity is an electron</p> <p>Quantum theory describes the behavior of microscopic particles; Albert Einstein's theory of relativity describes the behavior of macroscopic things source</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Architecture%20Quantum/#architectural-quantum","title":"Architectural quantum","text":"<p>Is an independently deployable component with high functional cohesion, which includes all the structural elements required for the system to function properly.\u00a0In a monolithic architecture, the quantum is the entire application; everything is highly coupled and therefore developers must deploy it en mass.</p> <p>Source</p> <p>Synchronous connascence\u00a0implies synchronous calls within an application context or between distributed services that form this architecture quantum.\u00a0For example, if one service in a microservices architecture calls another one synchronously, each service cannot exhibit extreme differences in operational architecture characteristics. If the caller is much more scalable than the callee, timeouts and other reliability concerns will occur. Thus, synchronous calls create dynamic connascence for the length of the call\u2014if one is waiting for the other, their operational architecture characteristics must be the same for the duration of the call.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Bounded%20Context/","title":"Bounded Context","text":"<p>DDD architecture systemDesign </p> <p>Bounded context is a term used in Domain-Driven Design (DDD) to refer to a specific and isolated area within a system that has its own language, models, and rules that are distinct from other areas of the system. In other words, a bounded context defines the boundaries around a particular problem domain, within which all relevant concepts, entities, and relationships can be effectively modelled and understood. By clearly defining and isolating the different bounded contexts within a system, DDD helps to prevent confusion, reduce complexity, and improve the maintainability and scalability of the system. (chatGPT)</p>","tags":["DDD","architecture","systemDesign"]},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Bounded%20Context/#quote-from-book","title":"Quote from book","text":"<p>bounded context, where everything related to the domain is visible internally but opaque to other bounded contexts ... Yet creating common shared artifacts causes a host of problems, such as coupling, more difficult coordination, and increased complexity.\u00a0The\u00a0bounded context\u00a0concept recognizes that each entity works best within a localized context. Thus, instead of creating a unified\u00a0<code>Customer</code>\u00a0class across the entire organization, each problem domain can create its own and reconcile differences at integration points.</p> <p>DDD</p> <p>Source</p>","tags":["DDD","architecture","systemDesign"]},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Connascence/","title":"Connascence","text":"<p>softwareDesign </p>","tags":["softwareDesign"]},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Connascence/#connascence","title":"Connascence","text":"<pre><code>Two components are connascent if a change in one would require the other to be modified in order to maintain the overall correctness of the system\n</code></pre> <p>1996, Meilir Page-Jones.\u00a0What Every Programmer Should Know About Object Oriented Design\u00a0(Dorset House)</p>","tags":["softwareDesign"]},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Connascence/#types-of-connascence","title":"Types of Connascence","text":"<ul> <li>Static, discoverable via static code analysis, </li> <li>Dynamic concerning runtime behavior.<ul> <li>Synchronous:  calls between two distributed services have the caller wait for the response from the callee</li> <li>Asynchronous: \u00a0calls allow fire-and-forget semantics in event-driven architectures, allowing two different services to differ in operational architecture</li> </ul> </li> </ul> <p>Source</p>","tags":["softwareDesign"]},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Domain%20application%20and%20infrastructure%20code/","title":"Domain application and infrastructure code","text":""},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Domain%20application%20and%20infrastructure%20code/#domain-application-and-infrastructure-code","title":"Domain, Application, and Infrastructure Code","text":"<ul> <li>The domain code is the code dealing with the domain concepts and related behavior. </li> <li>The application code is the code that interacts with the external world. It makes the software concrete; applications receive requests from end users or other systems.</li> <li>Infrastructure code is the code written to run the infra</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Event%20processor/","title":"Event processor","text":"<p>eventDriven architecture </p>","tags":["eventDriven","architecture"]},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Event%20processor/#event-processor","title":"Event processor","text":"<p>An event processor, on the other hand, is a software component that is responsible for handling events that are generated by other components in a system. Event processors typically subscribe to events and take appropriate action when an event is received. They are typically part of an event-driven architecture, where the communication between components is based on the publication and consumption of events.</p> <p>Source: ChatGPT</p>","tags":["eventDriven","architecture"]},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/High%20functional%20cohesion/","title":"High functional cohesion","text":""},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/High%20functional%20cohesion/#context","title":"Context","text":"<p>Component-level coupling isn\u2019t the only thing that binds software together.\u00a0Many business concepts semantically bind parts of the system together, creating\u00a0functional cohesion</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/High%20functional%20cohesion/#cohesion","title":"Cohesion","text":"<p>in component design refers to how well the contained code is unified in purpose</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/High%20functional%20cohesion/#high-functional-cohesion","title":"High functional cohesion","text":"<p>Implies that an architecture quantum does something purposeful</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Microservice/","title":"Microservice","text":"<p>microservice architecture </p>","tags":["microservice","architecture"]},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Microservice/#microservice_1","title":"Microservice","text":"<p>A microservice is a small, independent, and self-contained software component that performs a specific task and communicates with other components through well-defined interfaces, typically using APIs. Microservices are designed to be highly scalable, modular, and flexible, and to allow for rapid development and deployment of new features.</p> <p>Source: ChatGPT</p>","tags":["microservice","architecture"]},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Structure%20design--Coupling/","title":"Structure design  Coupling","text":"<p>softwareConcepts basicConcepts softwareDesign </p>","tags":["softwareConcepts","basicConcepts","softwareDesign"]},{"location":"03-areas%20%F0%9F%A7%BE/Glossary/Structure%20design--Coupling/#coupling","title":"Coupling","text":"<p>According to the structured design movement, the strength of coupling depends on:</p> <ol> <li>The types of connections between modules.</li> <li>The complexity of the interfaces of the modules.</li> <li>The type of information going through the connection.</li> </ol> <p>https://thevaluable.dev/cohesion-coupling-guide-examples/</p> <p>I\u2019ve a simple rule: if the implementation is trivial, using a library should be avoided.</p> <p>The first solution can be a good one if we try to follow the guidelines we saw above:</p> <ol> <li>Couple our modules only using the minimum amount of interfaces needed.</li> <li>Passing only the minimum amount of parameters needed via the interface(s).</li> <li>Passing only data and avoiding altering the control flow of our modules.</li> <li>Not relying on another, more global module.</li> </ol> <p>when to create an abstraction? 1.  If it never changes, there is no problem. 2.  If the logic change often enough that it gets annoying to maintain the same piece of code in two different places, or worst, if developers begin to forget to change one implementation and not the other, I would extract it to its own module. 3.  If more modules use exactly the same piece of code, and if this common code seems to codify the same knowledge, I would extract it in its own module.</p> <p>Coupling is about connections across the boundaries of different modules, while cohesion is about the connections between the elements inside the boundary of a module.</p> <p>A module is considered strongly cohesive when its elements should belong together; when they form a functional whole. To say it differently: the elements of a module should aim for the same goal; they should try to solve the same domain problem.</p> <p>What are the benefits of a strongly cohesive module?</p> <ol> <li>If you need to change some logic, it\u2019s easier to reason about a module when its elements have strong commonalities.</li> <li>Cohesive elements often change together. No need to think about changing multiple modules and their interfaces, when everything you need is in one module.</li> <li>When you have strong cohesion, you normally reduce the connections between other modules, because you have everything you need inside the module itself. In short, increasing cohesion reduces coupling.</li> </ol> <p>Here\u2019s the guideline I\u2019m trying to follow when I\u2019m building an application:</p> <ol> <li>Building cohesive modules is the priority. I aim for functional, sequential, or communicational cohesion. Cohesion should be about problem domains, not about technical concerns.</li> <li>If I can\u2019t be as cohesive as I want to, I ask myself why. If no good reasons can be found, I try to aim for higher cohesion.</li> <li>I look at the connections between the different modules while building them if I can, or afterward. I ask myself: are there good reasons to couple these modules? How can I reduce the coupling?</li> </ol> <p>Here are more questions we can ask ourselves while coding:</p> <ul> <li>What would happen if we had to change this module? Would we need to change other modules at the same time? If yes, should we refactor these modules to make them more cohesive (and, therefore, less coupled)?</li> <li>Should we reduce the scope of this module? Can we modify it easily, or does it take time, because it\u2019s too big for our poor brains to reason about? Should we consider creating two (or more) modules instead?</li> </ul>","tags":["softwareConcepts","basicConcepts","softwareDesign"]},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%200%20-%20Initial%20ways%20of%20working/","title":"Step 0   Initial ways of working","text":""},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%200%20-%20Initial%20ways%20of%20working/#early-adopter-of-micro-frontend-architecture","title":"Early adopter of micro frontend architecture","text":""},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%200%20-%20Initial%20ways%20of%20working/#initial-state","title":"Initial state:","text":"<p>No processes, no clear roles, no clear tech vision or goal, not enough know-how on the heuristics of building microfrontends</p> <p>Caused: Double work, high levels of stress, early symptoms of burnout, conflict among team members, no clear goal or direction, confusion, missed deadlines, deadlines and scope unclear</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%200%20-%20Initial%20ways%20of%20working/#first-lessons","title":"First Lessons","text":"<ul> <li>People comes first: psychological safety, respect, trust and work-life balance</li> <li>Setup clear roles an expectations</li> <li>Limit size of teams </li> <li>Setup a default initial process</li> <li>Communicate deadlines, and scope clearly</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%200%20-%20Initial%20ways%20of%20working/#next-lessons","title":"Next lessons","text":"<ul> <li>Setup processes across teams</li> <li>Setup communication models across teams</li> <li>Engage people by communicating purpose: <ul> <li>not: ship things</li> <li>yes: bring the product to the browser</li> </ul> </li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%200%20-%20Initial%20ways%20of%20working/#what-to-do","title":"What to do","text":"<ol> <li>Define roles clearly</li> <li>Define career framework</li> <li>Define values:</li> <li>\u201c*statements of value***\u201d, as they represent what the organisation values in regard to behaviours, methods, and outcomes.</li> <li>Define processes</li> </ol> <p>as your company grows, you stop being able to personally influence all employees. This is true for managers as well, as your team grows in size. Your personal behaviors no longer drive significant influence without other mechanisms in place. You need to scale your personal values.</p> <p>https://www.scarletink.com/why-do-the-amazon-leadership-principles-successfully-drive-behavior/</p> <p>If you say that you value something, but don't encourage it in any way, it creates zero results. For example, you could say that your company values transparency, but if you don't encourage transparency in any way, you have not changed any behaviors.</p> <p>You say you care about people, but your actions are not coherent with it, the message you are giving is that in reality you don't care about people</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%200%20-%20Initial%20ways%20of%20working/#guided-continuous-improvement","title":"Guided continuous improvement:","text":"<p>guidance to help teams identify techniques that are likely to work in\u00a0their context. Improve through small changes: https://www.pmi.org/disciplined-agile/gci/kaizen-improvement-through-small-changes</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%200%20-%20Initial%20ways%20of%20working/#resources-to-learn-the-next-lessons","title":"Resources to learn the next lessons:","text":"<p>https://www.pmi.org/disciplined-agile/gci https://www.infoq.com/articles/agile-scaling-value-delivery/ https://www.pmi.org/disciplined-agile/agility-at-scale/tactical-agility-at-scale/scaling-factors https://www.projectmanagement.com/blog/blogPostingView.cfm?blogPostingID=61732&amp;thisPageURL=/blog-post/61732/choosing-your-wow--the-situation-context-framework--scf-#_=_ https://www.pmi.org/disciplined-agile/ongoing-goals/evolve-wow https://www.pmi.org/disciplined-agile/gci/agile-methods-frameworks-only-get-you-so-far</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%200%20-%20Initial%20ways%20of%20working/#method-prisson","title":"Method prisson:","text":"<p>https://queue.acm.org/detail.cfm?id=3301760</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/","title":"Step 1   UI Concistency","text":""},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#goal","title":"Goal:","text":"<p>Quality + Efficiency + Consistency</p> <p>Our web experience should be nothing less than trying to adapt to the user\u2019s needs</p> <p>As our designs become more modular and pattern-driven, the value of media queries has decreased</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#problem","title":"Problem:","text":"<p>We need to provide efficiently visual consistency, while we build a product with high quality that is in the future accessible to every user.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#long-term-solutions","title":"Long term solutions","text":"<ul> <li>Global pattern lib</li> <li>too much work. We dont have to have a code global pattern library in order to let patterns arise</li> <li>Does your pattern library say how and when a pattern is meant to be used? If the design of your image/caption pattern was shaped outside forces\u2009\u2014\u2009by the kind of content inside it, by business requirements\u2009\u2014\u2009are those considerations, those tradeoffs documented in your pattern library?</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#short-term-alternatives","title":"Short term alternatives","text":"<ul> <li>Mindset of: Scale processes and delivery together with UX team</li> <li>Build patterns (maybe not even yet in a global pattern lib), focus the effort on discussing and documenting rising patterns in the context of how and why they were made. Reasoning is what enables a collection of patterns to mature into a fully-realized design system. We should keep defining how patterns look, how they\u2019re built, and how to integrate them into our websites\u2009\u2014\u2009but we don\u2019t have to stop there. We can also better describe the compromises we make\u2009\u2014\u2009the forces we resolve\u2009\u2014\u2009when we design (and use) our patterns</li> <li>Define UX/UI guidines on how devs create/implement work (and not in mocks/design)<ul> <li>ie: Content page: when to use which vertical spacing. When which headline. And so on</li> </ul> </li> <li>Get UI/UX giving feedback as soon as possible<ul> <li>ie: Involve UX  in the code reviews / release reviews</li> </ul> </li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#research","title":"Research","text":""},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#limitations-of-current-responsive-design","title":"Limitations of current responsive design","text":"<p>Once the screen is this size and the element appears in a different, smaller container, use a narrower layout on this element.\u201d</p> <p>But, well, that\u2019s weird. Why can\u2019t we apply styles based on the space available to the module we\u2019re designing, rather than looking at the shape of the viewport?</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#how-applies-to-new-my-present-project","title":"How applies to new my present project:","text":"<p>Designs design with responsive design in mind, viewport media queries and grids</p> <p>Developers do components, and deliver fragments, that dont know what space available there is.</p> <p>Problem: Building a UI in our scenario, based on the \"old\" mindset, risks our solution to have to cater for weird layout issues, UI not fitting grid etc.</p> <p>Solution: Design components and patterns, and make them fill the space available, with container queries for example</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#mind-switches-in-building-ui-in-2021","title":"Mind switches in building UI in 2021","text":"<p>The future of the web and design is just getting more complex and we need to adapt and challenge ourselves to be comfortable with what that means to craft these experiences.</p> <p></p> <p>source https://uxdesign.cc/the-start-of-a-new-era-for-responsive-web-design-6658a6bbeb9b</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#switch-to-components-thinking","title":"Switch to component's thinking","text":"<p>When we talk about components, I\u2019m referring to elements on the page that could be comprised of a collection of other elements</p> <p>in the last few years, my design work has focused much more on patterns, and less on \u201cpages.\u201d  ... In other words, my design process involves looking at a responsive design as a network of small layout systems. Each of those components are basically little responsive designs themselves, with their own sets of breakpoints.</p> <p>Ethan Marcotte</p> <p>A unified design language shouldn\u2019t be just a set of static rules and individual atoms; it should be an evolving ecosystem.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#what-to-do","title":"What to do","text":"<ul> <li>[] Introduce Component's thinking to designers. </li> <li>[] Forster mindset switch from pages to patterns</li> <li>[] Define design tokens</li> <li>[] Identify with designers UI patterns</li> <li>[] Start moving rising patterns to a Figma pattern lib, so they can be reused in design</li> <li>[] Shift less documentation: documenting throughout the creation process allows for smoother decision-making. Avoids confusion when teams scale</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#how-to-decide-that-a-ui-pattern-is-robust-enough-to-go-to-pattern-lib","title":"How to decide that a UI pattern is robust enough to go to pattern Lib","text":"<ul> <li>Uniqueness: Is this design pattern necessary, or can we use an already-built pattern instead? What new thing does this pattern offer us?</li> <li>Reusability: Is this design pattern abstracted enough to be reused elsewhere in the application? (Whether it\u2019s the code that\u2019s abstracted, or the general concept of the component itself.)</li> <li>Statefulness and Interactivity: Have we covered all bases regarding state with this component? We use this checklist.</li> <li>Clarity (in language, motion, and code): If code is presented, is it clear? Does it follow our code styleguide? (We use BEM, mixed with utility/helper classes.) If copy is present, is the language clear and friendly, or is there ambiguous terminology present? (Ideally, you\u2019d have a UI copy styleguide to check against.) If animation is present, is the transition clear and does it make sense, or is it superfluous and confusing? Can you conduct user testing to find answers to these questions?</li> <li>Responsiveness: Depends on the product, but most products should be small screen friendly. Does your design pattern scale gracefully?</li> <li>Accessibility: If code is presented, does it follow accessibility guidelines? If colors are used, does the pattern pass color contrast tests?</li> </ul> <p>source: https://product.voxmedia.com/2016/4/20/11458814/how-designers-can-use-unit-testing-to-build-resilient-and-happy-design-systems</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#users-have-now-preference-based-media-queries","title":"Users have now preference based media queries","text":"<p>Preference-based media queries would allow us to adapt our User Experience to be specific to a particular user\u2019s experience.</p> <pre><code>@prefers-reduced-motion: Does not have annimations, or has reduced animations\n@prefers-contrast\n@prefers-reduced-transparency\n@prefers-color-scheme: allows us to change our design to light or dark mode\n@inverted-colors\n</code></pre>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#what-to-do_1","title":"What to do","text":"<ul> <li>[] Add to DoD of developers to use the preference media queries</li> <li>[] Document in styleguide alternatives found for the preference media query</li> <li>[] Identify with designers what can be prepared during design phase and what can be prepared during dev phase</li> <li>[] Include in global Obi brand style guide alternatives for these queries</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#adopt-container-queries-in-the-design-system","title":"Adopt container queries in the design system","text":"<p>container queries would allow us to set rules based on the parent container, rather than the overall page. his means that any component is more self-contained, aligned to modern design systems, and truly become plug-and-play modules that could be moved to any page or layout without having to reconsider everything based on its new environment.</p> <p>Container queries will allow developers to vary the layout within specific elements on a page (and their children) based on the dimensions of the parent elements themselves, allowing for much more modular approaches to layout.</p> <p>http://ricg.io/</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#for-project","title":"For project","text":""},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#by-using-bem-together-with-utility-classes-the-html-is-easier-to-read-and-customize","title":"By using BEM together with utility classes, the HTML is easier to read and customize.","text":"<p>Use BEM for:</p> <ul> <li>DRY-ing the HTML from the CSS you don\u2019t plan on customizing (e.g., behavioral CSS-like transitions, positioning, hover/focus effects),</li> <li>advanced animations/effects.</li> </ul> <p>Use utility classes for:</p> <ul> <li>the \u201cfrequently-customized\u201d properties, often used to create component variations (like padding, margin, text-alignment, etc.),</li> <li>elements that are hard to identify with a new, meaningful class name (e.g., you need a parent element with a <code>position: relative</code> \u2192 create <code>&lt;div class=\"position-relative\"&gt;&lt;div class=\"my-component\"&gt;&lt;/div&gt;&lt;/div&gt;</code>).</li> </ul> <p>source: https://css-tricks.com/building-a-scalable-css-architecture-with-bem-and-utility-classes/</p> <p>https://codyhouse.co/ds/docs/framework/utilities</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#glossary","title":"Glossary","text":"<ul> <li>Pattern Lib</li> <li>UI Lib</li> <li>Design System</li> <li>Design Token</li> <li>Component</li> <li>Style guide</li> <li>Living style guide</li> <li>Pattern:  </li> <li>On the web, we think of patterns as reusable interface components . The pattern\u2019s value comes out of how reusable it is. a pattern never exists in isolation. It is always defined by, and shaped by, its environment. \u201cPatterns are not rules. They represent our shared understanding of design solutions.\u201d</li> <li>Design pattern:   reusable solution to a commonly occurring problem within a given context in software design. Design patterns are formalized best practices that the programmer can use to solve common problems when designing an application or system.</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%201%20-%20UI%20Concistency/#resources","title":"Resources","text":"<p>https://uxdesign.cc/the-start-of-a-new-era-for-responsive-web-design-6658a6bbeb9b</p> <p>https://css-tricks.com/building-a-scalable-css-architecture-with-bem-and-utility-classes/</p> <p>https://ethanmarcotte.com/wrote/on-container-queries/</p> <p>https://ethanmarcotte.com/wrote/pattern-patter/</p> <p>https://airbnb.design/building-a-visual-language/</p> <p>https://product.voxmedia.com/2016/4/20/11458814/how-designers-can-use-unit-testing-to-build-resilient-and-happy-design-systems</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%202%20-%20Coordination%20among%20teams/","title":"Step 2   Coordination among teams","text":""},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%202%20-%20Coordination%20among%20teams/#goal","title":"Goal:","text":"<p>To be both loosely coupled and highly aligned, we would need to be intentional in how we crafted our interactions with our teams, each other, and across the organization. source: https://adhoc.team/2022/01/04/crafting-leadership-teams-for-fast-effective-information-flow</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%202%20-%20Coordination%20among%20teams/#problem","title":"Problem","text":"<ul> <li>Many unknown unkonws</li> <li>Letting problems in teams to arise, collect context<ul> <li>case: trying to solve all the problems for the teams, protecting too much to the teams</li> </ul> </li> <li>Lay groundwork:<ul> <li>tai chi vs. kung fu: \"Instead of directly attacking a situation, what you really need to do is slowly position everything so that when it is really time to do something, just a light push gets you where you want to go.\"</li> </ul> </li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%202%20-%20Coordination%20among%20teams/#context","title":"context","text":"<p>We\u2019ve now got a landscape so our discussion can move to \u201cwhat would be the most effective movement we could make here to ensure we have the best outcome\u201d.</p> <ul> <li>Any of us could do that: improvements that anyone on the team could action/impediments anyone on the team could remove.</li> <li>We know someone who knows how to do this: we know an expert that could make the improvement for us/remove the impediment or could teach us how to do it.</li> <li>We\u2019d need to try a few things: We\u2019re not sure how to act on this and we don\u2019t know anyone who could so we\u2019ll have to experiment.</li> </ul> <p>Wardley Map  </p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%202%20-%20Coordination%20among%20teams/#types-of-conflict","title":"Types of conflict","text":"<ul> <li>*Process conflict \u2014 How are we doing it?**  </li> <li>*Relationship conflict \u2014 Who are you currently at odds with?**  </li> <li>*Task Conflict \u2014 What are we doing?**  <ul> <li>It includes your desired goals &amp; purpose (outcome) and deliverables (output)</li> </ul> </li> </ul> <p>source</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%202%20-%20Coordination%20among%20teams/#clarifying-team-project-structure-first-makes-you-more-successful","title":"Clarifying team &amp; project structure first makes you more successful.","text":"<p>Task-related</p> <ul> <li>Purpose and Goals (Business &amp; personal) \u2192 What problem to solve/outcome to create.</li> <li>Strength, Assets, Weaknesses &amp; Risks \u2192 What gaps to anticipate, what assets are there?</li> </ul> <p>Process-related</p> <ul> <li>Roles &amp; Responsibilities \u2192 Who does what and why?</li> <li>Methodologies &amp; Tools \u2192 What process procedures to follow?</li> <li>Communication structures \u2192 Which ways of working define the team?</li> </ul> <p>Relationship-related</p> <ul> <li>Values and Expectations \u2192 What culture should the team live in?</li> <li>Get to know each other \u2192 What do we have in common that helps them bond and trust each other?</li> </ul> <p>Solving complexity by introducing complicated workflows and protocols is the road to rigidity. Solving complexity through simplicity, is the way to agility.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%203%20-%20Strategic%20and%20tatics%20thinking%20-%20Guided%20continous%20improvement/","title":"Step 3   Strategic and tatics thinking   Guided continous improvement","text":"<p>Tactically scale agile: https://www.pmi.org/disciplined-agile/agility-at-scale/tactical-agility-at-scale https://www.pmi.org/disciplined-agile/process/introduction-to-dad/dad-provides-a-foundation-to-scale-agile-tactically-introduction</p> <p>https://www.pmi.org/disciplined-agile/gci/guided-continuous-improvement</p> <p>How what we do today connects us to where we want to be tomorrow?</p> <p>Bottom-Up scaling approach by prioritizing adaptiveness by giving their teams autonomy They work out their own goals, processes, and mechanisms to achieve the goals.</p> <ul> <li>Get leadership buy-in and provide clear business goals<ul> <li>Have a simple hierarchy that is easy to understand and clearly links specific tasks at the dev level to larger goal</li> <li>One well-known company that has really exemplified structural agility is Spotify. Spotify lets its people organize themselves into groups organized by shared objectives (squads), work environment (tribes), skills (chapters) and interests (guilds).</li> </ul> </li> <li>Support autonomy, encourage and empower teams to create their own way of working to deliver value and met goals</li> <li>Encourage collaboration</li> <li>Standardise only what is important</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Step%203%20-%20Strategic%20and%20tatics%20thinking%20-%20Guided%20continous%20improvement/#current-problems","title":"Current problems:","text":"<ul> <li>Collaboration: unstructured collaboration leading to low efficiency<ul> <li>Fix: find a new collaboration style</li> </ul> </li> <li>Life Cycle: <ul> <li>https://www.pmi.org/disciplined-agile/process/introduction-to-dad/full-delivery-lifecycles-introduction</li> </ul> </li> <li>Visualize existing process: business process model, value stream map?</li> <li>Tailor initial process: <ul> <li>discipline agile?: https://www.pmi.org/disciplined-agile/process/introduction-to-dad/people-first-roles-in-dad-introduction</li> <li>lean agile?</li> <li>https://www.pmi.org/disciplined-agile/process/introduction-to-dad/process-goals</li> </ul> </li> <li>Identify potential improvements:<ul> <li>Measure existing WoW</li> <li>Retrospectives: scrum of scrums?</li> <li>Process modeling</li> <li>Structured survey</li> <li>Project/Release post mortem</li> </ul> </li> <li>Lean coffee?</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/communication/","title":"Communication","text":"<p>reminder communication tip peopleTool </p> <ul> <li>give a heads up, say what you are up to. few lines, inform people</li> <li>be kind</li> <li>listen</li> </ul>","tags":["reminder","communication","tip","peopleTool"]},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/","title":"Chapter 4. Discovering Micro Frontend Architectures","text":"<p>In the previous chapter, we learned about decisions framework, the foundation of any micro-frontend architecture. In this chapter, we will review the different architecture choices, applying what we have learned so far.\u00a0</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#micro-frontend-decisions-framework-applied","title":"Micro-Frontend Decisions Framework Applied","text":"<p>The decisions framework helps you to choose the right approach for your micro-frontend project based on its characteristics (see Figure\u00a04-1). Your first decision will be between a horizontal and vertical split.</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-1-the-micro-frontends-decisions-framework","title":"Figure 4-1. The micro-frontends decisions framework","text":""},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#tip","title":"Tip","text":"<p>The micro-frontends decisions framework helps you determine the best architecture for a project.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#vertical-split","title":"Vertical Split","text":"<p>A vertical split offers fewer choices, and because they are likely well known by frontend developers who are used to writing single-page applications (SPAs), only the client-side choice is shown in Figure\u00a04-1. You\u2019ll find a vertical split helpful when your project requires a consistent user interface evolution and a fluid user experience across multiple views. That\u2019s because a vertical split provides the closest developer experience to an SPA, and therefore the tools, best practices, and patterns can be used for the development of a micro-frontend.</p> <p>Although technically you can serve vertical-split micro-frontends with any composition, so far all the explored implementations have a client-side composition in which an application shell is responsible for mounting and unmounting micro-frontends, leaving us with one composition method to choose from. The relation between a micro-frontend and the application shell is always one to one, so therefore the application shell loads only one micro-frontend at a time. You\u2019ll also want to use client-side routing. The routing is usually split in two parts, with a global routing used for loading different micro-frontends being handled by the application shell (see Figure\u00a04-2).</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-2-the-application-shell-is-responsible-for-global-routing-between-micro-frontends","title":"Figure 4-2. The application shell is responsible for global routing between micro-frontends","text":"<p>Although the local routing between views inside the same micro-frontend is managed by the micro-frontend itself, you\u2019ll have full control of the implementation and evolution of the views present inside it since the team responsible for a micro-frontend is also the subject-matter expert on that business domain of the application (Figure\u00a04-3).</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-3-a-micro-frontend-is-responsible-for-routing-between-views-available-inside-the-micro-frontend-itself","title":"Figure 4-3. A micro-frontend is responsible for routing between views available inside the micro-frontend itself","text":"<p>Finally, for implementing an architecture with a vertical-split micro-frontend, the application shell loads HTML or JavaScript as the entry point. The application shell shouldn\u2019t share any business domain logic with the other micro-frontends and should be technology agnostic to allow future system evolution, so you don\u2019t want to use any specific UI framework for building an application shell. Try Vanilla JavaScript if you built your own implementation.</p> <p>The application shell is always present during users\u2019 sessions because it\u2019s responsible for orchestrating the web application as well as exposing some life cycle APIs for micro-frontends in order to react when they are fully mounted or unmounted.</p> <p>When vertical-split micro-frontends have to share information with other micro-frontends, such as tokens or user preferences, we can use query strings for volatile data, or web storages for tokens or user preferences, similar to how the horizontal split ones do between different views.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#horizontal-split","title":"Horizontal Split","text":"<p>A horizontal split works well when a business subdomain should be presented across several views and therefore reusability of the subdomain becomes key for the project; when search engine optimization is a key requirement of your project and you want to use a server-side rendering approach; when your frontend application requires tens if not hundreds of developers working together and you have to split more granular our subdomains; or when you have a multitenant project with customer customizations in specific parts of your software.</p> <p>The next decision you\u2019ll make is between client-side, edge-side, and server-side compositions. Client side is a good choice when your teams are more familiar with the frontend ecosystem or when your project is subject to high traffic with significant spikes, for instance. You\u2019ll avoid dealing with scalability challenges on the frontend layer because you can easily cache your micro-frontends, leveraging a content delivery network (CDN).</p> <p>You can use edge-side composition for a project with static content and high traffic in order to delegate the scalability challenge to the CDN provider instead of having to deal with it in your infrastructure. As we discussed in Chapter\u00a03, embracing this architecture style has some challenges, such as its complicated developer experience and the fact that not all CDNs support it. But projects like online catalog with no personalized content may be a good candidate for this approach.</p> <p>Server-side composition gives us the most control of our output, which is great for highly indexed websites, such as news sites or ecommerce. It\u2019s also a good choice for websites that require great performance metrics, similar to PayPal and American Express, both of which use server-side composition.</p> <p>Next is your routing strategy. While you can technically apply any routing to any composition, it\u2019s common to use the routing strategy associated with your chosen composition pattern. If you choose a client-side composition, for example, most of the time, routing will happen at the client-side level. You might use computation logic at the edge (using Lambda@Edge in case of AWS or Workers in CloudFlare) to avoid polluting the application shell\u2019s code with canary releases or to provide an optimized version of your web application to search engine crawlers leveraging the dynamic rendering capability.</p> <p>On the other hand, an edge-side composition will have an HTML page associated with each view, so every time a user loads a new page, a new page will be composed in the CDN, which will retrieve multiple micro-frontends to create that final view. Finally, with server-side routing, the application server will know which HTML template is associated with a specific route; routing and composition happen on the server side.</p> <p>Your composition choice will also help narrow your technical solutions for building a micro-frontends project. When you use client-side composition and routing, your best implementation choice is an application shell loading multiple micro-frontends in the same view with the webpack plug-in called Module Federation, with iframes, or with web components, for instance. For the edge-side composition, the only solution available is using edge-side includes (ESI). We are seeing hints that this may change in the future, as cloud providers extend their edge services to provide more computational and storage resources. For now, though, ESI is the only option. And when you decide to use server-side composition, you can use server-side includes (SSI) or one of the many SSR frameworks for your micro-frontend applications. Note that SSRs will give you greater flexibility and control over your implementation.</p> <p>Missing from the decisions framework is the final pillar: how the micro-frontends will communicate when they are in the same or different views. This is mainly because when you select a horizontal split, you have to avoid sharing any state across micro-frontends; this approach is an antipattern. Instead, you\u2019ll use the techniques mentioned in Chapter\u00a03, such as an event emitter, custom events, or reactive streams using an implementation of the publish/subscribe (pub/sub) pattern for decoupling the micro-frontends and maintaining their independent nature. When you have to communicate between different views, you\u2019ll use a query string parameter to share volatile data, such as product identifiers, and web storage/cookies for persistent data, such as users\u2019 tokens or local users\u2019 settings.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#observer-pattern","title":"Observer Pattern","text":"<p>The observer pattern (also known as publish/subscribe pattern) is a behavioral design pattern that defines a one-to-many relationship between objects such that, when one object changes its state, all dependent objects are notified and updated automatically. An object with a one-to-many relationship with other objects that are interested in its state is called the subject or publisher. Its dependent objects are called observers or subscribers. The observers are notified whenever the state of the subject changes, and then they act accordingly. The subject can have any number of dependent observers.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#architecture-analysis","title":"Architecture Analysis","text":"<p>To help you better choose the right architecture for your project, we\u2019ll now analyze the technical implementations, looking at challenges and benefits. We\u2019ll review the different implementations in detail and then assess the characteristics for each architecture. The characteristics we\u2019ll analyze for every implementation:</p> <p>Deployability</p> <p>Reliability and ease of deploying a micro-frontend in an environment.</p> <p>Modularity</p> <p>Ease of adding or removing micro-frontends and ease of integrating with shared components hosted by micro-frontends.</p> <p>Simplicity</p> <p>Ease of being able to understand or do. If a piece of software is considered simple, it has likely been found to be easy to understand and to reason about.</p> <p>Testability</p> <p>Degree to which a software artifact supports testing in a given test context. If the testability of the software artifact is high, then finding faults in the system by means of testing is easier.</p> <p>Performance</p> <p>Indicator of how well a micro-frontend would meet the quality of user experience described by web vitals, essential metrics for a healthy site.</p> <p>Developer experience</p> <p>The experience developers are exposed to when they use your product, be it client libraries, SDKs, frameworks, open source code, tools, API, technology, or services.</p> <p>Scalability</p> <p>The ability of a process, network, software, or organization to grow and manage increased demand.</p> <p>Coordination</p> <p>Unification, integration, or synchronization of group members\u2019 efforts in order to provide unity of action in the pursuit of common goals.</p> <p>Characteristics are rated on a five-point scale, with one point indicating that the specific architecture characteristic isn\u2019t well supported and five points indicating that the architecture characteristic is one of the strongest features in the architectural pattern. The score indicates which architecture characteristic shines better with every approach described. It\u2019s almost impossible having all the characteristics working perfectly in an architecture due to the tension they exercise with each other. Our role would be to find the trade-off suitable for the application we have to build, hence the decision to create a score mechanism to evaluate all of these architectural approaches.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#architecture-and-trade-offs","title":"Architecture and Trade-offs","text":"<p>As I pointed out elsewhere in this book, I firmly believe that the perfect architecture doesn\u2019t exist; it\u2019s always a trade-off. The trade-offs are not only technical but also based on business requirements and organizational structure. Modern architecture considers other forces that contribute to the final outcome as well as technical aspects. We must recognize the sociotechnical aspects and optimize for the context we operate in instead of searching for the \u201cperfect architecture\u201d (which doesn\u2019t exist) or borrowing the architecture from another context without researching whether it would be appropriate for our context.</p> <p>In Fundamentals of Software Architecture, Neal Ford and Mark Richards highlight very well these new architecture practices and invite the readers to optimize for the \u201cleast worst\u201d architecture. As they state, \u201cNever shoot for the best architecture, but rather the least worst architecture.\u201d</p> <p>Before settling on a final architecture, take the time to understand the context you operate in, your teams\u2019 structures, and the communication flows between teams. When we ignore these aspects, we risk creating a great technical proposition that\u2019s completely unsuitable for our company. It\u2019s the same when we read case studies from other companies embracing specific architectures. We need to understand how the company works and how that compares to how our company works. Often the case studies focus on how a company solved a specific problem, which may or may not overlap with your challenges and goals. It\u2019s up to you to find out if the case study\u2019s challenges match your own.</p> <p>Read widely and talk with different people in the community to understand the forces behind certain decisions. Taking the time to research will help you avoid making wrong assumptions and become more aware of the environment you are working in.</p> <p>Every architecture is optimized for solving specific technical and organizational challenges, which is why we see so many approaches to micro-frontends. Remember: there isn\u2019t right or wrong in architecture, just the best trade-off for your own context.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#vertical-split-architectures","title":"Vertical-Split Architectures","text":"<p>For a vertical-split architecture, a client-side composition, client-side routing, and an application shell, as described above, are fantastic for teams with a solid background of building SPAs for their first foray into micro-frontends, because the development experience will be mostly familiar. This is probably also the easiest way to enter the micro-frontend world for developers with a frontend background.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#application-shell","title":"Application Shell","text":"<p>A persistent part of a micro-frontend application, the application shell is the first thing downloaded when an application is requested. It will shepherd a user session from the beginning to the end, loading and unloading micro-frontends based on the endpoint the user requests. The main reasons to load micro-frontends inside an application shell include:</p> <p>Handling the initial user state (if any)</p> <p>If a user tries to access an authenticated route via a deep link but the user token is invalid, the application shell redirects the user to the sign-in view or a landing page. This process is needed only for the first load, however. After that, every micro-frontend in an authenticated area of a web application should manage the logic for keeping the user authenticated or redirecting them to an unauthenticated page.</p> <p>Retrieving global configurations</p> <p>When needed, the application shell should first fetch a configuration that contains any information used across the entire user sessions, such as the user\u2019s country if the application provides different experiences based on country.</p> <p>Fetching the available routes and associated micro-frontends to load</p> <p>To avoid needlessly deploying the application shell, the route configurations should be loaded at runtime with the associated micro-frontends. This will guarantee control of the routing system without deploying the application shell multiple times.</p> <p>Setting logging, observability, or marketing libraries</p> <p>Because these libraries are usually applied to the entire application, it\u2019s best to instantiate them at the application shell level.\u00a0</p> <p>Handling errors if a micro-frontend cannot be loaded</p> <p>Sometimes micro-frontends are unreachable due to a network issue or bug in the system. It\u2019s wise to add an error message (a 404 page, for instance) to the application shell or load a highly available micro-frontend to display errors and suggest possible solutions to the user, like suggesting similar products or asking them to come back later.</p> <p>You could achieve similar results by using libraries in every micro-frontend rather than using an orchestrator like the application shell. However, ideally you want just one place to manage these things from. Having multiple libraries means ensuring they are always in sync between micro-frontends, which requires more coordination and adds complexity to the entire process. Having multiple libraries also creates risk in the deployment phase, where there are breaking changes, compared to centralizing libraries inside the application shell.</p> <p>Never use the application shell as a layer to interact constantly with micro-frontends during a user session. The application shell should only be used for edge cases or initialization. Using it as a shared layer for micro-frontends risks having a logical coupling between micro-frontends and the application shell, forcing testing and/or redeployment of all micro-frontends available in an application. This situation is also called a distributed monolith and is a developer\u2019s worst nightmare.</p> <p>In this pattern, the application shell loads only one micro-frontend at a time. That means you don\u2019t need to create a mechanism for encapsulating conflicting dependencies between micro-frontends because there won\u2019t be any clash between libraries or CSS styles (see Figure\u00a04-4), as long as both are removed from the window object when a micro-frontend is unloaded.</p> <p>The application shell is nothing more than a simple HTML page with logic wrapped in a JavaScript file. Some CSS styles may or may not be included in the application shell for the initial loading experience, such as for showing a loading animation like a spinner. Every micro-frontend entry point is represented by a single HTML page containing the logic and style of a single view or a small SPA containing several routes that include all the logic needed to allow a user to consume an entire subdomain of the application without a new micro-frontend needing to load. A JavaScript file could be loaded instead as a micro-frontend entry point, but in this case we are limited by the initial customer experience, because we have to wait until the JavaScript file is interpreted before it can add new elements into the domain object model (DOM).</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-4-vertical-split-architecture-with-client-side-composition-and-routing-using-the-application-shell","title":"Figure 4-4. Vertical-split architecture with client-side composition and routing using the application shell","text":"<p>The vertical split works well when we want to create a consistent user experience while providing full control to a single team. A clear sign that this may be the right approach for your application is when you don\u2019t have many repetitions of business subdomains across multiple views but every part of the application may be represented by an application itself.</p> <p>Identifying micro-frontends becomes easy when we have a clear understanding of how users interact with the application. If you use an analytics tool like Google Analytics, you\u2019ll have access to this information. If you don\u2019t have this information, you\u2019ll need to get it before you can determine how to structure the architecture, business domains, and your organization. With this architecture, there isn\u2019t a high reusability of micro-frontends, so it\u2019s unlikely that a vertical-split micro-frontend will be reused in the same application multiple times.</p> <p>However, inside every micro-frontend we can reuse components (think about a design system), generating a modularity that helps avoid too much duplication. It\u2019s more likely, though, that micro-frontends will be reused in different applications maintained by the same company. Imagine that in a multitenant environment, you have to develop multiple platforms and you want to have a similar user interface with some customizations for part of every platform. You will be able to reuse vertical-split micro-frontends, reducing code fragmentation and evolving the system independently based on the business requirements.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#challenges","title":"Challenges","text":"<p>Of course, there will be some challenges during the implementation phase, as with any architecture pattern. Apart from domain-specific ones, we\u2019ll have common challenges, some of which have an immediate answer, while others will depend more on context. Let\u2019s look at four major challenges: a sharing state, the micro-frontends composition, a multiframework approach, and the evolution of your architecture.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#sharing-state","title":"Sharing state","text":"<p>The first challenge we face when we work with micro-frontends in general is how to share states between micro-frontends. While we don\u2019t need to share information as much with a vertical-split architecture, the need still exists.</p> <p>Some of the information that we may need to share across multiple micro-frontends are fine when stored via web storage, such as the audio volume level for media the user played or the fonts recently used to edit a document.</p> <p>When information is more sensitive, such as personal user data or an authentication token, we need a way to retrieve this information from a public API and then share across all the micro-frontends interested in this information. In this case, the first micro-frontend loaded at the beginning of the user\u2019s session would retrieve this data, stored in a web storage with a retrieval time stamp. Then every micro-frontend that requires this data can retrieve it directly from the web storage, and if the time stamp is older than a preset amount of time, the micro-frontend can request the data again. And because the application loads only one micro-frontend at a time and every micro-frontend will have access to the selected web storage, there is no strong requirement to pass through the application shell for storing data in the web storage.</p> <p>However, let\u2019s say that your application relies heavily on the web storage, and you decide to implement security checks to validate the space available or type of message stored. In this scenario, you may want to instead create an abstraction via the application shell that will expose an API for storing and retrieving data. This will centralize where the data validation happens, providing meaningful errors to every micro-frontend in case a validation fails.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#composing-micro-frontends","title":"Composing micro-frontends","text":"<p>You have several options for composing vertical-split micro-frontends inside an application shell. Remember, however, that vertical-split micro-frontends are composed and routed on the client side only, so we are limited to what the browser\u2019s standards offer us. There are four techniques for composing micro-frontends on the client side:</p> <p>ES modules</p> <p>JavaScript modules can be used to split our applications into smaller files to be loaded at compile time or at runtime, fully implemented in modern browsers. This can be a solid mechanism for composing micro-frontends at runtime using standards. To implement an ES module, we simply define the module attribute in our script tag and the browser will interpret it as a module:</p> <pre><code>&lt;script \n</code></pre> <p>This module will be always deferred and can implement cross-origin resource sharing (CORS) authentication. ES modules can also be defined for the entire application inside an import map, allowing us to use the syntax to import a module inside the application. As of publication time, the main problem with import maps is that they are not supported by all the browsers. You\u2019ll be limited to Google Chrome, Microsoft Edge (with Chromium engine), and recent versions of Opera, limiting this solution\u2019s viability.</p> <p>SystemJS</p> <p>This module loader supports import maps specifications, which are not natively available inside the browser. This allows them to be used inside the SystemJS implementation, where the module loader library makes the implementation compatible with all the browsers. This is a handy solution when we want our micro-frontends to load at runtime, because it uses a syntax similar to import maps and allows SystemJS to take care of the browser\u2019s API fragmentation.</p> <p>Module Federation</p> <p>This is a plug-in introduced in webpack 5 used for loading external modules, libraries, or even entire applications inside another one. The plug-in takes care of the undifferentiated heavy lifting needed for composing micro-frontends, wrapping the micro-frontends\u2019 scope and sharing dependencies between different micro-frontends or handling different versions of the same library without runtime errors. The developer experience and the implementation are so slick that it would seem like writing a normal SPA. Every micro-frontend is imported as a module and then implemented in the same way as a component of a UI framework. The abstraction made by this plug-in makes the entire composition challenge almost completely painless.</p> <p>HTML parsing</p> <p>When a micro-frontend has an entry point represented by an HTML page, we can use JavaScript for parsing the DOM elements and append the nodes needed inside the application shell\u2019s DOM. At its simplest, an HTML document is really just an XML document with its own defined schema. Given that, we can treat the micro-frontend as an XML document and append the relevant nodes inside the shell\u2019s DOM using the DOMParser object. After parsing the micro-frontend DOM, we then append the DOM nodes using adoptNode or cloneNode methods. However, using cloneNode or adoptNode doesn\u2019t work with the script element, because the browser doesn\u2019t evaluate the script element, so in this case we create a new one, passing the source file found in the micro-frontend\u2019s HTML page. Creating a new script element will trigger the browser to fully evaluate the JavaScript file associated with this element. In this way, you can even simplify the micro-frontend developer experience because your team will provide the final results knowing how the initial DOM will look. This technique is used by some frameworks, such as qiankun, which allows HTML documents to be micro-frontend entry points.</p> <p>All the major frameworks composed on the client side implement these techniques, and sometimes you even have options to pick from. For example, with single SPA you can use ES modules, SystemJS with import maps, or Module Federation.</p> <p>All these techniques allow you to implement static or dynamic routes. In the case of static routes, you just need to hardcode the path in your code. With dynamic path, you can retrieve all the routes from a static JSON file to load at the beginning of the application or create something more dynamic by developing an endpoint that can be consumed by the application shell and where you apply logic based on the user\u2019s country or language for returning the final routing list.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#multiframework-approach","title":"Multiframework approach","text":"<p>Using micro-frontends for a multiframework approach is a controversial decision, because many people think that this forces them to use multiple UI frameworks, like React, Angular, Vue, or Svelte.\u00a0But what is true for frontend applications written in a monolithic way is also true for micro-frontends.</p> <p>Although technically you can implement multiple UI frameworks in an SPA, it creates performance issues and potential dependency clashes. This applies to micro-frontends as well, so using a multiframework implementation for this architecture style isn\u2019t recommended.</p> <p>Instead, follow best practices like reducing external dependencies as much as you can, importing only what you use rather than entire packages that may increase the final JavaScript bundle. Many JavaScript tools implement a tree-shaking mechanism to help achieve smaller bundle sizes.</p> <p>There are some use cases in which the benefits of having a multiframework approach with micro-frontends outweigh the challenges, such as when we can create a healthy flywheel for developers, reducing the time to market of their business logic without affecting production traffic.</p> <p>Imagine you start porting a frontend application from an SPA to micro-frontends. Working on a micro-frontend and deploying the SPA codebase alongside it would help you to provide value for your business and users.</p> <p>First, we would have a team finding best practices for approaching the porting (such as identifying libraries to reuse across micro-frontends), setting up the automation pipeline, sharing code between micro-frontends, and so on. Second, after creating the minimum viable product (MVP), the micro-frontend can be shipped to the final user, retrieving metrics and comparing with the older version. In a situation like this, asking a user to download multiple UI frameworks is less problematic than developing the new architecture for several months without understanding if the direction is leading to a better result. Validating your assumptions is crucial for generating the best practices shared by different teams inside your organization. Improving the feedback loop and deploying code to production as fast as possible demonstrates the best approach for overcoming future challenges with microarchitectures in general.</p> <p>You can apply the same reasoning to other libraries in the same application but with different versions, such as when you have a project with an old version of Angular and you want to upgrade to the latest version.</p> <p>Remember, the goal is creating the muscles for moving at speed with confidence and reducing the potential mistakes automating what is possible and fostering the right mindset across the teams. Finally, these considerations are applicable to all the micro-frontend architecture shared in this book.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#architecture-evolution-and-code-encapsulation","title":"Architecture evolution and code encapsulation","text":"<p>Perfectly defining the subdomains on the first try isn\u2019t always feasible. In particular, using a vertical-split approach may result in coarse-grained micro-frontends that become complicated after several months of work because of broadening project scope as the team\u2019s capabilities grow. Also, we can have new insights into assumptions we made at the beginning of the process. Fear not! This architecture\u2019s modular nature helps you face these challenges and provides a clear path for evolving it alongside the business. When your team\u2019s cognitive load starts to become unsustainable, it may be time to split your micro-frontend. One of the many best practices for splitting a micro-frontend is code encapsulation, which is based on a specific user flow. Let\u2019s explore it!</p> <p>The concept of encapsulation comes from object-oriented programming (OOP) and is associated with classes and how to handle data. Encapsulation binds together the attributes (data) and the methods (functions and procedures) that manipulate the data in order to protect the data. The general rule, enforced by many languages, is that attributes should only be accessed (that is, retrieved or modified) using methods that are contained (encapsulated) within the class definition.</p> <p>Imagine your micro-frontend is composed of several views, such as a payment form, sign-up form, sign-in form, and email and password retrieval form, as shown in Figure\u00a04-5.</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-5-authentication-micro-frontend-composed-of-several-views-that-may-create-a-high-cognitive-load-for-the-team-responsible-for-this-micro-frontend","title":"Figure 4-5. Authentication micro-frontend composed of several views that may create a high cognitive load for the team responsible for this micro-frontend","text":"<p>An existing user accessing this micro-frontend is more likely to sign in to the authenticated area or want to retrieve their account email or password, while a new user is likely to sign up or make a payment. A natural split for this micro-frontend, then, could be one micro-frontend for authentication and another for subscription. In this way, you\u2019ll separate the two according to business logic without having to ask the users to download more code than the flow would require (see Figure\u00a04-6).</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-6-splitting-the-authentication-micro-frontend-to-reduce-the-cognitive-load-following-customer-experience-more-than-technical-constraints","title":"Figure 4-6. Splitting the authentication micro-frontend to reduce the cognitive load, following customer experience more than technical constraints","text":"<p>This isn\u2019t the only way to split this micro-frontend, but however you split it, be sure you\u2019re prioritizing a business outcome rather than a technical one. Prioritizing the customer experience is the best way to provide a final output that your users will enjoy.</p> <p>Encapsulation helps with these situations. For instance, avoid having a unique state representing the entire micro-frontend. Instead, prefer state management libraries that allow composition of state, like MobX-State-Tree does. The data will be expressed in tree structure, which you can compose at will. Spend the time evaluating how to implement the application state, and you may save time later while also reducing your cognitive load. It is always easier to think when the code is well identified inside some boundaries than when it\u2019s spread across multiple parts of the application.</p> <p>When libraries or even logic are used in multiple domains, such as in a form validation library, you have a few options:</p> <p>Duplicate the code</p> <p>Code duplication isn\u2019t always a bad practice; it depends on what you are optimizing for and overall impact of the duplicated code. Let\u2019s say that you have a component that has different states based on user status and the view where it\u2019s hosted, and that this component is subject to new requirements more often in one domain than in others. You may want to centralize it. Keep in mind, though, that every time you have a centralized library or component, you have to build a solid governance for making sure that when this shared code is updated, it also gets updated in every micro-frontend that uses this shared code as well. When this happens, you also have to make sure the new version doesn\u2019t break anything inside each micro-frontend and you need to coordinate the activity across multiple teams. In this case, the component isn\u2019t difficult to implement and it will become easier to build for every team that uses it, because there are fewer states to take care of. That allows every implementation to evolve independently at its own speed. Here, we\u2019re optimizing for speed of delivery and reducing the external dependencies for every team. This approach works best when you have a limited amount of duplication. When you have dozens of similar components, this reasoning doesn\u2019t scale anymore; you\u2019ll want to abstract into a library instead.</p> <p>Abstract your code into a shared library</p> <p>In some situations, you really want to centralize the business logic to ensure that every micro-frontend is using the same implementation, as with integrating payment methods. Imagine implementing in your checkout form multiple payment methods with their validation logic, handling errors, and so on. Duplicating such a complex and delicate part of the system isn\u2019t wise. Creating a shared library instead will help maintain consistency and simplify the integration across the entire platform. Within the automation pipelines, you\u2019ll want to add a version check on every micro-frontend to review the latest library version. Unfortunately, while dealing with distributed systems helps you scale the organization and deliver with speed, sometimes you need to enforce certain practices for the greater good.</p> <p>Delegate to a backend API</p> <p>The third option is to delegate the common part to be served to all your vertical-split micro-frontends by the backend, thus providing some configuration and implementation of the business logic to each micro-frontend. Imagine you have multiple micro-frontends that are implementing an input field with specific validation that is simple enough to represent with a regular expression. You might be tempted to centralize the logic in a common library, but this would mean enforcing the update of this dependency every time something changes. Considering the logic is easy enough to represent and the common part would be using the same regular expression, you can provide this information as a configuration field when the application loads and make it available to all the micro-frontends via the web storage. That way, if you want to change the regular expression, you won\u2019t need to redeploy every micro-frontend implementing it. You\u2019ll just change the regular expression in the configuration, and all the micro-frontends will automatically use the latest implementation.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#code-duplication-over-wrong-abstractions","title":"Code Duplication over Wrong Abstractions","text":"<p>Many well-known people in the industry have started to realize that abstracting code is not always a benefit, especially in the long run. In certain cases, code duplication brings more benefits to a premature or a hasty abstraction. Moreover, duplicated code can be easily abstracted if and when needed; it\u2019s more challenging to try to move away from abstractions once they\u2019re present in the code. If you are interested in this topic, read \u201cThe Wrong Abstraction\u201d, a 2016 blog post by Sandi Metz. Kent Dodds\u2019s AHA programming or \u201cAvoid Hasty Abstractions\u201d concept is strongly inspired by the work Metz describes in his blog and talk. Also, the well-known DRY principle (don\u2019t repeat yourself) appears to be misapplied by many developers, who just looked in the code for duplicated lines of code and abstracted them. In the second edition of Pragmatic Programmer (Addison-Wesley), where the DRY principle was first introduced, the authors provide a great explanation of this point:</p> <p>In the first edition of this book we did a poor job of explaining just what we meant by Don\u2019t Repeat Yourself. Many people took it to refer to code only: they thought that DRY means \u201cdon\u2019t copy-and-paste lines of source.\u201d</p> <p>That is part of DRY, but it\u2019s a tiny and fairly trivial part. DRY is about the duplication of knowledge, of intent. It\u2019s about expressing the same thing in two different places, possibly in two totally different ways. [emphasis added]</p> <p>It\u2019s important to understand that no solution fits everything. Consider the context your implementation should represent and choose the best trade-off in the guardrails you are operating with. Could you have designed the micro-frontends in this way from the beginning? Potentially, you could have, but the whole point of this architecture is to avoid premature abstractions, optimize for fast delivery, and evolve the architecture when it is required due to complexity or just a change of direction.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#implementing-a-design-system","title":"Implementing a Design System","text":"<p>In a distributed architecture like micro-frontends, design systems may seem a difficult feature to achieve, but in reality the technical implementation doesn\u2019t differ too much from that of a design system in an SPA. When thinking about a design system applied to micro-frontends, imagine a layered system composed of design tokens, basic components, user interface library, and the micro-frontends that host all these parts together, as shown in Figure\u00a04-7.</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-7-how-a-design-system-fits-inside-a-micro-frontends-architecture","title":"Figure 4-7. How a design system fits inside a micro-frontends architecture","text":"<p>The first layer, design tokens, allows you to capture low-level values to then create the styles for your product, such as font families, text colors, text size, and many other characteristics used inside our final user interface. Generally, design tokens are listed in JSON or YAML files, expressing every detail of our design system.</p> <p>We don\u2019t usually distribute design tokens across different micro-frontends because each team will implement them in their own way, risking the introduction of bugs in some areas of the application and not in others, increasing the code duplication across the system, and, in general, slowing down the maintenance of a design system. However, there are situations when design tokens can be an initial step for creating a level of consistency for iterating later on, with basic components shared across all the micro-frontends. Often, teams do not have enough space for implementing the final design system components inside every micro-frontend. Therefore, make sure if you go down this path that you have the time and space for iterating on the design system.</p> <p>The next layer is basic components. Usually, these components don\u2019t hold the application business logic and are completely unaware of where they will be used. As a result, they should be as generic as can be, such as a label or button, which will provide the consistency we are looking for and the flexibility to be used in any part of the application.</p> <p>This is the perfect stage for centralizing the code that will be used across multiple micro-frontends. In this way, we create the consistency needed in the UI to allow every team to use components at the level they need.</p> <p>The third layer is a UI components library, usually a composition of basic components that contain some business logic that is reusable inside a given domain. We may be tempted to share these components as well, but be cautious in doing so. The governance to maintain and the organization structure may cause many external dependencies across teams, creating more frustration than efficiencies. One exception is when there are complex UI components that require a lot of iterations and there is a centralized team responsible for them. Imagine, for instance, building a complex component such as a video player with several functionalities, such as closed captions, a volume bar, and trick play. Duplicating these components is a waste of time and effort; centralizing and abstracting your code is by far more efficient.</p> <p>Note, though, that shared components are often not reused as much as we expect, resulting in a wasted effort. Therefore, think twice before centralizing a component. When in doubt, start duplicating the component and, after a few iterations, review whether these components need to be abstracted. The wrong abstraction is way more expensive than duplicated code.</p> <p>The final layer is the micro-frontend that is hosting the UI components library. Keep in mind the importance of a micro-frontend\u2019s independence. The moment we get more than three or four external dependencies, we are heading toward a distributed monolith. That\u2019s the worst place to be because we are treating a distributed architecture like a monolith that we wanted to move away from, no longer creating independent teams across the organization.</p> <p>To ensure we are finding the right trade-offs between development speed and independent teams and UI consistency, consider validating the dependencies monthly or every two months throughout the project life cycle. In the past, I\u2019ve worked at companies where this exercise was done every two weeks at the end of every sprint, and it helped many teams postpone tasks that may not have been achievable during a sprint due to blocks from external dependencies. In this way, you\u2019ll reduce your teams\u2019 frustration and increase their performance.</p> <p>On the technical side, the best investment you can make for creating a design system is in web components. Since you can use web components with any UI framework, should you decide to change the UI framework later, the design system will remain the same, saving you time and effort. There are some situations in which using web components is not viable, such as projects that have to target old browsers. Chances are, though, you won\u2019t have such strong requirements and you can target modern browsers, allowing you to leverage web components with your micro-frontend architecture.</p> <p>While getting the design system ready to be implemented is half the work, to accomplish the delivery inside your micro-frontends architecture, you\u2019ll need a solid governance to maintain that initial investment. Remember, dealing with a distributed architecture is not as straightforward as you can imagine. Usually, the first implementation happens quite smoothly because there is time allocated to that. The problems come with subsequent updates. Especially when you deal with distributed teams, the best approach is to automate the system design version validation in the continuous integration (CI) phase. Every time a micro-frontend is built, the package.json file should check that the design system library is up to date with the latest version.</p> <p>Implementing this check in CI allows you to be as strict as needed. You may decide to provide a warning in the logs, asking to update the version as soon as possible, or prevent artifact creation if the micro-frontend is one or more major versions behind.</p> <p>Some companies have custom dashboards for dealing with this problem, not only for design systems but also for other libraries, such as logging or authentication. In this way, every team can check in real time whether their micro-frontend implements the latest versions.</p> <p>Finally, let\u2019s consider the team\u2019s structure. Traditionally, in enterprise companies, the design team is centralized, taking care of all the aspects of the design system, from ideation to delivery, and the developers just implement the library the design team provides. However, some companies implement a distributed model wherein the design team is a central authority that provides the core components and direction for the entire design system, but other teams populate the design system with new components or new functionalities of existing ones. In this second approach, we reduce potential bottlenecks by allowing the development teams to contribute to the global design system. Meanwhile, we keep guardrails in place to ensure every component respects the overall plan, such as regular meetings between design and development, office hours during which the design team can guide development teams, or even collaborative sessions where the design team sets the direction but the developers actually implement the code inside the design system.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#developer-experience","title":"Developer Experience","text":"<p>For vertical-split micro-frontends, the developer\u2019s experience is very similar to SPAs. However, there are a couple of suggestions that you may find useful to think about up front. First of all, create a command line tool for scaffolding micro-frontends with a basic implementation and common libraries you would like to share in all the micro-frontends such as a logging library. While not an essential tool to have from day one, it\u2019s definitely helpful in the long term, especially for new team members. Also, create a dashboard that summarizes the micro-frontend version you have in different environments. In general, all the tools you are using for developing an SPA are still relevant for a vertical-split micro-frontend architecture. We will discuss this topic more in depth in Chapter\u00a07, where we review how to create automation pipelines for micro-frontend applications.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#search-engine-optimization","title":"Search Engine Optimization","text":"<p>Some projects require a strong SEO strategy, including micro-frontend projects. Let\u2019s look at two major options for a good SEO strategy with vertical-split micro-frontends. The first one involves optimizing the application code in a way that is easily indexable by crawlers. In this case, the developer\u2019s job is implementing as many best practices as possible for rendering the entire DOM in a timely manner (usually under five seconds). Time matters with crawlers, because they have to index all the data in a view and also structure the UI in a way that exposes all the meaningful information without hiding behind user interactions. Another option is to create an HTML markup that is meaningful for crawlers to extract the content and categorize it properly. While this isn\u2019t impossible, in the long run, this option may require a bit of effort to maintain for every new feature and project enhancement.</p> <p>Another option would be using dynamic rendering to provide an optimized version of your web application for all the crawlers trying to index your content. Google introduced dynamic rendering to allow you to redirect crawler requests to an optimized version of your website, usually prerendered, without penalizing the positioning of your website in the search engine results (see Figure\u00a04-8).</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-8-when-a-crawler-requests-a-specific-page-the-application-server-should-retrieve-the-user-agent-and-serve-the-crawlers-requests-to-a-prerendered-version-of-the-website-otherwise-serving-the-micro-frontend-implementation","title":"Figure 4-8. When a crawler requests a specific page, the application server should retrieve the user-agent and serve the crawler\u2019s requests to a prerendered version of the website, otherwise serving the micro-frontend implementation","text":"<p>There are a couple of solutions for serving a prerendered version of your application to a crawler. First, for the prerendering phase, you can create a customized version of your website that fetches the same data of the website your users will consume. For instance, you can create a server-side rendering output stored in an objects storage that translates a template into static HTML pages at compile time, maintaining the same user-facing URL structure. Amazon S3 is a good choice for this. You can also decide to server-side render at runtime, eliminating the need to store the static pages and serving the crawlers a just-in-time version created ad hoc for them. Although this solution requires some effort to implement, it allows you the best customization and optimization for improving the final output to the crawler.</p> <p>A second option would be using an open source solution like Puppeteer or Rendertron to scrape the code from the website created for the users and then deploy a web server that generates static pages regularly.</p> <p>After generating the static version of your website, you need to know when the request is coming from a browser and when from a crawler. A basic implementation would be using a regular expression that identifies the crawler\u2019s user-agents. A good Node.js library for that is crawler-user-agents. In this case, after identifying the user-agent header, the application server can respond with the correct implementation. This solution can be applied at the edge using technologies like AWS Lambda@Edge or Cloudflare Workers. In this case, CDNs of some cloud providers allow a computation layer after receiving a request. Because there are some constraints on the maximum execution time of these containers, the user-agent identification represents a good reason for using these edge technologies. Moreover, they can be used for additional logic, introducing canary releases or blue-green deployment, as we will see in Chapter\u00a06.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#performance-and-micro-frontends","title":"Performance and Micro-Frontends","text":"<p>Is good performance achievable in a micro-frontend architecture? Definitely! Performance of a micro-frontend architecture, like in any other frontend architecture, is key for the success of a web application. And a vertical-split architecture can achieve good performance thanks to the split of domains and, therefore, the code to be shared with a client.</p> <p>Think for a moment about an SPA. Typically, the user has to download all the code specifically related to the application, the business logic, and the libraries used in the entire application. For simplicity, let\u2019s imagine that an entire application code is 500 KB. The unauthenticated area, composed of sign-in, sign-up, the landing page, customer support, and few other views, requires 100 KB of business logic, while the authenticated area requires 150 KB of business logic. Both use the same bundled dependencies that are each 250 KB (see Figure\u00a04-9).</p> <p>A new user has to download all 500 KB, despite the action having to fulfill inside the SPA. Maybe one user just wants to understand the business proposition and visits just the landing page, another user wants to see the payment methods available, or an authenticated user is interested mainly in the authenticated area where the service or products are available. No matter what users are trying to achieve, they are forced to download the entire application.</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-9-any-user-of-an-spa-has-to-download-the-entire-application-regardless-of-the-action-they-intend-to-perform-in-the-application","title":"Figure 4-9. Any user of an SPA has to download the entire application regardless of the action they intend to perform in the application","text":"<p>In a vertical-split architecture, however, our unauthenticated user who wants to see the business proposition on the landing page will be able to download the code just for that micro-frontend, while the authenticated user will download only the codebase for the authenticated area. We often don\u2019t realize that our users\u2019 behaviors are different from the way we interpret the application, because we often optimize the application\u2019s performance as a whole rather than by how users interact with the site. Optimizing our site according to user experiences results in a better outcome.</p> <p>Applying the previous example to a vertical-split architecture, a user interested only in the unauthenticated area will download less than 100 KB of business logic plus the shared dependencies, while an authenticated user will download only the 250 KB plus the shared dependencies.</p> <p>Clearly a new user who moves beyond the landing page will download almost 500 KB, but this approach will still save some kilobytes if we have properly identified the application boundaries because it\u2019s unlikely a new user will go through every single application view. In the worst-case scenario, the user will download 500 KB as they would for the SPA, but this time not everything up front. Certainly, there is additional logic to download due to the application shell, but usually the size is only in the double digits, making it meaningless for this example. Figure\u00a04-10 shows the advantages of a vertical-split micro-frontend in terms of performance.</p> <p>A good practice for managing performance on a vertical-split architecture is introducing a performance budget. A performance budget is a limit for micro-frontends that a team is not allowed to exceed. The performance budget includes the final bundle size, multimedia content to load, and even CSS files. Setting a performance budget is an important part of making sure every team optimizes its own micro-frontend properly and can even be enforced during the CI process. You won\u2019t set a performance budget until later in the project, but it should be updated every time there is a meaningful refactoring or additional features introduced in the micro-frontend codebase.</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-10-a-vertical-split-micro-frontend-enables-the-user-to-download-only-the-application-code-needed-to-accomplish-the-action-the-user-is-looking-for","title":"Figure 4-10. A vertical-split micro-frontend enables the user to download only the application code needed to accomplish the action the user is looking for","text":"<p>Time to display the final result to the user is a key performance indicator, and metrics to track include time-to-interactive or first contentful paint, the size of the final artifact, font size, and JavaScript bundle size, as well as metrics like accessibility and SEO. A tool like Lighthouse is useful for analyzing these metrics and is available in a command-line version to be used in the continuous integration process. Although these metrics have been discussed extensively for SPA optimization, bundle size may be trickier when it comes to micro-frontends.</p> <p>With vertical-split architectures, you can decide either to bundle all the shared libraries together or to bundle the libraries for each micro-frontend. The former can provide greater performance because the user downloads the bundle only once, but you\u2019ll need to coordinate the libraries to update for every change across all the micro-frontends. While this may sound like an easy task, it can be more complicated than you think when it happens regularly. Imagine you have a breaking change on a specific shared UI framework; you can\u2019t update the new version until all the micro-frontends have done extensive tests on the new framework version. So while we gain in performance in this scenario, we must first overcome some organizational challenges. The latter solution\u2014maintaining every micro-frontend independently\u2014reduces the communication overhead for coordinating the shared dependencies but might increase the content the user must download. As seen before, however, a user may decide to stay within the same micro-frontend for the entire session, resulting in the exact same kilobytes downloaded.</p> <p>Once again, there isn\u2019t right or wrong in any of these strategies. Make a decision on the requirements to fulfill and the context you operate in. Don\u2019t be afraid to make a call and monitor how users interact with your application. You may discover that, overall, the solution you picked, despite some pitfalls, is the right one for the project. Remember, you can easily reverse this decision, so spend the right amount of time thinking which path your project requires, but be aware that you can change direction if a new requirement arises or the decision causes more harm than benefits.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#available-frameworks","title":"Available Frameworks","text":"<p>There are some frameworks available for embracing this architecture. However, building an application shell on your own won\u2019t require too much effort, as long as you keep the application shell decoupled from any micro-frontend business logic. Polluting the application shell codebase with domain logic is not only a bad practice but also may invalidate all effort and investment of using micro-frontends in the long run due to code and logic coupling.</p> <p>Two frameworks that are fully embracing this architecture are single-spa and qiankun. The concept behind single-spa is very simple: it\u2019s a lightweight library that provides undifferentiated heavy lifting for the following:</p> <p>Registration of micro-frontends</p> <p>The library provides a root configuration to associate a micro-frontend to a specific path of your system.</p> <p>Life cycle methods</p> <p>Every micro-frontend is exposed to many stages when mounted. Single-spa allows a micro-frontend to perform the right task for the life cycle method. For instance, when a micro-frontend is mounted, we can apply logic for fetching an API. When unmounted, we should remove all the listeners and clean up all DOM elements.</p> <p>Single-spa is a mature library, with years of refinement and many integrations in production. It\u2019s open source and actively maintained and has a great community behind it. In the latest version of the library, you can develop horizontal-split micro-frontends, too, including server-side rendering ones. Qiankun is built on top of single-spa, adding some functionality from the latest releases of single-spa.</p> <p>Module Federation may also be a good alternative for implementing a vertical-split architecture, considering that the mounting and unmounting mechanism, dependencies management, orchestration between micro-frontends, and many other features are already available to use. Module Federation is typically used for composing multiple micro-frontends in the same view (horizontal split). However, nothing is preventing us from using it for handling vertical-split micro-frontends. Moreover, it\u2019s a webpack plug-in. If your projects are already using webpack, it may help you avoid learning new frameworks for composing and orchestrating your project\u2019s micro-frontends. In the next chapter, we will explore the Module Federation for implementing vertical and horizontal split architectures.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#use-cases","title":"Use Cases","text":"<p>The vertical-split architecture is a good solution when your frontend developers have experience with SPA development. It will also scale up to a certain extent, but if you have hundreds of frontend developers working on the same frontend application, a horizontal split may suit your project better, because you can modularize your application even further.</p> <p>Vertical-split architecture is also great when you want UI and UX consistency. In this situation, every team is responsible for a specific business domain, and a vertical split will allow them to develop an end-to-end experience without the need to coordinate with other teams.</p> <p>Another reason to choose this architecture pattern is the level of reusability you want to have across multiple micro-frontends. For instance, if you reuse mainly components of your design system and some libraries, like logging or payments, a vertical split may be a great architecture fit. However, if part of your micro-frontend is replicated in multiple views, a horizontal split may be a better solution. Again, let the context drive the decision for your project.</p> <p>Finally, this architecture is my first recommendation when you start embracing micro-frontends because it doesn\u2019t introduce too much complexity. It has a smooth learning curve for frontend developers, it distributes the business domains to dozens of frontend developers without any problem, and it doesn\u2019t require huge upfront investment in tools but more in general in the entire developer experience.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#architecture-characteristics","title":"Architecture Characteristics","text":"<p>Deployability (5/5)</p> <p>Because every micro-frontend is a single HTML page or an SPA, we can easily deploy our artifacts on a cloud storage or \u00a0an application server and stick a CDN in front of it. It\u2019s a well-known approach, used for several years by many frontend developers for delivering their web applications. Even better, when we apply a multi-CDN strategy, our content will always be served to our user no matter which fault a CDN provider may have.</p> <p>Modularity (2/5)</p> <p>This architecture is not the most modular. While we have a certain degree of modularization and reusability, it\u2019s more at the code level, sharing components or libraries but less on the features side. For instance, it\u2019s unlikely a team responsible for the development of the catalog micro-frontend shares it with another micro-frontend. Moreover, when we have to split a vertical-split micro-frontend in two or more parts because of new features, a bigger effort will be required for decoupling all the shared dependencies implemented, since it was designed as a unique logical unit.</p> <p>Simplicity (4/5)</p> <p>Taking into account that the primary aim of this approach is reducing the team\u2019s cognitive load and creating domain experts using well-known practices for frontend developers, the simplicity is intrinsic. There aren\u2019t too many mindset shifts or new techniques to learn to embrace this architecture. The overhead for starting with single-spa or Module Federation should be minimal for a frontend developer.</p> <p>Testability (4/5)</p> <p>Compared to SPAs, this approach shows some weakness in the application shell\u2019s end-to-end testing. Apart from that edge case, however, testing vertical-split micro-frontends doesn\u2019t represent a challenge with existing knowledge of unit, integration, or end-to-end testing.</p> <p>Performance (4/5)</p> <p>You can share the common libraries for a vertical-split architecture, though it requires a minimum of coordination across teams. Since it\u2019s very unlikely that you\u2019ll have hundreds of micro-frontends with this approach, you can easily create a deployment strategy that decouples the common libraries from the micro-frontend business logic and maintains the commonalities in sync across multiple micro-frontends. Compared to other approaches, such as server-side rendering, there is a delay on downloading the code of a micro-frontend because the application shell should initialize the application with some logic. This may impact the load of a micro-frontend when it\u2019s too complex or makes many roundtrips to the server.</p> <p>Developer experience (4/5)</p> <p>A team familiar with SPA tools won\u2019t need to shift their mindset to embrace the vertical split. There may be some challenges during end-to-end testing, but all the other engineering practices, as well as tools, remain the same. Not all the tools available for SPA projects are suitable for this architecture, so your developers may need to build some internal tools to fill the gaps. However, the out-of-the-box tools available should be enough to start development, allowing your team to defer the decisions to build new tools.</p> <p>Scalability (5/5)</p> <p>The scalability aspect of this architecture is so great that we can even forget about it when we serve our static content via a CDN. We can also configure the time-to-live according to the assets we are serving, setting a higher time for assets that don\u2019t change often, like fonts or vendor libraries, and a lower time for assets that change often, like the business logic of our micro-frontends. This architecture can scale almost indefinitely based on CDN capacity, which is usually great enough to serve billions of users simultaneously. In certain cases, when you absolutely must avoid a single point of failure, you can even create a multiple-CDN strategy, where your micro-frontends are served by multiple CDN providers. Despite being more complicated, it solves the problem elegantly without investing too much time creating custom solutions.</p> <p>Coordination (4/5)</p> <p>This architecture, compared to others, enables a strong decentralization of decision making, as well as autonomy of each team. Usually, the touching points between micro-frontends are minimal when the domain boundaries are well defined. Therefore, there isn\u2019t too much coordination needed, apart from an initial investment for defining the application shell APIs and keeping them as domain unaware as possible.</p> <p>Table\u00a04-1 gathers the architecture characteristics and its associated score for this micro-frontend architecture.</p> <p>Table 4-1. Architecture characteristics summary for developing a micro-frontends architecture using vertical split and application shell as composition and orchestrator</p> <p>Architecture characteristics</p> <p>Score (1 = lowest, 5 = highest)</p> <p>Deployability</p> <p>5/5</p> <p>Modularity</p> <p>2/5</p> <p>Simplicity</p> <p>4/5</p> <p>Testability</p> <p>4/5</p> <p>Performance</p> <p>4/5</p> <p>Developer experience</p> <p>4/5</p> <p>Scalability</p> <p>5/5</p> <p>Coordination</p> <p>4/5</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#horizontal-split-architectures","title":"Horizontal-Split Architectures","text":"<p>Horizontal-split architectures provide a variety of options for almost every need a micro-frontend application has. These architectures have a very granular level of modularization thanks to the possibility to split the work of any view among multiple teams. In this way, you can compose views reusing different micro-frontends built by multiple teams inside your organization. Horizontal-split architectures are suggested not only to companies that already have a sizable engineering department but also to projects that have a high level of code reusability, such as a multitenant business-to-business (B2B) project in which one customer requests a customization or ecommerce with multiple categories with small differences in behaviors and user interface. Your team can easily build a personalized micro-frontend just for that customer and for that domain only. In this way, we reduce the risk of introducing bugs in different parts of the applications, thanks to the isolation and independence that every micro-frontend should maintain.</p> <p>At the same time, due to this high modularization, horizontal-split architecture is one of the most challenging implementations because it requires solid governance and regular reviews for getting the micro-frontends boundaries rights. Moreover, these architectures challenge the organization\u2019s structure unless they are well thought out up front. It\u2019s very important with these architectures that we review the communication flows and the team\u2019s structure to enable the developers to do their job and avoid too many external dependencies across teams. Also, we need to share best practices and define guidelines to follow to maintain a good level of freedom while providing a unique, consolidated experience for the user.</p> <p>One of the recommended practices when we use horizontal-split architectures is to reduce the number of micro-frontends in the same view, especially when multiple teams have to merge their work together. This may sound obvious, but there is a real risk of over-engineering the solution to have several tiny micro-frontends living together in the same view, which creates an antipattern. This is because you are blurring the line between a micro-frontend and a component, where the former is a business representation of a subdomain and the latter is a technical solution used for reusability purposes.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#components-versus-micro-frontends","title":"Components Versus Micro-Frontends","text":"<p>A good rule of thumb to understand if we are building a component or a micro-frontend is that, with a component, we tend to extend for different use cases, exposing multiple properties for covering all the use cases for different scenarios. Instead, with a micro-frontend, we encapsulate the logic, allowing communication via events.</p> <p>Moreover, managing the output of multiple teams in the same view requires additional coordination in several stages of the software development life cycle. Another sign of over-engineering a page is having multiple micro-frontends fetching from the same API. In that case, there is a good chance that you have pushed the division of a view too far and need to refactor. Remember that embracing these architectures provides great power, and therefore we have great responsibility for making the right choices for the project. In the next sections we will review the different implementations of horizontal-split architectures: client side, edge side, and server side.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#client-side","title":"Client Side","text":"<p>A client-side implementation of the horizontal-split architecture is similar to the vertical-split one in that there is an application shell used for composing the final view. The key difference is that, here, a view is composed of multiple micro-frontends, which can be developed by the same or different teams. Due to the horizontal split\u2019s modular nature, it\u2019s important not to fall into the trap of thinking too much about components. Instead, stick to the business perspective.</p> <p>Imagine, for example, you are building a video-streaming website and you decide to use a horizontal-split architecture using a client-side composition. There are several teams involved in this project; however, for simplicity, we will only consider two views: the landing page and the catalog. The bulk of work for these two experiences involve the following teams:</p> <p>Foundation team</p> <p>This team is responsible for the application shell and the design system, working alongside the UX team but from a more technical perspective.</p> <p>Landing page team</p> <p>The landing page team is responsible for supporting the marketing team to promote the streaming service and creating all the different landing pages needed.</p> <p>Catalog team</p> <p>This team is responsible for the authenticated area where a user can consume a video on demand. It works in collaboration with other teams for providing a compelling experience to the service subscribers.</p> <p>Playback experience team</p> <p>Considering the complexity for building a great video player available in multiple platforms, the company decides to have a team dedicated to the playback experience. The team is responsible for the video player, video analytics, implementation of the digital rights management (DRM), and additional security concerns related to the video consumption from unauthorized users.</p> <p>When it comes to implementing one of the many landing pages, three teams are responsible for the final view presented to every user. The foundation team provides the application shell, footer, and header and composes the other micro-frontends present in the landing page. The landing page team provides the streaming service offering, with additional details about the video platform. The playback experience team provides the video player for delivering the advertising needed to attract new users to the service. Figure\u00a04-11 shows the relationship between these elements.</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-11-the-landing-page-view-is-composed-by-the-application-shell-which-loads-two-micro-frontends-the-service-characteristics-and-the-playback-experience","title":"Figure 4-11. The landing page view is composed by the application shell, which loads two micro-frontends: the service characteristics and the playback experience","text":"<p>This view doesn\u2019t require particular communication between micro-frontends, so once the application shell is loaded, it retrieves the other two micro-frontends and provides the composed view to the user. When a subscriber wants to watch any video content, after being authenticated, they will be presented with the catalog that includes the video player (see Figure\u00a04-12).</p> <p>In this case, every time a user interacts with a tile to watch the content, the catalog micro-frontend has to communicate with the playback micro-frontend to provide the ID of the video selected by the user. When an error has to be displayed, the catalog team is responsible for triggering a modal with the error message for the user. And when the playback has to trigger an error, the error will need to be communicated to the catalog micro-frontend, which will display it in the view. This means we need a strategy that keeps the two micro-frontends independent but allows communication between them when there is a user interaction or an error occurs.</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-12-the-catalog-view-is-composed-by-the-application-shell-which-loads-two-micro-frontends-the-playback-experience-and-the-catalog-itself","title":"Figure 4-12. The catalog view is composed by the application shell, which loads two micro-frontends: the playback experience and the catalog itself","text":"<p>There are many strategies available to solve this problem, like using custom events or an event emitter, but we will discuss the different approaches later on in this chapter. Why wasn\u2019t there a specific composition strategy for this example? Mainly because every client-side architecture has its own way of composing a view. Also, in this case we will see, architecture by architecture, the best practice for doing so.</p> <p>Do you want to discover where the horizontal-split architecture really shines? Let\u2019s fast-forward a few months after the release of the video-streaming platform. The product team asks for a nonauthenticated version of the catalog to improve the discoverability of the platform assets, as well as providing a preview of their best shows to potential customers. This boils down to providing a similar experience of the catalog without the playback experience. The product team would also like to present additional information on the landing page so users can make an informed decision about subscribing to the service. In this case, the foundation team, catalog team, and landing page team will be needed to fulfill this request (see Figure\u00a04-13).</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-13-this-new-view-is-composed-by-the-catalog-owned-by-the-catalog-team-and-the-marketing-message-owned-by-the-landing-page-team","title":"Figure 4-13. This new view is composed by the catalog (owned by the catalog team) and the marketing message (owned by the landing page team)","text":"<p>Evolving a web application is never easy, for both technical and collaboration reasons. Having a way to compose micro-frontends simultaneously and then stitching them together in the same view, with multiple teams collaborating without stepping on each other\u2019s toes, makes life easier for everyone and enables the business to evolve at speed and in any direction.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#challenges_1","title":"Challenges","text":"<p>As with every architecture, horizontal splits have benefits and challenges that are important to recognize to ensure they\u2019re a good fit for your organization and projects. Evaluating the trade-offs before embarking on a development puts you one step closer to delivering a successful project.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#micro-frontend-communication","title":"Micro-frontend communication","text":"<p>Embracing a horizontal-split architecture requires understanding how micro-frontends developed by different teams share information, or states, during the user session. Inevitably, micro-frontends will need to communicate with each other. For some projects, this may be minimal, while in others, it will be more frequent. Either way, you need a clear strategy up front to meet this specific challenge. Many developers may be tempted to share states between micro-frontends, but this results in a socio-technical antipattern. On the technical side, working with a distributed system that has shared code with other micro-frontends owned by different teams means that the shared state requires it to be designed, developed, and maintained by multiple teams (see Figure\u00a04-14).</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-14-shared-state-between-multiple-micro-frontends-represents-an-antipattern","title":"Figure 4-14. Shared state between multiple micro-frontends represents an antipattern","text":"<p>Every time a team makes a change to the shared state, all the others must validate the change and ensure it won\u2019t impact their micro-frontends. Such a structure breaks the encapsulation micro-frontends provide, creating an underlying coupling between teams that has frequent, if not constant, external dependencies to take care of.</p> <p>Moreover, we risk jeopardizing the agility and the evolution of our system because a key part of one micro-frontend is now shared among other micro-frontends. Even worse is when a micro-frontend is reused across multiple views and a team is responsible for maintaining multiple shared states with other micro-frontends. On the organization side, this approach risks coupling teams, resulting in the need for a lot of coordination that can be avoided while maintaining intact the boundaries of every micro-frontend.</p> <p>The coordination between teams doesn\u2019t stop on the design phase, either. It will be even more exasperating during testing and release phases because now all the micro-frontends in the same view depend on the same state that cannot be released independently. Having constant coordination to handle instead of maintaining a micro-frontend\u2019s independent nature can be a team\u2019s worst nightmare. In the microservices world, this is called a distributed monolith: an application deployed like a microservice but built like a monolith.</p> <p>One of micro-frontends\u2019 main benefits is the strong boundaries that allow every team to move at the speed they need, loosely coupling the organization, reducing the time of coordination, and allowing developers to take destiny in their hands. In the microservices world, to achieve a loose coupling between microservices and therefore between teams, we use the choreography pattern, which uses an asynchronous communication, or event broker, to notify all the consumers interested in a specific event. With this approach we have:</p> <ul> <li> <p>Independent microservices that can react to (or not react to) external events triggered by one or more producers</p> </li> <li> <p>Solid, bounded context that doesn\u2019t leak into multiple services</p> </li> <li> <p>Reduced communication overhead for coordinating across teams</p> </li> <li> <p>Agility for every team so they can evolve their microservice based on their customers\u2019 needs</p> </li> </ul> <p>With micro-frontends, we should think in the same way to gain the same benefits. Instead of using a shared state, we maintain our micro-frontends\u2019 boundaries and communicate any event that should be shared on the view using asynchronous messages, something we\u2019re used to dealing with on the frontend.</p> <p>Other possibilities are implementing either an event emitter or a reactive stream (if you are in favor of the reactive paradigm) and sharing it across all the micro-frontends in a view (see Figure\u00a04-15).</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-15-every-micro-frontend-in-the-same-view-should-own-its-own-state-and-should-communicate-changes-via-asynchronous-communication-using-an-event-emitter-or-customevent-or-reactive-streams","title":"Figure 4-15. Every micro-frontend in the same view should own its own state and should communicate changes via asynchronous communication using an event emitter or CustomEvent or reactive streams","text":"<p>In Figure\u00a04-15, Team Fajitas is working on a micro-frontend (MFE B) that needs to react when a user interacts with an element in another micro-frontend (MFE A), run by Team Burrito. Using an event emitter, Team Fajitas and Team Burrito can define how the event name and the associated payload will look and then implement them, working in parallel (see Figure\u00a04-16).</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-16-mfe-a-emits-an-event-using-the-eventemitter-as-a-communication-bus-all-the-micro-frontends-interested-in-that-event-will-listen-and-react-accordingly","title":"Figure 4-16. MFE A emits an event using the EventEmitter as a communication bus; all the micro-frontends interested in that event will listen and react accordingly","text":"<p>When the payload changes for additional features implemented in the platform, Team Fajitas will need to make a small change to its logic and can then start integrating these features without waiting for other teams to make any change and maintaining its independence.</p> <p>The third micro-frontend in our example (MFE C, run by Team Tacos) doesn\u2019t care about any event shared in that view because its content is static and doesn\u2019t need to react to any user interactions. Team Tacos can continue to do its job knowing its part won\u2019t be affected by any state change associated with a view.</p> <p>A few months later a new team, Team Nachos, is created to build an additional feature in the application. Team Nachos\u2019 micro-frontend (MFE D) lives alongside MFE A and MFE B (see Figure\u00a04-17).</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-17-a-new-micro-frontend-was-added-in-the-same-view-and-has-to-integrate-with-the-rest-of-the-application-reacting-to-the-event-emitted-by-mfe-a-because-of-the-loose-coupling-nature-of-this-approach-mfe-d-just-listens-to-the-events-emitted-by-mfe-a-in-this-way-all-micro-frontends-and-teams-maintain-their-independence","title":"Figure 4-17. A new micro-frontend was added in the same view and has to integrate with the rest of the application reacting to the event emitted by MFE A. Because of the loose coupling nature of this approach, MFE D just listens to the events emitted by MFE A. In this way, all micro-frontends and teams maintain their independence.","text":"<p>Because every micro-frontend is well encapsulated and the only communication protocol is a pub/sub system like the event emitter, the new team can easily listen to all the events it needs to for plugging in the new feature alongside the existing micro-frontends. This approach not only enhances the technical architecture but also provides a loose coupling between teams while allowing them to continue working independently.</p> <p>Once again, we notice how important our technology choices are when it comes to maintaining independent teams and reducing external dependencies that would cause more frustration than anything else. As well, having the team document all the events in input and output for every horizontal-split micro-frontend will help facilitate the asynchronous communication between teams. Providing an up-to-date, self-explanatory list of contracts for communicating in and out of a micro-frontend will result in clear communication and better governance of the entire system. What these processes help achieve is speed of delivery, independent teams, agility, and a high degree of evolution for every micro-frontend without affecting others.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#clashes-with-css-classes-and-how-to-avoid-them","title":"Clashes with CSS classes and how to avoid them","text":"<p>One potential issue in horizontal-split architecture during implementation is CSS classes clash. When multiple teams work on the same application, there is a strong possibility of having duplicate class names, which would break the final application layout. To avoid this risk, we can prefix each class name for every micro-frontend, creating a strong rule that prevents duplicate names and, therefore, undesired outcomes for our users. Block Element Modifier, or BEM, is a well-known naming convention for creating unique names for CSS classes. As the name suggests, we use three elements to assign to a component in a micro-frontend:</p> <p>Block</p> <p>An element in a view. For example, an avatar component is composed of an image, the avatar name, and so on.</p> <p>Element</p> <p>A specific element of a block. In the previous example, the avatar image is an element.</p> <p>Modifier</p> <p>A state to display. For instance, the avatar image can be active or inactive.</p> <p>Based on the example described, we can derive the following class names:</p> <pre><code>.avatar\n</code></pre> <p>While following BEM can be extremely beneficial for architecting your CSS strategy, it may not be enough for projects with multiple micro-frontends. So we build on the BEM structure by prefixing the micro-frontend name to the class.</p> <p>For our avatar example, when it\u2019s used in the \u201cMy account\u201d micro-frontend, the names become:</p> <pre><code>.myaccount_avatar\n</code></pre> <p>Although this makes names long, it guarantees the isolation needed and makes clear what every class refers to. Any other naming convention for CSS class names you want to create is also acceptable, but just remember to add prefixes when used with micro-frontends.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#tip_1","title":"Tip","text":"<p>For a good guide to starting with BEM, check out Inna Belaya\u2019s article \u201cBEM for Beginners: Why You Need BEM\u201d at Smashing magazine. You can read additional content on the topic at Smashing as well.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#multiframework-approach_1","title":"Multiframework approach","text":"<p>Using multiple frameworks isn\u2019t great for vertical-split architectures due to performance issues. On horizontal-split architectures, it\u2019s even more dangerous. When this problem is not addressed in the design phase, it can cause runtime errors in the final view.</p> <p>Imagine having multiple versions of React in the same view. It does not lead to a great experience for the user. When the browser downloads two versions for a rendering view, performance issues can crop up. Consider, too, the potential variables clashing when we load the libraries or append new components in the view.</p> <p>There are many ways to address this problem. For instance, iframes create a sandbox so that what loads inside one iframe doesn\u2019t clash with another iframe. Module Federation allows you to share libraries and provides a mechanism for avoiding clashing dependencies. Import maps allow us to define scopes for every dependency so we can define different versions of the same libraries to different scopes. And web components can \u201chide\u201d behind the shadow DOM the frameworks need for a micro-frontend.</p> <p>Still, using a multiframework approach is strongly discouraged due to performance issues. Having more kilobytes to download in order to render a page is not a great customer experience, and our job as developers and architects should be to provide the best user experience possible. Multiframework isn\u2019t acceptable in other frontend architectures, like SPAs, and micro-frontends should not be an exception.</p> <p>The only acceptable time to use a multiframework strategy is when we have to migrate a legacy application to a new one, resulting in the micro-frontends being iteratively released rather than releasing all at once. In this case, the multiframework strategy allows you to provide customer value and lowers risks in deploying your artifacts.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#authentication","title":"Authentication","text":"<p>Horizontal-split architectures present an interesting challenge when it comes to system authentication, because, more often than not, multiple teams are working on the same view, and they need to maintain a unique experience for the customer. When a user enters into an authenticated area of a web application, all the micro-frontends composing the page have to communicate with the respective APIs providing tokens.</p> <p>Let\u2019s say we have three different teams creating a micro-frontend, each composing a view for the customer. These micro-frontends have to fetch data from the backend, which is a distributed system composed of multiple microservices (see Figure\u00a04-18).</p> <p>How can different micro-frontends retrieve and store a token safely without multiple round trips to the backend? The best option we have is storing the token in the localStorage, the sessionStorage, or a cookie. In this case, all the micro-frontends will retrieve the same token in the defined web storage solution by convention.</p> <p>Different security restrictions will be applied based on the web storage selected for hosting the token. For instance, if we use localStorage or sessionStorage, all the micro-frontends have to be hosted in the same subdomain; otherwise the localStorage or sessionStorage where the token is stored won\u2019t be accessible. In the case of cookies, we can use multiple subdomains but must use the same domain.</p> <p>We also have to consider when we have multiple micro-frontends consuming the same API with the same request body that it\u2019s very likely that these micro-frontends can be merged into a unique micro-frontend.</p> <p>Don\u2019t be afraid to review the domain boundaries of micro-frontends, because they will evolve alongside the business. Additionally, because there isn\u2019t a scientific way to define boundaries, taking a step back and reassessing the direction taken can sometimes be more beneficial than ignoring the problem. The longer we ignore the problem, the more disruption the teams will experience. It\u2019s far better to invest time at the beginning of the project for refactoring a bunch of micro-frontends.</p> <p>Finally, this approach is applicable also to the vertical-split architecture, and we don\u2019t even have to be worried about multiple teams looking for a token considering we load just one micro-frontend per time.</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-18-every-micro-frontend-in-a-horizontal-split-architecture-has-to-fetch-data-from-an-api-passing-a-jwt-token-to-the-backend-to-validate-that-the-user-is-entitled-to-retrieve-the-data-requested","title":"Figure 4-18. Every micro-frontend in a horizontal-split architecture has to fetch data from an API passing a JWT token to the backend to validate that the user is entitled to retrieve the data requested","text":""},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#micro-frontends-refactoring","title":"Micro-frontends refactoring","text":"<p>Another benefit of the horizontal-split architecture is the ability to refactor specific micro-frontends when the code becomes too complicated to be manageable by a single team or a new team starts owning a micro-frontend they didn\u2019t develop. While you can do this with a vertical split as well, the horizontal-split micro-frontends have far less logic to maintain, making them a great benefit, especially for enterprise organizations that have to work on the same platform for many years.</p> <p>Because every micro-frontend is independent, refactoring the code to make it more understandable for the team is a benefit because this activity won\u2019t impact anyone else in the company. While you need to keep tech leadership\u2019s guidelines in mind, refactoring a well-designed micro-frontend requires far less time than refactoring a large monolithic codebase. This characteristic makes micro-frontends more maintainable in the long run. Additionally, when a complete rewrite is needed, having the domain experts\u2014the team\u2014in charge of rewriting something they know inside out requires significantly less work than rewriting an unfamiliar application from scratch. And because of the micro-frontends\u2019 nature, you can decide to rewrite them iteratively and ship them in production to gain immediate benefits of your work, instead of working for several months before releasing everything all at once.</p> <p>I\u2019m not encouraging refactoring or rewriting just because they\u2019re easier. But sometimes the team gains additional business knowledge, or they have to implement a tactical solution due to a hard delivery date; making a refactor or a rewrite from scratch can make life easier in the long run, speeding up new-feature development or reducing the possibility of bugs in the production environment.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#search-engine-optimization_1","title":"Search Engine Optimization","text":"<p>Dynamic rendering is another valid technique for this architecture, especially when we decide to use iframes for encapsulating our micro-frontends. In that situation, redirecting a crawler to an optimized version of static HTML pages helps with the search engine\u2019s ranking. Overall, what has been discussed so far about dynamic rendering is also valid for client-side horizontal-split architectures.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#developer-experience_1","title":"Developer Experience","text":"<p>The developer experience (DX) of the horizontal-split architecture with a client-side composition is very similar to the vertical split when a team is developing its own micro-frontend. However, it becomes more complex when the team needs to test micro-frontends inside a view with other micro-frontends. The main challenge is keeping up with the versions and having a quick turnaround for assembling a view on the developer\u2019s laptop.</p> <p>As we will describe in Chapter\u00a07, we can use webpack DevServer Proxy for testing locally, with micro-frontends available in testing, staging, or production environments. Often, companies that embrace this architecture create tools for improving their teams\u2019 feedback loop, often in the form of command line tools that can enhance the standard tools available for the frontend developers\u2019 community, like Rollup, webpack, or Snowpack. It\u2019s important to note that it\u2019s very likely this architecture will require some internal investments to create a solid DX. Currently, frameworks and tools (webpack Module Federation, for instance) are trying an opinionated approach; while this isn\u2019t necessarily a bad thing, in large companies, additional effort will most likely be required to maintain the guidelines and standards the tech leadership designed based on the industry the company operates in.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#maintaining-control-with-effective-communication","title":"Maintaining control with effective communication","text":"<p>Although horizontal-split architectures are the most versatile, they also present intrinsic implementation challenges from an organizational point of view, with coordinating a final output for the use being the main one. When we have multiple micro-frontends owned by different teams composed in the same view, we have to create a social mechanism for avoiding runtime issues in production due to dependency clashes or CSS classes overriding each other. As well, observability tools must be added to quickly identify which micro-frontends are failing in production and provide the team with clear information so they can diagnose the issue in their micro-frontend.</p> <p>The best way to avoid issues is to keep the communication channels open and maintain a fast feedback loop that keeps all teams in sync, such as a weekly or biweekly meeting with a member from every micro-frontend team responsible for a view. Syncing the work between teams has to happen either in a live meeting or via asynchronous communication, such as emails or instant messaging clients.</p> <p>We must also reduce the number of teams working on the same page and make one team responsible for the final output presented to the users. This doesn\u2019t mean that the team responsible for the final look and feel of a view should do all the work. However, shared responsibilities often lead to misunderstandings, so having one team lead the effort creates a better experience for your users.</p> <p>As we saw in our client-side video player example, we have three teams involved in delivering the catalog page. It\u2019s very likely that the catalog team would perform any additional checks on the playback experience because after a user clicks on a movie or a show, it should play in the video player. In this case, then, the catalog team should be responsible for the final outcome and should coordinate the effort with the playback experience team for providing the best output for their users.</p> <p>When possible, reducing external dependencies should be a periodic job for an engineer manager or a team lead. Don\u2019t blindly accept the status quo. Instead, embrace a continuous improvement mindset and challenge the work done so far to find better ways to serve your customers.</p> <p>Strongly encourage your teams to document their micro-frontend inputs and outputs, the events a micro-frontend expects to receive, and those that will trigger to keep the teams in sync and to allow the discussion of potential breaking changes. Especially for the latter case, keeping track of breaking changes using requests for comments (RFCs) or similar documents is strongly recommended for several reasons. First, it creates asynchronous communication between teams, which is especially when teams are distributed across time zones. It also maintains a record of decisions with the context the company was operating in when the decision was made. Finally, not everyone performs well during meetings; sometimes one person will monopolize the discussion, preventing others from sharing their opinion. Moving from verbal to written communications helps everyone have their voice be heard.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#use-cases_1","title":"Use Cases","text":"<p>One reason to embrace the horizontal-split architecture is the micro-frontends\u2019 reusability across the application or multiple applications. Imagine a team responsible for the payment micro-frontend of an ecommerce website, and the micro-frontend contains different states based on the type of view and payments available. The payment micro-frontend is present in every view in which the user wants to perform a payment action, including a landing page, a product detail view, or even a subscription page for another product. This situation is applicable at a larger scale on a B2B application, where similar UX constructs are replicated in several system views.</p> <p>Another use case for this architecture is for enterprise applications, for which we often deal with dashboards containing a variety of data that we want to collect into different views for different purposes, such as financial and monitoring. New Relic uses this approach to provide monitoring tools for cloud services, as well as a frontend one that implements micro-frontends for scaling the organization, allowing multiple teams to contribute different data representations, all collected into a unique dashboard.</p> <p>In Figure\u00a04-19, you can see how New Relic divided its application so that a small number of teams work in the same view, reducing the amount of communication needed for composing the final view but allowing the team to be well encapsulated inside its business domain.</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-19-new-relic-micro-frontend-implementation-every-team-is-responsible-for-their-own-domain-and-when-a-user-selects-a-dashboard-the-related-micro-frontend-is-lazy-loaded-inside-the-application-shell","title":"Figure 4-19. New Relic micro-frontend implementation. Every team is responsible for their own domain, and when a user selects a dashboard, the related micro-frontend is lazy-loaded inside the application shell.","text":"<p>This approach allows New Relic teams to work on their own micro-frontends, and by following some contracts for deploying micro-frontends in production, they can see the final results in their web application.</p> <p>The final use case for this architecture is when we are developing a multitenant application for which the vast majority of the interface is the same but allowing customers to build specific features to make the software suitable for their specific organization. For example, let\u2019s say we are developing a digital till system for restaurants, and we want to configure the tables on the floor on a customer-by-customer basis. The application will have the same functionality for every single customer, but a restaurant chain can request specific features in the digital till system. The micro-frontend team responsible for the application can implement these features without forking the code for every customer; instead, they will create a new micro-frontend for handling the specific customer\u2019s needs and deploy it in their tenant.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#module-federation","title":"Module Federation","text":"<p>Micro-frontend architectures received a great gift with the release of webpack 5: a new native plug-in called Module Federation. Module Federation allows chunks of JavaScript code to load synchronously or asynchronously, meaning multiple developers or even teams can work in isolation and take care of the application composition, lazy-loading different JavaScript chunks behind the scenes at runtime, as shown in Figure\u00a04-20.</p> <p>A Module Federation application is composed of two parts:</p> <p>The host</p> <p>Represents the container of one or more micro-frontends or libraries loaded.</p> <p>The remote</p> <p>Represents the micro-frontend or library that will be loaded inside a host at runtime. A remote exposes one or more objects that can be used by the host when the remote is lazy-loaded into an application.</p> <p>The part of Module Federation that really shines is the simplicity of exposing different micro-frontends, or even shared libraries such as a design system, allowing a simple asynchronous integration. The developer experience is incredibly smooth. As when you\u2019re working with a monolithic codebase, you can import remote micro-frontends and compose a view in the way you need.</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-20-module-federation-allows-multiple-micro-frontends-to-be-loaded-asynchronously-providing-the-user-with-a-seamless-experience","title":"Figure 4-20. Module Federation allows multiple micro-frontends to be loaded asynchronously, providing the user with a seamless experience","text":"<p>Testing locally or pointing to a specific endpoint online doesn\u2019t make a difference because we can work in a similar way to handle multiple environments, with webpack having a common configuration augmented by a specific one for every environment (test, stage, or production).</p> <p>Another important feature of webpack with Module Federation is the ability to share external libraries across multiple micro-frontends without the fear of potential clashes happening at runtime. In fact, we can specify which libraries are shared across multiple micro-frontends, and Module Federation will load just one version for all the micro-frontends using the library.</p> <p>Imagine that all your micro-frontends are using Vue.js 3.0.0. With Module Federation, you will just need to specify that Vue version 3 is a shared library; at compile time, webpack will export just one Vue version for all the micro-frontends using it. And if you wanted to intentionally work with different versions of Vue in the same project? Module Federation will wrap the two libraries in different scopes to avoid the clashes that could happen at runtime, or you can even specify the scope for a different version of the same library using Module Federation APIs.</p> <p>Module Federation is available not only when we want to run an application fully client side but also when we want to use it with server-side rendering. In fact, we can asynchronously load different components without needing to deploy the application server that composes the page again and serve the final result to a client request.</p> <p>Unfortunately, the great simplicity of code sharing across projects is also the weakest point of this plug-in. When you work in a team that\u2019s not disciplined enough, sharing libraries, code snippets, and micro-frontends across multiple views can result in a very complicated architecture to maintain, thanks to the frictionless integration. So it\u2019s critical to create guidelines that follow the micro-frontend decisions framework in order not to regret the freedom Module Federation provides.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#performance","title":"Performance","text":"<p>With webpack, you can use a long list of official plug-ins to optimize your code when it is bundled, as well as even more plug-ins from independent developers and companies on GitHub.</p> <p>Module Federation benefits from this ecosystem because many of these plug-ins can manipulate a micro-frontend\u2019s output and work in conjunction with the plug-in. One of the main challenges we face when working with micro-frontends is how to share dependencies across this distributed architecture, and Module Federation can help there too. Let\u2019s say you have multiple teams working in the same application. Each team owns a single micro-frontend, and the teams have agreed to use the same UI library for the entire application. You can share these libraries automatically with Module Federation from the plug-in configuration, and they\u2019ll be loaded only once at the beginning of the project.</p> <p>You can also load micro-frontends dynamically inside JavaScript logic instead of defining all of them in the webpack configuration file.</p> <p>Optimizing the micro-frontends code from webpack is definitely a great option, mainly because, while the tool was created for bundling JavaScript, now it can optimize other static assets, such as CSS or HTML files.</p> <p>With so many organizations and independent developers using webpack, the ecosystem is more alive than ever, and the community-created enhancements are great for supporting any type of workload.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#composition","title":"Composition","text":"<p>Using Module Federation for a micro-frontend architecture is as simple as importing an external JavaScript chunk lazy-loaded inside a project. Composition takes place at runtime either on the client side, when we use an application shell for loading different micro-frontends, or on the server side, when we use server-side rendering. When we load a micro-frontend on an application shell at runtime, we can fetch the micro-frontend directly from a CDN or from an application server. And the same is true when we are working with a server-side rendering architecture. In this case, composition takes place at the origin, and we can load micro-frontends at runtime before serving them to a client request.</p> <p>In the next chapter, we will dive deeply into Module Federation composition, providing more insights into how to achieve horizontal- and vertical-split composition with code examples.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#shared-code","title":"Shared code","text":"<p>Module Federation makes sharing code very simple, providing a frictionless developer experience. However, we have to carefully consider why we are embracing micro-frontends in the first place. This plug-in allows you to have bidirectional sharing across micro-frontends, therefore flattening the hierarchical nature of an application where a host micro-frontend can share code with a remote micro-frontend and vice versa. I tend to discourage this practice because a unidirectional implementation brings several advantages, such as the following:</p> <ul> <li> <p>Code is easier to debug, as we know what code is coming from where.</p> </li> <li> <p>It\u2019s less prone to errors, as we have more control over our code.</p> </li> <li> <p>It\u2019s more efficient, as the micro-frontend knows the boundaries of each part of the system.</p> </li> </ul> <p>In the past, we have seen a similar approach with frontend architecture moving from a bidirectional data flow to a unidirectional one with the release of Facebook\u2019s Flux, which made developers\u2019 lives easier and the applications more stable. The same reasoning was applied to React and how we deal with props objects injected from the parent component to one or more child components. \u00a0Additionally, reactive architectures have fully embraced this pattern with interesting implementations, like Model-View-Intent (MVI) applied on Elm or Cycle.js.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#unidirectional-data-flow","title":"Unidirectional Data Flow","text":"<p>One of the more recent and largest revolutions in frontend architecture is the introduction of unidirectional data flow. Compared to previous architectures, such as Model-View-ViewModel, Model-View-Presenter, or even the popular Model-View-Controller, unidirectional data flow completely changed the evolution of many state management systems.</p> <p>Andr\u00e9 Staltz\u2019s website is a great resource for seeing how unidirectional data flow was applied in several recent frontend architectures. Staltz did an amazing job researching the topic and creating MVI, a fully reactive, unidirectional architecture based on RxJS Observables.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#developer-experience_2","title":"Developer experience","text":"<p>Webpack with Module Federation makes developers\u2019 lives easier, especially when they\u2019re familiar with the main tool.\u00a0 The people behind the plug-in did an incredible job abstracting all the complexity needed to create a smooth DX, and now developers can load asynchronously or synchronously shared code in the form of libraries or micro-frontends. Even better, Module Federation fits perfectly inside the webpack ecosystem and can be used with other plug-ins or configurations available in the webpack configuration file.</p> <p>By default, this plug-in produces small JavaScript chunks for every micro-frontend, enabling dependencies to be shared across micro-frontends when specified in the plug-in\u2019s configuration. However, when we use the optimization capability webpack offers out of the box, we can instruct the output to use fewer but larger chunks, maybe dividing our output in vendor and business logic files. These two files can then be cached in different ways, which is valuable since the business logic will be iterated more frequently than a project\u2019s external dependencies will be changed or upgraded.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#use-cases_2","title":"Use cases","text":"<p>Because this plug-in provides such extensive flexibility, we can apply to it any horizontal- or vertical-split micro-frontend use case. We can compose an application on the client or server side and then easily route using any available routing libraries for our favorite UI framework. Finally, we can use an event emitter library or custom events for communications across micro-frontends. Webpack with Module Federation covers almost all micro-frontends use cases, providing a great DX for every team or developer used to working with webpack.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#architecture-characteristics_1","title":"Architecture characteristics","text":"<p>Deployability (4/5)</p> <p>Webpack divides a micro-frontend into JavaScript chunks, making them easy to deploy in any cloud service from any automation pipeline. \u00a0And because they are all static files, they are highly cacheable. While we have to handle the scalability of the application servers responding to any client requests in an SSR approach, the ease of integration and rapid feedback are definitely big pluses for this approach.</p> <p>Modularity (4/5)</p> <p>This plug-in\u2019s level of modularity is very high, but so is its risk. If we\u2019re not careful, we can create many external dependencies across teams; therefore, we have to use Module Federation wisely to avoid creating organizational friction.</p> <p>Simplicity (5/5)</p> <p>Webpack\u2019s new system solves many problems behind the scenes, but the abstraction created by Module Federation makes the integration of micro-frontends very similar to other, more familiar frontend architectures like SPA or SSR.</p> <p>Testability (4/5)</p> <p>Although Module Federation offers an initial version of a federated test using Jest for integration testing, we can still apply unit and end-to-end testing similar to how we\u2019re used to working with other frontend architectures.</p> <p>Performance (4/5)</p> <p>With Module Federation, we gain a set of capabilities, such as sharing common libraries or UI frameworks, that won\u2019t compromise the final artifact\u2019s performance. Bear in mind that the mapping between a micro-frontend and its output files could be one to many, so a micro-frontend may be represented by several small JavaScript files, which may increase the initial chattiness between a client and a CDN performing multiple roundtrips for loading all the files needed for rendering a micro-frontend.</p> <p>Developer experience (5/5)</p> <p>This is probably one of the best developer experiences currently available for working with micro-frontends. Module Federation integrates very nicely in the webpack ecosystem, hiding the complexity of composing micro-frontends and enabling the implementation of more traditional features, taking care of tedious topics like code sharing and asynchronous import of our static artifacts or libraries.</p> <p>Scalability (5/5)</p> <p>Module Federation\u2019s approach makes scaling easy, especially when the application is fully client side. The static JavaScript chunks easily served via a CDN make this approach extremely scalable for a vertical-split architecture.</p> <p>Coordination (3/5)</p> <p>When we follow the decisions framework shared in the first chapters of this book in conjunction with Module Federation, we can really facilitate the life of our enterprise organization. However, the accessible approach provided by this plug-in can lead to abuse of the modularity, resulting in increased coordination and potential refactors in the long term.</p> <p>Table\u00a04-2 gathers the architecture characteristics and their associated score for this micro-frontend architecture.</p> <p>Table 4-2. Architecture characteristics summary for developing a micro-frontend architecture using webpack with Module Federation</p> <p>Architecture characteristics</p> <p>Score (1 = lowest, 5 = highest)</p> <p>Deployability</p> <p>4/5</p> <p>Modularity</p> <p>4/5</p> <p>Simplicity</p> <p>5/5</p> <p>Testability</p> <p>4/5</p> <p>Performance</p> <p>4/5</p> <p>Developer experience</p> <p>5/5</p> <p>Scalability</p> <p>5/5</p> <p>Coordination</p> <p>3/5</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#iframes","title":"Iframes","text":"<p>Iframes are probably not the first thing that comes to mind in relation to micro-frontends, but they provide an isolation between micro-frontends that none of the other solutions can offer.</p> <p>An iframe is an inline frame used inside a webpage to load another HTML document inside it. When we want to represent a micro-frontend as an independent artifact completely isolated from the rest of the application, iframes are one of the strongest isolations we can have inside a browser. An iframe gives us granular control over what can run inside it. The less-privileged implementation using the sandbox attribute prevents any JavaScript logic from executing or any forms from being submitted:</p> <pre><code>&lt;iframe\n</code></pre> <p>An iframe gives us access to specific functionalities, combining <code>sandbox</code> with other sandbox attribute values, such as <code>allow-forms</code> or <code>allow-scripts</code>, to ease the sandbox attribute restrictions, allowing form submission or JavaScript file execution, respectively:</p> <pre><code>&lt;iframe\n</code></pre> <p>Additionally, the iframe can communicate with the host page when we use the <code>post\u200bMessage</code> method. In this way, the micro-frontend can notify the broader application when there is a user interaction inside its context, and the application can trigger other activities, such as sharing the event with other iframes or changing part of the UI interface present in the host application.</p> <p>Iframes aren\u2019t new, but they are still in use for specific reasons and have found a place within the micro-frontend ecosystem. So far, the main use cases for implementing micro-frontends with iframes are coming from desktop applications and B2B applications, when we control the environment where the application is consumed. Note, though, that this approach is strongly discouraged for consumer websites because iframes are really bad for performance. They are CPU-intensive, especially when multiple iframes are used in the same view.</p> <p>A proposal for adding a ShadowRealm, a sandbox like iframes that is lighter and closer to modern web APIs, is in draft to the TC39, the committee responsible for evolving the ECMAScript programming language and authoring the specification. A ShadowRealm object would abstract the notion of a distinct global environment with its own global object, copy of the standard library, and intrinsics. This is the dynamic equivalent of a same-origin iframe without DOM. Basically, this is a lighter implementation of an iframes sandbox with the same isolation capabilities but without the performance issues that multiple iframes can have when rendered inside the same view.</p> <p>We can find a list of use cases where ShadowRealms can be used in the proposal repository. Sandboxing is just one of them, and there are some interesting scenarios possible. The proposal may never go beyond the draft stage, but it looks very interesting and could be a great fit for the micro-frontend ecosystem.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#best-practices-and-drawbacks","title":"Best practices and drawbacks","text":"<p>There are some best practices to follow when we want to compose micro-frontends in a horizontal split with iframes.\u00a0 First, we must define a list of templates where the iframes will be placed; having a few layouts can help simplify managing an application with iframes (see Figure\u00a04-21).</p> <p>Using templates allows your teams to understand how to implement their micro-frontends\u2019 UI and minimizes edge cases thanks to some guardrails to follow.</p> <p>Try to avoid too many interactions across micro-frontends; too many interactions can increase the complexity of the code to be maintained. If you need to share a lot of information across micro-frontends, iframes may not be the right approach for the project. This architecture allows teams to build their micro-frontends in isolation without any potential clash between libraries. However, to create a UI consistency, you will need to share the design system at build-time.</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-21-different-layouts-for-composing-micro-frontends-with-iframes-minimizing-the-number-of-iframes-in-a-page-would-result-in-better-performance-despite-there-being-an-intrinsic-performance-overhead-when-we-integrate-one-or-more-iframes-into-a-view","title":"Figure 4-21. Different layouts for composing micro-frontends with iframes. Minimizing the number of iframes in a page would result in better performance despite there being an intrinsic performance overhead when we integrate one or more iframes into a view.","text":"<p>Using iframes for responsive websites can be challenging, as dealing with a fluid layout with iframes and their content can be fairly complicated. Try to stick with fixed dimensions as much as you can. If fixed dimensions aren\u2019t possible, one of the other architectures in this chapter may work better for you.</p> <p>When you have to store data in webstorage or a cookie, use the webstorage or cookie in the application shell to avoid issues with retrieving data across multiple iframes. In this situation, communication between the host page and every micro-frontend living inside an iframe has to be well implemented and thoroughly tested.</p> <p>When using a pub/sub pattern between iframes and the host page, you have to share an event emitter instance between the main actors of a page. To do this, create an event emitter and append it to the iframe <code>contentWindow</code> object so that you can communicate via the emit or dispatch method across all the micro-frontends listening to it. Alternatively, you can rely on an open source library such as Poster, which abstracts the communication API between the host and every micro-frontend in an iframe:</p> <p>index.js</p> <pre><code>var\n</code></pre> <p>catalog-mfe.js</p> <pre><code>var\n</code></pre> <p>Frameworks such as Luigi from SAP provide solutions for the pitfalls listed so far, which we\u2019ll discuss in more depth in the \u201cAvailable framework\u201d section that follows.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#developer-experience_3","title":"Developer experience","text":"<p>Dealing with iframes makes developers\u2019 lives easier, considering the sandboxed environment they use. One of the main challenges of using this approach is with end-to-end testing, when retrieving objects programmatically across multiple iframes can result in a huge effort due to object nesting. Overall, a micro-frontend will be represented by an HTML entry point, with additional resources loaded such as JavaScript or CSS files\u2014very similar to what we are used to in other frontend architectures, like SPAs.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#available-framework","title":"Available framework","text":"<p>There aren\u2019t many options available for simplifying the developer experience of micro-frontends inside iframes; usually we can create an in-house strategy, or you can use Luigi framework. Luigi from SAP is a micro-frontends framework used for building intranet applications, which simplifies integration with SAP, but it also can be used outside an SAP context and provides a set of libraries for managing common challenges like routing or localization.</p> <p>The Luigi framework uses iframes for encapsulating micro-frontends and having a true sandbox around the code. Luigi is the main framework for applications that need to extract data from SAP and aggregate it in a more user-friendly interface. These applications are also mainly running in intranet environments, where it\u2019s possible to control which browser version a micro-frontend application runs in without needing to index the content on the main search engines. Given these things, iframes are probably a good fit for using some web standards without the need to create proprietary solutions to handle micro-frontend challenges. In fact, out of the box, Luigi provides a typical implementation for an enterprise application, composed in two main parts:</p> <p>Main view</p> <p>An application shell that provides an abstraction for handling authentication integration with an authentication provider, navigation between views, localization, and general application settings</p> <p>Luigi client</p> <p>A micro-frontend that can interact with the main view via a postMessage mechanism abstracted by the Luigi APIs and several other APIs to allow capabilities like web storage integration or life cycle hooks</p> <p>After implementing these two parts, a developer then can implement a micro-frontend without the risk of interfering with other parts of the application because the implementation uses iframes to create the requested isolation between key elements of the architecture (see Figure\u00a04-22).</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-22-a-micro-frontend-architecture-at-left-with-the-luigi-framework-is-composed-of-two-parts-the-main-view-and-a-luigi-client-the-luigijs-api-provides-an-abstraction-for-common-operations-such-as-communication-between-a-micro-frontend-and-the-host","title":"Figure 4-22. A micro-frontend architecture (at left) with the Luigi framework is composed of two parts: the main view and a Luigi client. The Luigi.js API provides an abstraction for common operations, such as communication between a micro-frontend and the host.","text":""},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#use-cases_3","title":"Use cases","text":"<p>Iframes are definitely not the solution for every project, yet iframes can be handy in certain situations. Iframes shine when there isn\u2019t much communication between micro-frontends and we must enforce the encapsulation of our system using a sandbox for every micro-frontend. The sandboxes release the memory, and there won\u2019t be dependency clashes between micro-frontends, removing some complexities of other implementations.</p> <p>Drawbacks include accessibility, performance, and lack of indexability by crawlers, so best use cases for iframes are in desktop, B2B, or intranet applications. For example, Spotify used to use iframes to encapsulate its micro-frontends in desktop applications, preventing teams from leaking anything outside an iframe while allowing communication between them via events. That helps a desktop application to not download all the dependencies for rendering a micro-frontend; they are all available with the executable download. If you have a desktop application to develop, then, and multiple teams will contribute to specific domains, iframes might be a possible solution. (Note that Spotify recently decided to add its web modular architecture to the desktop application to unify the codebase and allow reusability across multiple targets.)</p> <p>Many large organizations also use iframes in intranet applications as strong security boundaries between teams. For instance, when a company has dozens of teams working on the same project and it wants to enforce the teams\u2019 independence, iframes could be a valid solution to avoid code or dependency clashes without creating too many tools to work with.</p> <p>Imagine you have to build a dashboard where multiple teams will contribute their micro-frontends, composing a final view with a snapshot of different metrics and data points to consult. Iframes can help isolate the different domains without the risk of potential clashes between codebases from different teams. They can even prevent specific features inside an iframe using the sandbox attribute.</p> <p>The final use case is when we have to maintain a legacy application that isn\u2019t actively developed but is just in support mode and it has to live alongside the development of a new application, which will both have to be presented to users. In this case, the legacy application can be easily isolated in an iframe living alongside a micro-frontends architecture without the risk of polluting it.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#architecture-characteristics_2","title":"Architecture characteristics","text":"<p>Deployability (5/5)</p> <p>The deployability of this architecture is nearly identical to the vertical-split one, with the main difference being we will have more micro-frontends in the horizontal split because we will be dealing with multiple micro-frontends per view.</p> <p>Modularity (3/5)</p> <p>Iframes provide a good level of modularity, thanks to the ability to organize a view in multiple micro-frontends. At the same time, we will need to find the right balance to avoid abusing this characteristic.</p> <p>Simplicity (3/5)</p> <p>For a team working on a micro-frontend, iframes are not difficult. The challenge is in communicating across iframes, orchestrating iframe sizes when the page is resized without breaking the layout. In general, dealing with the big picture in absence of frameworks may require a bit of work.</p> <p>Testability (3/5)</p> <p>Testing in iframes doesn\u2019t have any particular challenges apart from the one described for horizontal-split architectures. However, end-to-end testing may become verbose and challenging due to the DOM tree structure of iframes inside a view.</p> <p>Performance (2/5)</p> <p>Performance is probably the worst characteristic of this architecture. If not managed correctly, performance with iframes may be far from great. Although iframes solve a huge memory challenge and prevent dependency clashing, these features don\u2019t come free. In fact, iframes aren\u2019t a solution for accessible websites because they aren\u2019t screen-reader-friendly. Moreover, iframes don\u2019t allow search engines to index the content. If either of these is a key requirement for your project, it\u2019s better to use another approach.</p> <p>Developer experience (3/5)</p> <p>The iframes DX experience is similar to the SPA one. Automation pipelines are set up in a similar manner, and final outputs are static files, like an SPA. The main challenge is creating a solid client-side composition that allows every team working with micro-frontends to test their artifacts in conjunction with other micro-frontends. Some custom tools for speeding up our teams\u2019 DX may be needed. The most challenging part, though, is creating end-to-end testing due to the DOM replication across multiple iframes and the verbosity for selecting an object inside it.</p> <p>Scalability (5/5)</p> <p>The content served inside an iframe is highly cacheable at the CDN level, so we won\u2019t suffer from scalability challenges at all. At the end, we are serving static content, like CSS, HTML, and JavaScript files.</p> <p>Coordination (3/5)</p> <p>As with all horizontal-split architectures, it\u2019s important to avoid too many teams collaborating in the same view. Thanks to the sandbox nature of iframes, code clashes aren\u2019t a concern, but we can\u2019t have interactions spanning across the screen when we have multiple iframes, because coordinating these kinds of experiences is definitely not suitable for this architecture.</p> <p>Table\u00a04-3 gathers the architecture characteristics and their associated score for this micro-frontend architecture.</p> <p>Table 4-3. Architecture characteristics summary for developing a micro-frontend architecture using horizontal split and iframes</p> <p>Architecture characteristics</p> <p>Score (1 = lowest, 5 = highest)</p> <p>Deployability</p> <p>5/5</p> <p>Modularity</p> <p>3/5</p> <p>Simplicity</p> <p>3/5</p> <p>Testability</p> <p>3/5</p> <p>Performance</p> <p>2/5</p> <p>Developer experience</p> <p>3/5</p> <p>Scalability</p> <p>5/5</p> <p>Coordination</p> <p>3/5</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#web-components","title":"Web Components","text":"<p>Web components are a set of web platform APIs that allow you to create custom, reusable, and encapsulated HTML tags for use in web pages and web apps. You may argue that web components are not the first thing that comes to mind when thinking about micro-frontends. However, they have interesting characteristics that make web components a suitable solution for building micro-frontend architecture. For instance, we can encapsulate our styles inside web components without fear of leaking in the main application. As well, all the major UI frameworks, like React, Angular, and Vue, are capable of generating web components, and the number of open source libraries to simplify creating this web standard is increasing, particularly with projects like Svelte, which can compile to web components, and LitElement from Google. Web components are also great tools for creating shared libraries for micro-frontend projects used with the same or different UI framework. In fact, in several 2019 surveys about the state of frontend development, web components were one of the most used solutions for building micro-frontends. They play a pivotal role in micro-frontend architecture, either for sharing components across micro-frontends or for encapsulating micro-frontends.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#web-components-technologies","title":"Web components technologies","text":"<p>Web components consist of three main technologies, which can be used together to create custom elements with encapsulated functionality that can be reused wherever you like without fear of code collisions.</p> <p>Custom elements</p> <p>They are an extension of HTML components. We can use them as containers of our micro-frontends, allowing us to interact with the external world via callbacks or events, for instance. Moreover, we can configure exposed properties to configure our micro-frontends accordingly when needed.</p> <p>Shadow DOM</p> <p>A set of JavaScript APIs for attaching an encapsulated \u201cshadow\u201d DOM tree to an element, rendered separately from the main DOM. In this way, you can keep an element\u2019s features private, so they can be scripted and styled without the fear of collision with other parts of the document.</p> <p>HTML templates</p> <p>The template and slot elements enable you to write markup templates that are not displayed in the rendered page. These can then be reused multiple times as the basis of a custom element\u2019s structure.</p> <p>Among these three technologies, custom elements and shadow DOM are those that make web components useful for micro-frontend architectures. Both elements allow encapsulation of the code needed in a subdomain without affecting the application shell. Custom elements are used as wrappers of a micro-frontend, while the shadow DOM allows us to encapsulate the micro-frontend\u2019s styles without causing them to override another style of micro-frontend.</p> <p>An important aspect to consider when we are working with web components as wrappers of our micro-frontends is avoiding domain logic leaks. The moment we are allowing the container of our micro-frontends, wrapped inside web components, to customize their behaviors, we are exposing the domain logic to the external world, causing the container of a micro-frontend to know how to interact with a specific API contract via attributes.</p> <p>It\u2019s essential to make sure the communication between a micro-frontend wrapped by a web component and the rest of the view happens in a decoupled and unified way. We may risk blurring the line between components and micro-frontends, where the former should be open to extension, while the latter should be close to extension but open to communication.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#compatibility-challenges","title":"Compatibility challenges","text":"<p>Before choosing web components for our next micro-frontend project, we need to take into consideration if the requirements are suitable for them. When we have to target many versions of web browsers, including the old ones and Internet Explorer, the only option provided by web components are polyfills. There are two ways for integrating polyfills for web components. The first is including them all. The package size would be quite large, but you are bulletproof, extending the retrocompatibility of your code for older browsers. The second option is loading at runtime only the polyfills needed. In this case, the package size is by far smaller, but it could require a bit of time before loading the right polyfills, considering we have to identify which ones are needed on the browser in which we are running the application.</p> <p>Another compatibility challenge to be aware of is that there are some bugs on WebKit engine that affect web components\u2019 customized built-in elements. Also, older versions of Safari (7 and 8, for instance) don\u2019t support <code>importNode</code> or <code>cloneNode</code> methods for appending HTML templates to the DOM. For more information about the web components\u2019 fragmentation across all the major browsers divided by vendor and version, I recommend checking out the Can I Use website.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#seo-and-web-components","title":"SEO and web components","text":"<p>When our micro-frontend project requires search engine optimization, dealing with web components may be nontrivial. In fact, the best way to allow a crawler indexing the content rendered inside a web component is exposing its content in the light DOM:</p> <pre><code>&lt;my-account-mfe&gt;\n</code></pre> <p>In this way, the vast majority of the crawlers available worldwide would be capable of indexing the content of your application. The usage of content inside the shadow DOM is discouraged when you deploy an application that should not be indexed only by major search engines like Google. Therefore, when a SEO is a key requirement for your micro-frontend project, dynamic rendering can be an option if you have to use web components.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#use-cases_4","title":"Use cases","text":"<p>Embracing web components for your micro-frontend architecture is a great choice when you need to support multitenant environments. Given their broad compatibility with all the major frameworks, web components are the perfect candidate for use in multiple projects with the same or different frontend stack, as with multitenant projects. In multitenant projects, our micro-frontends should be integrated in multiple versions of the same application or even in multiple applications, which makes web components a simple, effective solution.</p> <p>Let\u2019s say your organization is selling a customer-support solution in which the chat micro-frontend should be live alongside any frontend technology your customers use. Web components can also play an important role in shared libraries. In a design system, for instance, using a web standard allows you to evolve your applications without having to start from scratch every time, because part of the work is reusable no matter what direction your tech teams or business will take. This is a great investment to make.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#architecture-characteristics_3","title":"Architecture characteristics","text":"<p>Deployability (4/5)</p> <p>Loading web components at runtime is easily doable. We just need a CDN for serving them, and they can then be integrated everywhere. They are also easy to integrate with compile time integration; we add them as we import libraries in JavaScript. Although technically you can render them server side, the DX is not as sleek as other solutions proposed by UI frameworks like React.</p> <p>Modularity (3/5)</p> <p>Web components\u2019 high degree of modularity allows you to decompose an application into well-encapsulated subdomains. Moreover, because they are a web standard, we can use them in several situations without too many problems when we operate inside browsers that support them. The risk of using them as a micro-frontend wrapper is that it can confuse new developers who are joining a project, blurring the line between components and micro-frontends. This often results in a proliferation of \u201cmicro-frontends\u201d' in a view, but probably we should call them nano-frontends.</p> <p>Simplicity (4/5)</p> <p>Using web components should be a simple task for anyone who is familiar with frontend technologies. The main challenge is not splitting our micro-frontends too granularly. Because web components can also be used for building component libraries, the line between micro-frontends and components can be blurred. However, focusing on the business side of our application should lead us to correctly identify micro-frontends from components in our applications.</p> <p>Testability (4/5)</p> <p>Leveraging different testing strategies using web components doesn\u2019t present too many challenges, but we have to be familiar with their APIs. Web components\u2019 APIs differ from UI frameworks, making it challenging to do what we are used to doing with our favorite framework.</p> <p>Performance (4/5)</p> <p>One of the main benefits of web components is that we are extending HTML components, meaning we aren\u2019t making them extremely dense with external code from libraries. As a result, they should be one of the best solutions for rendering your micro-frontends client side.</p> <p>Developer experience (4/5)</p> <p>The DX of your projects shouldn\u2019t be too different from your favorite framework. You have to learn another framework to simplify your life, though there aren\u2019t too many differences in the development life cycle, especially in the syntax, but that\u2019s why there are web component frameworks for simplifying the developer\u2019s life.</p> <p>Scalability (5/5)</p> <p>Whether we implement our web components at compile or runtime, we will be delivering static files. A simple infrastructure can easily serve millions of customers without the bother of maintaining complex infrastructure solutions to handle traffic.</p> <p>Coordination (3/5)</p> <p>The main challenge is making sure we have the micro-frontends\u2019 granularity right, because this will impact application delivery speed and avoid external dependencies that may lead to developer frustrations. We need to have a strong sense of discipline when identifying what is represented by a component or by a micro-frontend.</p> <p>Table\u00a04-4 gathers the architecture characteristics and their associated score for this micro-frontend architecture.</p> <p>Table 4-4. Architecture characteristics summary for developing a micro-frontends architecture using web components</p> <p>Architecture characteristics</p> <p>Score (1 = lowest, 5 = highest)</p> <p>Deployability</p> <p>4/5</p> <p>Modularity</p> <p>3/5</p> <p>Simplicity</p> <p>4/5</p> <p>Testability</p> <p>4/5</p> <p>Performance</p> <p>4/5</p> <p>Developer experience</p> <p>4/5</p> <p>Scalability</p> <p>5/5</p> <p>Coordination</p> <p>3/5</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#server-side","title":"Server Side","text":"<p>Horizontal-split architectures with a server-side composition are the most flexible and powerful solutions available in the micro-frontend ecosystem, thanks to cloud, which is the perfect environment for developers wanting to focus on the value stream more than infrastructure operationalization. In the cloud, we have the agility to spin up the infrastructure as requests increase and reduce it again when traffic goes back to normal. We can also set up our baseline without too many headaches, focusing on what really matters: the value created for our users.</p> <p>Server-side composition is usually chosen when our applications have a strong requirement for SEO because this technique speeds up the page load time and the page is fully rendered without the need of any JavaScript logic. Server-side rendering also helps with the position of your application on search engine results pages, considering every search engine takes into account the page load speed.</p> <p>In a server-side composition, the final view is created on the server side, where we can control the speed of the final output using techniques like caching in different layers (e.g., in a service, in-memory, or CDN), reducing the hops between services to retrieve all the micro-frontends, as well as the type of compute used for running the logic to compose our micro-frontends. Nowadays we have all the tools and resources needed to impact how fast a view is composed and served to our users.</p> <p>Many of the challenges described in the horizontal split with client-side composition are challenges on the server side too, so rather than repeating them here, let\u2019s focus on a few additional challenges this approach creates.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#scalability-and-response-time","title":"Scalability and response time","text":"<p>Despite the infrastructure flexibility cloud provides, we have to set up the infrastructure correctly in the first place based on our application\u2019s traffic patterns. While a cloud provider\u2019s auto-scaling functionalities can help you to achieve this goal, the type of compute layer you choose will affect how fast you can ramp up your application. Containers are faster to run than virtual machines, and managed containers like serverless ones delegate the operationalization of our infrastructure to the cloud provider, so we just need to focus on comparing different services\u2019 implementations and plug-and-play options to achieve our goals.</p> <p>Of course, not all web applications behave in the same way, so there\u2019s a risk that our chosen auto-scaling solution will not be fast enough to copy with our specific traffic surges. A classic example would be the beginning of Black Friday sales or a global live event available only on our platform. In these cases, we would need to ensure that we meet the predictive load by manually increasing our solution\u2019s baseline infrastructure before the users join our platform.</p> <p>Another challenge we face with this architecture is understanding how we can speed up the response time of services and maybe microservices, and whether we need to consume them every time or if we can cache the response for specific micro-frontends instead of embracing eventual consistency. An in-memory cache solution like Redis can be a great ally in this situation, allowing us to store the microservice response for a short time, thereby increasing our micro-frontend composition\u2019s throughput. We can also store the entire micro-frontend DOM inside an in-memory cache and fetch it from there instead of composing it every time.</p> <p>Alternatively, we can use a CDN, which can increase a web page\u2019s delivery speed, reducing the latency between the client and the content requested.</p> <p>Latency, response time, cache eviction, and similar metrics become our measure of success in these situations, but creating the right infrastructure is not a trivial process, especially when there is a lack of knowledge or experience.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#infrastructure-ownership","title":"Infrastructure ownership","text":"<p>Composition layer ownership is another challenge with this architecture.\u00a0 In the best implementations, a cross-functional team of frontend and backend developers work together to manage the micro-frontend composition layer end to end. In this way, they can collaborate on the best outputs at the composition layer level, improving how data flows through it.</p> <p>Some companies may decide to split the composition layer from micro-frontend development. The risk here is that a frontend developer will be working in a silo, requiring additional mechanisms to keep the teams in sync to consolidate the integration of the two layers. Frontend developers must clearly understand what\u2019s going on in the composition layer and be able to help enhance it on code, infrastructure, monitoring, and logging levels. In this way, they can optimize the micro-frontend code written based on the implementation made in the composition layer.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#composing-micro-frontends_1","title":"Composing micro-frontends","text":"<p>Composing micro-frontends in a server-side architecture may deviate from what we have seen till now, but deviations are in the details, not the substance. As we can see from Figure\u00a04-23, the typical architecture is composed of three layers.</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-23-a-typical-high-level-architecture-for-a-server-side-micro-frontend-architecture-where-a-composer-is-responsible-for-stitching-together-the-different-micro-frontends-at-runtime-a-cdn-can-be-used-for-offloading-traffic-to-the-origin","title":"Figure 4-23. A typical high-level architecture for a server-side micro-frontend architecture, where a composer is responsible for stitching together the different micro-frontends at runtime. A CDN can be used for offloading traffic to the origin.","text":"<p>The three layers are as follows:</p> <p>Micro-frontends</p> <p>These can be deployed as static assets, maybe prepared at compile time during the automation pipeline, or as dynamic assets in which an application server prepares a template and its associated data for every user\u2019s requests.</p> <p>Composer</p> <p>This layer is used to assemble all the micro-frontends before returning the final view to a user. In this case, we can have an NGINX or HTTPd instance for leveraging SSI\u2019s directives or a more complex scenario leveraging Kubernetes and custom application logic for stitching everything together.</p> <p>CDN</p> <p>Whenever possible, you should add a CDN layer in front of your application server in order to cache as many requests as possible. And if you can cache a page for a few minutes, you can offload a lot of traffic from the composer and increase your web application\u2019s performance, thanks to the shorter roundtrip for the response.</p> <p>Many frameworks out there will do the undifferentiated heavy lifting of implementing this type of architecture. To choose the best one for your project, you\u2019ll have to understand the project\u2019s business goals to evaluate the frameworks against the business requirements and architecture characteristics you aim for.</p> <p>In the next section, I\u2019ll cover some of these frameworks so that you can see how they align with the pattern described above. However, every framework emphasizes different aspects than others, and not all the DXs are first class, so you may end up investing more time streamlining the DX before realizing the expected outcome from your chosen framework.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#micro-frontend-communication_1","title":"Micro-frontend communication","text":"<p>When you choose the server-side approach, you likely won\u2019t have many communications inside the view but instead have communication between the view and the APIs. This is because at the end, the page will reload after every significant user action on it. Still, there are situations in which one micro-frontend has to notify another that something happened in the session, such as a user adding a product to the cart. The micro-frontend that owns the domain will need to show the new product on a drop-down to show the user that the change was made in the cart. To accomplish this, we will add some logic on the frontend, and, using an event emitter or custom event, we will keep the micro-frontends loosely coupled while allowing them to communicate when something happens inside the application. In Figure\u00a04-24, we can see how this mechanism works in practice:</p> <ol> <li> <p>A user adds a product to the cart. This event is communicated to the backend, which acknowledges the added product within the user\u2019s session.</p> </li> <li> <p>The product micro-frontend notifies the checkout experience micro-frontend that a new product was added to the cart.</p> </li> <li> <p>The checkout experience micro-frontend fetches the new list of products in the cart and displays the new information in the UI.</p> </li> </ol> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-24-an-example-of-how-the-products-micro-frontend-notifies-the-checkout-experience-micro-frontend-to-refresh-the-cart-interface-when-a-user-adds-a-product-to-the-cart","title":"Figure 4-24. An example of how the product\u2019s micro-frontend notifies the checkout experience micro-frontend to refresh the cart interface when a user adds a product to the cart","text":"<p>There aren\u2019t many of these types of interactions per view in most web applications, so the code won\u2019t negatively impact performance or the maintainability of the final solution.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#available-frameworks_1","title":"Available frameworks","text":"<p>Some of the available frameworks for this category include Podium, Mosaic, Puzzle.js, and Ara Framework, with Mosaic probably being one of the most famous because it was one of the first open source frameworks to embrace this architecture style. Mosaic is really a collection of frameworks and tools made famous by Zalando, a fashion ecommerce site, one of the first to leverage the concept of micro-frontends. There are many forks of Tailor.js, the tool used to stitch together different HTML fragments in the Mosaic suite, which testifies how good the solution was. As of publication time, however, Zalando had decided to create a new version of Mosaic with a more opinionated approach based on React and GraphQL.</p> <p>To implement a micro-frontend architecture with a server-side composition, we explore the high-level architectures of a couple other frameworks that are currently in use by American Express (Amex), OpenTable, and Skyscanner, well-known brands that decided to scale their organizations and frontend development using micro-frontends. Then we\u2019ll spend some time revisiting a well-known approach, SSI, since it falls in this category and there are still organizations leveraging this approach for their micro-frontend applications.</p> <p>Amex released the open source project OneApp, a Node.js server used for serving server-side rendered micro-frontends on a single HTML page by using Holocron modules, another open source project from Amex. Every module represents a micro-frontend implementation with a set of utilities for simplifying the development experience, as well as for augmenting existing libraries such as Redux for store management. The view is a combination of Holocron modules called the Holocron roots.</p> <p>As we can see in Figure\u00a04-25, when a user requests a page, OneApp retrieves the associated root module, triggering the retrieval of the associated micro-frontends in order to render the final view. Next, the view is server-side rendered and served to the user. For performance reasons, the OneApp server periodically pulls the modules map JSON from the CDN, storing it in memory as a fast way to retrieve the module associated with a view without introducing too much latency in every request.</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-25-holocron-is-a-server-side-rendering-system-for-micro-frontends","title":"Figure 4-25. Holocron is a server-side rendering system for micro-frontends","text":"<p>The pain point of this architecture is the use of Redux as global state management for sharing the application state between micro-frontends. As discussed, every micro-frontend should be completely independent, but in Holocron this isn\u2019t the case. Instead, custom events are used for communication between micro-frontends. Although this isn\u2019t the most common communication technique for React applications, it\u2019s definitely a step closer to fully embracing micro-frontend principles. And because Holocron modules can be stored anywhere and don\u2019t necessarily need to be retrieved from a CDN, a virtual machine, an object storage, or a container may also be a suitable solution.</p> <p>OpenComponents is another micro-frontend framework for server-side horizontal-split architectures. This opinionated framework provides several features out of the box, including prewarming of a CDN via runtime agents, a micro-frontend registry, and tools for simplifying the DX. Every micro-frontend is encapsulated inside a computational layer completely isolated from the others. This approach enables each team to focus on the implementation of their own domain without taking into account the entire application. Moreover, every micro-frontend has a set of utilities, such as observability, monitoring, or dashboards. For managing burst traffic at specific times of the day, such as from a constant flow of people reserving tables at restaurants, the traffic prewarming the CDN in use is offloaded every time a new micro-frontend is created or when a change to an existing one is made (see Figure\u00a04-26).</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-26-the-opencomponents-architecture-shows-how-a-server-side-rendered-micro-frontend-is-flowing-from-development-to-an-environment","title":"Figure 4-26. The OpenComponents architecture shows how a server-side rendered micro-frontend is flowing from development to an environment","text":"<p>Interestingly, OpenComponents allows not only server-side rendering but also client-side rendering, so you can choose the right technique for every use case. When SEO is a key goal of a project, for example, you can choose SSR, while when you need a more SPA-like experience, you can use client-side rendering. Once again, you can see how all these frameworks had to make an investment in the developer experience to accelerate their adoption. As you compare frameworks, keep in mind that the vast majority of the time, these frameworks were built by midsize to large organizations, for which the final benefits definitely overcame the initial investment of resources and time.</p> <p>SSI are used for dividing a final view into multiple parts, usually called fragments, that are composed by a server before returning a static page to the client request. Back in the 1990s, SSI were used to decouple an HTML page\u2019s static content from other parts that may or not have been dynamic. SSI have directives\u2014placeholders that the server interprets in order to perform a specific action on a page. That action might be including a micro-frontend or running logic, like including different fragments based on specific parameters, such as providing different UIs based on the user status.</p> <p>SSI directives look like this:</p> <pre><code>&lt;!--# include virtual=\"acme.com/mfe/catalog\" --&gt;\n</code></pre> <p>In particular, the include directive is very important for micro-frontends because when the server interprets this directive, it will add the fragment into the final DOM. Figure\u00a04-27 summarizes how the logic applied by a server, like NGINX or HTTPd, composes micro-frontends using SSI.</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#figure-4-27-the-sequence-diagram-shows-how-a-client-request-is-handled-by-a-server-when-ssi-are-used","title":"Figure 4-27. The sequence diagram shows how a client request is handled by a server when SSI are used","text":"<p>When a client requests a page, the server retrieves the page containing the different directives. The server interprets all the directives and fetches the different fragments in parallel. When the directives are fully loaded, the server returns the final response to the client.</p> <p>Clearly, when a fragment takes time to return, the page\u2019s time to the first byte is affected. Luckily for us, we can set up timeouts as well as stub content to replace a fragment that times out or returns an empty body. Another challenge of this approach is avoiding overlaps in our CSS classes. As discussed before, creating prefixes for every class can help avoid undesired outcomes for your customers. Finally, it\u2019s important to highlight that SSI won\u2019t enrich your user\u2019s website experience, so you will need to add some JavaScript logic to the page to run on the client side if you want the benefits of both s and page interactivity.</p> <p>The main benefit of SSI is the server-side composition of the final page, which makes it easier for a search engine crawler to index the page. This is a plus for all server-side composition frameworks, but considering SSI were created several years ago, we can say they were the first technique to integrate this feature out of the box.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#use-cases_5","title":"Use cases","text":"<p>The typical use cases for this architecture are business-to-consumer (B2C) websites, for which the content has to be highly discoverable by search engines, or B2B solutions with modular layouts, such as dashboards where the user interface doesn\u2019t require too many drifts in the layout, as with a customer-facing solution. A tangible example of these types of implementations is OpenTable, an online restaurant-reservation service company based in San Francisco, with offices all over the world. The platform contains a host of tools that streamline the DX, making it easy to build micro-frontends thanks to OpenComponents.</p> <p>This architecture is recommended for B2B applications, with many modules that are reused across different views. It\u2019s important, however, that full stack or backend developers with the appropriate skills facilitate the introduction of this implementation. This architecture generally isn\u2019t a good choice for very interactive, fluid layouts, mainly due to the coordination needed across teams to create a cohesive final result or when there are bugs in production that may require more effort in discovering their root cause.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#architecture-characteristics_4","title":"Architecture characteristics","text":"<p>Deployability (4/5)</p> <p>These architectures may be challenging when you have to handle burst traffic or with high-volume traffic. When we decide to deploy a new micro-frontend, we\u2019ll also likely have to deploy some API to fetch the data, creating more infrastructure and configuration to handle. To limit the extra work and avoid production issues, automate repetitive tasks as much as possible.</p> <p>Modularity (5/5)</p> <p>This architecture key characteristic is the control we have over not only how we compose micro-frontends but also how we manage different levels of caching and final output optimization. Because we can control every aspect of the frontend with this approach, it\u2019s important to modularize the application to fully embrace this approach.</p> <p>Simplicity (3/5)</p> <p>This architecture isn\u2019t the easiest to implement. There are many moving parts, and observability tools on both the frontend and backend need to be configured so that you\u2019ll understand what\u2019s happening when the application doesn\u2019t behave as expected. Taking into account the architectures seen so far, this is the most powerful and the most challenging, especially on large projects with burst traffic.</p> <p>Testability (4/5)</p> <p>This is probably the easiest architecture to test, considering it doesn\u2019t differ too much from server-side rendering applications. There may be some challenges when we expect every micro-frontend to hydrate the code on the client side because we\u2019ll have some additional logic to test, but since we\u2019re talking about micro-frontends, it won\u2019t be too much additional effort.</p> <p>Performance (5/5)</p> <p>With this implementation, we have full control of the final result being served to a client, allowing us to optimize every single aspect of our application, down to the byte. That doesn\u2019t mean optimization is easier with this approach, but it definitely provides all the possibilities needed to make a micro-frontend application highly performant.</p> <p>Developer experience (3/5)</p> <p>There are frameworks that provide an opinionated way to create a smooth developer experience, but it\u2019s very likely you will need to invest time creating custom tools to improve project management and introducing dashboards, additional command line tools, and so on. Also, a frontend developer may need to boost their backend knowledge, learning how to run servers locally, scale them in production, work in the cloud or on premises efficiently, manage the observability of the composition layer, and more. Full stack developers are more likely to embrace this approach but not always.</p> <p>Scalability (3/5)</p> <p>Scalability may be a nontrivial task for high-volume projects because you\u2019ll need to scale the backend that composes the final view to the user. A CDN can work, but you will have to deal with different levels of caching. CDNs are helpful with static content, but less so with personalized ones. Moreover, when you need to maintain a low response latency and you aren\u2019t in control of the API you are consuming, you will have another challenge to solve on top of the scalability of the micro-frontend composition layer.</p> <p>Coordination (3/5)</p> <p>Considering all the moving parts included in this architecture, the coordination has to be well designed. The structure has to enable different teams to work independently, reducing the risks of too many external dependencies that can jeopardize a sprint and cause frustration for developers. Furthermore, developers have to keep both the big picture and the implementation details in mind, making the organization structure a bit more complicated, especially with large organizations and distributed teams.</p> <p>Table\u00a04-5 gathers the architecture characteristics and their associated score for this micro-frontend architecture.</p> <p>Table 4-5. Architecture characteristics summary for developing a micro-frontend architecture using horizontal split and server-side composition</p> <p>Architecture characteristics</p> <p>Score (1 = lowest, 5 = highest)</p> <p>Deployability</p> <p>4/5</p> <p>Modularity</p> <p>5/5</p> <p>Simplicity</p> <p>3/5</p> <p>Testability</p> <p>4/5</p> <p>Performance</p> <p>5/5</p> <p>Developer experience</p> <p>3/5</p> <p>Scalability</p> <p>3/5</p> <p>Coordination</p> <p>3/5</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#edge-side","title":"Edge Side","text":"<p>Edge Side Includes, or ESI, was created in 2001 by companies like Akamai and Oracle. It\u2019s a markup language used for assembling different HTML fragments into an HTML page and serving the final result to a client. Usually, ESI is performed at the CDN level, where it offers great scalability options because of the CDN\u2019s architecture. Different points of presence across the globe serve every user requesting static content. Every request is redirected to the closest point of presence, reducing the latency between the user and where the content is stored. Additionally, because CDNs are great for caching static assets, this combination of capillarity across the globe and cacheability makes ESI a potential solution for developing micro-frontends that don\u2019t require dynamic content, such as catalog applications.</p> <p>Another alternative for using ESI is using proxies like NGINX or Varnish, both of which offer ESI implementations. Unfortunately, ESI specifications are not fully supported everywhere. We often find only a subset of the features available in CDN provider or a proxy solution, which may compromise the flexibility needed for a business, reducing the possibility of the frontend architecture evolution. Moreover, the frontend community hasn\u2019t embraced this standard as it has with others, such as React, Vue, or Angular. The fragmentation between vendors, the lack of tools, and the friction on the developer experience have all played a pivotal role in the adoption of this technology.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#implementation-details","title":"Implementation details","text":"<p>As we said, every micro-frontend is composed with an HTML page as entry point with either a reverse proxy or a CDN provider. ESI language and composition are very similar to SSI, except that the markup is interpreted before the page is served to a client. ESI is composed by a template containing multiple fragments that represent, in this case at least, our micro-frontends. Here are the main functionalities:</p> <p>Inclusion</p> <p>ESI can compose pages by assembling included content, which is fetched from the network. The template uses transclusion to replace the placeholder tag within it with the micro-frontend it has retrieved.</p> <p>Variable support</p> <p>ESI supports the use of variables based on HTTP request attributes. These variables can be used by ESI statements or written directly into the processed markup.</p> <p>Conditional processing</p> <p>ESI allows conditional logic with Boolean comparisons to influence how a template is processed.</p> <p>Exception and error handling</p> <p>ESI allows you to handle errors or exceptions with alternative content to create a smoother user experience.</p> <p>This is how ESI looks before being served to a browser:</p> <pre><code>&lt;html&gt;\n</code></pre> <p>When the markup language is interpreted, the final result will be a static HTML page completely renderable by a browser.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#transclusion","title":"Transclusion","text":"<p>ESI uses a technique called transclusion for including existing content inside a new document without the need to duplicate it. In early 2000, this mechanism was used to reduce the cut-and-paste process that every developer was using to create web pages. Now we can use it to reuse content and generate new views based on simple constructs like conditional processing or variable support. This provides a useful mechanism to reduce the time it takes to build websites despite the poor developer experience.</p> <p>Client-side includes (CSI) also leverage transclusion, such as the h-include. Applying transclusion inside the browser uses the same logic for interpreting an ESI tag. In fact, each <code>&lt;h-include&gt;</code> element will create a request to the URL and replace the innerHTML of the element with the response of the request. Using CSI with ESI will help supplement ESI\u2019s limitation, adding the possibility of serving dynamic content inside a predefined template. In this way, we can use ESI to leverage a CDN\u2019s scalability. When we further combine this with JavaScript\u2019s ability to load HTML fragments directly on the client side, we can make our websites far more interactive.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#challenges_2","title":"Challenges","text":"<p>While ESI may seem like a viable option, there are some challenges to be aware of. First, ESI specifications are not implemented in all CDN providers or proxy servers the way Varnish and NGINX are. This lack of adoption increases the chance that you will have to evolve your infrastructure in the future. Your web application requires a certain resilience, and if you are considering a multi-CDN strategy, ESI probably won\u2019t be the right solution for you.</p> <p>Another problem that ESI won\u2019t solve is the integration of dynamic contents. Let\u2019s say you want to integrate personalized content in your micro-frontends. A caching strategy won\u2019t help because you may end up with a list of personalized content per user, and segmenting your content for a group of users may result in segments too large to be meaningfully cached by a CDN. In these cases, ESI should be integrated in conjunction with JavaScript running inside the browser and consuming some APIs. Depending on the business requirements, you might also use the CSI transclusion mechanism. CSI leverages the same mechanism as ESI but on the client side, so that once the application is loaded inside a browser, a JavaScript code will scan the DOM to find and replace tags and then mount new DOM elements instead of the placeholders. However, you may want to just load some DOM elements or even some external JavaScript files that would run the logic to render personalized content inside an ESI application. Obviously, all these roundtrips may impact micro-frontend application performance, so you\u2019ll want to find the right balance to implement micro-frontends with a combination of ESI and CSI, and you\u2019ll need to spend the time finding the best way to stitch everything together.</p> <p>Last but not least, ESI doesn\u2019t shine for a frictionless developer experience, with the poor adoption contributing to the lack of investment in this markup language.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#developer-experience_4","title":"Developer experience","text":"<p>The DX is one of ESI\u2019s main challenges. It\u2019s very important to create a smooth, functional environment for developers so that they can concentrate on developing new features, hardening algorithms, and, in general, striving in their daily job. However, ESI requires developers to use different tools to ensure the final result is the one expected by the user.</p> <p>Imagine we decide to embrace ESI and use Akamai for handling the transclusion at the CDN level. Akamai implements the full specifications for using ESI, but how would you test that locally? Akamai offers an ESI test server provided as a Docker container for local development and for integration with your automation pipelines. The testing server mimics the Akamai servers\u2019 behaviors when receiving a request, fetching the page to serve, interpreting the ESI tags, and serving the final HTML page to a browser. Other CDN providers don\u2019t implement the entire specification, so you risk using a technique that could end up with false positives and invalidate the quick feedback loop for your developers.</p> <p>Finally, this architecture is not widely embraced by the frontend community, resulting in a lack of documentation, tools, and support compared to more modern solutions described in this chapter.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#use-cases_6","title":"Use cases","text":"<p>One of the main use cases for edge-side composition is for managing large static websites where multiple teams are contributing to the same final application. The IKEA catalog was implemented in some countries using a combination of ESI and CSI in this way.</p> <p>Another potential application would be using ESI for the static part of a website and serving the rest with micro-frontends rendered at client side. This technique is also known as micro-caching, but it is complicated to put in place as well as to debug. Because of the poor developer experience, not many companies have implemented this technology, and despite its age, it has never seen the mainstream.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#architecture-characteristics_5","title":"Architecture characteristics","text":"<p>Deployability (3/5)</p> <p>Similar to the client-side composition, this approach guarantees an easy deployment and artifacts consumptions via CDN.\u00a0Because we are talking about a horizontal split, we need to increase the effort of managing potential network errors that would prevent a micro-frontend from being composed on the CDN level. Finally, not all the CDN supports ESI, which could be a problem in the long run for your project, especially when you have to change CDN providers. However, managing multiple environments and deploying micro-frontends in local environment is not a smooth experience.</p> <p>Modularity (4/5)</p> <p>Transclusion facilitates modular design, so we can reuse micro-frontends in multiple pages. ESI becomes even more interesting when mixed with CSI, covering the static parts with ESI and the more dynamic ones with CSI.</p> <p>Simplicity (2/5)</p> <p>If horizontal-split architectures can become quite complex in the long run, the edge-side ones can be even more complex because of the poor developer experience and the need of a CDN or Varnish to test your code.</p> <p>Testability (3/5)</p> <p>ESI doesn\u2019t shine in testing either. Unit testing may be similar to what we\u2019re used to implementing for other architectures, but to implement an integration and end-to-end testing strategy, we need to rely on a more complex infrastructure, which could slow down the feedback loop for a team.</p> <p>Performance (3/5)</p> <p>Since ESI is a composition on the CDN level most of the time, the application can have great performance out of the box thanks to the cache for static content. However, we need to consider that when a micro-frontend hangs due to network issues, none of the pages will be served until the request timed out\u2014not exactly the best customer experience.</p> <p>Developer experience (2/5)</p> <p>The DX of any solution is a key factor in adoption; the more complicated a solution is, the less developers will embrace it. ESI is definitely a complicated solution. To locally test your implementation, you will need a Varnish, NGINX, or Akamai testing server inside a virtual machine or a docker container. And if you are using a CDN, be ready for a long feedback loop on whether your code is behaving correctly. There are other tools available, but it\u2019s still a clunky experience compared to the other architectures.</p> <p>Scalability (4/5)</p> <p>If your project is static content, ESI is probably one of the best solutions you can have, thanks to the composition at the CDN level. And with a mix of static and dynamic content, using ESI in conjunction with CSI, the scalability of your solution will be bulletproof.</p> <p>Coordination (3/5)</p> <p>Edge-side composition allows you to leverage micro-frontend principles, allowing you to have independent teams and artifacts. However, due to the poor DX, you may need more coordination across teams, especially when there are changes in the production environment that affect all the teams. Similar to the recommendation for server-side composition, plan your team structure accordingly and be sure to iterate to validate decisions.</p> <p>Table\u00a04-6 gathers the architecture characteristics and their associated score for this micro-frontend architecture.</p> <p>Table 4-6. Architecture characteristics summary for developing a micro-frontends architecture using horizontal split and edge-side composition</p> <p>Architecture characteristics</p> <p>Score (1 = lowest, 5 = highest)</p> <p>Deployability</p> <p>3/5</p> <p>Modularity</p> <p>4/5</p> <p>Simplicity</p> <p>2/5</p> <p>Testability</p> <p>3/5</p> <p>Performance</p> <p>3/5</p> <p>Developer experience</p> <p>2/5</p> <p>Scalability</p> <p>4/5</p> <p>Coordination</p> <p>3/5</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Chapter%204.%20Discovering%20Micro-Frontend%20Architectures/#summary","title":"Summary","text":"<p>In this chapter, we have applied the micro-frontend decisions framework to multiple architectures. Defining the four pillars (defining, composing, routing, and communicating) offered by the micro-frontends decisions framework helps us to filter our choices and select the right architecture for a project. We have analyzed different micro-frontend architectures, highlighting their challenges and scoring the architecture characteristics so that we can easily select the right architecture based on what we have to optimize for. Finally, because we understand that the perfect architecture doesn\u2019t exist, we realized that we have to find the less worse architecture based on the context we operate in. In the next chapter, we will analyze a technical implementation and focus our attention on the main challenges we may encounter in a micro-frontend implementation.</p> <ul> <li>Support</li> <li>Sign Out</li> </ul> <p>\u00a92022 O'Reilly Media, Inc.\u00a0</p> <ul> <li>Terms of Service</li> <li>Privacy Policy</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Delivery%20Models/","title":"Delivery Models","text":"<ol> <li>Product strategy. A written strategy which outlines the environment and way forward.</li> <li>Standards. Rules that define guardrails in team behavior and force conversations about non-standard choices.</li> <li>Tenets. Mental shortcuts to help people globally make tradeoff decisions.</li> <li>Goal frameworks. A way to set goals that attempt to be coherent across the organization, and translate across the functions to coordinate work.</li> <li>Metrics. Track numbers to drive particular outcomes, add observability, or force attention to an area.</li> <li>Centralized/decentralized prioritization. Cut through cross-team projects gridlock by providing prioritization for critical projects and a way to break ties in prioritizations between decentralized teams.</li> </ol> <p>https://www.rubick.com/coordination-models/</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Delivery%20Models/#roles","title":"Roles","text":"<ol> <li>Program manager. A role that runs programs (projects containing projects) and coordinates efforts across teams.</li> <li>Integrator. A role that solicits information from a broad variety of sources and synthesizes them into prioritization and plans.</li> <li>Controller. A role that has explicit authority to demand behavior in a particular arena.</li> <li>Standard definer. A role that defines guidelines and guardrails that constrain behavior that can be done without discussion.</li> </ol> <p>https://www.rubick.com/coordination-models/</p>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Delivery%20Models/#the-flow","title":"The flow","text":"<p>A person in flow state is no longer thinking of multiple things, or even their sense of self, but is singularly focused on a task or challenge. Many people report it is the happiest feeling in their lives.</p> <p>Being in the flow is the state when people are more efficient</p> <ul> <li>You can concentrate for an extended period of time</li> <li>The task has a clear goal</li> <li>You receive immediate feedback on your progress</li> <li>You feel a sense of control</li> <li>You\u2019re absorbed, and it feels effortless. You\u2019re singularly focused instead of focused on many things and distracted</li> <li>Your sense of time is altered; time passes quickly or it is slowed in a good way</li> <li>You don\u2019t feel self-conscious, and your sense of self emerges stronger</li> <li>You desire to repeat the task</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/Microfrontends/Quotes-and-references/Delivery%20Models/#getting-people-in-the-flow","title":"Getting people in the flow","text":"<ol> <li>Communicate purpose</li> <li>Define purpose</li> <li>Challenging work, but not impossible</li> <li>Split work into doable goals</li> <li>Build trust, and give people sense of control over their work</li> <li>People can make changes, if accidents happen we find a fix to the situation</li> <li>fast feedback cycles: A person in flow state should get immediate feedback on their process. </li> <li>Technical feedback (lint, tests, etc)</li> <li>Human feedback (Know if we are on track with our work or if something needs to be adjusted)</li> <li>A person will struggle to reach flow state if they are not compensated fairly.</li> <li>Salary</li> <li>Promotion</li> <li>Clear expextations of what will take to get a team member to the next level.</li> <li>A manager has to believe in their staff. </li> <li>The Pygmalion effect. This is when our belief in each other\u2019s potential brings that potential to life. </li> </ol> <p>Source: https://leaddev.com/culture-engagement-motivation/why-flow-matters-more-passion</p> <p>Wrong abstractions work against this goal. Right abstractions help us to achieve it.</p> <p>Abstractions can give us optionality. And optionality enables us to react to new challenges and changing requirements faster.</p> <p>I think there is so much poor code out there because we somehow got convinced that things like refactoring and testing are extras. Things that we can do later. They are not! They are part of a professional coding workflow!</p> <p>https://future.a16z.com/the-case-for-developer-experience</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Need%20to%20know%20-%20Hight%20risk%20groups/","title":"Need to know   Hight risk groups","text":"<ul> <li>Notably, however, anyone passionate about what they do is at high risk of burnout, especially high performers. \"Because I love and appreciate my work, my mental \u201cimmune system\u201d had nothing to reject.\"</li> <li>Underrepresented groups are at high risk because on top they have to manage micro aggressions Clark says, \u201cBurnout for white, upper-middle-class millennials might be taxing mentally, but the consequences of being overworked and underpaid while managing micro aggressions toward marginalized groups damages our bodies by the minute with greater intensity</li> <li>Another at-risk group for burnout is working parents, especially as the number of families in which both parents worked outside the home doubled over the last 30 years.</li> <li>Women report higher levels of burnout. One study identified gender inequalities in the workplace as a key element that\u2019s impacting occupational mental health. Women were found to have lower levels of decision-making authority and were often overqualified for their roles, which ultimately leads to less satisfaction at work and a sense that they have fewer career alternatives. We see this frustration all the time, and it often manifests in beating oneself up. Women often think it\u2019s their own fault that they\u2019re not thriving.</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Need%20to%20know%20-%20what%20is%20burnout/","title":"Need to know   what is burnout","text":"<p>Maslach, Leiter, and Jackson defined burnout as a \u201cpsychological syndrome emerging as a prolonged response to chronic interpersonal stressors on the job. The three key dimensions of this response are overwhelming exhaustion, feelings of cynicism and detachment from the job, and a sense of ineffectiveness and lack of accomplishment.\u201d Although these three dimensions\u2014exhaustion,\u00a0cynicism, and\u00a0professional efficacy\u2014helped us understand the negative outcomes of burnout, it remained a challenge to reliably detect them in ourselves and others.</p> <p>https://learning.oreilly.com/library/view/hbr-guide-to/9781647820015/Text/08_Introduction__Rethinking_Burnout.xhtmlpage_6</p> <p>WHO</p> <p>Burn-out is .\u00a0.\u00a0. an occupational phenomenon. It is\u00a0not\u00a0classified as a medical condition.</p> <p>Burn-out is a syndrome conceptualized as resulting from chronic workplace stress that has not been successfully managed. It is characterized by three dimensions:</p> <ul> <li>feelings of energy depletion or exhaustion;</li> <li>increased mental distance from one\u2019s job, or feelings of negativism or cynicism related to one\u2019s job; and</li> <li>reduced professional efficacy.</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20%20what%20to%20do%20-%20individual/","title":"Notes from research    what to do   individual","text":"<ul> <li>Blue: Truly living in the moment, present, balanced, weightless.</li> <li>Green: Energized, happy, flow state. Helping other people be their best.</li> <li>Yellow: Some stress, but manageable, nothing totally broken, most important things done, didn\u2019t cause anyone serious delay.</li> <li>Orange: Incapable of doing deep work, basic functioning, might be able to get 1 personal thing done. Might be causing someone a delay.</li> <li>Red: Cognitive delays, borderline burnout, definitely not serving the team well.</li> <li>Dark Red: Depressed, need time off.</li> </ul> <p>might wanna mention in the beginning who the audience is</p> <p>eI think depending on the position, the strategy of dealing with burnout can be quite different. Manager/Developer/Service Worker etc...</p> <p>\"Happiness is reality divided by expectations\" Alden Cass.can instead be explained by the</p> <p>level of \u201cmismatch\u201d between an individual and six strategic areas of the workplace: workload, control, reward, community, fairness and values.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20%20what%20to%20do%20-%20individual/#internal-causes-individual","title":"Internal causes: Individual","text":"<ul> <li>Age or experience:  the research raises as many questions as it answers and invites more investigation to determine how reliable age and years of experience are as predictors of burnout.</li> <li>Personality: we might conclude that while research of this nature provides us with some insight into the linkage between personality and burnout, it also raises a number of questions as to how universally applicable the findings are.</li> <li>Locus of control: Locus of control has to do with an individual\u2019s beliefs about the future and who or what has the power to control future events. Studies have shown workers are more vulnerable to stress and burnout when their locus of control is external</li> <li>Marital status: On the effects of marriage on burnout, however, research has shown mixed results.these studies often raise as many questions as they answer and call for more investigation.</li> <li>Gender: In other words, men and women have been found to suffer from both mental and physical health problems when forced to endure chronic stress on the job. </li> <li>Work-home interference: \u201cInterference\u201d happens when a work deadline requires an individual to forgo a family gathering (external interference) or when one cannot stop thinking about or being preoccupied by work (internal interference). Individuals with this particular problem cannot participate fully in and enjoy home life, and find recovery from the stresses of the workday much more difficult. In contrast, when matters from one\u2019s home life interfere negatively with one\u2019s work life, researchers refer to this as home\u2013work interference (HWI). HWI affects the ability to think, concentrate and perform tasks in the workplace as required </li> <li>Expectations:  the gulf between expectations of what a job will be like and what a job is actually like is generally responsible for the burnout. \"Happiness is reality divided by expectations\" Alden Cass.</li> <li>\u201crealistic job preview\u201d (RJP) and \u201cexpectation lowering procedures\u201d (ELP) in order to \u201cadjust\u201d the expectations of potential and new employees.</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20%20what%20to%20do%20-%20individual/#measures-that-are-in-our-individual-control","title":"Measures that are in our individual control","text":"<p>Yet it is not in our control to address the underlying cause and mitigate the causing problem, it is in our control what boundaries that protect our mental, physical, and emotional health.  </p> <p>These boundaries can be different from person to person, generally speaking I would suggest.</p> <ul> <li>Raise the red flag in your organization</li> <li>Set your boundaries, putting a drastic limit on the things that have caused your burnout. </li> </ul> <p>Truth is, if you are facing burnout, stakes are high that you are as well feeling guilty, that you were not good enough to handle the situation. What I can tell you, and what books and research show about this is: you are not alone, it is common that people who face burnout feel this way. </p> <p>The feeling of guilt could be a mix of two things: the story that you tell to yourself about burnout (ie: \"I am not good enough, others could have managed\"), and/or how your colleagues and supervisors address the situation (ie: \"You are over reacting\", \"You should have asked for help\", \"You are not good enough\"). </p> <p>In either of both cases: The story you are telling to yourself, and the story that your colleagues, bosses might be telling you, if they go in the direction of: You are responsible and you are not good enough, let me tell you: It is not true.</p> <p>Yet you might lack of one or other skill, yet could be that another person might be able to handle the workload better than you are, but the fact that an employee is in burnout is an organizational issue. It should have never reached this level, and your organization, and your supervisor are responsible of looking after you, and providing you with a work environment where everyone is productive, whatever that means for each individiual.</p> <p>Steps to get out</p> <ul> <li>Take time to unwind, take time off</li> <li>Identify the cause, keep a stress diary</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20%20what%20to%20do%20-%20individual/#action-tips","title":"Action tips","text":"<p>Meditation is proven to provide us with enough internal resources to unwind, and respond to life situations in a healthy manner. It is medicine for the mind.</p> <p>With burnout come negative thoughts about our professionalism, about us not being enough, or just feeling bad. For that, what has worked for me the best is to practice self compassion, here is a set of guided meditations to chose from, that I recommend you. </p> <p>https://self-compassion.org/category/exercises/</p> <ul> <li>Routine that marks the beginning of the work day</li> <li>Routine that marks the end of the work day. </li> <li>Excersice daily</li> <li>Cook my meals</li> <li>Keep a stressors diary: date, time, situation, scale, symptoms, efficiency and reaction</li> <li>Decrease factors that give me stress</li> <li>Manage your energy, not your time (https://learning.oreilly.com/library/view/hbrs-10-must/9781647822521/12572/OEBPS/xhtml/09_Manage_Y.xhtml)</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20%20what%20to%20do%20-%20individual/#actions-for-the-individual-per-job-domain","title":"Actions for the individual per job domain","text":"<p>https://learning.oreilly.com/library/view/managing-burnout-in/9781843347347/xhtml/B9781843347347500086.htm#st0065</p> <ul> <li>Workload: </li> <li>self-awareness and self-monitoring are critical in preventing burnout, and when tackling the problem of workload, workers need to know what fires them up about the job and what, on the other hand, drains them of energy. Is it simply a case of too much work? Are deadlines too severe? Is it the type of work?</li> <li>Fix: limit hours</li> <li>Fix: learn to say no (dont take in more work) <ul> <li>or say a conditional no, </li> <li>or sleep on it no. </li> <li>alternative solution no</li> <li>secret weapon no (saying no without explaining why)</li> </ul> </li> <li>Fix: delegate</li> <li>Fix: manage time wisely<ul> <li>prioritize week's work</li> <li>minimize notifications and interruptions</li> <li>schedule down time</li> <li>periodically evaluate commitments</li> <li>take vactions</li> </ul> </li> <li>Fix: Break routines<ul> <li>for example, incorporating new activities into the work day or carrying out old activities in different ways or at different times is a start. Employees who eat lunch at their desk each day while trying to work not only have no chance to unwind, but they risk the physical problems which result when eating while under stress. As Ashley Koff, RD, a Los Angeles dietitian, notes,</li> <li>do hobby during lunch break</li> <li>work at different times</li> <li>incorporate non brain activities if you are a mind worker</li> </ul> </li> <li> <p>Fix: increase resilience</p> <ul> <li>eat healthy</li> <li>Get enough sleep</li> <li>Excersice</li> <li>Employ relaxation techniques</li> </ul> </li> <li> <p>Control</p> </li> <li>Autonomy: <ul> <li>Identifying the type of control which is absent in the environment and then responding accordingly. </li> <li>building a record of exceptional performance on the job and earning the trust of management.</li> <li>Volunteering to take more control is also an option.</li> <li>the way an employee might achieve more autonomy in the workplace is through external validation. Volunteering for professional associations, </li> </ul> </li> <li>Supervision<ul> <li>Creative control involves keeping the boss up to date on innovation, new ideas or new concepts</li> <li>Critical control involves taking more interest in job performance and working with the supervisor to enhance quality in the workplac</li> <li>supportive control involves paying more attention to the supervisor and communicating more about frustrations and accomplishments in an attempt to model supportive behavior</li> </ul> </li> <li>Reward</li> <li>Ask for salary increase or promotion</li> <li>Ask for feedback from supervisor when acknowledgment is the issue</li> <li>Bring accomplishments to the eyes of others</li> <li>Seek validation beyond the workplace</li> <li>Or change jobs</li> <li>Community</li> <li>first step determining who the problems are \u2013 co-workers, supervisors and/or clients \u2013 and where the solution might lie.</li> <li>building a better community starts with better communication and by reaching out to others in the workplace.</li> <li>build better relationships in the workplace and to create alliances.</li> <li>Fairness and respect</li> <li>first ways to address incidents of disrespect or discrimination is to talk about the incident with the offending party, or when that does not change the behavior, to talk to a supervisor.</li> <li>Values</li> <li>Find a source of meaining inside or outside the job</li> </ul> <p>[b]urning out may literally save our lives by stopping us before we suffer a more serious or fatal illness. It operates like a circuit breaker that keeps the whole system from blowing. On another level, burnout saves our life by showing us how and when our life lost its old meaning and by forcing us to do something about it. We may not save our old life, but we can free ourselves to be more fully alive. (p. 57)</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20-%20what%20to%20do%20-%20workplace/","title":"Notes from research     what to do   workplace","text":"<p>Burnout is an organizational issue. If you are facing burnout, is not in your entire responsibility to fix it, the fact that you have it is a symthom of a systematic issue that happens in your workplace, and it is a major red flag.</p> <p>The Always-On manager fails to take time to step back and think strategically about their role. They can only see trees and not the forest. As a result, their department never has the desired impact on the business's bottom line, and the team burns out, one at a time.</p> <p>https://medium.com/management-matters/the-mangers-driving-the-great-resignation-29406ae74c56</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20-%20what%20to%20do%20-%20workplace/#environmental-causes-organization","title":"Environmental causes: Organization","text":"<p>can instead be explained by the level of \u201cmismatch\u201d between an individual and six strategic areas of the workplace: workload, control, reward, community, fairness and values.</p> <ul> <li>Feelings of lack of control:</li> <li>An employee is said to have control when she is able to participate in and influence workplace decision-making and is also able to exercise professional autonomy. Control has to do not only with how and when the job is done, but also how much leeway employees have in determining when they can take a break or when they can schedule their vacation</li> <li>In terms of burning out, workers who feel they have little job autonomy or control are at greater risk (Paine, 1982; Glass et al., 1993). Lack of control can take a number of different forms including supervisors who micromanage or organizations that do not allow employees to participate in policy or other work-related decisions (Glass et al., 1993). Lack of control is particularly stressful in an environment in which downsizing and job restructuring are taking place.</li> <li>fix: Give more control to people, autonomy and power of decision making</li> <li>Role conflict or role ambiguity: </li> <li> <p>Role ambiguity is a term used to  describe the lack of clarity, certainty and/or predictability one might  have expected with regards to behaviour in a job (due, perhaps to an  ill-defined or ambiguous job description and/or uncertain organizational objectives). </p> <p>Employees who work hard on what they think is an important project only to find it shelved or placed on the back burner, as well  as employees who don\u2019t understand the scope and parameters of their job, the goals they should be pursuing, and what their priorities should be  are more likely to suffer from role ambiguity.</p> <p>In contrast, role  conflict involves competing and incompatible demands placed on an  employee. This can involve the sometimes contradictory demand of being  both a supervisor and a friend, the irreconcilable demands of providing  good service while striving to reduce costs, or the difficulties of  doing a job which is at odds with one\u2019s own values. Where role conflict  and role ambiguity are high, high levels of burnout are also found (Tunc and Kutanis, 2009).</p> <p>https://learning.oreilly.com/library/view/managing-burnout-in/9781843347347/xhtml/B9781843347347500025.htm#st0095</p> </li> <li> <p>Lack of support from management:  Leadership style in terms of credibility has to do with the extent to which workers feel they can trust the person in charge.</p> </li> </ul> <p>Where workers feel they can trust their managers/supervisors, they are less likely to question managerial objectives or to refrain from volunteering to take on additional work required to accomplish these objectives. Where leadership credibility is low, the extent to which employees are burned out is likely to be higher</p> <ul> <li>Social support: </li> <li>Part of social support concerns appreciation and is a major buffer against stress.  People who feel unappreciated almost never reach out to show appreciation of someone else\u2019s work. Our experience has shown that one of the best ways for individuals to encourage others to pay attention to their work is to start acknowledging the good work of others. peer appreciation (which is easy to institute) reduces the need for approval from above (which is frequently difficult, if not impossible, to institute).</li> <li>Younger employees need more social support from their supervisors to reduce stress. They tend to rely far more on assistance and encouragement from their supervisors to help buffer higher levels of job stress.</li> <li>Have good social support and a network of people with similar interest have lower scores on emotional exhaustion</li> <li>Conflict: Although conflict may occur for many reasons, the feeling that one has too much work and too few resources with which to carry it out is likely to contribute to interpersonal conflict in the workplace</li> <li>fix: social support</li> <li>Reciprocity: </li> <li>Reciprocity involves the amount an individual invests in a particular relationship with another and whether, and to what extent, that investment is returned. In the case of workers who feel they are contributing more to relationships with clients, patrons, patients, etc. than is being returned, there is an increased risk of burnout. But a perceived lack of reciprocity may exist not only with the recipients of one\u2019s care but also with colleagues. The later contributes a lot to burnout, and by colleagues also mean: supervisors. Indeed, employees who feel a lack of reciprocity with their employing organization have been found to experience an even greater distress than when that lack of reciprocity exists with patients and co-workers</li> <li>employees are expected to give more in terms of time, effort, skills, and flexibility, whereas they receive less in terms of career opportunities, lifetime employment, job security, and so on. Violation of the psychological contract is likely to produce burnout because it erodes the notion of reciprocity, which is crucial in maintaining well-being.</li> <li>Underwork:  Underwork has been described in a number of ways including not being challenged enough on the job, or not having enough work to do, or lacking interest in the tasks that need to be done, or trying to look busy because there is not enough work. Certain experts who deal with the syndrome call it \u201cboreout\u201d \u2013 a syndrome with symptoms almost identical to burnout but which is differentiated by the fact that it afflicts the under-challenged </li> <li>Leadership style: There is an established link between type of leadership style, negative emotions, stress and burnout. </li> <li>employees working with a transformational leader rather than a transactional leader are less likely to see an impending stressor as threatening. Transformational leadership has been found to increase well-being and job satisfaction, and to decrease burnout in employees </li> <li>A transformational leadership style is one in which the leader attempts to inspire and motivate by appealing to an individual\u2019s sense of self-worth in addition to other unique emotional and developmental needs. </li> <li>transactional leadership is of these types: contingent reward, management by exception-active, and management by exception-passive<ul> <li>Contingent reward\u201d involves the provision of a reward (money, positive feedback, commendation) in exchange for good job performance</li> <li>\u201cManagement by exception\u201d may be active or passive. In the active form, the leader monitors an employee\u2019s work, and if job performance deviates from expected performance standards, correction in the shape of negative feedback, discipline or punishment takes place. </li> <li>In the passive form, the leader is not actively involved in the monitoring of work, and only steps in when any deviation is brought to his or her attention</li> </ul> </li> <li>Unmanageable workload &amp; time pressure: they contribute strongly to emotional exhaustion. Overload is bad for both the individual and the organization \u2013 the quality of work drops, co-workers have no time for collegiality or to build community, and morale and motivation suffer.</li> <li>When to know? If it's hard to find relief at work. If restful moments between events are gone, and each demand rolls in the next one. When this happens exhaustion builds up, additional demands are not manageable and  the current scramble for survival often results in a shortage of resources. </li> <li>Workload can be of two types \u2013 either quantitative (e.g., high job demands with too little time in which to carry out those demands) or qualitative (e.g., jobs with a great deal of complexity or requiring a great deal of concentration</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20-%20what%20to%20do%20-%20workplace/#organizational-issue","title":"Organizational issue","text":"<p>Burnout is an organizational issue. If you are facing burnout, is not in your entire responsibility to fix it, the fact that you have it is a symthom of a systematic issue that happens in your workplace, and it is a major red flag.</p> <p>as employees, are not responsible for solving it. Still, it is not entirely out of our control. We can choose to set boundaries that protect our mental, physical, and emotional health. The challenge is that our efforts to do so are often hijacked by guilt.</p> <p>https://egn.com/dk/wp-content/uploads/sites/3/2020/08/Burnout-is-about-your-workplace-not-your-people-1.pdf</p> <p>overload the most capabale: The overload problem is compounded for companies because the best  people are the ones whose knowledge is most in demand and who are often  the biggest victims of collaboration overload. </p> <p>...</p> <p>Giving people the time to do work that drives the company\u2019s success will pay huge dividends by raising productivity, increasing productive  output and reducing burnout. Everybody wins.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20-%20what%20to%20do%20-%20workplace/#organizational-measures","title":"Organizational measures","text":"<p>https://learning.oreilly.com/library/view/managing-burnout-in/9781843347347/xhtml/B9781843347347500086.htm#st0095</p> <p>This is a post focused mainly on the individual, rather than the organization. However, provided most of the causes of burnout have origin in the organization, some actions that the organization can look at, in order to address properly are:</p> <ul> <li>Define roles</li> <li>Prioritize work</li> <li>Work on important non urgent things</li> <li>Provide people more control, for example over:  autonomy, opportunity for promotion, feedback and social  support</li> <li>Adjust organizational structures and routines, decrease decision nodes, to address excessive collaboration</li> <li>Evaluate leadership style of managers, target to transformational service leadership</li> <li>Workload:</li> <li>Reduce workload<ul> <li>if not possible workload is expected to be busier than usual, but only temporarily, managers need to let employees know what has brought about this change, how long the increased amount of work is expected, and why additional staff are not being hired.</li> </ul> </li> <li>Identify and reduce boredom<ul> <li>create \u201ca culture of \u2018psychological safety\u2019 in which \u2018it\u2019s okay to ask questions\u2019</li> <li>allow to change tasks, make rotations</li> <li>encourage physical and mental health</li> </ul> </li> <li>model desired behavirour<ul> <li>Managers need to be aware they model behavior including work-life balance.  Where managers work excessive numbers of hours and do not take time out for family or vacations, they signal to subordinates that this is expected behavior and, in turn, increase the levels of stress in the workplace.</li> <li>A stressed-out manager may exhibit signs of irritability, impatience, frustration or irrational thinking</li> <li>scheduling a \u201cwalking meeting\u201d where meetings take place while going for a walk around the block</li> </ul> </li> <li>dont skip vacations</li> <li>consider sabbaticals<ul> <li>For employees who are burning out, a sabbatical might be the first big step towards recovery. Ironically, individuals who are at risk for burning out might be those most reluctant to relinquish control of their specific area of work.</li> </ul> </li> <li>Control</li> <li>give people more autonomy and flexibility</li> <li>let people have a say on how the work will be done</li> <li>Reward</li> <li>Keep in mind employee aspirations, to satisfy them</li> <li>Community</li> <li>encourage people to do activities that are not work related together</li> <li>building a better community in the workplace involves more than just workplace friends, it also requires supportive managers. </li> <li>Employees who are treated with respect and made to feel valued in the workplace have less difficulty handling heavy work demands than their less respected co-workers</li> <li>Fairness</li> <li>handle promotions fairly and transparently</li> <li>constructive feedback</li> <li>having clear and transparent procedures</li> <li>Values</li> <li>do values inventory, find discrepancies between written and acted</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20-%20what%20to%20do%20-%20workplace/#how-to-measure-it","title":"How to measure it","text":"<p>Burnout: negative scores on exhaustion, cynicism, and professional efficacy Overextended: strong negative score on exhaustion only Ineffective: strong negative score on professional efficacy only Disengaged: strong negative score on cynicism only Engagement: strong positive scores on exhaustion, cynicism, and professional efficacy</p> <p>the overextended group has just one key problem: workload (high demands and low resources). </p> <p>But the disengaged or ineffective groups seem to have other problems, including fairness in the workplace, or social rewards and recognition.</p> <p>The burnout group has major issues with multiple aspects of the workplace\u2014a pattern that stands in sharp contrast to the \u201cexhaustion-only\u201d overextended group. Any solution that an employer undertakes to improve the work-life experience needs to account for the varying sources of the five different patterns, rather than assuming that one type of solution will fit all.</p> <p>For organizations that do not have internal resources to conduct an applied study of employee burnout and engagement, an alternative option is to obtain assessment services from consultants or test publishers. External surveyors can assure confidentiality by acting as intermediaries between employee respondents and management. They often have a greater capacity to generate individual or work group reports. source</p> <p>https://learning.oreilly.com/library/view/managing-burnout-in/9781843347347/xhtml/B9781843347347500050.htmst0020</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20Physical%20and%20behavioral%20clues/","title":"Notes from research   Physical and behavioral clues","text":"<p>Physical and behavioral clues</p> <p>These 4 dimensions can portrait themselves of physical and behavioral signs as well, after all our minds and bodies are more connected than most people think. Here are a few:</p> <p>Physical fatigue: Sitting at the desk in front of a computer for 8+ hours per day is\u00a0bad for your health: it causes body pain, headache, eye strain, and more. If you don\u2019t get enough physical activity, fatigue and lethargy become the norm.</p> <p>Mental fatigue: Programming is a cognitively demanding job that requires you to solve complex problems. If you don\u2019t take breaks, the fatigue accumulates. If you don\u2019t switch activities and let your brains rest, the fatigue will eventually take its toll.</p> <p>Procrastination: When drained and in doubt of your skills, you are most likely to withdraw from responsibilities to avoid possible failure.</p> <p>Change in appetite or sleep habits:\u00a0A lack of proper sleep, use of stimulants, accumulated stress, and anxiety are most likely to influence your eating or sleep habits. For example, you may try to eat away your anxiety by having more snacks throughout the day, which may lead to overeating and weight gain, or sleep for 10-12 hours a day and still feel tired.</p> <p>Frequent body aches:\u00a0Body tensions, joint and muscle pain may appear not only due to low physical activity but also be caused by exhaustion \u2013 one of the key symptoms of burnout.</p> <p>Isolating yourself from others: You may no longer want to talk to friends or coworkers, decline invitations, become angry when someone speaks to you, or even come in early or leave late to avoid interactions. When you feel overwhelmed and exhausted by your job, it seems like you no longer have energy for socializing, which translates social isolation into loneliness and aggravates burnout.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/","title":"Notes from research   burnout theory and notes","text":""},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#draft","title":"Draft","text":""},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#part-1","title":"Part 1:","text":"<ul> <li>Burnout: we all know it, but we don't necessarily know how to recognize it in ourseves</li> <li>Early stages are more common than we think</li> <li>How to recognize it</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#part-2","title":"Part 2:","text":"<ul> <li>Internal fixes: Setting limits on things we can control</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#part-3","title":"Part 3:","text":"<ul> <li>External fixes: Stablishing actions to address it in your team/organiation</li> </ul> <p>https://www.thisiscalmer.com/blog/5-stages-of-burnout https://www.winona.edu/stress/bntstages.htm https://anjuansimmons.com/talks/managing-the-burnout-burndown/</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#define-burnout","title":"Define: Burnout","text":"<p>The World Health Organization recognized burnout as an occupational phenomenon. Yet they don't classify it as a medical condition, it has become so common, that today the WHO labels it, and calls to address it as the syndrome it is due to the effects it has in human beings.</p> <p>\u201cBurn-out is a syndrome conceptualized as resulting from chronic workplace stress that has not been successfully managed. It is characterized by three dimensions:</p> <ul> <li>Feelings of energy depletion or exhaustion;</li> <li>Increased mental distance from one\u2019s job, or feelings of negativism or cynicism related to one's job; and</li> <li>Reduced professional efficacy.</li> </ul> <p>Burn-out refers specifically to phenomena in the occupational context and should not be applied to describe experiences in other areas of life.\u201d</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#dimensions","title":"Dimensions","text":"<p>As we see in the official definition, burnout has three dimensions. We can see them as symptoms: </p> <p>Exhaustion is the central symptom of burnout. It comprises profound physical, cognitive, and emotional fatigue that undermines people\u2019s ability to work effectively and feel positive about what they\u2019re doing</p> <p>Cynicism, also called depersonalization, represents an erosion of engagement. It is essentially a way of distancing yourself psychologically from your work. Instead of feeling invested in your assignments, projects, colleagues, customers, and other collaborators, you feel detached, negative, even callous</p> <p>Inefficacy refers to feelings of incompetence and a lack of achievement and productivity. People with this symptom of burnout feel their skills slipping and worry that they won\u2019t be able to succeed in certain situations or accomplish certain tasks</p> <p>Source</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#early-indicators","title":"Early indicators","text":"<p>burnout is more than merely the alignment of risk factors, but can instead be explained by the level of \u201cmismatch\u201d between an individual and six strategic areas of the workplace: workload, control, reward, community, fairness and values.</p> <p>Research has shown that burnout is generally a consequence of a dysfunctional relationship between two parties \u2013 the individual and the workplace.</p> <p>When individuals alone seek to change the troubling elements within their control, but the organizational environment remains static, problems will most likely remain.</p> <p>trying to identify early signs of burnout development</p> <p>People\u2019s psychological relationships to their jobs have been conceptualized as a continuum between the negative experience of burnout and the positive experience of engagement. </p> <p>exhaustion\u2013 energy, cynicism\u2013involvement, and inefficacy\u2013 efficacy  A commonly discussed source of burnout is overload: job demands exceeding human limits</p> <p>That is, acute fatigue resulting from an especially demanding event at work\u2014meeting a deadline or addressing a crisis\u2014need not lead to burnout if people have an opportunity to recover during restful periods at work or at home</p> <p>When this kind of overload is a chronic job condition, not an occasional emergency, there is little opportunity to rest, recover, and restore balance. A sustainable workload, in contrast, provides opportunities to use and refine existing skills as well as to become effective in new areas of activity </p> <p>Supervisor support has been more consistently associated with exhaustion, reflecting the supervisors\u2019 impact on staff members\u2019 workload.</p> <p>Recent research has found that a conflict in values is related to all three dimensions of burnout (Leiter &amp; Harvie, 1997), and a structural model of burnout suggests that values may play a key role in predicting levels of burnout and engagement (Leiter &amp; Maslach, 2005)</p> <p>A consistent theme throughout the research literature on organizational risk factors is the problematic relationship between the person and the environment, which is often described in terms of imbalance or misalignment or misfit. For example, the demands of the job exceed the capacity of the individual to cope effectively</p> <p>early warning: exhaustion and cynicism are the two primary measures of burnout</p> <p>exhaustion and cynicism are the two primary measures of burnout .... Thus, a potential early warning sign is the presence of one of these two dimensions, but not the other ... For example, during a period of peak demand, employees may become seriously exhausted, but their cynicism remains low because they can address the demands through effective coping. </p> <p>Given the strong relationship between exhaustion and cynicism,the operating assumption is that these two dimensions are consistent with one another and tend to mutually reinforce one another</p> <p>For example, in the \u201cexhaustion only\u201d pattern, prolonged exhaustion has the potential to undermine the capacity for constructive coping eventually resulting in a high level of cynicism (the consistent burnout pattern). </p> <p>Once people begin to feel hostile and angry about job inequities, and lack faith in organizational processes to right any wrongs, this may set in motion an increasing cascade of negative reactions to the job. However, people who feel the workplace is fair and equitable, and who trust that good solutions will be found for problems, may be able to weather the storm that has led to the early warning sign. If correct, this analysis would suggest that fairness constitutes a primary tipping point\u2014 either the first, or only, or most important one. For example, the presence of a tipping point may signal the need for a more extensive organizational intervention to cope with the growing problem.</p> <p>source</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#internal-causes-individual","title":"Internal causes: Individual","text":"<ul> <li>Age or experience:  the research raises as many questions as it answers and invites more investigation to determine how reliable age and years of experience are as predictors of burnout.</li> <li>Personality: we might conclude that while research of this nature provides us with some insight into the linkage between personality and burnout, it also raises a number of questions as to how universally applicable the findings are.</li> <li>Locus of control: Locus of control has to do with an individual\u2019s beliefs about the future and who or what has the power to control future events. Studies have shown workers are more vulnerable to stress and burnout when their locus of control is external</li> <li>Marital status: On the effects of marriage on burnout, however, research has shown mixed results.these studies often raise as many questions as they answer and call for more investigation.</li> <li>Gender: In other words, men and women have been found to suffer from both mental and physical health problems when forced to endure chronic stress on the job. </li> <li>Work-home interference: \u201cInterference\u201d happens when a work deadline requires an individual to forgo a family gathering (external interference) or when one cannot stop thinking about or being preoccupied by work (internal interference). Individuals with this particular problem cannot participate fully in and enjoy home life, and find recovery from the stresses of the workday much more difficult. In contrast, when matters from one\u2019s home life interfere negatively with one\u2019s work life, researchers refer to this as home\u2013work interference (HWI). HWI affects the ability to think, concentrate and perform tasks in the workplace as required </li> <li>Expectations:  the gulf between expectations of what a job will be like and what a job is actually like is generally responsible for the burnout. \"Happiness is reality divided by expectations\" Alden Cass.</li> <li>\u201crealistic job preview\u201d (RJP) and \u201cexpectation lowering procedures\u201d (ELP) in order to \u201cadjust\u201d the expectations of potential and new employees.</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#environmental-causes-organization","title":"Environmental causes: Organization","text":"<p>can instead be explained by the level of \u201cmismatch\u201d between an individual and six strategic areas of the workplace: workload, control, reward, community, fairness and values.</p> <ul> <li>Feelings of lack of control:</li> <li>An employee is said to have control when she is able to participate in and influence workplace decision-making and is also able to exercise professional autonomy. Control has to do not only with how and when the job is done, but also how much leeway employees have in determining when they can take a break or when they can schedule their vacation</li> <li>In terms of burning out, workers who feel they have little job autonomy or control are at greater risk (Paine, 1982; Glass et al., 1993). Lack of control can take a number of different forms including supervisors who micromanage or organizations that do not allow employees to participate in policy or other work-related decisions (Glass et al., 1993). Lack of control is particularly stressful in an environment in which downsizing and job restructuring are taking place.</li> <li>fix: Give more control to people, autonomy and power of decision making</li> <li>Role conflict or role ambiguity: </li> <li> <p>Role ambiguity is a term used to  describe the lack of clarity, certainty and/or predictability one might  have expected with regards to behaviour in a job (due, perhaps to an  ill-defined or ambiguous job description and/or uncertain organizational objectives). </p> <p>Employees who work hard on what they think is an important project only to find it shelved or placed on the back burner, as well  as employees who don\u2019t understand the scope and parameters of their job, the goals they should be pursuing, and what their priorities should be  are more likely to suffer from role ambiguity.</p> <p>In contrast, role  conflict involves competing and incompatible demands placed on an  employee. This can involve the sometimes contradictory demand of being  both a supervisor and a friend, the irreconcilable demands of providing  good service while striving to reduce costs, or the difficulties of  doing a job which is at odds with one\u2019s own values. Where role conflict  and role ambiguity are high, high levels of burnout are also found (Tunc and Kutanis, 2009).</p> <p>https://learning.oreilly.com/library/view/managing-burnout-in/9781843347347/xhtml/B9781843347347500025.htm#st0095</p> </li> <li> <p>Lack of support from management:  Leadership style in terms of credibility has to do with the extent to which workers feel they can trust the person in charge.</p> </li> </ul> <p>Where workers feel they can trust their managers/supervisors, they are less likely to question managerial objectives or to refrain from volunteering to take on additional work required to accomplish these objectives. Where leadership credibility is low, the extent to which employees are burned out is likely to be higher</p> <ul> <li>Social support: </li> <li>Part of social support concerns appreciation and is a major buffer against stress.  People who feel unappreciated almost never reach out to show appreciation of someone else\u2019s work. Our experience has shown that one of the best ways for individuals to encourage others to pay attention to their work is to start acknowledging the good work of others. peer appreciation (which is easy to institute) reduces the need for approval from above (which is frequently difficult, if not impossible, to institute).</li> <li>Younger employees need more social support from their supervisors to reduce stress. They tend to rely far more on assistance and encouragement from their supervisors to help buffer higher levels of job stress.</li> <li>Have good social support and a network of people with similar interest have lower scores on emotional exhaustion</li> <li>Conflict: Although conflict may occur for many reasons, the feeling that one has too much work and too few resources with which to carry it out is likely to contribute to interpersonal conflict in the workplace</li> <li>fix: social support</li> <li>Reciprocity: </li> <li>Reciprocity involves the amount an individual invests in a particular relationship with another and whether, and to what extent, that investment is returned. In the case of workers who feel they are contributing more to relationships with clients, patrons, patients, etc. than is being returned, there is an increased risk of burnout. But a perceived lack of reciprocity may exist not only with the recipients of one\u2019s care but also with colleagues. The later contributes a lot to burnout, and by colleagues also mean: supervisors. Indeed, employees who feel a lack of reciprocity with their employing organization have been found to experience an even greater distress than when that lack of reciprocity exists with patients and co-workers</li> <li>employees are expected to give more in terms of time, effort, skills, and flexibility, whereas they receive less in terms of career opportunities, lifetime employment, job security, and so on. Violation of the psychological contract is likely to produce burnout because it erodes the notion of reciprocity, which is crucial in maintaining well-being.</li> <li>Underwork:  Underwork has been described in a number of ways including not being challenged enough on the job, or not having enough work to do, or lacking interest in the tasks that need to be done, or trying to look busy because there is not enough work. Certain experts who deal with the syndrome call it \u201cboreout\u201d \u2013 a syndrome with symptoms almost identical to burnout but which is differentiated by the fact that it afflicts the under-challenged </li> <li>Leadership style: There is an established link between type of leadership style, negative emotions, stress and burnout. </li> <li>employees working with a transformational leader rather than a transactional leader are less likely to see an impending stressor as threatening. Transformational leadership has been found to increase well-being and job satisfaction, and to decrease burnout in employees </li> <li>A transformational leadership style is one in which the leader attempts to inspire and motivate by appealing to an individual\u2019s sense of self-worth in addition to other unique emotional and developmental needs. </li> <li>transactional leadership is of these types: contingent reward, management by exception-active, and management by exception-passive<ul> <li>Contingent reward\u201d involves the provision of a reward (money, positive feedback, commendation) in exchange for good job performance</li> <li>\u201cManagement by exception\u201d may be active or passive. In the active form, the leader monitors an employee\u2019s work, and if job performance deviates from expected performance standards, correction in the shape of negative feedback, discipline or punishment takes place. </li> <li>In the passive form, the leader is not actively involved in the monitoring of work, and only steps in when any deviation is brought to his or her attention</li> </ul> </li> <li>Unmanageable workload &amp; time pressure: they contribute strongly to emotional exhaustion. Overload is bad for both the individual and the organization \u2013 the quality of work drops, co-workers have no time for collegiality or to build community, and morale and motivation suffer.</li> <li>When to know? If it's hard to find relief at work. If restful moments between events are gone, and each demand rolls in the next one. When this happens exhaustion builds up, additional demands are not manageable and  the current scramble for survival often results in a shortage of resources. </li> <li>Workload can be of two types \u2013 either quantitative (e.g., high job demands with too little time in which to carry out those demands) or qualitative (e.g., jobs with a great deal of complexity or requiring a great deal of concentration</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#organizational-issue","title":"Organizational issue","text":"<p>Burnout is an organizational issue. If you are facing burnout, is not in your entire responsibility to fix it, the fact that you have it is a symthom of a systematic issue that happens in your workplace, and it is a major red flag.</p> <p>as employees, are not responsible for solving it. Still, it is not entirely out of our control. We can choose to set boundaries that protect our mental, physical, and emotional health. The challenge is that our efforts to do so are often hijacked by guilt.</p> <p>https://egn.com/dk/wp-content/uploads/sites/3/2020/08/Burnout-is-about-your-workplace-not-your-people-1.pdf</p> <p>overload the most capabale: The overload problem is compounded for companies because the best  people are the ones whose knowledge is most in demand and who are often  the biggest victims of collaboration overload. </p> <p>...</p> <p>Giving people the time to do work that drives the company\u2019s success will pay huge dividends by raising productivity, increasing productive  output and reducing burnout. Everybody wins.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#measures-that-are-in-our-individual-control","title":"Measures that are in our individual control","text":"<p>Yet it is not in our control to address the underlying cause and mitigate the causing problem, it is in our control what boundaries that protect our mental, physical, and emotional health.  </p> <p>These boundaries can be different from person to person, generally speaking I would suggest.</p> <ul> <li>Raise the red flag in your organization</li> <li>Set your boundaries, putting a drastic limit on the things that have caused your burnout. </li> </ul> <p>Truth is, if you are facing burnout, stakes are high that you are as well feeling guilty, that you were not good enough to handle the situation. What I can tell you, and what books and research show about this is: you are not alone, it is common that people who face burnout feel this way. </p> <p>The feeling of guilt could be a mix of two things: the story that you tell to yourself about burnout (ie: \"I am not good enough, others could have managed\"), and/or how your colleagues and supervisors address the situation (ie: \"You are over reacting\", \"You should have asked for help\", \"You are not good enough\"). </p> <p>In either of both cases: The story you are telling to yourself, and the story that your colleagues, bosses might be telling you, if they go in the direction of: You are responsible and you are not good enough, let me tell you: It is not true.</p> <p>Yet you might lack of one or other skill, yet could be that another person might be able to handle the workload better than you are, but the fact that an employee is in burnout is an organizational issue. It should have never reached this level, and your organization, and your supervisor are responsible of looking after you, and providing you with a work environment where everyone is productive, whatever that means for each individiual.</p> <p>Steps to get out</p> <ul> <li>Take time to unwind, take time off</li> <li>Identify the cause, keep a stress diary</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#action-tips","title":"Action tips","text":"<p>Meditation is proven to provide us with enough internal resources to unwind, and respond to life situations in a healthy manner. It is medicine for the mind.</p> <p>With burnout come negative thoughts about our professionalism, about us not being enough, or just feeling bad. For that, what has worked for me the best is to practice self compassion, here is a set of guided meditations to chose from, that I recommend you. </p> <ul> <li>self compassion ecercises</li> <li>Routine that marks the beginning of the work day</li> <li>Routine that marks the end of the work day. </li> <li>Excersice daily</li> <li>Cook my meals</li> <li>Keep a stressors diary: date, time, situation, scale, symptoms, efficiency and reaction</li> <li>Decrease factors that give me stress</li> <li>Manage your energy, not your time</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#actions-for-the-individual-per-job-domain","title":"Actions for the individual per job domain","text":"<p>source</p> <ul> <li>Workload: </li> <li>self-awareness and self-monitoring are critical in preventing burnout, and when tackling the problem of workload, workers need to know what fires them up about the job and what, on the other hand, drains them of energy. Is it simply a case of too much work? Are deadlines too severe? Is it the type of work?</li> <li>Fix: limit hours</li> <li>Fix: learn to say no (dont take in more work) <ul> <li>or say a conditional no, </li> <li>or sleep on it no. </li> <li>alternative solution no</li> <li>secret weapon no (saying no without explaining why)</li> </ul> </li> <li>Fix: delegate</li> <li>Fix: manage time wisely<ul> <li>prioritize week's work</li> <li>minimize notifications and interruptions</li> <li>schedule down time</li> <li>periodically evaluate commitments</li> <li>take vactions</li> </ul> </li> <li>Fix: Break routines<ul> <li>for example, incorporating new activities into the work day or carrying out old activities in different ways or at different times is a start. Employees who eat lunch at their desk each day while trying to work not only have no chance to unwind, but they risk the physical problems which result when eating while under stress. As Ashley Koff, RD, a Los Angeles dietitian, notes,</li> <li>do hobby during lunch break</li> <li>work at different times</li> <li>incorporate non brain activities if you are a mind worker</li> </ul> </li> <li> <p>Fix: increase resilience</p> <ul> <li>eat healthy</li> <li>Get enough sleep</li> <li>Excersice</li> <li>Employ relaxation techniques</li> </ul> </li> <li> <p>Control</p> </li> <li>Autonomy: <ul> <li>Identifying the type of control which is absent in the environment and then responding accordingly. </li> <li>building a record of exceptional performance on the job and earning the trust of management.</li> <li>Volunteering to take more control is also an option.</li> <li>the way an employee might achieve more autonomy in the workplace is through external validation. Volunteering for professional associations, </li> </ul> </li> <li>Supervision<ul> <li>Creative control involves keeping the boss up to date on innovation, new ideas or new concepts</li> <li>Critical control involves taking more interest in job performance and working with the supervisor to enhance quality in the workplac</li> <li>supportive control involves paying more attention to the supervisor and communicating more about frustrations and accomplishments in an attempt to model supportive behavior</li> </ul> </li> <li>Reward</li> <li>Ask for salary increase or promotion</li> <li>Ask for feedback from supervisor when acknowledgment is the issue</li> <li>Bring accomplishments to the eyes of others</li> <li>Seek validation beyond the workplace</li> <li>Or change jobs</li> <li>Community</li> <li>first step determining who the problems are \u2013 co-workers, supervisors and/or clients \u2013 and where the solution might lie.</li> <li>building a better community starts with better communication and by reaching out to others in the workplace.</li> <li>build better relationships in the workplace and to create alliances.</li> <li>Fairness and respect</li> <li>first ways to address incidents of disrespect or discrimination is to talk about the incident with the offending party, or when that does not change the behavior, to talk to a supervisor.</li> <li>Values</li> <li>Find a source of meaining inside or outside the job</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#organizational-measures","title":"Organizational measures","text":"<p>source</p> <p>This is a post focused mainly on the individual, rather than the organization. However, provided most of the causes of burnout have origin in the organization, some actions that the organization can look at, in order to address properly are:</p> <ul> <li>Define roles</li> <li>Prioritize work</li> <li>Work on important non urgent things</li> <li>Provide people more control, for example over:  autonomy, opportunity for promotion, feedback and social  support</li> <li>Adjust organizational structures and routines, decrease decision nodes, to address excessive collaboration</li> <li>Evaluate leadership style of managers, target to transformational service leadership</li> <li>Workload:</li> <li>Resuce workload<ul> <li>if not possible workload is expected to be busier than usual, but only temporarily, managers need to let employees know what has brought about this change, how long the increased amount of work is expected, and why additional staff are not being hired.</li> </ul> </li> <li>Identify and reduce boredom<ul> <li>create \u201ca culture of \u2018psychological safety\u2019 in which \u2018it\u2019s okay to ask questions\u2019</li> <li>allow to change tasks, make rotations</li> <li>encourage physical and mental health</li> </ul> </li> <li>model desired behavirour<ul> <li>Managers need to be aware they model behavior including work-life balance.  Where managers work excessive numbers of hours and do not take time out for family or vacations, they signal to subordinates that this is expected behavior and, in turn, increase the levels of stress in the workplace.</li> <li>A stressed-out manager may exhibit signs of irritability, impatience, frustration or irrational thinking</li> <li>scheduling a \u201cwalking meeting\u201d where meetings take place while going for a walk around the block</li> </ul> </li> <li>dont skip vacations</li> <li>consider sabbaticals<ul> <li>For employees who are burning out, a sabbatical might be the first big step towards recovery. Ironically, individuals who are at risk for burning out might be those most reluctant to relinquish control of their specific area of work.</li> </ul> </li> <li>Control</li> <li>give people more autonomy and flexibility</li> <li>let people have a say on how the work will be done</li> <li>Reward</li> <li>Keep in mind employee aspirations, to satisfy them</li> <li>Community</li> <li>encourage people to do activities that are not work related together</li> <li>building a better community in the workplace involves more than just workplace friends, it also requires supportive managers. </li> <li>Employees who are treated with respect and made to feel valued in the workplace have less difficulty handling heavy work demands than their less respected co-workers</li> <li>Fairness</li> <li>handle promotions fairly and transparently</li> <li>constructive feedback</li> <li>having clear and transparent procedures</li> <li>Values</li> <li>do values inventory, find discrepancies between written and acted</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#conclusion","title":"conclusion","text":"<p>[b]urning out may literally save our lives by stopping us before we suffer a more serious or fatal illness. It operates like a circuit breaker that keeps the whole system from blowing. On another level, burnout saves our life by showing us how and when our life lost its old meaning and by forcing us to do something about it. We may not save our old life, but we can free ourselves to be more fully alive. (p. 57)</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20burnout-theory-and-notes/#quotes-and-resources","title":"Quotes and resources","text":"<p>source</p> <p>our decisions to do mental work appear to include a comparison of the costs of an action against the potential benefits resulting from it</p> <p>When a tricky task makes your brain hurt. What to do - Phyche magazine</p> <ul> <li>Good system-level prioritization is essential. You won\u2019t decouple your teams without good product management. You need a product management (or Integrator) listening and prioritizing for global needs. If teams prioritize based on local needs, you need to strengthen your Integrators.</li> </ul> <p>source</p> <ol> <li>Program manager. A role that runs programs (projects containing projects) and coordinates efforts across teams.</li> <li>Integrator. A role that solicits information from a broad variety of sources and synthesizes them into prioritization and plans.</li> <li>Controller. A role that has explicit authority to demand behavior in a particular arena.</li> <li>Standard definer. A role that defines guidelines and guardrails that constrain behavior that can be done without discussion.</li> </ol> <p>source coordination models</p> <p>If your company is using the OKR framework:</p> <ul> <li>The Goal (G) is your Objective (O)</li> <li>The Measures (M) are your Key Results (KR)</li> </ul> <p>Get your OKRs out of my gems</p> <p>The Always-On manager fails to take time to step back and think strategically about their role. They can only see trees and not the forest. As a result, their department never has the desired impact on the business's bottom line, and the team burns out, one at a time.</p> <p>The managers driving the great resignation</p> <p>The hard truth is: If the present has to be in perfect shape before we allow ourselves to work on the future, then we\u2019d never do any strategic work.</p> <p>Mental toughness with strategic work</p> <p>Excessive collaboration is a common ailment in organizations with too many decision makers and too many decision-making nodes. It manifests itself in endless rounds of meetings and conference calls to ensure that every stakeholder is heard and aligned</p> <p>...</p> <p>Companies can begin to address the collaboration overload problem by adjusting organizational structures and routines. One easy step is to look at the number of nodes in the organization. These are intersections in the organizational matrix where a decision maker sits. A proliferation of nodes is a sign of unnecessary organizational complexity, and nodes act as organizational speed bumps, slowing down the action and stealing organizational time and energy.</p> <p>Source Employee burnout is a leader - hbr</p> <p>overload the most capabale: The overload problem is compounded for companies because the best  people are the ones whose knowledge is most in demand and who are often  the biggest victims of collaboration overload. </p> <p>...</p> <p>Giving people the time to do work that drives the company\u2019s success will pay huge dividends by raising productivity, increasing productive output and reducing burnout. Everybody wins.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20high%20pressure%20project%20and%20metal%20health/","title":"Notes from research   high pressure project and metal health","text":""},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Notes%20from%20research%20-%20high%20pressure%20project%20and%20metal%20health/#things-ive-done-to-aid-with-high-conflict-high-pressure-10-months-project-as-em","title":"Things I've done to aid with high conflict high pressure 10 months project as EM","text":"<p>During the roughly 8-10 months I was in a project that was going through a really tough time, we had a lot of pressure, no rest, and everyone, including me were facing extreme acute work stress. This is what I did to address the situation</p> <ol> <li>Understand what burnout is, by reading research. I found this book particularly helpful, especially because it explains the different areas that might influence work-related burnout, and what can you do at the individual level, and at the organizational level: https://www.amazon.com/Managing-Burnout-Workplace-Professionals-Professional/dp/1843347342 (understanding this helped me to figure what kind of questions would I ask in the 1:1s with my team members to understand what was the cause o their burnout - this could be a complement of the recommendation of Vaidehi in her article)</li> <li>Do a self analysis on where I was, and what the causes of my stress were, in my case was: role ambiguity and that I had higher expectations. I addressed these actively focusing my mental health, taking breaks when I felt it was too much, and set for myself early signs that told me when I had to take a break. For example: Ending the work day being exhausted, or starting a week being irritated.</li> <li>I preached a lot that our goal was not to lose anyone to early stage burnout, and that taking a break due to stress, was encouraged, we started to see it as if you had a cold. If you have a cold (in Germany, where I leave) you have to take a day off to rest. In the same way we adopted this mindset when anyone was too stressed. </li> <li>The 1:1s were the key, they were focused mainly at understanding where the frustrations where, and figuring out what could we do to address them. </li> <li> <p>Depending on what the cause was, I shared resources with my team members, such as: walking meditations, how to say no, etc, as complement of what they were doing already.</p> <p>Additionally, there is a nice website (https://yerbo.co/), that has a survey that you can do with yourself, to figure out where you are with regards of burnout: https://burnoutindex.yerbo.co/</p> </li> </ol>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Things%20to%20do%20-%20%20Self%20monitoring/","title":"Things to do    Self monitoring","text":"<ol> <li>Are you regularly physically and emotionally exhausted?\u00a0Do you feel a lack of energy and/or have trouble sleeping? Do you worry excessively? Feel more edgy? Feel sad or hopeless?</li> <li>Are you more cynical and detached than usual?\u00a0Do you no longer feel joy from things that used to bring you joy? Are you less interested in socializing and are you feeling less connected to people\u00a0than you once did? Are you more negative than usual? Do you see the glass as half empty?</li> <li>Are you feeling like you\u2019re not contributing anything meaningful, where you once were?\u00a0Do you feel a sense of ineffectiveness and that all of your hard work isn\u2019t actually accomplishing anything?</li> </ol> <p>Source: HBR guide to beating burnout</p> <p>The Mayo Clinic describes the list of job burnout risk factors as:</p> <ul> <li>You identify so strongly with work that you lack balance between your work life and your personal life</li> <li>You have a high workload, including overtime work</li> <li>You try to be everything to everyone</li> <li>You work in a helping profession, such as health care</li> <li>You feel you have little or no control over your work</li> <li>Your job is monotonous2</li> </ul> <p>MBI dimensions -  Burnout:\u00a0negative scores on exhaustion, cynicism, and professional efficacy -  Overextended:\u00a0strong negative score on exhaustion only -  Ineffective:\u00a0strong negative score on professional efficacy only -  Disengaged:\u00a0strong negative score on cynicism only -  Engagement:\u00a0strong positive scores on exhaustion, cynicism, and professional efficacy https://learning.oreilly.com/library/view/hbr-guide-to/9781647820015/Text/36_24__Burnout__What_It_Is_and_How.xhtmlpage_211</p> <p>six key components of their workplace\u00a0culture (workload, control, reward, community, fairness, values\u2014as reflected by scores on the Areas of Worklife Survey, or AWS),</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Things%20to%20do%20-%20Anchor%20breathing/","title":"Things to do   Anchor breathing","text":"<ol> <li>Imagine being on a boat, feeling calm, and safe</li> <li>Attached to the boat is an anchor. It keeps you there, where you want, and happy</li> <li>Our bodies, like the boat, also have anchors, and they can help us focus. Our belly, our nose and mouth, and our chest and lungs can help us feel grounded.</li> <li>With your hands on your chest, breathe in deeply</li> <li>Breathe out slowly</li> <li>Feel your ribs rise and fall</li> <li>As your mind wanders, gently bring it back to the anchor point.</li> </ol> <p>Source: https://positive.b-cdn.net/wp-content/uploads/Anchor-Breathing.pdf</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Things%20to%20do%20-%20Embrace%20do%20nothing%20time/","title":"Things to do   Embrace do nothing time","text":"<p>Amidst the achievement society, we got to embrace the non-achievement parts of life. </p> <p>\"In a world of excess doing, we need to develop the capacity to mindfully choose not to do. \u00a0This is far from easy, as it means confronting deeply held beliefs, many cultural and personal, that have served us well to date: \u201cTime is money.\u201d \u201cIf it\u2019s not done perfectly, it isn\u2019t worth doing.\u201d Even the tyranny of the seemingly positive \u201cCarpe Diem\u201d in which we must make every moment count.\"</p> <p>We need moments of not doing; we need moments that don\u2019t count.</p> <p>Things to do (actions) - 8 weeks MBSR program -  1.  Mindfulness meditation practices: These practices involve paying attention to the present moment in a non-judgmental way, typically by focusing on the breath, body sensations, or other sensory experiences. 2.  Gentle yoga or other mindful movement practices help cultivate body awareness and reduce physical tension and stress. 3.  Group discussions: Participants in MBSR programs typically have opportunities to discuss their experiences with meditation practices and explore how to apply mindfulness in daily life. 4.  Homework assignments: Participants are usually asked to practice mindfulness meditation and/or mindful movement practices on their own between classes to help reinforce what they've learned. 5.  Teacher support: Participants receive guidance and support from a trained MBSR teacher throughout the program.</p> <p>Improves: improvements in self-compassion, empathy, mindfulness, and emotional well-being</p> <p>https://self-compassion.org/wp-content/uploads/publications/MBSR-Exploring_self-compassion_empathy_in_the_context_of_mindfulness_based_stress_reduction.pdf</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Things%20to%20do%20-%20Habits%20that%20help/","title":"Things to do   Habits that help","text":"<p>End of day reflection time:  the act of reflection improves satisfaction, especially during the difficult circumstances of a crisis</p> <p>Daily reflection is powerful: it\u00a0makes us aware of areas for improvement, and\u00a0can increase our satisfaction. </p> <p>Self monitoring: Brings more awareness and can help us to set and improve our goals over time. Battles the lack of emotional self awareness, which can promote burnout when we have frequent negative emotions. Hack: Install an app to track at the beginning and end of the day if your mood is low or high negative</p> <p>Find inner-beliefs that help and don't help: Find out which are your close enemies (beliefs) ie: endurance makes you do more, and resilience might make you feel replenished</p> <p>Find negative biases or mental traps that can be dampening the impact of positive events, things like: self-blaming, mental rumination, catastrophizing, among other mechanisms. </p> <p>Find internal values such as: \"I will work harder\" (Endurance). Change them to more wellbeing beliefs, such as resilience</p> <p>Welcome Gaps as Opportunities to Rest, Not Inconveniences.  We need moments of not doing; we need moments that don\u2019t count, to let our nervous system to recover from the high-doing, high-achievement part of the day.</p> <p>Example: While waiting at the train, airport, or doctor, instead of pulling out your phone, just do nothing</p> <p>Curb the urge to overwork even if it's 8h a day it can be mentally overwork</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Things%20to%20do%20-%20While%20you%20are%20in%20a%20high%20pressure%20time/","title":"Things to do   While you are in a high pressure time","text":"<p>**Practice self-compassion:</p> <p>Self-compassion entails three fundamental components:  </p> <ol> <li>Extending kindness and understanding to oneself rather than harsh self-criticism and judgment</li> <li>Seeing one\u2019s experiences as part of the larger humanity rather than as separating and isolating; and </li> <li>Holding one\u2019s painful thoughts and feelings in balanced awareness rather than over-identifying with them </li> </ol> <p>The \u201cButterfly Hug\u201d, or \u201cHug of self love\u201d The Butterfly Hug is accomplished by an individual wrap their arms around themselves, so that each hand touches the opposite upper arm or shoulder. They then move their hands like the wings of a butterfly, to tap their arms/shoulders in an alternating rhythm. (as an alternative, the person might just tap their knees.)</p> <p>https://www.crowe-associates.co.uk/psychotherapy/butterfly-hug-method/#:~:text=The%20Butterfly%20Hug%20is%20accomplished,might%20just%20tap%20their%20knees.)</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Things%20to%20do%20-%20catching%20it%20early/","title":"Things to do   catching it early","text":"<ul> <li>Go to the doc and get a sick leave. During your sick leave focus on self-pampering, doing nothing, disconnecting. Use the last days to establish boundaries for when you are back</li> <li>Get support: from a coach, therapist, friend. Once burnout has its hold on your mindset, decision making can get fuzzy. By identifying patterns and regaining clarity on priorities, you can establish better boundaries, for instance, by delegating where necessary, by saying no to projects that do not serve you long term, and by taking better care of yourself. These steps can help you feel a sense of progress toward relieving your symptoms.</li> <li>Make Your Emotional and Physical Well-Being a Priority Put healthy eating, exercise, and a good sleep routine at the top of the list. Schedule in lunch breaks and stop working at a reasonable time. Take all of your vacation. Too many companies report that employees forgo vacation time; 27.2% of paid time off went unused in 2018. And too many women tell us that they\u2019re the first ones into the office, and the last ones out. Reframe that \u201cwork harder\u201d message to work smarter, which includes breaks from work to stimulate the relaxation response and dissipate the stress response. It takes giving yourself permission to shift your mindset around what\u2019s a priority and a commitment to establishing healthy coping mechanisms to combat stress.</li> <li>Examine your workplace, and look at what are the triggers that dont help you. The current workplace mantra of \u201cwe have to do more with less\u201d is not sustainable. With your manager or other senior leaders, review the structure of your role, the culture of the firm, and how to support an environment where everyone thrives.</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Things%20to%20do%20-%20purpose%20driven%20employees/","title":"Things to do   purpose driven employees","text":"<ul> <li>significantly more engaged (p &lt; .001), significantly more inspired (p &lt; .001)</li> <li>purpose-driven employees are significantly more stressed (p &lt; .01) than non-purpose-driven employees, and reported significantly lower levels of general well-being (p &lt; 0.5), resilience (p &lt; .001), and self-efficacy (p &lt; .001).</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/Things%20to%20do%20-%20purpose%20driven%20employees/#tips-for-purpose-driven-employees","title":"TIPS FOR PURPOSE-DRIVEN EMPLOYEES","text":"<p>1.\u00a0\u00a0\u00a0\u00a0 Take gratitude seriously. 2.\u00a0 Ask \u201chow are you?\u201d</p>"},{"location":"03-areas%20%F0%9F%A7%BE/burnout/resources/","title":"Resources","text":"<p>https://learning.oreilly.com/library/view/managing-burnout-in/9781843347347/?_gl=184vl6q_gaMTIwODAyMTU2MS4xNjgzOTc1Mzk1_ga_092EL089CH*MTY4Mzk4MDIzOC4yLjEuMTY4Mzk4MDI0My41NS4wLjA.</p> <p>https://learning.oreilly.com/library/view/hbr-guide-to/9781647820015/Text/18_8__Five_Steps_for_Women_to_Comba.xhtml</p> <p>https://github.com/githubocto/good-day-bot</p> <p>https://self-compassion.org/wp-content/uploads/publications/MBSR-Exploring_self-compassion_empathy_in_the_context_of_mindfulness_based_stress_reduction.pdf</p> <p>https://github.blog/2021-05-25-octoverse-spotlight-good-day-project/</p> <p>https://queue.acm.org/detail.cfm?id=3454124</p> <p>https://devhealth.tech/developer-burnout-101/signs</p> <p>https://devhealth.tech/developer-burnout-101/causes</p>"},{"location":"03-areas%20%F0%9F%A7%BE/career/2022-10-27%20Reflection%20on%20how%20I%20did%20in%20a%20coding%20chanllenge/","title":"2022 10 27 Reflection on how I did in a coding chanllenge","text":"<p>reflection self-insight interviewing </p>","tags":["reflection","self-insight","interviewing"]},{"location":"03-areas%20%F0%9F%A7%BE/career/2022-10-27%20Reflection%20on%20how%20I%20did%20in%20a%20coding%20chanllenge/#common-tips","title":"Common tips","text":"<ul> <li>I rush to start coding</li> <li>I become too nervous when I don't know something</li> <li>I get stuck there...</li> </ul>","tags":["reflection","self-insight","interviewing"]},{"location":"03-areas%20%F0%9F%A7%BE/career/2022-10-27%20Reflection%20on%20how%20I%20did%20in%20a%20coding%20chanllenge/#reflections-on-how-i-did","title":"Reflections on how I did","text":"<ul> <li>Feedback from Beamery dev, go slower and solve/write the things that I already know</li> <li>Build on it</li> <li>Once I get to the point I am stuck: diagram, draw and be ok to be slower and draw things out, till I understand it</li> </ul>","tags":["reflection","self-insight","interviewing"]},{"location":"03-areas%20%F0%9F%A7%BE/career/2022-10-27%20Reflection%20on%20how%20I%20did%20in%20a%20coding%20chanllenge/#other-reflections","title":"Other reflections","text":"<ul> <li>I got feedback to learn of matheus and be more humble and less stuborn... Understand first then be understood: the approach of the guy of the interview felt a bit condescending at times, but the end result was good. I slowed down to learn the basics.. Dejan told me the same: what is the hurry? --- take my time, take low profile and learn from the others, so that I relearn the basics\u00a0 and rebuild my foundation.</li> <li>My goal is to work with AI, ML, or any of the sort technologies... Deep high level software...\u00a0</li> <li>should I study again?</li> </ul>","tags":["reflection","self-insight","interviewing"]},{"location":"03-areas%20%F0%9F%A7%BE/career/2022-12-12-%20What%20is%20the%20story%20that%20shapes%20my%20path%20as%20humane%20technologist%3F/","title":"2022 12 12  What is the story that shapes my path as humane technologist?","text":"<p>reflection humaneTech </p> <p>I have been a web developer for years, working for digital consultancy agencies who build systems that benefit financial growth only for their clients. I have decided to move out of that side of the industry, and move to product. I have searched for almost a year for place to work where I feel comfortable, have a deeper sense of belonging, and build humane tech products. I ended up in trade republic, where the mission is in that direction.</p> <p>I would like to develop a new definition of success for myself, and for what it means to be successful professionally. I would like to have a new definition, one that is about building and sharing more humane technology with users of the products I build, and with colleagues.</p> <p>I would like to make sense that I am not the only one succeeding, I would like to change how people think about technology, how to build technology, and build strong human relationships with my allies on this vision.</p>","tags":["reflection","humaneTech"]},{"location":"03-areas%20%F0%9F%A7%BE/career/2022-12-12-%20What%20is%20the%20story%20that%20shapes%20my%20path%20as%20humane%20technologist%3F/#idea","title":"Idea:","text":"<p>Present the videos on these videos and share at work &lt;3  -- maybe after work, a watch and dinner date</p>","tags":["reflection","humaneTech"]},{"location":"03-areas%20%F0%9F%A7%BE/career/2022-12-12-%20What%20is%20the%20story%20that%20shapes%20my%20path%20as%20humane%20technologist%3F/#what-to-do","title":"What to do","text":"<ul> <li>practicing gratefulness daily</li> <li>reducing alcohol and treating myself with more self care and love</li> <li>sharing love and gratefulness, and respect with those around me</li> <li>nurture with love my current relationships, grow them</li> <li>share more knowledge and ideas about humane technology and kindness</li> <li>stop jumping into leadership, go at my own pace, slow is good</li> <li>there are going to be always crisis, and I am resistant to these crisis, I support fairness and justice, I help to create shared understanding,</li> </ul>","tags":["reflection","humaneTech"]},{"location":"03-areas%20%F0%9F%A7%BE/career/2023-01-08%20act%20-%20finding%20my%20values/","title":"2023 01 08 act   finding my values","text":"<p>understandMyself self-insight </p>","tags":["understandMyself","self-insight"]},{"location":"03-areas%20%F0%9F%A7%BE/career/2023-01-08%20act%20-%20finding%20my%20values/#my-first-draft-values","title":"my first draft values","text":"<p>https://harvard.az1.qualtrics.com/jfe/form/SV_e35whN7tkXtvlHv</p>","tags":["understandMyself","self-insight"]},{"location":"03-areas%20%F0%9F%A7%BE/career/2023-01-08%20act%20-%20finding%20my%20values/#most-important-ones","title":"Most important ones","text":"<ul> <li>challenge</li> <li>balance in life</li> <li>openness and receptiveness to new ideas</li> <li>rewarding and supportive relationships</li> </ul>","tags":["understandMyself","self-insight"]},{"location":"03-areas%20%F0%9F%A7%BE/career/2023-01-08%20act%20-%20finding%20my%20values/#less-important-ones","title":"less important ones","text":"<ul> <li>broad interests</li> <li>faith</li> <li>fame success</li> <li>power and influence</li> </ul>","tags":["understandMyself","self-insight"]},{"location":"03-areas%20%F0%9F%A7%BE/career/A%20categorization%20of%20goals/","title":"A categorization of goals","text":"<p>career goals </p>","tags":["career","goals"]},{"location":"03-areas%20%F0%9F%A7%BE/career/A%20categorization%20of%20goals/#goals-should-contain-the-following-characteristics","title":"Goals should contain the following characteristics:","text":"<ul> <li>Attainability: Challenge but not overwhelm</li> <li>Flexibility: Have a range of goals</li> <li>Time: Reasonable deadlines and allow for process</li> <li>Process-focus: Be mindful of the steps along the way</li> <li>Inspiration: How do you want to feel</li> </ul>","tags":["career","goals"]},{"location":"03-areas%20%F0%9F%A7%BE/career/A%20categorization%20of%20goals/#categories-of-goals","title":"Categories of goals","text":"<ol> <li>Specific: Measurable and quantifiable. Example: Race completion, finish times, pace, speed, weight, workout consistency</li> <li>Non-Specific: Emotional, subjective process or global. Example: Happiness with yourself, confidence, resilience, stress management, contentment, general well-being</li> </ol> <p>source</p>","tags":["career","goals"]},{"location":"03-areas%20%F0%9F%A7%BE/career/Quarterly%20Self%20Review%20-%20Professional/","title":"Quarterly Self Review   Professional","text":"<p>career self-insight</p> <p>Am I Growing Complacent Currently</p> <ul> <li>Accomplishment: Have I done anything noteworthy these last three months?</li> <li>Impact: Would I write a line in my resume about the work I have done over these three months? Would I value this specific work experience if I was hiring for my own company?</li> <li>Growth/Future alignment: Have I acquired valuable insights or skills? Are these skills aligned with my future goals?</li> <li>Challenge: Have there been days when I was thinking about a work problem in the shower so profoundly that I forgot if I used the soap or not?</li> <li>Community: Am I excited and happy to go to work every morning and see my teammates. Do I believe in the mission, vision, and leadership of this team or company?</li> </ul>","tags":["career","self-insight"]},{"location":"03-areas%20%F0%9F%A7%BE/career/Quarterly%20Self%20Review%20-%20Professional/#less-than-40-a-quarter-means-action","title":"Less than 40% a quarter means action","text":"Accomplishment Impact Growth Challenge Community Total <p>Reinventing myself</p> <p>What, specifically, do you want to learn? The first step in developing your board is a rigorous self-assessment. Where are you headed professionally, and what skills do you need to get there?</p> <p>Whom do you respect most? Once you\u2019ve developed your list of skills, write down the people you know and respect who possess them. Think broadly \u2014 they could be peers, senior leaders, or even (like Phillippi Ryan\u2019s mentor) interns or junior employees.</p> <p>How can you arrange to spend more time with them?</p> <p>How can you make the relationship reciprocal?</p> <p>How are you adapting to the new reinvention curve?</p> <p>How do you stay comptetitive and relevant?</p>","tags":["career","self-insight"]},{"location":"03-areas%20%F0%9F%A7%BE/career/The%20Role%20of%20an%20Architect%20-%20Creating%20a%20Context%20for%20Success%20through%20Vision%2C%20Standards%2C%20and%20Trade-offs/","title":"The Role of an Architect   Creating a Context for Success through Vision, Standards, and Trade offs","text":"<p>theArchitectRole </p> <p>As noted designer, author, and artist Edwin Schlossberg said so wonderfully, \u201cThe skill of writing is to create a context in which other people can think.\u201d Likewise, the skill of leading an organization, or creating an architecture, or creating a strategy, is structurally analogous: you are creating a context in which other people can succeed.</p> <p>The job of the architect, CTO, technology manager, or strategist is to determine how to create a context\u2014design a system\u2014in which new concepts can erupt and evolve (they\u2019re extensible) and people can do the best at what they do (they\u2019re fit for purpose).</p> <p>The outcome is the difference your output makes to a customer. Outcomes are the Why. They represent the benefits your customer gets.</p> <p>The vision is a single sentence characterising the end state. If you don\u2019t understand the problem you\u2019re solving, or the desired outcome you would get at the end, you will just rearrange the deck chairs</p> <p>Here\u2019s my definition of an architect\u2019s work: it comprises the set of strategic and technical models that create a context for position (capabilities), velocity (directness, ability to adjust), and potential (relations) to harmonize strategic business and technology goals.</p> <p>Over my 20 years in this field, I\u2019ve come to conclude that there are three primary concerns of the\u00a0 architect:</p> <p>Contain entropy: The architect defines standards, conventions, and toolsets for teams to use. These are common practices, and generally idiosyncratic to any given organization. As application or solution architects, they help within a system, within an ecosystem, and across an organization to create a common set of practices for developers that help things both go quicker and be more understandable and maintainable. This is a form of containing entropy. the architect works to ensure that there is alignment between the systems, yes, but also between those systems and the organization, and between the organization and its stated aims. The architect who is containing entropy is stating a vision around which to rally; showing a path in a roadmap; garnering support for that vision through communication of guidelines and standards; and creating clarity to ensure efficiency of execution and that you\u2019re doing the right things and doing things right.</p> <p>Specify the nonfunctional requirements: The nonfunctional requirements are properties of the system that do not necessarily appear directly to the user. They are typically described as the \u201c-ilities.\u201d The ones I focus on most are scalability, availability, maintainability, manageability, monitor ability, extensibility, interoperability, portability, security, and performance.</p> <p>The architect is responsible for specifying how the system will realize the functional and nonfunctional requirements in its construction. In order to do so, she must write a document that specifies how these will be realized.</p> <p>Determine trade-offs: you\u2019re never quite solving a problem. You\u2019re only trading it for one that you\u2019d rather have.</p>","tags":["theArchitectRole"]},{"location":"03-areas%20%F0%9F%A7%BE/career/what-is-a-software-engineer/","title":"What is a software engineer","text":"<p>theArchitectRole career roles</p> <p>Moving from maker to multiplier is a switch that takes time to understand. For me it has taken years to be honest. </p> <p>I have never understood properly the standard career framework of a software engineer, and because of that, my progression has taken turns that have affected me.</p> <p>I've suffered a bit because for some years I was in a work relationship that was dysfunctional for me and I felt my progression was stagnated.</p> <p>With the pass of the time, I have come to understand better the different stages of the career, and what sense to make of the career of a software engineer.</p> <p>The first thing is: There is a difference between a programmer and a software engineer.</p>","tags":["career","theArchitectRole","roles"]},{"location":"03-areas%20%F0%9F%A7%BE/career/what-is-a-software-engineer/#what-is-a-software-engineer","title":"What is a software engineer?","text":"<p>For example, (definition of coursera)</p> <p>Software engineering is the branch of computer science that deals with the design, development, testing, and maintenance of software applications. Software engineers apply engineering principles and knowledge of programming languages to build software solutions for end users.</p> <p>So, a software engineer does: * Development * Testing * Maintenance</p> <p>Applying * Engineering principles * Knowledge of programming languages.</p> <p>In the same article, the suggest that within the tasks of a software engineer appear:</p> <ul> <li>Designing and maintaining software systems</li> <li>Evaluating and testing new software programs</li> <li>Optimizing software for speed and scalability</li> <li>Writing and testing code</li> <li>Consulting with clients, engineers, security specialists, and other stakeholders  </li> <li>Presenting new features to stakeholders and internal customers</li> </ul> <p>In short: The Software engineer designs complex systems, from a broad perspective. They are involved in all the phases of software development. The SDLC involves planning, defining, designing, building, testing, and deploying software.</p>","tags":["career","theArchitectRole","roles"]},{"location":"03-areas%20%F0%9F%A7%BE/career/what-is-a-software-engineer/#what-is-a-developer","title":"What is a developer?","text":"<p>A developer is a person who designing, planning, and writing code for pieces of software. They can be also involved on planning a piece of the system.</p> <p>They are involved in the actual process of the creation of software. They can be involved in the design and planning of smaller systems.</p>","tags":["career","theArchitectRole","roles"]},{"location":"03-areas%20%F0%9F%A7%BE/career/what-is-a-software-engineer/#what-is-a-programmer","title":"What is a programmer?","text":"<p>The programmer is a person who focuses only on the code itself, and does not get involved in planning or design of the system.</p>","tags":["career","theArchitectRole","roles"]},{"location":"03-areas%20%F0%9F%A7%BE/career/what-is-a-software-engineer/#web-developers","title":"Web developers?","text":"<p>They are in charge of building web applications, from the Backend or Frontend side. Yet these are areas of work that require high expertise, the entry barrier is flatter as the one required for other types of software.</p> <p>The software engineer is the architect The software developer is the carpenter</p> <p>The engineer stays close to theory and translates the client's needs into software systems The developer uses computer science background knowledge, and mixes it with patterns, and creativity to find solutions. They connect on the functional level and are the creative driving force of the process of creation of software</p>","tags":["career","theArchitectRole","roles"]},{"location":"03-areas%20%F0%9F%A7%BE/career/what-is-a-software-engineer/#sources","title":"Sources","text":"<p>https://bootcamp.cvn.columbia.edu/blog/software-engineer-vs-developer/ https://www.indeed.com/career-advice/finding-a-job/software-engineer-vs-developer</p>","tags":["career","theArchitectRole","roles"]},{"location":"03-areas%20%F0%9F%A7%BE/feminism/feminism/","title":"Feminism","text":"<p>feminism </p> <p>La acad\u00e9mica de la Casa de Bello agrega: \u201cEsto es lo que plantea Simone de Beauvoir desde El segundo sexo. La mujer es un sujeto que debe hacerse cargo de s\u00ed misma, armar su historia a partir de una deconstrucci\u00f3n de los conceptos y valores que la han normado a ella y que ha aceptado pasivamente. Este segundo ciclo, de reconocimiento, es el comienzo de los feminismos de la actualidad\u201d. https://www.latercera.com/culto/2020/07/06/el-segundo-sexo-cuando-simone-de-beauvoir-fundo-el-feminismo/</p> <p>\u2018Solo despu\u00e9s de que las mujeres empiezan a sentirse en esta tierra como en su casa, se ve aparecer una Rosa Luxemburgo, una madame Curie. Ellas demuestran deslumbrantemente que no es la inferioridad de las mujeres lo que ha determinado su insignificancia\u2019. Rescato su profundidad, su pensamiento cr\u00edtico\u201d.</p> <p>\u201cAs\u00ed es. Necesitamos desprendernos de los constructos culturales para saber qui\u00e9nes somos. Ah\u00ed tenemos que preguntarnos (y de Beauvoir nos ayuda): \u00bfQu\u00e9 significa set mujer? \u00bfDe qu\u00e9 manera esto nos corroe? \u00bfNos resume? \u00bfNos forma? Esa concepci\u00f3n cambia con el tiempo, con los a\u00f1os. El feminismo nos have otras mujeres. A los hombres los have otros hombres. Nos vuelve m\u00e1s humanos, m\u00e1s sensibles, m\u00e1s iguales, m\u00e1s libres. Simone de Beauvoir fue profundamente original. Su escritura, su pensamiento, su dial\u00e9ctica es revolucionaria. Y lo seguir\u00e1 siendo. Ella cre\u00eda en un solo g\u00e9nero: el humano. Ese es el futuro. Una sociedad basada en la fraternidad. El resto importa poco\u201d.</p>","tags":["feminism"]},{"location":"03-areas%20%F0%9F%A7%BE/feminism/onLabels/","title":"onLabels","text":"<p>feminism self-insight understandMyself </p>","tags":["feminism","self-insight","understandMyself","becomeWoman"]},{"location":"03-areas%20%F0%9F%A7%BE/feminism/onLabels/#becoming-a-woman","title":"Becoming a woman","text":"<p>Simone de Beauvoir said once that we are not born women, we become. </p> <p>-- What is to be a woman then? If what I am today is not a woman, then what does it mean to be a woman? --</p> <p>I asked my self back then. I knew that what I was back them, was a rebel without cause. I always followed my impulses. When someone told me to behave in a certain manner, I tried it, but soon enough, I would know with my guts, not with my rational brain, that I did not belong to that box. And I moved on, searching.</p> <p>Not always refusing to behave in the way I was told was received positively, as a matter of facts, many times this awoke in a way the \"fury of the beast\" that is the pathriarcal morality. There were not many extreme situations in my life, but some of them, made a big impact in my life, in those moments when it happened, I ran away faster. I was a good rebel: I tried the requested behaviour, if it didn't work, I moved on and searched a new community, a new city, a new social group, a new country, a new culture. New morals.</p> <p>What I am saying is: I have always been in the search of what it means to become a woman, as well as I have suffered, but I kept walking.</p> <p>Today I feel that I finally became a woman. And from a place of having embraced myself as the woman I am, I want to share with you my journey. I don't know who are you, or if you, a reader, will ever exist, but I sharing my journey is something that I do for you as much as I do for myself.</p> <p>Writing this down, is also a way for me to describe what is to be a woman, how does it feel. Why how does it feel? because I always asked myself this question. I did not admit it it, but I always asked myself: How does it feel to be a woman?. But I did not ask it with my neocortex, I asked it with my reptilian brain. I asked it to myself with my guts.</p>","tags":["feminism","self-insight","understandMyself","becomeWoman"]},{"location":"03-areas%20%F0%9F%A7%BE/feminism/onLabels/#a-victim","title":"A victim","text":"<p>During years I have been feeling victim of mysoginism. I have been hurting for the effects that subconsous bias and patriarchal moral has had in my life. </p> <p>Many times I have been called uncomfortable things, told to behave in a certain way, be exiled from social groups when I have revelled against those request.</p> <p>Yet I have been a victim, I have also been a rebel, and I am proud of it. I have been focused for so long, on how much it hurts to be constantly asked to behave in a manner that conforms with the idea that women are less than men, and all the implications that has on my flourishing as a woman.</p> <p>Finally, after long time, I see things clearly, I see how important is to deal with our pain, feel it through, all the way, cry it out, with all our hearts. Be angry, and scream it out loud, explode, let it all out. I have acknowledged my pain, and I have comforted myself. I have given me what I needed, and what I wanted, I have been kind to myself, and allowed me to feel that pain, as long as was needed, so that I could heal.</p> <p>A note on feeling and expressing your emotions:</p> <p>It is important to express emotions in a healthy manner, avoid self destructive behaviours.f you are not sure if your way to express your emotions is self destructive, or destructive to others, the best thing to do, is talk to a therapist. Friends are also good, but the best person to talk to you about this, is a therapist. They can help you identify and get over any unhealthy manner to express and feel your emotions, and can also get you on a high way to overcome your pain and heal.</p> <p>Only after healing your pain, you can go to a next step: be a rebel</p>","tags":["feminism","self-insight","understandMyself","becomeWoman"]},{"location":"03-areas%20%F0%9F%A7%BE/feminism/onLabels/#a-rebel","title":"A rebel","text":"","tags":["feminism","self-insight","understandMyself","becomeWoman"]},{"location":"03-areas%20%F0%9F%A7%BE/feminism/onLabels/#quotes","title":"Quotes","text":"<p>La acad\u00e9mica de la Casa de Bello agrega: \u201cEsto es lo que plantea Simone de Beauvoir desde El segundo sexo. La mujer es un sujeto que debe hacerse cargo de s\u00ed misma, armar su historia a partir de una deconstrucci\u00f3n de los conceptos y valores que la han normado a ella y que ha aceptado pasivamente. Este segundo ciclo, de reconocimiento, es el comienzo de los feminismos de la actualidad\u201d. https://www.latercera.com/culto/2020/07/06/el-segundo-sexo-cuando-simone-de-beauvoir-fundo-el-feminismo/</p> <p>\u2018Solo despu\u00e9s de que las mujeres empiezan a sentirse en esta tierra como en su casa, se ve aparecer una Rosa Luxemburgo, una madame Curie. Ellas demuestran deslumbrantemente que no es la inferioridad de las mujeres lo que ha determinado su insignificancia\u2019. Rescato su profundidad, su pensamiento cr\u00edtico\u201d.</p> <p>\u201cAs\u00ed es. Necesitamos desprendernos de los constructos culturales para saber qui\u00e9nes somos. Ah\u00ed tenemos que preguntarnos (y de Beauvoir nos ayuda): \u00bfQu\u00e9 significa set mujer? \u00bfDe qu\u00e9 manera esto nos corroe? \u00bfNos resume? \u00bfNos forma? Esa concepci\u00f3n cambia con el tiempo, con los a\u00f1os. El feminismo nos have otras mujeres. A los hombres los have otros hombres. Nos vuelve m\u00e1s humanos, m\u00e1s sensibles, m\u00e1s iguales, m\u00e1s libres. Simone de Beauvoir fue profundamente original. Su escritura, su pensamiento, su dial\u00e9ctica es revolucionaria. Y lo seguir\u00e1 siendo. Ella cre\u00eda en un solo g\u00e9nero: el humano. Ese es el futuro. Una sociedad basada en la fraternidad. El resto importa poco\u201d.</p>","tags":["feminism","self-insight","understandMyself","becomeWoman"]},{"location":"03-areas%20%F0%9F%A7%BE/feminism/onLabels/#feminism-becomewoman-understandmyself","title":"feminism #becomeWoman #understandMyself","text":"","tags":["feminism","self-insight","understandMyself","becomeWoman"]},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/2023-01-06%20Category%20theory/","title":"2023 01 06 Category theory","text":"<p>functionalProgramming math</p> <p>Category theory is a branch of mathematics initially concerned with finding similar constructs within different areas of mathematics. It is a unifying theory. It later was applied to FP.</p>","tags":["functionalProgramming","math"]},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/2023-01-06%20Category%20theory/#parts","title":"Parts","text":"<p>In category theory,\u00a0objects\u00a0can be\u00a0anything: sets, numbers, matrices, just to name a few. In addition to having objects, a category also needs something called morphisms. A\u00a0morphism\u00a0can be defined only in the context of two objects from the category. Let us suppose that\u00a0A\u00a0and\u00a0B\u00a0are objects from a category\u00a0C. Then a morphism is an arrow from\u00a0A\u00a0to\u00a0B.</p> <p>We write it like this:</p> <ul> <li>A\u00a0\u2192\u00a0B</li> </ul> <p>But what does an arrow mean, exactly? Well, it connects object\u00a0A\u00a0to object\u00a0B. Where the arrow starts and where the arrow ends is the information that defines the morphism.</p> <p>In category theory,\u00a0objects\u00a0can be\u00a0anything: sets, numbers, matrices, etc</p> <p>A morphism from object\u00a0A\u00a0to object\u00a0B\u00a0is an arrow from\u00a0A\u00a0to\u00a0B. You could also think of it as a pair of objects in a particular order.</p> <p>First, morphisms compose. What does this mean? We will give the actual\u00a0definition of two morphisms composing, but the general idea is that when you compose two morphisms, you call one morphism and then apply the second morphism to the result of calling the first morphism. Example:</p> <p>f:\u00a0A\u00a0\u2192\u00a0B\u00a0is a morphism, and\u00a0g:\u00a0B\u00a0\u2192\u00a0C\u00a0is a morphism. Since we are in a category, there must exist a morphism\u00a0h\u00a0from\u00a0A\u00a0to\u00a0C\u00a0satisfying: If\u00a0f\u00a0is a morphism from\u00a0A\u00a0to\u00a0B, and\u00a0g\u00a0is a morphism from\u00a0B\u00a0to\u00a0C, then there must exist a morphism\u00a0h\u00a0from\u00a0A\u00a0to\u00a0C\u00a0where for all\u00a0x\u00a0in\u00a0A,\u00a0h(x) =\u00a0g(f(x)). In this case, we denote\u00a0h\u00a0with the expression\u00a0g\u00a0o\u00a0f\u00a0and call it\u00a0f composed with g.</p> <ul> <li>h(x) =\u00a0g(f(x))</li> </ul> <p>A set is just a collection of objects. The objects can be numbers, people, or even other sets. We are about to consider the category whose objects are\u00a0all\u00a0sets.</p> <p>The identity function on a set A is the\u00a0function that maps every element to itself. The category theory version of this is that the identity morphism on\u00a0A, denoted\u00a0idA, when it composes with another function, leaves that function unchanged. *   idB\u00a0o\u00a0g\u00a0=\u00a0g</p> <p>Category theorists tend to think not in terms of points, but rather in terms of composition of functions. The earlier\u00a0expression is how you express the identity function in category theory in terms of composition.... Instead of saying identity morphism takes every point in the object to itself (because we don\u2019t think about the points), you say that when you compose the identity morphism with another morphism, you get the original morphism back.</p> <p>A semigroup is a non-empty set with an associative binary operation on it.</p> <p>A\u00a0semigroup\u00a0has two main parts, a set of elements, (could be any non-empty set) and a binary operation on the set. A binary operation, like multiplication for whole numbers, takes\u00a0two things and returns a third thing. There is one condition that must hold. The binary operation must be associative. We will denote the binary operation with an asterisk (*).</p> <p>In a semigroup, we often call the binary operation multiplication, even if it is not necessarily the usual multiplication of numbers.</p> <p>Functor Is a function that when gets a type applied, produces another type: <code>List[String]</code>\u00a0is not a functor. It is a type.\u00a0<code>List</code>\u00a0by itself is a functor. When you apply it to a type, like\u00a0<code>String</code>, for example, you get a type. This is why, in Scala, a functor is also called a type constructor. (given two categories:\u00a0C1\u00a0and\u00a0C2.) Then a functor\u00a0F\u00a0from\u00a0C1\u00a0to\u00a0C2\u00a0is a function from the first category to the second category, which satisfies the following properties.</p> <ol> <li> <p>F\u00a0takes objects in\u00a0C1\u00a0to objects in\u00a0C2. (Just like\u00a0<code>List</code>\u00a0takes\u00a0<code>String</code>\u00a0to\u00a0<code>List[String]</code>.)</p> </li> <li> <p>F\u00a0takes morphisms in\u00a0C1\u00a0to morphisms in\u00a0C2. (What\u00a0<code>List</code>\u00a0does to a morphism is trickier. It involves the\u00a0<code>map</code>\u00a0function and we will address this next.)</p> </li> <li> <p>F(f\u00a0o\u00a0g) =\u00a0F(f) o\u00a0F(g) whenever the morphism domains and codomains of\u00a0f\u00a0and\u00a0g\u00a0line up.</p> </li> </ol> <p>This condition basically means that the two categories\u00a0C1\u00a0and\u00a0C2\u00a0have similar structure with respect to morphisms. The idea to keep in mind when considering functors is that they measure how similar two categories are.</p> <p>Functors turn up in FP anywhere there are types that implement the\u00a0<code>map</code>\u00a0function. Think\u00a0<code>functor</code>\u00a0= mappable trait (or interface).</p> <p>In category theory, the\u00a0<code>map</code>\u00a0function is what you get when you apply a functor to a morphism. We know that there are three properties a functor from category\u00a0C\u00a0to category\u00a0D\u00a0must satisfy:</p> <ul> <li> <p>A functor\u00a0<code>F</code>\u00a0takes objects in\u00a0C\u00a0to objects in\u00a0D. In the case of the category Scal, this means\u00a0<code>F</code>\u00a0takes Scala types to Scala types.</p> </li> <li> <p><code>F</code>\u00a0takes morphisms in\u00a0C\u00a0to morphisms in\u00a0D.</p> </li> <li> <p>A composition property, seen here:</p> <p>F(f\u00a0o\u00a0g) =\u00a0F(f) o\u00a0F(g)$ where\u00a0f\u00a0and\u00a0g\u00a0are morphisms.</p> </li> <li> <p>They always have a map function.</p> </li> <li> <p>They can always be composed.</p> </li> </ul>","tags":["functionalProgramming","math"]},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/2023-01-06%20Category%20theory/#monoids","title":"Monoids","text":"<p>As I mentioned earlier in the chapter, a semigroup\u00a0is a set with an associative operation on it. If a semigroup has an identify element, which means an element\u00a0e\u00a0in the semigroup with the property that:\u00a0e\u00a0*\u00a0x\u00a0=\u00a0x\u00a0*\u00a0e\u00a0=\u00a0x\u00a0for all elements\u00a0x\u00a0in the semigroup, the semigroup is called a\u00a0monoid.</p>","tags":["functionalProgramming","math"]},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/2023-01-06%20Category%20theory/#categories","title":"Categories","text":"","tags":["functionalProgramming","math"]},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/2023-01-06%20Category%20theory/#set","title":"Set","text":"<p>The objects are all sets. What are the morphisms? Simply all functions from\u00a0A\u00a0to\u00a0B. Every function from\u00a0A\u00a0to\u00a0B\u00a0is a morphism. So\u00a0the category Set is the category whose objects are sets and morphisms are functions from\u00a0A\u00a0to\u00a0B, for all pairs of sets,\u00a0A\u00a0and\u00a0B. A\u00a0is called the domain of the morphism and\u00a0B\u00a0is called the codomain of the morphism</p>","tags":["functionalProgramming","math"]},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/2023-01-06%20Category%20theory/#sources","title":"Sources","text":"<p>Learning Functional programming by Jack Widman in aug. 2022</p>","tags":["functionalProgramming","math"]},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/2023-01-06%20FP%20Patterns/","title":"2023 01 06 FP Patterns","text":"<p>A\u00a0software pattern\u00a0is a reusable solution to a commonly\u00a0occurring problem within a given context in software design. Software patterns mean that we do not have to start from scratch every time we write code. A software pattern is a template for solving a type of problem.</p> <p>Functional programs use code constructs that are immutable, obey referential transparency, use higher order functions, and make liberal use of functional patterns.</p> <p>category theory based Functor, Monoid, and Monad\u00a0patterns</p>"},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/2023-01-06%20FP%20Patterns/#patterns","title":"Patterns","text":""},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/2023-01-06%20FP%20Patterns/#option-pattern","title":"Option pattern","text":"<p>The\u00a0<code>Option</code>\u00a0class comes in two flavors:\u00a0<code>Some</code>\u00a0and\u00a0<code>None</code>.</p> <p>The Option pattern is perfect for problems that involve a\u00a0<code>null</code>\u00a0value. The idea is to have an object represent the case that nulls are used for but to do it with a type. The\u00a0<code>Option</code>\u00a0trait addresses this problem exactly.\u00a0<code>Option</code>\u00a0comes in two flavors.\u00a0<code>Some()</code>, a wrapper\u00a0around a value, such as\u00a0<code>Some(user)</code>, and\u00a0<code>None</code>, which represents the case where there is no answer, the case often expressed by\u00a0<code>null</code>. But\u00a0<code>None</code>\u00a0has a type and so the compiler can check that the code is correct.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/2023-01-06%20FP%20Patterns/#sources","title":"Sources","text":"<p>Learning Functional programming by Jack Widman in aug. 2022</p>"},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/Curry%20%26%20Partial%20Application/","title":"Curry & Partial Application","text":"<p>functionalProgramming softwareConcepts </p> <p>All curried functions are a form of higher-order function which allows you to create specialized versions of the original function for the specific use case at hand.</p> <p>Source</p> <p>point-free style</p> <p>Declare a function without all its parameters. For example: Function composition and curry</p> <p>functionalProgramming softwareConcepts </p>","tags":["functionalProgramming","softwareConcepts"]},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/Maybe%20type/","title":"Maybe type","text":"<p>functionalProgramming fpTerm monad</p>","tags":["functionalProgramming","fpTerm","monad"]},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/Maybe%20type/#definition-from-haskel","title":"Definition from Haskel","text":"<p>A maybe is a monad The\u00a0Maybe\u00a0type is defined as follows:</p> <p>```  data Maybe a = Just a | Nothing</p> <p>```</p> <p>Represent values that may or may not exist. It can be useful if you have a record field that is only filled in sometimes. Or if a function takes a value sometimes, but does not absolutely need it. (this is from elm)</p> <pre><code>    { name : String\n    , age : Maybe Int\n    }\n\ntom = { name = \"Tom\", age = Just 42 }\nsue = { name = \"Sue\", age = Nothing }\n</code></pre> <p>Maybe\u00a0satisfies the\u00a0type\u00a0equation\u00a0, where the functor\u00a0\u00a0takes a set to a point plus that set.</p> <p>source</p>","tags":["functionalProgramming","fpTerm","monad"]},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/Maybe%20type/#definition-from-flow","title":"Definition from flow","text":"<p>It's common for JavaScript code to introduce \"optional\" values so that you have the option of leaving out the value or passing\u00a0<code>null</code>\u00a0instead.</p> <p>Using Flow you can use Maybe types for these values. Maybe types work with any other type by simply prefixing it with a question mark\u00a0<code>?</code>\u00a0such as\u00a0<code>?number</code>\u00a0as a sort of modifier.</p> <p>Maybe types accept the provided type as well as\u00a0<code>null</code>\u00a0or\u00a0<code>undefined</code>. </p> <p>source</p>","tags":["functionalProgramming","fpTerm","monad"]},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/Maybe%20type/#maybe-type-in-typescript","title":"Maybe type in Typescript","text":"<p>It is something or nothing. In JS nothing can be: null or undefined. Due to this is better to define the <code>Nothing</code> as undefined.</p> <p>If an API returns null, then could use something like this: <pre><code>function convertToMaybe(value) {\n  return value ?? undefined;\n}\n</code></pre></p> <p>Or in TS terms, could be:</p> <pre><code>type Maybe&lt;T&gt; = NonNullable&lt;T&gt; | undefined;\n</code></pre> <p>This is a Generic type of the name T.</p> <p>Generics act as a placeholder for a future type not yet decided. Generics let us pass in a type, much like how we pass arguments to a function. We are then using the Generic\u00a0<code>T</code>\u00a0to pass into the\u00a0<code>NonNullable</code>\u00a0type, which basically ensures that\u00a0<code>T</code>\u00a0can't be\u00a0<code>null</code>\u00a0or\u00a0<code>undefined</code>. We are then using the union type operator,\u00a0<code>|</code>, to also allow\u00a0<code>undefined</code>\u00a0as an allowed value.</p>","tags":["functionalProgramming","fpTerm","monad"]},{"location":"03-areas%20%F0%9F%A7%BE/functional-programming/Monad/","title":"Monad","text":"<p>functionalProgramming fpTerm monad</p> <p>Source: https://github.com/getify/Functional-Light-JS/blob/master/manuscript/apB.md/#appendix-b-the-humble-monad</p> <p>\"A monad is a data structure. It's a type. It's a set of behaviors that are specifically designed to make working with a value predictable.\"</p> <ul> <li>functors: a value along with a map-like utility to perform an operation on all its constitute data members.</li> </ul> <p>A monad is a functor that includes some additional behavior.</p> <p>Actually, a monad isn't a single data type, it's really more like a related collection of data types. It's kind of an interface that's implemented differently depending on the needs of different values. Each implementation is a different type of monad.</p> <p>What is a monad, anyway? A monad is a value type, an interface, an object data structure with encapsulated behaviors.</p> <p>But none of those definitions are particularly useful. Here's an attempt at something better: a monad is how you organize behavior around a value in a more declarative way.</p>","tags":["functionalProgramming","fpTerm","monad"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/00-Readme/","title":"00 Readme","text":"<p>This section contains a bunch of quotes from different sources I've used to learn more about cloud native. As a web frontend specialist, I have neglected over the years to learn about these topics, and in the present I find myself being very interested at understanding what this is all about, and in which box what technology, approach, or tool fits.</p> <p>I have followed some Daniela-version of the Zettelkasten method. I am still learning the best way to tag content, so bare with me, or bare with myself</p>"},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/00-Readme/#overview","title":"Overview","text":"<p>Here is an overview of how all this somewhat connects.</p> <p></p>"},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/00-Readme/#good-sources","title":"Good sources","text":"<p>https://www.ibm.com/cloud/learn https://aws.amazon.com/what-is-cloud-computing/?nc2=h_ql_le_int_cc</p>"},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/cloud%20storage/Data%20management%20and%20Databases/","title":"Data management and Databases","text":"<p>microservice database techStack dataManagement cloudComputing cloudNative </p>","tags":["microservice","techStack","dataManagement","cloudComputing","cloudNative","database"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/cloud%20storage/Data%20management%20and%20Databases/#relational-databases-with-jvm","title":"Relational Databases (with JVM)","text":"<p>SQL databases are relational. The relational database management system (RDBMS) is the basis for structured query language (SQL), which lets users access and manipulate data in highly structured tables. This is foundational model for database systems such as MS SQL Server, IBM DB2, Oracle, and MySQL</p> <p>Source: https://www.oracle.com/database/nosql/what-is-nosql/</p>","tags":["microservice","techStack","dataManagement","cloudComputing","cloudNative","database"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/cloud%20storage/Data%20management%20and%20Databases/#how-the-data-is-stored","title":"How the data is stored","text":"<p>The data in an RDBMS is stored in database objects that are called tables. A table is a collection of related data entries, and it consists of columns and rows. These databases require defining the schema upfront, that is, all of the columns and their associated datatypes must be known beforehand so applications can write data to the database. They also store information linking multiple tables through the use of keys, thus creating a relationship across multiple tables. In the simplest case, a key is used to retrieve a specific row so that it can be examined or modified Source: https://www.oracle.com/database/nosql/what-is-nosql/</p>","tags":["microservice","techStack","dataManagement","cloudComputing","cloudNative","database"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/cloud%20storage/Data%20management%20and%20Databases/#when-to-chose-sql","title":"When to chose SQL","text":"<ul> <li>When the business applications rely on highly normalized data to prevent data anomalies as well as data duplication. ie: finance, accounting, and enterprise resource planning </li> <li>When need to do complex queries, sub queries, nested queries</li> </ul>","tags":["microservice","techStack","dataManagement","cloudComputing","cloudNative","database"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/cloud%20storage/Data%20management%20and%20Databases/#tool-hibernate","title":"Tool: Hibernate","text":"<ul> <li>Object Relational Mapping (ORM) database: is a programming technique for converting data between relational databases and object oriented programming languages such as Java, C#, etc.</li> <li>Good for: <ul> <li>perform CRUD operations</li> <li>match better the database with objects</li> <li>mapping metadata</li> </ul> </li> </ul>","tags":["microservice","techStack","dataManagement","cloudComputing","cloudNative","database"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/cloud%20storage/Data%20management%20and%20Databases/#tool-jooq","title":"Tool: JOOQ","text":"<ul> <li>Tool to write SQL. Stands for:  JOOQ Object Oriented Querying</li> <li>Light database mapping library for Java that implements the active record pattern. It aims to provide relational and object oriented domain specific queries. It uses JDBC for the relational queries, might use Hibernate for the Object Mapping ones</li> </ul> <p>active record pattern: an approach to accessing data in a database. The table/view is wrapped in a class, thus an object instance is tied to a row in a table. When the object is updated, the row in the DB is updated too. more: https://en.wikipedia.org/wiki/Active_record_pattern</p>","tags":["microservice","techStack","dataManagement","cloudComputing","cloudNative","database"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/cloud%20storage/Data%20management%20and%20Databases/#nosql-db","title":"noSQL db","text":"<p>NoSQL databases (aka \"not only SQL\") are non-tabular databases and store data differently than relational tables. NoSQL databases come in a variety of types based on their data model. The main types are document, key-value, wide-column, and graph. They provide flexible schemas and scale easily with large amounts of data and high user loads. https://www.mongodb.com/nosql-explained</p>","tags":["microservice","techStack","dataManagement","cloudComputing","cloudNative","database"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/cloud%20storage/Data%20management%20and%20Databases/#how-the-data-is-stored_1","title":"How the data is stored","text":"<p>The data can be stored without defining the schema upfront\u2014which means you have the ability to get moving and iterate quickly, defining the data model as you go. This can be suitable for specific business requirements, whether it\u2019s graph-based, column-oriented, document-oriented, or as a key-value store. https://www.oracle.com/database/nosql/what-is-nosql/</p>","tags":["microservice","techStack","dataManagement","cloudComputing","cloudNative","database"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/cloud%20storage/Data%20management%20and%20Databases/#types","title":"Types","text":"<ul> <li>Document databases store data in documents similar to JSON (JavaScript Object Notation) objects. Each document contains pairs of fields and values. The values can typically be a variety of types including things like strings, numbers, booleans, arrays, or objects.</li> <li>Key-value databases are a simpler type of database where each item contains keys and values.</li> <li>Wide-column stores store data in tables, rows, and dynamic columns.</li> <li>Graph databases store data in nodes and edges. Nodes typically store information about people, places, and things, while edges store information about the relationships between the nodes. https://www.mongodb.com/nosql-explained</li> </ul>","tags":["microservice","techStack","dataManagement","cloudComputing","cloudNative","database"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/cloud%20storage/Data%20management%20and%20Databases/#when-should-nosql-be-used","title":"When should NoSQL be used?","text":"<p>TLDR: real-time web applications and big data</p> <ul> <li>Fast-paced Agile development</li> <li>Storage of structured and semi-structured data</li> <li>Huge volumes of data</li> <li>Requirements for scale-out architecture</li> <li>Modern application paradigms like microservices and real-time streaming</li> </ul>","tags":["microservice","techStack","dataManagement","cloudComputing","cloudNative","database"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/cloud%20storage/Data%20management%20and%20Databases/#tool-apache-cassandra","title":"Tool: Apache Cassandra","text":"<p>https://cassandra.apache.org/_/index.html</p> <p>noSQL Database  that offers wide column (store data in tables, rows, and dynamic columns) with eventually consistent semantics.</p> <p>Read: http://www.sosp.org/2001/papers/welsh.pdf staged event-driven architecture (SEDA) architecture used to design Cassandra.</p> <p>Sources:\" https://cassandra.apache.org/doc/latest/cassandra/architecture/overview.html -- there are there papers to read.</p>","tags":["microservice","techStack","dataManagement","cloudComputing","cloudNative","database"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/cloud%20storage/Data%20management%20and%20Databases/#nosql-in-memory-database","title":"NoSQL - In Memory database","text":"","tags":["microservice","techStack","dataManagement","cloudComputing","cloudNative","database"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/cloud%20storage/Data%20management%20and%20Databases/#redis","title":"Redis","text":"<p>(for REmote DIctionary Server) Is an open source, in-memory, NoSQL key/value store that is used primarily as an application cache or quick-response database. Because it stores data in memory, rather than on a disk or solid-state drive (SSD), Redis delivers unparalleled speed, reliability, and performance. https://www.ibm.com/cloud/learn/redis#toc-differenti-2K4obpj3</p>","tags":["microservice","techStack","dataManagement","cloudComputing","cloudNative","database"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/communication-among-microservices/Data%20Streaming%20in%20Cloud%20Computing/","title":"Data Streaming in Cloud Computing","text":"<p>dataStreaming cloudComputing cloudNative microservice #microservice </p> <p>is the continuous transmission of data from a source to a destination. With streaming, data sources send data frequently, sometimes multiple times per second, and in small quantities. Contrast that with the more traditional batch processing, where operations run infrequently and transmit larger amounts of data each time. Source: https://www.udacity.com/blog/2021/08/what-is-data-streaming.html</p> <p>People who work with this: Data scientist</p> <p>Aka: Streaming data processing</p> <p>Streaming data is data that is generated continuously by thousands of data sources, which typically send in the data records simultaneously, and in small sizes (order of Kilobytes). This data needs to be processed sequentially and incrementally on a record-by-record basis or over sliding time windows, and used for a wide variety of analytics including correlations, aggregations, filtering, and sampling. ... Stream processing requires ingesting a sequence of data, and incrementally updating metrics, reports, and summary statistics in response to each arriving data record. It is better suited for real-time monitoring and response functions.</p> <p>https://aws.amazon.com/streaming-data/</p> <p>In contrast there is: Batch processing</p> <p>Batch processing can be used to compute arbitrary queries over different sets of data. It usually computes results that are derived from all the data it encompasses, and enables deep analysis of big data sets. MapReduce-based systems, like Amazon EMR, are examples of platforms that support batch jobs</p> <p>Many organizations are building a hybrid model by combining the two approaches, and maintain a real-time layer and a batch layer. Data is first processed by a streaming data platform such as Amazon Kinesis to extract real-time insights, and then persisted into a store like S3, where it can be transformed and loaded for a variety of batch processing use cases.</p> <p>treaming data processing requires two layers: a storage layer and a processing layer. </p> <p>The storage layer needs to support record ordering and strong consistency to enable fast, inexpensive, and replayable reads and writes of large streams of data.</p> <p>The processing layer is responsible for consuming data from the storage layer, running computations on that data, and then notifying the storage layer to delete data that is no longer needed.</p> <p>... You also have to plan for scalability, data durability, and fault tolerance in both the storage and processing layers.</p>","tags":["dataStreaming","cloudComputing","cloudNative","microservice"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/communication-among-microservices/Data%20Streaming%20in%20Cloud%20Computing/#infrastructure-tools-to-build-streaming-data-applications","title":"Infrastructure tools to build streaming data applications","text":"<p>Common in event driven architecture</p>","tags":["dataStreaming","cloudComputing","cloudNative","microservice"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/communication-among-microservices/Data%20Streaming%20in%20Cloud%20Computing/#storage-and-processing-layer-kafka","title":"Storage and processing layer: Kafka","text":"<ul> <li>Does: collect, process, and store continuous streams of event data or data that has no precise beginning or end.</li> </ul> <p>Distributed data store optimized to store and handle real time data. Uses pub/sub to stream records and fault tolerance storage.</p> <p>Kafka provides three main functions to its users:</p> <ul> <li>Publish and subscribe to streams of records</li> <li>Effectively store streams of records in the order in which records were generated</li> <li>Process streams of records in real time</li> </ul> <p>https://aws.amazon.com/msk/what-is-kafka/</p>","tags":["dataStreaming","cloudComputing","cloudNative","microservice"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/communication-among-microservices/Data%20Streaming%20in%20Cloud%20Computing/#rabbitmq","title":"RabbitMQ","text":"<p>Open source message broker that uses messaging queue approach. Queues are spread across a cluster of nodes and optionally replicated, with each message only being delivered to a single consumer.</p> <p>https://www.rabbitmq.com/ https://aws.amazon.com/msk/what-is-kafka/</p>","tags":["dataStreaming","cloudComputing","cloudNative","microservice"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/communication-among-microservices/Data%20Streaming%20in%20Cloud%20Computing/#storage-and-processing-layer-aws-kinesis","title":"Storage and processing layer: AWS Kinesis","text":"<ul> <li>Does: collects, processes and analyzes streaming data</li> </ul> <p>process, and analyze real-time, streaming data so you can get timely insights and react quickly to new information</p> <p>Amazon Kinesis is a real-time, fully managed, and highly scalable cloud service for streaming large volumes of data on AWS https://www.whizlabs.com/blog/what-is-aws-kinesis/</p>","tags":["dataStreaming","cloudComputing","cloudNative","microservice"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/communication-among-microservices/Event%20driven%20architecture/","title":"Event driven architecture","text":"<p>architecturePatterns cloudNative microservice reactiveProgramming </p> <p>Microservices are  a foundational part of cloud native application architecture event-driven architecture is widely considered best practice for microservices implementations</p> <p>Event-driven architecture maximizes the potential of cloud native applications and enables powerful applications technologies, such as real-time analytics and decision support. Source: https://www.ibm.com/cloud/learn/event-driven-architecture</p>","tags":["architecturePatterns","cloudNative","microservice","reactiveProgramming"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/communication-among-microservices/Event%20driven%20architecture/#parts","title":"Parts","text":"<ol> <li>Producer: transmits an event\u2014in the form of a message\u2014to a broker or some other form of event router, where the event\u2019s chronological order is maintained relative to other events</li> <li>Consumer:  ngests the message\u2014in real-time (as it occurs) or at any other time it wants\u2014and processes the message to trigger another action, workflow, or event of its own.<ol> <li>Simple event processing. An event immediately triggers an action in the consumer. For example, you could use Azure Functions with a Service Bus trigger, so that a function executes whenever a message is published to a Service Bus topic.</li> <li>Complex event processing. A consumer processes a series of events, looking for patterns in the event data, using a technology such as Azure Stream Analytics or Apache Storm. For example, you could aggregate readings from an embedded device over a time window, and generate a notification if the moving average crosses a certain threshold.</li> <li>Event stream processing. Use a data streaming platform, such as Azure IoT Hub or Apache Kafka, as a pipeline to ingest events and feed them to stream processors. The stream processors act to process or transform the stream. There may be multiple stream processors for different subsystems of the application. This approach is a good fit for IoT workloads.</li> </ol> </li> <li>Broker: The broker receives each event message, translates it if necessary, maintains its order relative to other messages, makes them available to subscribers for consumption, and then deletes them once they are consumed (so that they cannot be consumed again).</li> <li>Message models<ol> <li>Pub/sub: event consumers subscribe to a class or classes of messages published by event producers. When an event producer publishes an event, the message is sent directly to all subscribers who want to consume it. </li> <li>Event Streaming:  In the event streaming model, event producers publish streams of events to a broker. Event consumers subscribe to the streams, but instead of receiving and consuming every event as it is published, consumers can step into each stream at any point and consume only the events they want to consume.\u00a0The key difference here is that the events are retained by the broker even after the consumers have received them. (Kafka is a tool for this)</li> </ol> </li> </ol> <p>source: https://www.ibm.com/cloud/learn/event-driven-architecture</p>","tags":["architecturePatterns","cloudNative","microservice","reactiveProgramming"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/communication-among-microservices/Event%20driven%20architecture/#notes","title":"Notes","text":"<p>Event driven is reactive Event-Driven Systems are Reactive</p> <p>The Reactive Manifesto addresses problems with legacy by laying out the philosophies of modern web-native software development. https://medium.com/swlh/monolith-to-event-driven-microservices-with-apache-kafka-6e4abe171cbb</p> <ul> <li>events are simple notifications raised towards an event store</li> <li>messages are data sent towards an addressable recipient</li> </ul>","tags":["architecturePatterns","cloudNative","microservice","reactiveProgramming"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/communication-among-microservices/Message%20Brokers/","title":"Message Brokers","text":"<p>https://www.ibm.com/cloud/learn/message-brokers</p>"},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/devOps--Infra/Containerization/","title":"Containerization","text":"<p>cloudComputing realTime devOps microservice </p>","tags":["cloudComputing","realTime","devOps","microservice"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/devOps--Infra/Containerization/#container-orchestration","title":"Container Orchestration","text":"<p>Container orchestrators provide automated management for containerized applications, especially in environments in which large numbers of containers are running on multiple hosts. In complex environments such as these, orchestrators are usually needed to handle operations such as deploying and scaling the containers. Kubernetes and Amazon Elastic Container Service (ECS) are examples of popular container orchestration tools. https://www.datadoghq.com/knowledge-center/containerized-applications/#the-role-of-container-orchestration-tools</p> <p>Purspose Constainer applications: * provide a secure, reliable, and lightweight runtime environment for applications that is consistent from host to host.</p> <p>Purpose of serverless: * provide a way to build and run applications without having to consider the underlying hosts at all. To support serverless applications, a cloud provider provisions and deallocates servers as needed behind the scenes.</p>","tags":["cloudComputing","realTime","devOps","microservice"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/devOps--Infra/Containerization/#kubernetes","title":"Kubernetes","text":"<p>System to automate deployment, scaling and management of containerized applications</p> <p>containerized applications: are applications that run in isolated runtime environments called containers. Containers encapsulate an application with all its dependencies, including system libraries, binaries, and configuration files. https://www.datadoghq.com/knowledge-center/containerized-applications/</p>","tags":["cloudComputing","realTime","devOps","microservice"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/devOps--Infra/Databases/","title":"Databases","text":"<p>softwareArchitecture infrastructure devOps database </p>","tags":["softwareArchitecture","infrastructure","devOps","database"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/devOps--Infra/Databases/#tool-db-provisioning-aws-rds","title":"Tool DB provisioning: AWS RDS","text":"<p>Amazon Relational Database Service (Amazon RDS) is a web service that makes it easier to set up, operate, and scale a relational database in the AWS Cloud. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Welcome.html</p>","tags":["softwareArchitecture","infrastructure","devOps","database"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/devOps--Infra/Infrastructure%20provisioning/","title":"Infrastructure provisioning","text":"<p>softwareArchitecture infrastructureAsCode devOps microservice </p>","tags":["softwareArchitecture","infrastructureAsCode","devOps","microservice"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/devOps--Infra/Infrastructure%20provisioning/#historic-background","title":"Historic background","text":"<p>Good read: https://dzone.com/articles/infrastructure-provisioning-%E2%80%93 Summary: Provisioning servers for technology were traditionally: * Buy computers, setup servers, make available, or * Hire a service of managed hosting: you decided what you needed, then hired a service to manage it for you</p> <p>Cloud computing came as the next evolution step of provisioning of infrastructure, the area is called: Cloud provisioning of infrastructure, which was a change of paradigm where no sales person was involved and all is automated.</p> <p>Cloud provisioning of infrastructure is a practice of DevOps. Along with: * CD/CI management: Automate processes of building and deploying software, they might use tools like containers (where they manage the underlying infrastructure) or serverless (where they dont) * Version control of systems and code * Agile software development * Infrastructure as code (IaC) * Configuration management of systems * Monitoring</p>","tags":["softwareArchitecture","infrastructureAsCode","devOps","microservice"]},{"location":"03-areas%20%F0%9F%A7%BE/research-cloud-architectures/devOps--Infra/Infrastructure%20provisioning/#tool-iac-terraform","title":"Tool IaC: Terraform","text":"<p>https://developer.hashicorp.com/terraform/intro Infrastructure as code tool, to build, change and version cloud services. Helps provisioning a consistent workflow and manage all infrastructure in a life cycle. It can manage low-level components like compute, storage, and networking resources, as well as high-level components like DNS entries and SaaS features.</p> <p>for cloud and on-prem (On-premises data centers, commonly referred to as \u201con-prem,\u201d allow you to have full control of your infrastructure, while cloud computing is cost-efficient and easy to scale up and down.)</p>","tags":["softwareArchitecture","infrastructureAsCode","devOps","microservice"]},{"location":"03-areas%20%F0%9F%A7%BE/research-machine-learning-systems/Feature%20engineering/","title":"Feature engineering","text":"<p>A feature store is a specialized component in a machine learning system that is designed to manage and organize the features used for training machine learning models.</p> <p>Features, in this context, refer to the input variables or attributes that are fed into a machine learning algorithm to make predictions or decisions. </p> <p>Feature engineering, which involves selecting, transforming, and preprocessing these features, is a critical part of the machine learning pipeline.</p> <p>The process of choosing what information to use and how to extract this information into a format usable by your ML models is feature engineering.</p> <p>For complex tasks such as recommending videos for users to watch next on TikTok, the number of features used can go up to millions. For domain-specific tasks such as predicting whether a transaction is fraudulent, you might need subject matter expertise with\u00a0banking and frauds to be able to come up with useful features.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/research-machine-learning-systems/Feature%20engineering/#handling-data-leakage","title":"Handling data leakage","text":"<p>Data leakage\u00a0refers to the phenomenon when a form of the label \u201cleaks\u201d into the set of features used for making predictions, and this same information is not available during inference.</p> <p>Example: models were \u201cfound to be picking up on the text font that certain hospitals used to label the scans. As a result, fonts from hospitals with more serious caseloads became predictors of covid risk.\u201d</p>"},{"location":"03-areas%20%F0%9F%A7%BE/research-machine-learning-systems/Feature%20engineering/#glossary","title":"Glossary","text":"<p>Feature: A property of an instance used in a prediction task. For example, a web page might have a feature \"contains the word 'cat'\". Feature Column: A set of related features, such as the set of all possible countries in which users might live. An example may have one or more features present in a feature column. \"Feature column\" is Google-specific terminology. A feature column is referred to as a \"namespace\" in the VW system (at Yahoo/Microsoft), or a\u00a0field.</p> <p>https://learning.oreilly.com/library/view/designing-machine-learning/9781098107956/ch05.htmlsummary-id000006</p>"},{"location":"03-areas%20%F0%9F%A7%BE/research-machine-learning-systems/Glossary/","title":"Glossary","text":"<ul> <li>Instance: The thing about which you want to make a prediction. For example, the instance might be a web page that you want to classify as either \"about cats\" or \"not about cats\".</li> <li>Label: An answer for a prediction task \u00ad\u00ad either the answer produced by a machine learning system, or the right answer supplied in training data. For example, the label for a web page might be \"about cats\".</li> <li>Feature: A property of an instance used in a prediction task. For example, a web page might have a feature \"contains the word 'cat'\".</li> <li>Feature Column: A set of related features, such as the set of all possible countries in which users might live. An example may have one or more features present in a feature column. \"Feature column\" is Google-specific terminology. A feature column is referred to as a \"namespace\" in the VW system (at Yahoo/Microsoft), or a\u00a0field.</li> <li>Example: An instance (with its features) and a label.</li> <li>Model: A statistical representation of a prediction task. You train a model on examples then use the model to make predictions.</li> <li>Metric: A number that you care about. May or may not be directly optimized.</li> <li>Objective: A metric that your algorithm is trying to optimize.</li> <li>Pipeline: The infrastructure surrounding a machine learning algorithm. Includes gathering the data from the front end, putting it into training data files, training one or more models, and exporting the models to production.</li> <li>Click-through Rate\u00a0The percentage of visitors to a web page who click a link in an ad.</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/research-machine-learning-systems/Glossary/#sources","title":"Sources","text":"<p>https://developers.google.com/machine-learning/guides/rules-of-ml</p>"},{"location":"03-areas%20%F0%9F%A7%BE/research-machine-learning-systems/Infrastructure/","title":"Infrastructure","text":""},{"location":"03-areas%20%F0%9F%A7%BE/research-machine-learning-systems/Infrastructure/#inference-generating-predictions","title":"Inference: generating predictions.","text":"<p>Inference: process of generating predictions</p> <p>Main ways a model generates and serves its predictions to users: online prediction and batch prediction. </p> <p>Three main modes of prediction: - Batch prediction, which uses only batch features. Is when predictions are generated periodically or whenever triggered. The predictions are stored somewhere, such as in SQL tables, \u00a0and retrieved as needed. E.g: Discover weekly in Spotify     - \u00a0Also known as\u00a0asynchronous prediction: predictions are generated asynchronously with requests.     - Downsides:          - Makes your model less responsive to users\u2019 change preferences         - \u00a0You need to know what requests to generate predictions for in advance - Online prediction that uses only batch features (e.g., precomputed embeddings). Is when predictions are generated and returned as soon as requests for these predictions arrive. Eg. Translate something in deepl     - Request for predictions happen through RESTful APIs. synchronous prediction: predictions are generated in synchronization with requests.     - Downsides:         - Inference latency: When the model takes too long to generate the prediction.  (Big bottleneck comes from network latency)             - Fix 1: make it do inference faster -&gt; Inference optimization             - Fix 2: make the model smaller -&gt; Model compresion              - Fix 3: make the hardware it\u2019s deployed on run faster. - Online prediction that uses both batch features and streaming features. This is also known as streaming prediction.</p> <p>Generating predictions should be done: on the device (also referred to as the edge)  and the cloud</p> <p>How a model serves and computes the predictions influences how it should be designed, the infrastructure it requires, and the behaviors that users encounter.</p>"},{"location":"03-areas%20%F0%9F%A7%BE/research-machine-learning-systems/Infrastructure/#features","title":"Features","text":"<ul> <li>features computed from historical data, such as data in databases and data warehouses, are\u00a0batch features</li> <li>Features computed from streaming data\u2014data in real-time transports\u2014are\u00a0streaming features. In online prediction, however, it\u2019s possible to use both batch features and streaming features Example: Batch features The mean preparation time of this restaurant in the past</li> </ul> <p>Streaming features: In the last 10 minutes, how many other orders they have, and how many delivery people are available</p> Batch prediction (asynchronous) Online prediction (synchronous) Frequency Periodical, such as every four hours Useful for Processing accumulated data when you don\u2019t need immediate results (such as recommender systems) Optimized for High throughput"},{"location":"03-areas%20%F0%9F%A7%BE/research-machine-learning-systems/Infrastructure/#where-computations-are-done","title":"Where computations are done","text":"<p>where your model\u2019s computation will happen: on the cloud or on the edge - On the cloud means a large chunk of computation is done on the cloud, either\u00a0public clouds or private clouds.     - Downsides:          - Cost - On the edge means a large chunk of computation is done on consumer devices\u2014such as browsers, phones, laptops, smartwatches, cars, security cameras, robots, embedded devices, FPGAs (field programmable gate arrays), and ASICs (application-specific integrated circuits)\u2014which are also known as edge devices.     - Benefits:         - Can run anywhere even if there is no internet         - Lower cost of servers         - No worry about network latency         - Good for handling sensitive user data, makes it easier to comply with GDPR</p> <p>Starting point of many companies: on the cloud in AWS or GCP</p>"},{"location":"03-areas%20%F0%9F%A7%BE/research-machine-learning-systems/Infrastructure/#modes-of-dataflow","title":"Modes of Dataflow","text":"<p>Data passing through databases: Requires both processes to have access to the DB and that the DB is fast</p> <p>Data passing through services using requests such as the requests provided by REST and RPC APIs (e.g., POST/GET requests): A service makes a request, the other responds. Example: To put the microservice architecture in the context of ML systems, imagine you\u2019re an ML engineer working on the price optimization problem for a company that owns a ride-sharing application like Lyft. In reality, Lyft has\u00a0hundreds of services\u00a0in its microservice architecture, but for the sake of simplicity, let\u2019s consider only\u00a0three services:</p> <p>Driver management service Predicts how many drivers will be available in the next minute in a given area.</p> <p>Ride management service Predicts how many rides will be requested in the next minute in a given area.</p> <p>Price optimization service Predicts the optimal price for each ride. The price for a ride should be low enough for riders to be willing to pay, yet high enough for drivers to be willing to drive and for the company to make a profit.</p> <p>Because the price depends on supply (the available drivers) and demand (the requested rides), the price optimization service needs data from both the driver management and ride management services. Each time a user requests a ride, the price optimization service requests the predicted number of rides and predicted number of drivers to predict the optimal price for this ride.24</p> <p>Downside:  Request-driven data\u00a0passing is synchronous, \u00a0the target service has to listen to the request for the request to go through</p> <p>Data passing through a real-time transport like Apache Kafka and Amazon Kinesis.</p> <p>Whichever service wants data from the driver management service can check that broker for the most recent predicted number of drivers, imilarly, whenever the price optimization service makes a prediction about the surge charge for the next minute, this prediction is broadcast to the broker. </p> <p>Technically, a database can be a broker\u2014each service can write data to a database and other services that need the data can read from that database. However, one needs to mind its downsides</p>"},{"location":"03-areas%20%F0%9F%A7%BE/research-machine-learning-systems/Sources/","title":"Sources","text":"<p>Paper about tech debt in ML systems: https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43146.pdf</p>"},{"location":"03-areas%20%F0%9F%A7%BE/research-machine-learning-systems/Technical%20requirements/","title":"Technical requirements","text":"<ul> <li>Since a model\u2019s performance decays\u00a0over time, we want to update it as fast as possible</li> <li>Frequency to retrain your models: 1 a month? --&gt; Question: Does a new deployment means to retrain the model?</li> <li>https://learning.oreilly.com/library/view/designing-machine-learning/9781098107956/ch02.htmlreliability</li> </ul>"},{"location":"03-areas%20%F0%9F%A7%BE/research-programming-and-languages/00-Readme/","title":"00 Readme","text":"<p>This section contains a bunch of quotes from different sources I've used to learn more about programming languages and programming techniques. </p> <p>As a web frontend specialist, I have neglected over the years to learn about these topics, and in the present I find myself being very interested at understanding what this is all about, and in which box what technology, approach, or tool fits.</p> <p>I have followed some Daniela-version of the Zettelkasten method. I am still learning the best way to tag content, so bare with me, or bare with myself</p>"},{"location":"03-areas%20%F0%9F%A7%BE/research-programming-and-languages/paradigms/Functional%20programming/","title":"Functional programming","text":"<p>functionalProgramming programmingParadigm </p> <p>Writing code in \u201cstateless functions\u201d. A stateless function takes in data and outputs it without changing the global state</p> <p>Functional programming is a programming paradigm where you model everything as a result of a function that avoids changing state and mutating data. We will discuss concepts such as state and data mutability and their importance in subsequent sections, but for reference:</p> <p>consider state as one of the different permutations and combinations that your program can have at any given time during its execution</p> <p>data mutability is the concept where a given dataset might change over a given course of time during program execution.</p> <p>Source: https://www.freecodecamp.org/news/functional-reactive-programming-frp-imperative-vs-declarative-vs-reactive-style-84878272c77f/</p>","tags":["functionalProgramming","programmingParadigm"]},{"location":"03-areas%20%F0%9F%A7%BE/research-programming-and-languages/paradigms/Reactive%20Programming/","title":"Reactive Programming","text":"<p>reactiveProgramming realTime eventDriven programmingParadigm</p> <p>Reactive programming is a programming paradigm oriented toward data flows and the propagation of change: programming with asynchronous data streams.</p>","tags":["reactiveProgramming","realTime","eventDriven","programmingParadigm"]},{"location":"03-areas%20%F0%9F%A7%BE/research-programming-and-languages/paradigms/Reactive%20Programming/#good-for","title":"Good for","text":"<ul> <li>Event driven architecture</li> <li>Real time applications</li> <li>Handle large number of active users</li> </ul>","tags":["reactiveProgramming","realTime","eventDriven","programmingParadigm"]},{"location":"03-areas%20%F0%9F%A7%BE/research-programming-and-languages/paradigms/Reactive%20Programming/#reactive-manifesto","title":"Reactive manifesto","text":"<ul> <li>Responsive \u2013 The system responds in a timely manner. Responsive systems focus on providing rapid and consistent response times, so they deliver a consistent quality of service.</li> <li>Resilient \u2013 In case the system faces any failure, it stays responsive. Resilience is achieved by replication, isolation, and delegation. Failures are contained within each component, isolating components from each other, so when failure has occurred in a component, it will not affect the other components or the system as a whole.</li> <li>Scalable- Reactive systems can react to changes and stay responsive under varying workload. They achieve elasticity in a cost-effective way on commodity hardware and software platforms.</li> <li>Message-driven \u2013 In order to establish the resilient principle, reactive systems need to establish a boundary between components by relying on asynchronous message passing.</li> </ul>","tags":["reactiveProgramming","realTime","eventDriven","programmingParadigm"]},{"location":"03-areas%20%F0%9F%A7%BE/research-programming-and-languages/paradigms/Reactive%20Programming/#reactive-tools","title":"Reactive tools","text":"","tags":["reactiveProgramming","realTime","eventDriven","programmingParadigm"]},{"location":"03-areas%20%F0%9F%A7%BE/research-programming-and-languages/paradigms/Reactive%20Programming/#vertx","title":"Vert.x","text":"<p>Reactive applications tooling for JVM a polyglot event-driven application framework that runs on the Java Virtual Machine. https://vertx.io/docs/</p>","tags":["reactiveProgramming","realTime","eventDriven","programmingParadigm"]},{"location":"03-areas%20%F0%9F%A7%BE/research-programming-and-languages/paradigms/Reactive%20Programming/#sources","title":"Sources","text":"<p>https://distributedsystemsauthority.com/what-is-reactive-programming-the-complete-guide/ https://www.reactivemanifesto.org/</p>","tags":["reactiveProgramming","realTime","eventDriven","programmingParadigm"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-04%20-%20Archictecture%20trade-off%20analysis/","title":"2023 01 04   Archictecture trade off analysis","text":"<p>techniques softwareArchitecture tradeOff</p> <p>Idea Making technical decisions on architecture requires to specify clearly what the trade offs are. It has been common in  my experience to see technical people making architecture decisions, leaving the trade offs undocumented, and invisible. </p> <p>I want to change that for myself now, and for my team.</p> <p>Techniques * Qualitative vs quantitative  * MECE lists * out of context trap * model relevant use cases </p> <p>Source theory https://learning.oreilly.com/library/view/software-architecture-the/9781492086888/ch15.html</p> <p>examples https://learning.oreilly.com/library/view/software-architecture-the/9781492086888/app03.html</p>","tags":["techniques","softwareArchitecture","tradeOff"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/","title":"2023 01 16   ADRs & RFCs differences and process","text":"<p>technicalWritting softwareArchitecture systemsDocumentation</p>","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#need","title":"Need","text":"<p>At work I am currently designing a new system together with my team. The system will start as an MVP, and in will be extended in features and scaled to users and regions over time.</p> <p>With such scale of the system, the people working on the system will also scale, therefore the need to start with a lean documentation approach, something that is the minimum required for us to kick start, and iterate over it, adding the necessary layers.</p>","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#types-of-documentation","title":"Types of documentation","text":"<ol> <li>Product documentation: Anything related to UI/UX design, functionality, users, business needs, and any other similar input that characterises the system</li> <li>Technical documentation: Systems documentation including architecture (structure), best practices, non functional requirements. This documentation aims to describe the mechanics of how the system works. Within this type there are some subtypes I can identify:<ol> <li>Non Functional requirements/-ilities, and how we measure them</li> <li>Systems/Architecture diagrams/C4Model</li> <li>RFCs/ADRs</li> <li>Practices etc</li> </ol> </li> </ol>","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#when-to-do-an-rfc-and-when-to-do-an-adr","title":"When to do an RFC and when to do an ADR?","text":"<p>For that, let's look at this definition of software architecture</p> <p>\u201cIn most successful software projects, the expert developers working on that project have a shared understanding of the system design. This shared understanding is called \u2018architecture.\u2019 This understanding includes how the system is divided into components and how the components interact through interfaces. These components are usually composed of smaller components, but the architecture only includes the components and interfaces that are understood by all the developers.\u201d </p> <p>Martin Fowler in Who needs an architect</p> <p>Here we can get the point that suggest: * Architecture is about the overall structure of the whole system, meaning Architecture &gt; Design * Architecture is a social construct because it depends on group consensus as well as on software.</p> <p>So, within this context, and RFC is suitable to design decisions, and ADRS for architecture decisions.</p>","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#adrs","title":"ADRs","text":"<p>Alternative</p>","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#when-to-make-an-adr","title":"When to make an ADR","text":"<p>Martin Fowler described an Architectural Decision (AD) as \u201ca decision that you wish you could get right early\u201d in an\u00a0IEEE Software article.</p> <p>Translation: when the decision is architecturally significant. Architectural significance 1.  Architectural decisions directly or indirectly determine the\u00a0non-functional characteristics (or qualities)\u00a0of a system (think -ilities) 2.  Each decision describes a concrete, architecturally significant\u00a0design issue (problem)\u00a0for which several potential\u00a0solution options\u00a0exist and provides rationale for the\u00a0decision outcome\u00a0(the selection of the chosen solution option, that is), for instance by arguing whether and how the desired quality attributes will be achieved. 3.  Architectural decisions concern a\u00a0software system as a whole, or one or more of the\u00a0core components\u00a0of such system (whatever the \u201ccore\u201d might be).</p> <p>Architectural significance test Do this to decide if making an ADR makes sense for this use case 1.  Impact on\u00a0business value and risk? 2.  Key stakeholder concern? 3.  Unusual quality-of-service requirement\u00a0(at least one order of magnitude more advanced than previous ones)? 4.  About\u00a0external dependencies that are uncontrollable, unpredictable or unreliable? 5.  Cross-cutting, system-wide impact? 6.  First-of-a-kind character\u00a0(novelty for team)? 7.  Caused\u00a0bad experience and trouble in the past?</p> <p>Source</p>","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#process-to-make-an-adr","title":"Process to make an ADR","text":"<pre><code>\nflowchart TB\n  A[Seek Evidence proposed solution works] &lt;--&gt; B[Establish selection Criteria and alternative]\n  A &amp; B --&gt; C[Seek Agreement]\n  C --&gt; D[Document decision outcome]\n  D --&gt; E[Realization and plan a Revision in the future]\n\n</code></pre> <p>Source</p> <p>Process checklist</p> <ul> <li> Are we confident enough that this design will work (<code>Evidence</code>)?</li> <li>[] Have we decided between at least two options, and compared them (semi-)systematically (<code>Criteria</code>) ?</li> <li>[] Have we discussed among each other and with peers just enough and come to a common view (<code>Agreement</code>)?</li> <li>[] Have we captured the decision outcome\u00a0and shared the decision record (<code>Document</code>)?</li> <li>[] Do we know when to realize, review and possibly revise this decision (<code>Realization  &amp; Revise</code>)</li> </ul> <p>Suggested template Decision record template by Michael Nygard</p>","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#rfc","title":"RFC","text":"","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#when-to-make-an-rfc","title":"When to make an RFC","text":"<ul> <li>You want to frame a problem and propose a solution.</li> <li>You want thoughtful feedback from team members on our globally-distributed remote team.</li> <li>You want to surface an idea, tension, or feedback.</li> <li>You want to define a project or design brief to drive project collaboration.</li> <li>You need to surface and communicate around an important, highly cross-functional decision.</li> </ul>","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#when-to-skip-the-rfc","title":"When to skip the RFC","text":"<ul> <li>You want to discuss personal or sensitive topics one-on-one with another team member.</li> <li>If you can decide on your own. In the vast majority of cases, creating an RFC to explain yourself will be overkill. RFCs should only be used if a decision explicitly requires one of the bullets in the section above.</li> </ul>","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#process","title":"Process","text":"<p>Suggested process</p> <ul> <li>Draft the proposal for the type of problem, feedback, practice, that you want to propose. Create spike if necessary</li> <li>Seek for comments and place a due date for the comments</li> <li>Bring topic to architecture forum, web guild or so, if necessary</li> <li>Plan and do implementation</li> </ul> <p>Open decision: Confluence? or Git?</p>","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#tr-template","title":"TR Template","text":"<p><pre><code>## Summary\n### Goals\n### Non Goals\n## Overview\n## Product requirements\n# Detailed design\n# Risks and unresolved questions\n</code></pre> Other alternatives</p> <pre><code>-   Background\n-   Proposal\n-   Abandoned ideas\n-   (Custom sections, for example:)\n-   Implementation\n-   UX\n-   UI\n</code></pre>","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#notations-to-consider","title":"Notations to consider","text":"<p>Status</p> <p>Draft | Proposed | Published</p> <p>Type</p> <p>Experimental | Informational | Best Current Practice | Required</p> <p>Scope</p> <p>The scope of work affected by the RFC document.</p> <p>Notational conventions</p> <p>The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"NOT RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this document are to be interpreted as described in\u00a0BCP 14 RFC2119,\u00a0RFC8174\u00a0when, and only when, they appear in all capitals, as shown here, and without quotes.</p> <p>Context</p> <p>A description of the problem space and/or requirements that this RFC is set to address.</p> <p>Decision</p> <p>A description of the proposed solution, which sets out the specifications of the implementation of the RFC. Should include specific details on how the solution addresses the requirements as laid out in the Context section.</p> <p>Consequences</p> <p>Any consequences that are in play as a result of the decision being put into place.</p>","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#references","title":"References","text":"","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#technical-decisions-that-scale-the-org","title":"Technical decisions that scale the org","text":"<ul> <li>The Architecture Advice Process with Andrew Harmel-Law</li> <li>Design docs at Google</li> <li>Architecture decision record resources and templates</li> <li>Love Unrequited: The Story of Architecture, Agile, and How Architecture Decision Records Brought Them Together</li> <li>ADR = Any Decision Record? Architecture, Design and Beyond</li> <li>Who needs an architect?</li> </ul>","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#rfcs","title":"RFCS","text":"<ul> <li>Rust process</li> <li>Planning for change with RFCs</li> <li>Scaling Engineering Teams via RFCs: Writing Things Down</li> </ul>","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-16%20-%20ADRs%20%26%20RFCs%20differences%20and%20process/#further-reading","title":"Further reading","text":"<ul> <li>Design practice Why? Seems more suitable for DDD, and the artifacts are similar to the ones we are currently using</li> <li>Scaling Engineering Teams via RFCs: Writing Things Down</li> <li>6 Lessons I learned while implementing technical RFCs as a decision making tool</li> </ul>","tags":["technicalWritting","softwareArchitecture","systemsDocumentation"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/2023-01-25%20-%20Component%20API/","title":"2023 01 25   Component API","text":"<p>wip-post components developIdea componentAPI impossibleState</p> <p>What is? An API is an interface that allows an encapsulated software component to communicate with the outside world. </p> <p>Designing UI components can also be thought in the same manner, an UI component should be encapsulated, and its props are what allow it to communicate with the outside world.</p> <p>Therefore, the props of the component are imthe API of the component.</p> <p>As any API, if design principles were not thought through, evolved and agreed upon, they might end up being hard to use, hard to configure, and overtime become unmaintainable or unused.</p> <p>Ideas of design principles</p> <p>1 Make impossible states impossible: State pattern: An object should change its behavior when its internal state changes. An impossible state in a UI component happens when two or more properties collide or override each other, letting the component to \"not know\" what should do.</p> <p>ie:  <pre><code>&lt;alert warning&gt; hola&lt;/alert&gt;\n&lt;alert success&gt; hola&lt;/alert&gt;\n\nImpossible state:\n&lt;alert warning success&gt; hola&lt;/alert&gt;\n</code></pre></p> <p>A fix for this could be use an Enum instead of a Boolean to set the behaviour of the component. <pre><code>&lt;alert state=\"warning\"&gt; hola&lt;/alert&gt;\n</code></pre></p> <ul> <li>Original principle from Elm</li> <li>Kent Dods article:  </li> </ul> <p>2. Use Types for the props, and inside the components: Maybe avoid booleans, and try to use enums instead of strings for prop types so you can make it easy to pass the specific values allowed by your prop.</p> <p>3. Be consistent with names across all components ie: use always the same prop name for props that do the same thing across components. ie: <code>variant</code></p> <p>4. Minimize boolean usage</p> <p>Boolean ambiguity can lead to loss of intent and loss of information in our code, resulting in ambiguous logic. To avoid this issue, we should prefer self-documenting alternatives whenever the intention is unclear.</p> <p>Inspiration guides</p> <p>[Inspiration article])(https://hackernoon.com/principles-of-component-api-prop-design-bb20cd58da54)</p>","tags":["web","components","developIdea","wip-post","componentAPI","impossibleState"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/","title":"Tech stack for a real time app","text":"<p>realTime softwareArchitecture </p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#container-orchestration","title":"Container Orchestration","text":"<p>Container orchestrators provide automated management for containerized applications, especially in environments in which large numbers of containers are running on multiple hosts. In complex environments such as these, orchestrators are usually needed to handle operations such as deploying and scaling the containers. Kubernetes and Amazon Elastic Container Service (ECS) are examples of popular container orchestration tools. https://www.datadoghq.com/knowledge-center/containerized-applications/#the-role-of-container-orchestration-tools</p> <p>Purspose Constainer applications: * provide a secure, reliable, and lightweight runtime environment for applications that is consistent from host to host.</p> <p>Purpose of serverless: * provide a way to build and run applications without having to consider the underlying hosts at all. To support serverless applications, a cloud provider provisions and deallocates servers as needed behind the scenes.</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#kubernetes","title":"Kubernetes","text":"<p>System to automate deployment, scaling and management of containerized applications</p> <p>containerized applications: are applications that run in isolated runtime environments called containers. Containers encapsulate an application with all its dependencies, including system libraries, binaries, and configuration files. https://www.datadoghq.com/knowledge-center/containerized-applications/</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#languages","title":"Languages","text":"","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#kotlin","title":"Kotlin","text":"<p>Good for * Multiplatform:      * iOS, Android: Major use case.     * Web frontend: kotlinJS     * Server-Side: Kotlin/JVM * Data science:     * has tooling for: deep learning, visualization tools, data processing, statistics, math, etc.</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#python","title":"Python","text":"","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#reactive-tools","title":"Reactive tools","text":"","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#vertx","title":"Vert.x","text":"<p>Reactive applications tooling for JVM a polyglot event-driven application framework that runs on the Java Virtual Machine. https://vertx.io/docs/</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#databases","title":"Databases","text":"","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#relational-databases-with-jvm","title":"Relational Databases (with JVM)","text":"<p>SQL databases are relational. The relational database management system (RDBMS) is the basis for structured query language (SQL), which lets users access and manipulate data in highly structured tables. This is foundational model for database systems such as MS SQL Server, IBM DB2, Oracle, and MySQL</p> <p>Source: https://www.oracle.com/database/nosql/what-is-nosql/</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#how-the-data-is-stored","title":"How the data is stored","text":"<p>The data in an RDBMS is stored in database objects that are called tables. A table is a collection of related data entries, and it consists of columns and rows. These databases require defining the schema upfront, that is, all of the columns and their associated datatypes must be known beforehand so applications can write data to the database. They also store information linking multiple tables through the use of keys, thus creating a relationship across multiple tables. In the simplest case, a key is used to retrieve a specific row so that it can be examined or modified Source: https://www.oracle.com/database/nosql/what-is-nosql/</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#when-to-chose-sql","title":"When to chose SQL","text":"<ul> <li>When the business applications rely on highly normalized data to prevent data anomalies as well as data duplication. ie: finance, accounting, and enterprise resource planning </li> <li>When need to do complex queries, sub queries, nested queries</li> </ul>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#tool-hibernate","title":"Tool: Hibernate","text":"<ul> <li>Object Relational Mapping (ORM) database: is a programming technique for converting data between relational databases and object oriented programming languages such as Java, C#, etc.</li> <li>Good for: <ul> <li>perform CRUD operations</li> <li>match better the database with objects</li> <li>mapping metadata</li> </ul> </li> </ul>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#tool-jooq","title":"Tool: JOOQ","text":"<ul> <li>Tool to write SQL. Stands for:  JOOQ Object Oriented Querying</li> <li>Light database mapping library for Java that implements the active record pattern. It aims to provide relational and object oriented domain specific queries. It uses JDBC for the relational queries, might use Hibernate for the Object Mapping ones</li> </ul> <p>active record pattern: an approach to accessing data in a database. The table/view is wrapped in a class, thus an object instance is tied to a row in a table. When the object is updated, the row in the DB is updated too. more: https://en.wikipedia.org/wiki/Active_record_pattern</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#nosql-db","title":"noSQL db","text":"<p>NoSQL databases (aka \"not only SQL\") are non-tabular databases and store data differently than relational tables. NoSQL databases come in a variety of types based on their data model. The main types are document, key-value, wide-column, and graph. They provide flexible schemas and scale easily with large amounts of data and high user loads. https://www.mongodb.com/nosql-explained</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#how-the-data-is-stored_1","title":"How the data is stored","text":"<p>The data can be stored without defining the schema upfront\u2014which means you have the ability to get moving and iterate quickly, defining the data model as you go. This can be suitable for specific business requirements, whether it\u2019s graph-based, column-oriented, document-oriented, or as a key-value store. https://www.oracle.com/database/nosql/what-is-nosql/</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#types","title":"Types","text":"<ul> <li>Document databases store data in documents similar to JSON (JavaScript Object Notation) objects. Each document contains pairs of fields and values. The values can typically be a variety of types including things like strings, numbers, booleans, arrays, or objects.</li> <li>Key-value databases are a simpler type of database where each item contains keys and values.</li> <li>Wide-column stores store data in tables, rows, and dynamic columns.</li> <li>Graph databases store data in nodes and edges. Nodes typically store information about people, places, and things, while edges store information about the relationships between the nodes. https://www.mongodb.com/nosql-explained</li> </ul>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#when-should-nosql-be-used","title":"When should NoSQL be used?","text":"<p>TLDR: real-time web applications and big data</p> <ul> <li>Fast-paced Agile development</li> <li>Storage of structured and semi-structured data</li> <li>Huge volumes of data</li> <li>Requirements for scale-out architecture</li> <li>Modern application paradigms like microservices and real-time streaming</li> </ul>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#tool-apache-cassandra","title":"Tool: Apache Cassandra","text":"<p>https://cassandra.apache.org/_/index.html</p> <p>noSQL Database  that offers wide column (store data in tables, rows, and dynamic columns) with eventually consistent semantics.</p> <p>Read: http://www.sosp.org/2001/papers/welsh.pdf staged event-driven architecture (SEDA) architecture used to design Cassandra.</p> <p>Sources:\" https://cassandra.apache.org/doc/latest/cassandra/architecture/overview.html -- there are there papers to read.</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#nosql-in-memory-database","title":"NoSQL - In Memory database","text":"","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#redis","title":"Redis","text":"<p>(for REmote DIctionary Server) Is an open source, in-memory, NoSQL key/value store that is used primarily as an application cache or quick-response database. Because it stores data in memory, rather than on a disk or solid-state drive (SSD), Redis delivers unparalleled speed, reliability, and performance. https://www.ibm.com/cloud/learn/redis#toc-differenti-2K4obpj3</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#architecture","title":"Architecture","text":"<p>Event driven reactive Event-Driven Systems are Reactive</p> <p>The Reactive Manifesto addresses problems with legacy by laying out the philosophies of modern web-native software development. https://medium.com/swlh/monolith-to-event-driven-microservices-with-apache-kafka-6e4abe171cbb</p> <ul> <li>events are simple notifications raised towards an event store</li> <li>messages are data sent towards an addressable recipient</li> </ul>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#infrastructure","title":"Infrastructure","text":"","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#terraform","title":"Terraform","text":"<p>infrastructureAsCode https://developer.hashicorp.com/terraform/intro Infrastructure as code tool, to build, change and version cloud services. Helps provisioning a consistent workflow and manage all infrastructure in a life cycle. It can manage low-level components like compute, storage, and networking resources, as well as high-level components like DNS entries and SaaS features.</p> <p>for cloud and on-prem (On-premises data centers, commonly referred to as \u201con-prem,\u201d allow you to have full control of your infrastructure, while cloud computing is cost-efficient and easy to scale up and down.)</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#aws-rds","title":"AWS RDS","text":"<p>Amazon Relational Database Service (Amazon RDS) is a web service that makes it easier to set up, operate, and scale a relational database in the AWS Cloud. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Welcome.html</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#data-streaming","title":"Data Streaming","text":"","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#kafka","title":"Kafka","text":"<p>Distributed data store optimized to store and handle real time data. Uses pub/sub to stream records and fault tolerance storage. Kafka provides three main functions to its users:</p> <ul> <li>Publish and subscribe to streams of records</li> <li>Effectively store streams of records in the order in which records were generated</li> <li>Process streams of records in real time</li> </ul> <p>https://aws.amazon.com/msk/what-is-kafka/</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#rabbitmq","title":"RabbitMQ","text":"<p>Open source message broker that uses messaging queue approach. Queues are spread across a cluster of nodes and optionally replicated, with each message only being delivered to a single consumer.</p> <p>Used to communicate among services. It creates a queue of messages</p> <p>https://www.rabbitmq.com/ https://aws.amazon.com/msk/what-is-kafka/</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-areas%20%F0%9F%A7%BE/software-architecture/Tech%20stack%20for%20a%20real%20time%20app/#aws-kinesis","title":"AWS Kinesis","text":"<p>process, and analyze real-time, streaming data so you can get timely insights and react quickly to new information</p> <p>Amazon Kinesis is a real-time, fully managed, and highly scalable cloud service for streaming large volumes of data on AWS https://www.whizlabs.com/blog/what-is-aws-kinesis/</p>","tags":["tools","softwareArchitecture","realTime","infrastructureAsCode"]},{"location":"03-projects%20%F0%9F%93%85/readme/","title":"Readme","text":"<p>\u201ca series of tasks linked to a goal, with a deadline.\u201d</p>"},{"location":"03-projects%20%F0%9F%93%85/app-in-my-music/draft-ideas.md/","title":"Draft ideas.md","text":"<p>pet-project , idea-to-refine build-for-fun music </p> <p>The main idea of the app is to be a web browser app, made with whatever tech I decide, to practice, and learn full software design, and product design. At my own pace, with or without help of others. To have my own thing that I grow over time.</p> <p>It would solve my need of: * Finding new music * Finding something in my music sources, according to: mood, genre, occasion, rather than only by title of playlist, artist name or album.  * Recommend and promote alternative, indie-web-like, new music, new music sources (ie: flow state, fip radio, etc) * Find in those whatever they are playing</p>","tags":["pet-project","idea-to-refine","build-for-fun","music"]},{"location":"03-projects%20%F0%9F%93%85/app-in-my-music/draft-ideas.md/#music-streaming-apis","title":"Music streaming APIS","text":"<p>https://rapidapi.com/search/music</p> <p>Shazam - Best for Identifying Songs &amp; Music Recognition</p> <p>TheAudioDB - Best for All Around Song &amp; Music Video Data</p> <p>Spotify Best for Music Metadata &amp; Playlists</p> <p>LastFM - Best for Metadata, Charts &amp; Cover Art</p> <p>30,000 radio stations and music charts Best for Radio Station Data</p> <p>https://jonasrmichel.github.io/radio-garden-openapi/</p>","tags":["pet-project","idea-to-refine","build-for-fun","music"]},{"location":"03-projects%20%F0%9F%93%85/app-in-my-music/draft-ideas.md/#features","title":"Features","text":"<ul> <li>Search by mood, genre, occasion</li> <li>Search in spotify, radios</li> <li>Get info of current song (artist etc)</li> <li>Sort playlists by genre</li> <li>Web player</li> <li>Music inspiration:<ul> <li>online magazines?</li> </ul> </li> <li>Option to edit custom order of my playlits</li> <li>Intelligent search:<ul> <li>Powered by AI?</li> <li>Search by mood, genre, name of artist, playlist, album, year.</li> </ul> </li> <li>My library with sorting of albums and playlists per genre, mood</li> </ul>","tags":["pet-project","idea-to-refine","build-for-fun","music"]},{"location":"03-projects%20%F0%9F%93%85/app-in-my-music/draft-ideas.md/#data-fetching-alternatives","title":"Data Fetching alternatives","text":"<ul> <li>https://relay.dev/</li> <li>https://swr.vercel.app/</li> </ul> <p>Questions: * What are the standards nowadays?</p>","tags":["pet-project","idea-to-refine","build-for-fun","music"]},{"location":"03-projects%20%F0%9F%93%85/app-in-my-music/draft-ideas.md/#state-management","title":"State management","text":"<ul> <li>What are the options nowadays? </li> </ul>","tags":["pet-project","idea-to-refine","build-for-fun","music"]},{"location":"03-projects%20%F0%9F%93%85/app-in-my-music/draft-ideas.md/#backend-deployments","title":"Backend &amp; Deployments","text":"<ul> <li>Lambda AWS -&gt; Event driven serverless computing platform</li> <li>Nest JS ?</li> <li>Lambda Netlify + faunadb</li> </ul> <p>Boilerplates * https://github.com/arabold/serverless-react-boilerplate</p>","tags":["pet-project","idea-to-refine","build-for-fun","music"]},{"location":"03-projects%20%F0%9F%93%85/app-in-my-music/draft-ideas.md/#database","title":"Database","text":"<ul> <li>DynamoDB</li> </ul>","tags":["pet-project","idea-to-refine","build-for-fun","music"]},{"location":"03-projects%20%F0%9F%93%85/app-in-my-music/draft-ideas.md/#tasks","title":"Tasks","text":"<ul> <li>[] Finish AWS registration</li> <li>[] Create AWS key -&gt; https://www.serverless.com/framework/docs/providers/aws/guide/credentials#create-an-iam-user-and-access-key</li> <li>[] Follow tutorial: https://blog.logrocket.com/building-serverless-app-typescript/</li> </ul>","tags":["pet-project","idea-to-refine","build-for-fun","music"]},{"location":"03-projects%20%F0%9F%93%85/app-in-my-music/draft-ideas.md/#tech","title":"Tech","text":"<ul> <li>React</li> <li>Backend: NodeJs</li> <li>AWS Serverless</li> </ul>","tags":["pet-project","idea-to-refine","build-for-fun","music"]},{"location":"03-projects%20%F0%9F%93%85/app-in-my-music/draft-ideas.md/#web-apis","title":"Web APIs","text":"<p>https://developer.spotify.com/documentation/web-playback-sdk/ https://developer.spotify.com/documentation/web-api/ https://developer.spotify.com/documentation/web-api/reference/#/ https://developer.spotify.com/documentation/general/guides/working-with-playlists/ https://developer.spotify.com/documentation/general/guides/local-files-spotify-playlists/</p>","tags":["pet-project","idea-to-refine","build-for-fun","music"]},{"location":"03-projects%20%F0%9F%93%85/app-in-my-music/draft-ideas.md/#references","title":"References","text":"<p>https://medium.com/geekculture/spotify-system-architecture-6bb418db6084</p>","tags":["pet-project","idea-to-refine","build-for-fun","music"]},{"location":"03-projects%20%F0%9F%93%85/app-personal-finances/Draft/","title":"Draft","text":""},{"location":"03-projects%20%F0%9F%93%85/app-personal-finances/Draft/#product","title":"Product","text":""},{"location":"03-projects%20%F0%9F%93%85/app-personal-finances/Draft/#tech-stack","title":"Tech stack","text":"<ul> <li>Backend options: <ul> <li>nodeJs - NestJS</li> <li>python</li> <li>kotlin/JVM https://kotlinlang.org/docs/multiplatform-full-stack-app.html#create-a-data-model</li> </ul> </li> <li>DB options: (noSQL)</li> <li>Frontend options:<ul> <li>Kotlin/JS</li> <li>React</li> <li>Vue</li> </ul> </li> </ul>"},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/2022-10-27%20-%20Take%20home%20challenge/","title":"2022 10 27   Take home challenge","text":"<p>career interviewing </p> <p>This is a more practical type of interview. The company prepares a code challenge, that you do in your own time. The rule is that you take 3-5 days to solve. Once you send it, the development team reviews the submission, and if your solution matches their expectations, then they invite you for a 90minute interview, to talk about your solution, do some live coding, and talking further about topis specifics to the position.</p> <p>The goal of this type of interview, usually is to figure out in a practical manner how you code, and to know how much you can do pair programming, how do you solve problems on the spot etc.</p> <p>Good for: * Finding in a practical manner how people code. * Have some code that allows for practical conversations to understand where the person is technically speaking</p> <p>Limitations: * Setting up the code challenge, in a way that helps you find what you want to know is hard * Time investment: considering the stack is new to the candidate, the setup needs to be simple enough for them to quickly jump in and do something * Expectation management: some companies tend to expect the candidate to produce production ready code. However, a code challenge is something that candidates do in their own time, and should be solved in 8h max. Depending on the amount of work that needs to be done, producing production ready code might be setting unrealistic expectations * Room for interpretation: In some cases the ask is very open to the interpretations of the candidate. This can lead to having different expectations, the company might expect A, B and C. And the candidate might think A and B are enough and decide deliberately not to do C. The company ends up rejecting the candidate, even though they were able to do C and D. * It is still a code challenge: Some places tend to expect production ready solutions. However, this is a code challenge. They are missing the fact that what this actually helps to know, is how they solve a specific software problem within the bounds of 8h, in a setup and product terminology that is new to them. * Candidates might not be honest with regards of the type they invested on it: Many candidates will have the tendency to say that they spent less time than they actually did on the challenge. Doing this mostly comes from the desire to pass the challenge. When they do this, and you blindly trust this, without actually putting yourself on the seat of the candidate, you might end up with the idea the challenge takes less time than it does, and this might lead you to developed a flawed technical assessment. * Fluency with specific tools: Being an engineer in general is more about having the mental structured in the mind to be able to read and understand how different tools work. Many developers for example, are fluent with a specific tool, but being fluent with it is not an indicator of their understanding and fluency with software itself. So, a candidate who is not fluent with the tools that you provided, might build a less refined solution than another candidate who is more fluent with it. You might end up hiring the more fluent one, but you might be missing the opportunity to hire a good engineer who would pick things up very quickly and ultimately deliver more value than a tool-specific developer.</p> <p>Challenges to overcome * Setting up of the challenge: it is important while setting up a challenge with regards to:     * Delivery form: will you give and receive a zip file, a repository, a code sandbox?     * Timeline: How long will you give the candidate to solve the challenge, and how you handle delays, or expectations with regards to this.     * Problem to solve: What excersice will you give the candidate to solve, level of specificity of requirements, room for interpretation, etc.     * Technical setup: Will you give more or less a ready app for the candidate to build upon it, or will you give a document, letting the candidate to decide on the technology? will the candidate have a command to run to install everything and just start working? or do they need to install other tooling in order to be able to start? Do they need to choose libraries to install to be able to solve the problem? or do they need to write vanilla code to solve the problem?     * Documentation about the delivery: Building software is not only about writing code, it is also documenting and explaining solutions, trade-offs, and guiding others when it comes to reviewing code. In this regard, and as part of the solution of the challenge, the question are: will the developer need to answer specific questions in the delivery? not at all? fill a template?      * Reviewing time and feedback giving: If the feedback is that the person didn't pass, usually is enough to just name the pros and the contras. However, when naming the contras as a reason for why the candidate didn't pass, usually what the candidate gets is a simple list with some words, but lack of explanation of why these things lead the decision maker to say it is not a fit. Communicating a rejection is part of interview experience, and this is often overlooked. On the other side, communicating why a person passed, is neither communicated. Giving this feedback might be useful for the candidate to explicitly know which items of what they did led you to find them as a good fit.     * 90 min technical call: A practice for those who passed the challenge is to have a 90 min call to basically talk nerd. Live coding calls might be not intimidating, but also are time consuming for the candidate. What is the structure you will follow in this call? Will you continue putting the same skills of the developers under test? Are you trying to find flaws? Are your expectations that in these 90 minutes the developer does a production ready solution? or are you looking for structure of thinking, problem solving approach? Mentoring skills, pair programming skills, architecture thinking, etc? Basically, are you still trying to assess the same technical skills based on expectations to assess production ready quality code? or are you trying to figure out where the non-code-writing skills of the candidate are?</p>","tags":["career","interviewing"]},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/2022-10-27%20-%20question%20only%20interview/","title":"2022 10 27   question only interview","text":"<p>career interviewing </p> <p>A type of technical assessment that some companies do, is to make a verbal interview. Some companies might ask about your experience, and digg into the specifics of the projects, out of them gather information about where you are technically.</p> <p>Other companies prepare a list of topic specific questions, such as: What is a closure in JS? What is a Generic in TS, and what is good for?</p> <p>None of the different types of technical interviews are inherently bad, nor good. All of them serve a purpose, and help the company to find out where is the person, technically speaking.</p> <p>Here some ideas about this interview</p> <p>Good for: * Figuring out the cognitive knowledge of the person with regards of software engineering * Might be a good form of screening, and filtering out some candidates. However, this should be taken with a pinch of salt, due to the limitations highlighted below. * Companies who are in need of building software in a more academic perspective, where all the engineers have to match the traditional stereotype of a good engineer: has rational brain completely informed about technical concepts, traverse a binary tree, etc.</p> <p>Limitations: * Having cognitive knowledge about software engineering is not an indicator of what the candidate can actually do. A student from CS has a lot of cognitive knowledge about software engineering, however when putting this knowledge into practice, they usually have limitations.  * There are multiple types of engineers, some people have a fully informed brain with all the concepts, some don't. Having a question only interview about technical topics, will make difficult to find the candidate who doesn't have all the names in, or the names of the things that you have asked, but is a good engineer who can deliver value, and diverse ideas to your team.</p>","tags":["career","interviewing"]},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/Guide%20to%20interviewing%20and%20thoughts/","title":"Guide to interviewing and thoughts","text":"<p>interviewing reflection self-insight #reflection </p> <p>These are unrefined notes based on my experience of interviewing for different product companies. I have done many interviews in 2022, and out of interviewing a lot, I have learned some things about:</p> <ul> <li>Where do I want to work?</li> <li>What type of interview processes exist?</li> <li>How do I like one or other?</li> <li>Length of interview process</li> <li>Time needed to invest on them</li> <li>Usually when I am rejected, it was a bidirectional rejection, just that the recruiter said it first. In all the cases I've been grateful for the rejection, and I have learned something</li> </ul>","tags":["interviewing","reflection","self-insight"]},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/Guide%20to%20interviewing%20and%20thoughts/#outline","title":"Outline","text":"<ul> <li>Hiring processes:</li> <li>Email &amp; scheduling with recruiters</li> <li>Screening</li> <li>Tech interview<ul> <li>Live coding: practical case / Algorithm</li> <li>White boarding</li> <li>Read code</li> <li>Take home exercise</li> </ul> </li> <li>Eng. management exercise</li> <li>Defend the submitted code</li> <li>System's design</li> <li>Interview with Engineering Manager // Tech lead // CTO</li> <li>Interview with team</li> <li>What I've learned</li> </ul>","tags":["interviewing","reflection","self-insight"]},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/Guide%20to%20interviewing%20and%20thoughts/#what-ive-learned","title":"What I've learned","text":"<p>*** Talk to recruiters &amp; scheduling:**   * How much refined, automated and digitalised the scheduling with the recruiter might be an indicator for the digital maturity of the organisation * Right mindset for interview**   * One interview a day is best   * If I am too stressed, is better to reschedule   * Warm up before coding interviews * Diagnosing culture match by talks to interviewers:    * How experienced are the interviewers, and how comfortable I feel talking with them   * Kind of empathy EMs give   * How do EM/ICs deliver feedback within the interview -&gt; Sometimes they are too cold, too critic, might be an indicator of a culture that is more masculine (Understood according to Hofstede's culture dimensions: distinct gender roles, assertive, and concentrated on material achievements and wealth-building) driven * People/companies I dont necessarily match well     * Lack of empathy or showing a smile but I still feel \"evaluated\" in a critical manner     * Put pressure/doesn't know how to help me be less nervous in coding interviews * My needs from a workplace:   * Have support   * Understand and be understood   * Be able to be myself, this means: I am a woman who leads, codes and behaves in a collaborative manner, looking to improve the tech and the processes of building softare - In contrast of: focus on business needs alone, deadlines, compromising human wellbeing for 'progress', defensiveness, competitiveness   * Learn with, and from my colleagues   * Psychological safety * Ideal benefits    * Unlimited paid time off    * Budget for learning    * Company focusing on building a well-being focused culture    * Work life balance    * All common baselines: hardware, safari books, hybrid or remote friendly    * Flexible working hours    * Recruiter verbally and clearly acknowledges gender pay gap, and pushes me up if I say something below people in similar positions in the company * As an IC:    * How is the process to get professional compensation (salary increases, promotions, technical challenges)?    * Do I get continuously salary increases even if I want to stay as an IC and not take a Staff/principal or Engineering manager role?    * How do the engineering managers/company deal with frustration in the team?    * How does the engineering manager/company solves conflict?    * What are the means that the company is actively doing to foster diversity and inclusion?    * How does the company/EM deals with: choleric developers/passive aggressiveness/behaviours that derail psychological safety?</p>","tags":["interviewing","reflection","self-insight"]},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/Guide%20to%20interviewing%20and%20thoughts/#my-thoughts-on-coding-interviews","title":"My thoughts on Coding Interviews","text":"<ul> <li>Live coding: -&gt; Is currently my least preferred version (time of writing August 2022) <ul> <li>practical case: These are more approachable, and assess the things that I have been doing (or not). These are easier for me to take, but it depends on the interviewers</li> <li>algorithm: Usually these are used in companies that are building products such as: Browsers, Open source frameworks, high demand software (ie: Spotify, Miro, etc) -&gt; They use this because they are optimising for performance in software.</li> <li>Contra:</li> <li>I have to practice and learn the skill of programming out loud and competitive programming</li> <li>The mental resources that I invest on competitive programming, are taken out of the actual programming</li> <li>You pass when you complete the task, is like a math teacher giving point for result and not for procedure.</li> <li>You have to study for this</li> <li>Benefit:</li> <li>You assess how the person collaborate with others and their capacity of leading mob programming or pair programming sessions (note: this is not entirely true, because the level of trust you have with team mates is different than the one you have with people who you just met and are evaluating you)</li> <li>Is time effective for the recruiter, if the interviewer sees that you cant solve the problem (for whatever reason) they cut you off and say is not a fit. Or if you solve the problem, you know it in 45mins (the average length)</li> <li>Studying for these types of interviews, in my personal case, gives me quick mental challenges, helps me refresh on software algorithms, and is intellectually estimating. Currently I am doing exercises of this in HackerRank, mainly for fun, and maybe as side effect become better at these types of interviews one day.</li> </ul> </li> <li>White boarding:<ul> <li>It's long time since I have one of these, therefore my contras are not listed, and the benefits might be incomplete</li> <li>Benefit:</li> <li>Like a math teacher giving points for procedure not for results</li> <li>Assess how you think of problems</li> <li>You dont have to remember the details of everything</li> </ul> </li> <li>Read code:<ul> <li>I would probably prefer this one, I've been reading code non stop during all my career, and jumping back from a management role to an individual contributor role, this version would help me better, and require less studying.</li> <li>Haven't done one of these. Benefits and contras absent therefore</li> </ul> </li> <li>Take home exercise:<ul> <li>Contra: They are the ones that require more time investment: you have to ramp yourself up, understand the tooling, the task and do it. Then you have to 'defend' your work in an interview</li> <li>Benefit: I can do the work as I normally would do work. So I dont have to study and learn the skill of competitive programming, needed in live coding interviews</li> </ul> </li> </ul>","tags":["interviewing","reflection","self-insight"]},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/interview-questions/","title":"Interview questions","text":"<p>interviewing career </p> <p>Inspiration of questions to ask / to assess in a new organisation https://franciscomt.medium.com/the-systems-within-a-software-team-dc69d31cf9f9</p>","tags":["interviewing","career"]},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/interview-questions/#as-an-interviewee","title":"As an interviewee","text":"","tags":["interviewing","career"]},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/interview-questions/#for-first-calls","title":"For first calls","text":"<ul> <li>From your perspective, what are the strengths and weaknesses of this firm?</li> <li>How engineering strategy and product strategy work together?</li> </ul>","tags":["interviewing","career"]},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/interview-questions/#for-technical-interviewers","title":"For technical interviewers","text":"<ul> <li>What is currently slowing down the team's delivery? </li> <li>What process does the team have to identify and improve the system?</li> <li>What do you expect me to accomplish in the first 90 days?</li> <li>What does the shipping look like internally?</li> </ul>","tags":["interviewing","career"]},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/interview-questions/#for-hiring-managers-or-recruiters","title":"For hiring managers or recruiters","text":"<ul> <li>What are the current goals of the team?</li> <li>How much attention do you pay to reducing friction for the engineering team?</li> <li>How engineering strategy and product strategy work together?</li> <li>What is the largest problem facing the current team that needs to be addressed immediately?</li> <li>What type of personalities generally work well within your team?</li> </ul>","tags":["interviewing","career"]},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/interview-questions/#as-an-interviewer-or-interviewee","title":"As an interviewer or interviewee","text":"<ul> <li>What do you like most and you dislike most about what you do?</li> </ul> <p>1. How will I fail? can clue you into whether or not the person who\u2019s interviewing you has truly thought about your success in the role</p> <p>2. How do you incentivise your team? tells what is important for the person Red flags if the incentives are unfair, unattainable, or not well thought through.</p> <p>3. Can you share an example of something the team did that didn\u2019t go well, and what did you do to course correct?</p> <p>helps you learn is whether or not the team and leadership have thought about principles and values, how they communicate and uphold those, and how they work to hold a high bar. The second thing this question can do is help you understand if the team is rewarded for thinking like scientists</p> <p>Source https://github.com/readme/guides/technical-interviews</p>","tags":["interviewing","career"]},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/interview-questions/#questions-per-caterogy","title":"Questions per caterogy","text":"<p>Culture * How engineering strategy and product strategy work together? * From your perspective, what are the strengths and weaknesses of this firm? * How do you balance deadlines with innovation and quality? * What are the key organizational values and principles that I should pay attention to? * How do you choose who to promote?</p> <p>Impact * What is the largest problem facing the current team that needs to be addressed immediately? * How does this role and project contribute to the firm\u2019s larger goals? * What types of skills and expertise are you looking to fill with a contract engineer? * What are some of the challenges or roadblocks I might encounter? * If you hire me, what would your top priorities be for me? * What behaviors do team members that are the most successful exhibit? What behaviors do team members who struggle the most exhibit?  What do you think are the best ways to keep an engineering team motivated?</p> <p>team work *   \u2013 How can I make sure that I get off on the right foot with my teammates? *   \u2013 How often does the team meet and how do they prefer to communicate? *   \u2013 How would you describe the team chemistry and dynamics? Who are the key players? *   \u2013 With whom will I be working most closely? *   \u2013 What will be my role on the team? *   \u2013 What other tips would you offer me?</p>","tags":["interviewing","career"]},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/interview-questions/#ask-myself","title":"Ask myself","text":"<ol> <li>What is my personality?</li> <li>What are my values?</li> <li>What are my strengths vs opportunities for development?</li> <li>What brings me joy?</li> <li>What type of work environment do I thrive in?</li> </ol>","tags":["interviewing","career"]},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/interview-questions/#as-an-interviewer","title":"As an interviewer","text":"<p>Eng manager questions * How do you handle conflict? * How would I monitor team performance from a Product perspective. * Tell me about a time you had an underperforming direct report * What does it mean success to you? How do you measure it? Can you give us some examples? * How you do you measure direct reports performance? Have you managed a low performer individual? * Talk about your teams tech stack and how you picked it. * How do you health-check a team? * How do you health-check a codebase? * Can you tell me about a feedback that had a big impact on your career? Who provided it? What kind of impact did it have on you? * What is your biggest weakness? * Tell me about a time you had to work alongside a difficult co-worker * Describe a time when you failed. How did you overcome this? * You're assigned a task you don't know how to complete. What do you do?</p>","tags":["interviewing","career"]},{"location":"03-projects%20%F0%9F%93%85/post-technical-assessments/interview-questions/#screening","title":"Screening","text":"<p>1: Tell me about the highest-impact project you've done recently. </p> <p>\u201cTell me about a time you acted quickly without enough information.\u201d -&gt; If the candidate explains a situation in a way which demonstrates that they have (and understand) bias for action, they are more likely to be hired.</p> <p>2: What were the goals, and how did you deliver on them? </p> <p>3: If you replaced yourself with any other PM at the company, how would the outcome of the project have been different?</p> <p>3 additions from me: 1. Tell me specific moments that you felt celebrating in the PM role? 2. What things do you not like to do? 3. Tell us things didn't go the way you wanted, or a project that didn't turn out how you had hoped.</p> <p>Great answers:  1: Clearly articulates a high-impact project.  2</p> <p>: Shares specific milestones and metrics, while giving credit to the team.  </p> <p>3: Cites their specific impact and unique contributions, but does not over-congratulate themselves.</p> <p>interviewing career interview-questions</p>","tags":["interviewing","career"]},{"location":"03-projects%20%F0%9F%93%85/tech-radar/Tech%20Radar%20-%20presentation/","title":"Tech Radar   presentation","text":"<p>technicalDecisions techRadar </p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/Tech%20Radar%20-%20presentation/#tech-radar","title":"Tech radar","text":"<p>The tech radar is an advisory tool that provides insight into the current de-facto standards in a problem space, as well as past practices, and experimental techniques we use within the company. It's a visual representation of our evolving technological landscape, showing what software or methodologies we use, experiment with, or retire.</p> <p>It is informed with insights coming from both external elements, such as industry trends and technological landscape, and internal elements, such as what teams are doing and using, and what skills we have in the organisation.</p> <p>In summary, it helps making a decision by providing context of:</p> <ul> <li>What everyone else is doing</li> <li>Who has which skills</li> <li>What are the general trends in the industry</li> </ul>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/Tech%20Radar%20-%20presentation/#benefits","title":"Benefits","text":"<ul> <li>Creating consistency and focus of efforts in the organisation: By providing an overview of the technological landscape the tech radar helps to create discussions about where our effort should be directed and where it should be reduced.</li> <li>Fosters alignment and architecture mindset: It creates general alignment and technological understanding and promotes a broader engagement to contribute to our evolving architecture and grow the architectural mindset of our engineers.</li> <li>Tool to evaluate and inform decisions: The Tech Radar helps with evaluating new technologies in a coherent manner, without jumping into the latest trend. It also provides a structure for analysing new technologies and making experiments public to the company, which ultimately leads to better decisions.</li> <li>Structure for experimentation and innovation: it provides a structure to evaluate new technologies in a coherent manner (without jumping in the latest trend), to be able to analyse it whilst making the experiment public to the company and ultimately make better decisions.</li> <li>Cross-team collaboration and knowledge sharing: ti helps to bring transparency to what technologies are being used, and how collaboration can happen among teams using a similar tool that don't work closely. It also gives visibility about consistency in the organisation.</li> </ul>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/Tech%20Radar%20-%20presentation/#usages-of-tech-radar","title":"Usages of tech radar","text":"<p>The tech radar is a complementary decision making tool to other decision making practices that exist in our company. In practical manner, some ways to use the tech radar more actively to inform decisions in following manners:</p> <ul> <li>Link it to technical decision documents: When writing and technical decision document, providing the link to the tech radar entry, to complement it with the contextual information</li> <li>Link it to best practices or engineering principles: When we are writing a best practice, or an engineering principle document, we could link it to the tech radar entry. For example: Adding a note if we start using a new technology or decide to adopt a practice that was previously experimental. Which can help to keep track of how our decisions impact the technology landscape and whether we need to update our radar accordingly.</li> <li>Informing individual career learning path, as well as profiles to hire: By having visibility of the landscape of technologies and practices, engineers can use it as a guide to decide in which areas they could expand their knowledge, and the hiring team can create more informed profiles</li> </ul>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/Tech%20Radar%20-%20presentation/#frequency-of-updates","title":"Frequency of updates","text":"<p>These are guild specific to decide, common practices on this regard are quarterly or half-yearly updates. The key is to pay attention of how the radar is being consumed/or not, by the guilds or arch forum.</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/Tech%20Radar%20-%20presentation/#structure-quadrants","title":"Structure: Quadrants","text":"<ul> <li>Programming Languages and Frameworks.\u00a0This was just languages but we rolled frameworks into here with the October 2012 Radar.  <ul> <li>Examples: io-ts, NestJS, Swift package manager.</li> </ul> </li> <li>Tools.\u00a0These can be components, such as databases, software development tools, such as versions control systems; or more generic categories of tools, such as the notion of polyglot persistence.<ul> <li>Examples: AWS Control tower, XCode Cloud,</li> </ul> </li> <li>Platforms.\u00a0Things that we build software on top of such as mobile technologies like Android, virtual platforms like the JVM, or generic kinds of platforms like hybrid clouds.<ul> <li>Examples: backstage, AWS Database Migration Service (DMS), Teleport</li> </ul> </li> <li>Techniques.\u00a0These include elements of a software development process, such as experience design; and ways of structuring software, such as microservices.<ul> <li>Examples: Path to production mapping, Team cognitive load, Design tokens, Component visual regression testing</li> </ul> </li> </ul> <p>We don't make a big deal out of the quadrants \u2014 they\u2019re really just a way to break up the Radar into topic areas. We don't think it's important which quadrant a blip goes into, unlike the rings - which generate a lot of discussion.</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/Tech%20Radar%20-%20presentation/#structure-rings","title":"Structure: Rings","text":"<p>Each entry goes through the following 4 stages (usually). </p> <p>Adopt: We feel strongly that we should be adopting these items, and we we should use them when appropriate on our projects. They are mature and proven in the org or one of the guilds. Our engineers know how to use them and all the tooling is there.</p> <p>Trial: Worth pursuing. It is important to understand how to build up this capability. We don\u2019t have yet the knowledge or capability of using these technologies. We should try this technology on a project that can handle the risk.</p> <p>Assess: They are worth exploring with the goal of understanding how they could affect our practice. They are to be considered, but not necessarily trial yet \u2013 unless you think they would be a particularly good fit for a specific project, for which you have a technical decision document (ADR, RFC). Technologies in this stage are interesting and worth keeping an eye on.</p> <p>Hold: We can proceed using them but with caution. These technologies are to be retired/deprecated.</p> <p>A recent alternative to these rings is the introduced in the Build your own tech radar tool from thought works which are: \u201cexperiment\u201d, \u201cadopt\u201d, \u201chold\u201d and finally \u201cretire\u201d</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/Tech%20Radar%20-%20presentation/#faq","title":"FAQ","text":""},{"location":"03-projects%20%F0%9F%93%85/tech-radar/Tech%20Radar%20-%20presentation/#must-i-use-only-what-is-in-tech-radar","title":"Must I use only what is in tech radar?","text":"<p>The tech radar is advisory in nature. If you have the need to use a technology or practice that is not in tech radar, you can use it. However, if you chose to use it, and skip tech radar, you would be missing an opportunity, as well as the benefits we have highlighted in this document. </p> <p>What is important here is to understand why we encourage you to do this, which we try to explain below:</p> <p>The tech radar aims to provide an overview of what we use in the organisation, technical trends, and climate within the company. And also helps having transparency over what technologies are we experimenting with, bringing up possibilities of collaboration and knowledge sharing.</p> <p>One of the primary goals of the tech radar, is to serve to make better decisions, independently of what, you want to make informed decisions, so that when you look at the past, you feel good with yourself about the decision you made, because you made the best decision you could, provided the knowledge and resources you had at the time.</p> <p>So, If you find yourself in the need of making a technical decision for something that is not in tech radar, a way to go would be:</p> <ul> <li>Write a technical decision document such an ADR or an RFC</li> <li>Share it with the members of your guild (you can also share a draft of a technical decision)</li> <li>Get feedback (making your decision more informed), and discuss about bringing it to tech radar under assess.</li> </ul> <p>The benefits of contributing to tech radar in this particular case go to you as an engineer with knowledge, to your team with stronger decisions, and to your guild and our engineering domain with transparency, visibility and ultimately evolving our technological landscape.</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/Where%20tech%20radar%20fits%20in%20the%20engineering%20strategy/","title":"Where tech radar fits in the engineering strategy","text":"<p>technicalDecisions techRadar </p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/Where%20tech%20radar%20fits%20in%20the%20engineering%20strategy/#where-tech-radar-fits","title":"Where tech radar fits?","text":"<p>When you go and seek advice, spend most time and effort speaking to people who will disagree with you; those who you know think along different lines and where you know you will have blind spots. Not only this, challenge yourself. Consider \u201cwhat\u2019s bad about this alternative? What are its shortcomings?\u201d Spend the most time thinking about the alternatives which challenge your decision most directly and fundamentally.</p> <p>To learn most effectively you need to feel safe, and when learning collectively everyone benefits from the broadest, most diverse range of inputs contributing to discussions. Remember, in this approach, we are explicitly not looking for consensus, but we are looking for a broad range of inputs and voices.</p> <p>Our adoption of the Advice Process opened up the space for anyone to make decisions, but it has also put conversations, the responsibility to seek out expertise, and think about impact at the core. The remainder of the elements of this approach, each of which supports the core element focus specifically on ensuring those conversations are as timely, focused and effective as possible. There are four of them:</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/Where%20tech%20radar%20fits%20in%20the%20engineering%20strategy/#a-thinking-and-recording-tool-adrs","title":"A thinking and recording tool: ADRs","text":"<p>The first supporting element is\u00a0Architectural Decision Records\u00a0or ADRs. These are lightweight documents, frequently stored in source code repositories alongside the artefacts they describe.</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/Where%20tech%20radar%20fits%20in%20the%20engineering%20strategy/#a-time-and-place-for-conversations-the-architecture-advisory-forum","title":"A time and place for conversations: The Architecture Advisory Forum","text":"<p>The second supporting element in this alternative approach exists to make all the conversations supporting this advice-seeking easier: a weekly, hour-long Architecture Advisory Forum (\u201cAAF\u201d).</p> <p>Fundamentally, this is a regular and recurring place and time for conversations. Your ideal attendees are delegates from each team as well as your key representatives from your Advice Process checklist. However, the invite should remain completely open to encourage transparency and openness. The timeliness and quality of the conversations which take place is a key indicator of success, but equally important is the breadth and diversity of views shared, and the same goes for the contributors. If architecture is being \u201cdone\u201d here, and lessons shared and learned, then you\u2019re winning.</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/Where%20tech%20radar%20fits%20in%20the%20engineering%20strategy/#a-light-to-illuminate-a-unified-goal-team-sourced-architectural-principles","title":"A light to illuminate a unified goal: Team-sourced Architectural Principles","text":"<p>-&gt; The principles, you\u2019ll recall, give us an idea of the direction of travel which our ideal solution will ideally manifest, \u00a0Not all will be relevant, but some principles ought to help our decision-making. Recall that it\u2019s an architectural principal\u2019s primary goal to assist in the evaluation of multiple technical possibilities, and highlight the one which fits best.</p> <p>Having architectural principles is not new, though sadly I rarely encounter serviceable ones. Always important, in a world of highly-autonomous-teams they become essential because they are the means by which an aligned delivery direction is achieved without the need for control.</p> <p>So what makes a good architectural principle? Firstly, it must provide a criteria with which to evaluate our architectural decisions (which in practice means it must be specific, measurable, achievable, realistic and testable, aka \u201cS.M.A.R.T\u201d). Secondly, it must support the business\u2019s strategic goals. Thirdly, it must articulate the consequences / implications it necessarily contains within it. Finally, taken together as a set, they should number neither too few to cover the key needs which architectural principles meet, nor too many that teams cannot remember them all.</p> <p>Remember that this approach is aimed at supporting team autonomy, so one key role played by our principles is as a minimal viable set of understandings and agreements between everyone.</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/Where%20tech%20radar%20fits%20in%20the%20engineering%20strategy/#a-means-to-sense-the-current-technical-landscape-and-climate-tech-radar","title":"A means to sense the current technical landscape and climate: Tech radar","text":"<p>How do we also take note of our surrounding landscape and climate? Architectural decisions are also frequently based on what everyone else is doing, who has which skills, and what the general trends in the tech industry are. Enter the fourth and final supporting element: your own Technology Radar.</p> <p>The radar in comparison is a lot more advisory in nature. It will give an idea of what, if anything, is the current de-facto standard in our problem space, what\u2019s been done in the past, and what other teams might be experimenting with. Going a different way is a lot less likely to raise eyebrows, but it is again a definite reason to address the deviation in the ADR.</p> <p>Result will give a great overview of the landscape and prevailing climate, and brings many discussions about where effort should be directed, and where it should be reduced. And just as with the principles, give rise to a general aligning of team understanding.</p> <p>Questions: - Shouldn't we include UX/UI design things? - Shouldn't we include human relate things like: managing team's cognitive load? etc?</p> <p>Result will give a great overview of the landscape and prevailing climate, and brings many discussions about where effort should be directed, and where it should be reduced. And just as with the principles, give rise to a general aligning of team understanding.</p> <p>Goal: - Have an overview of the landscape of technologies we use in the organisation and prevailing climate. The idea is to bring discussions about where our effort should be directed, and where should be reduced. With this we give rise to have a general alignment and understanding - Create a broadest engagement with your evolving architecture as possible, as well as a growing architectural mindset across all team members.</p> <p>Usages: - Link an assess technology with an ADR and/ or a discussion in a guild or arch forum - Entries in ADRs, or engineering principles can be linked to tech radar entries. Example: if we start using a new technology or decide to adopt a practice that was previously experimental, we would flag it here. This helps us keep track of how our decisions impact the technology landscape and whether we need to update our radar accordingly.</p> <p>How often to update it? - Cadence is specific to the guild. Can be: quarterly, half-yearly. The key is to pay attention of how the radar is being consumed/or not, by the guilds or arch forum.</p> <p>What about the usage of your radar? As with the principles, there is also a place in our ADRs for \u201cRelevant Radar Blips\u201d. This is where we flag both adherence to the existing landscape as reflected in the current radar, but also, and more importantly, potential changes to the existing radar which this decision will introduce. Perhaps it\u2019s the spiking of a new framework, or a move from \u201cexperiment\u201d to \u201cadopt\u201d for a specific practice.</p> <p>Again, this is great grist for the AAF discussion forum, and great content to capture in the ADR itself. You can even go so far as linking specific types of blip appearances and movements to the need to submit ADRs, though in my experience this happens anyway without anyone having to push it explicitly. Remember, your goals here are the broadest engagement with your evolving architecture as possible, as well as a growing architectural mindset across all team members.</p> <p>How about keeping your radar up to date? I've seen quarterly cadences work, and half-yearly too. The key is to pay attention to how the radar is being consumed (or not) at the AAF and elsewhere. That should give you a good idea when it's worth investing in a refresh.</p> <p>Tech Radar</p> <p>It helps you bring transparency in the enterprise to what technologies are being used, and how collaboration can happen among teams using a similar tool that dont work closely. It also gives visibility about consistency in the organisation.</p> <p>For example the status assess helps you to not jump on the latest new tech, to be able to analyse it, and make it public to the company to learn if other people are doing something and experimenting with it. Which will help making a better decision.</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/","title":"Welcome to Slidev!","text":"<p>To start the slide show:</p> <ul> <li><code>npm install</code></li> <li><code>npm run dev</code></li> <li>visit http://localhost:3030</li> </ul> <p>Edit the slides.md to see the changes.</p> <p>Learn more about Slidev on documentations.</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/notes/","title":"What's in for the audience?","text":"<p>Makers * Understand framework where tech radar fits, and how they can use it to their advantage for their career growth as well as making technical decisions Multipliers * Understand how the framework can help to tackle common scale up issues, such as alignment, consistency, cross team collaboration, knowledge sharing</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/notes/#once-upon-a-time","title":"Once upon a time:","text":"<p>There was an engineer who was very good, he was an eminence, he made all the decisions. There was also an engineer who wanted to jump onto the latest big thing... (aka: Let's go to monolith because Prime Video is going monolith !!!)</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/notes/#but-one-day","title":"But one day","text":"<p>The company decides to go from 1 to N (scale up) </p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/notes/#because-of-that","title":"Because of that","text":"<p>They could not go on vacation, and had to work late, make many decisions, etc The developer who wanted to adopt monoliths got upset because their boss said no, and they didn't understand why</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/notes/#because-of-that_1","title":"Because of that","text":"<p>They burned out, and his team started to get upset, because they lacked autonomy and did not learn further. The developer decided to change jobs because they had a bad boss, and they could not use the lates hip technology (monoliths)</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/notes/#until-one-day-until-finally","title":"Until one day/ Until finally","text":"<p>They decide to adopt the Advisory architecture  - Architecture as a team sport</p> <p>[explain here what it is]</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/notes/#problem-its-all-about-making-a-decision","title":"Problem: It's all about making a decision","text":""},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/notes/#why-making-decisions-is-hard","title":"Why making decisions is hard","text":"<p>Fear of Failure</p> <p>Making a decision means you might be wrong. And nobody likes to be wrong.</p> <p>Fear of Hurt Feelings</p> <p>Sometimes, being decisive means choosing one idea over another. We are afraid this will make someone upset or cause conflict.</p> <p>Fear of Incomplete information</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/notes/#tackling-making-decision-fears","title":"Tackling making decision fears","text":"<p>The Fear: Fear of Failure Tackling Tip:  Not making a decision is also making a decision!</p> <p>The Fear: Fear of Hurt Feelings Tackling Tip:  It\u2019s not about right vs wrong - we succeed as a team, and we fail as a team</p> <p>The Fear: Fear of Incomplete Information Tackling Tip: Embrace imperfect information - you\u2019ll never know everything but that doesn\u2019t mean you can\u2019t make a decision</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/notes/#moral-of-the-story-take-aways","title":"Moral of the story: / Take aways:","text":"<ul> <li>Making decisions is hard, using tools to aid on it, helps</li> </ul>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/slides/","title":"Once upon a time","text":"<p>Intro</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/slides/#but-one-day","title":"But one day","text":"<p>Problem </p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/slides/#and-because-of-that","title":"and because of that","text":""},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/slides/#until-one-day-advisory-architecture","title":"Until one day: Advisory architecture","text":"<p>seeking advice in this context means to spend most time and effort speaking to people who will disagree with you to find where are the flaws in your design. </p> <p>It is not consensus, it means to be an informed captain, where you hear different voices and perspectives</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/slides/#mindset-architecture-as-a-team-sport","title":"Mindset: Architecture as a team sport","text":"<p>Where there is not THE architect who is the person entitled to make decisions, every participant can make a decision. This happens providing a framework for it to happen.</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/slides/#a-tool-to-think-adrs","title":"A tool to think: ADRs","text":""},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/slides/#a-place-to-have-conversations-architecture-forum-or-guild-round-tables","title":"A place to have conversations: Architecture forum or Guild round tables","text":""},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/slides/#a-tool-to-understand-the-current-environment-climate-tech-radar","title":"A tool to understand the current environment climate: Tech Radar","text":"<p>It is an advisory tool that helps making a decision by providing context of our engieering tech radar * What everyone else is doing * Who has which skill * What are the general trends in the industry </p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/slides/#and-ever-since","title":"And ever since","text":"<ul> <li>Consistency</li> <li>Alignment</li> <li>Evaluate and inform decision</li> <li>Structure for collaboration and innovation</li> <li>Cross team collaboration </li> <li>Linking it in technical decision document</li> <li>Create your own learning paths</li> <li>Find best practices </li> </ul>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/pages/multiple-entries/","title":"Multiple Entries","text":"<p>You can split your slides.md into multiple files and organize them as you want using the <code>src</code> attribute.</p>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/pages/multiple-entries/#slidesmd","title":"<code>slides.md</code>","text":"<pre><code># Page 1\n\nPage 2 from main entry.\n\n---\nsrc: ./subpage.md\n---\n</code></pre>"},{"location":"03-projects%20%F0%9F%93%85/tech-radar/tech%20radar/pages/multiple-entries/#subpagemd","title":"<code>subpage.md</code>","text":"<pre><code># Page 2\n\nPage 2 from another file.\n</code></pre> <p>Learn more</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/","title":"00  Safari books bookshelf","text":"<p>career learning tech</p>","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#software-architecture","title":"Software Architecture","text":"","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#design-it-from-programmer-to-software-architect","title":"Design It!: From programmer to software architect","text":"<p>By\u00a0Michael Keeling OReilly</p>","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#software-architecture-the-hard-parts","title":"Software architecture: The hard parts","text":"<p>By\u00a0Neal Ford,\u00a0Mark Richards,\u00a0Pramod Sadalage,\u00a0Zhamak Dehghani Oct 2021 OReilly</p>","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#fundamentals-of-software-architecture","title":"Fundamentals of Software Architecture","text":"<p>By\u00a0Mark Richards,\u00a0Neal Ford Jan 2020 OReilly</p>","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#semantic-software-design","title":"Semantic software design","text":"<p>By\u00a0Eben Hewitt Oct 2019 OReilly</p>","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#continuous-delivery-reliable-software-releases-through-build-test-and-deployment-automation","title":"Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation","text":"<p>By\u00a0David Farley,\u00a0Jez Humble July 2010 OReilly</p>","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#building-evolutionary-architectures","title":"Building Evolutionary Architectures","text":"<p>By\u00a0Neal Ford,\u00a0Rebecca Parsons,\u00a0Patrick Kua Sept 2017 OReilly</p>","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#software-architecture-in-practice-4th-edition","title":"Software Architecture in Practice, 4th Edition","text":"<p>By\u00a0Len Bass,\u00a0Paul Clements,\u00a0Rick Kazman Aug 2021 OReilly</p>","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#foundations-of-development","title":"Foundations of development","text":"","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#code-complete-2nd-edition","title":"Code Complete, 2nd Edition","text":"<p>By\u00a0Steve McConnell Jun 2010 https://learning.oreilly.com/library/view/code-complete-2nd/0735619670/</p>","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#refactoring-improving-the-design-of-existing-code","title":"Refactoring: Improving the Design of Existing Code","text":"<p>By\u00a0Martin Fowler Nov 2018 https://learning.oreilly.com/library/view/refactoring-improving-the/9780134757681/</p>","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#the-art-of-readable-code","title":"The art of readable code","text":"<p>By\u00a0Dustin Boswell,\u00a0Trevor Foucher Nov 2011 https://learning.oreilly.com/library/view/the-art-of/9781449318482/</p>","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#clean-code","title":"Clean code","text":"<p>By\u00a0Robert C. Martin Aug. 2008 https://learning.oreilly.com/library/view/clean-code-a/9780136083238/</p>","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#clean-coder","title":"Clean coder","text":"<p>By\u00a0Robert C. Martin May 2011 https://learning.oreilly.com/library/view/clean-coder-the/9780132542913/</p>","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#paradigms","title":"Paradigms","text":"","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#learning-functional-programming","title":"Learning Functional Programming","text":"<p>by  Jack Widman Aug. 2022 oReily</p>","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/00-%20Safari%20books%20bookshelf/#effective-software-testing","title":"Effective software testing","text":"<p>By\u00a0Mauricio Aniche April 2022 https://learning.oreilly.com/library/view/effective-software-testing</p>","tags":["career","learning","tech"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/peter-natur-programming-as-theory/","title":"Peter natur programming as theory","text":"<p>Link to PDF https://pages.cs.wisc.edu/~remzi/Naur.pdf</p> <p>Found in: https://blog.ceejbot.com/posts/programming-as-theory-building/</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/phillip-armour-5-orders-of-ignorance/","title":"Phillip armour 5 orders of ignorance","text":""},{"location":"05-reference%20system%20%F0%9F%A7%BE/phillip-armour-5-orders-of-ignorance/#link","title":"Link","text":"<p>Armour</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/readme.md/","title":"Readme.md","text":"<p>Articles, pdfs, links to articles, books</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/06-ebooks/readme/","title":"Playing to win: How strategy really works","text":"<ul> <li>Strategy is not about perfection, is about shortening your odds</li> <li>Reverse engineering: Make a list of things that have to be true for your strategy to work</li> </ul> <p>Blog post: </p> <p>https://fs.blog/2013/03/playing-to-win-how-strategy-really-works/</p> <p>Summary:</p> <p>HBR_Martin_Playing+to+Win_executive-summary.pdf</p> <p>In our terms, a strategy is a coordinated and integrated set of five choices: a winning aspiration, where to play, how to win, core capabilities, and management systems. \u2026 The five choices make up the strategic choice cascade, the foundation of our strategy work and the core of this book.</p> <p>Specifically, strategy is the answer to these five interrelated questions:</p> <ol> <li>What is your winning aspiration? The purpose of your enterprise, its motivating aspiration.</li> <li>Where will you play? A playing field where you can achieve that aspiration.</li> <li>How will you win? The way you will win on the chosen playing field.</li> <li>What capabilities must be in place? The set and configuration of capabilities required to win in the chosen way.</li> <li>What management systems are required? The systems and measures that enable the capabilities and support the choices.</li> </ol>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/","title":"CHAPTER 15   String Algorithms","text":"<p>String operations are common in many programs, so they have been studied extensively, and many programming libraries have good string tools. Because these operations are so important, the tools available to you probably use the best algorithms available, so you are unlikely to beat them with your own code.</p> <p>For example, the Boyer\u2013Moore algorithm described in this chapter lets you find the first occurrence of a string within another string. Because this is such a common operation, most high-level programming languages have tools for doing this. (In C#, that tool is the <code>string</code> class's <code>IndexOf</code> method. In Python, it's a string variable's <code>find</code> method.)</p> <p>Those tools probably use some variation of the Boyer\u2013Moore algorithm, so your implementation is unlikely to be much better. In fact, many libraries are written in assembly language or at some other very low level, so they may give better performance even if you use the same algorithm in your code.</p> <p>If your programming library includes tools to perform these tasks, use them. The algorithms explained in this chapter are presented because they are interesting, form an important part of a solid algorithmic education, and provide examples of useful techniques that you may be able to adapt for other purposes.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#matching-parentheses","title":"Matching Parentheses","text":"<p>Some string values, such as arithmetic expressions, can contain nested parentheses. For proper nesting of parentheses, you can place a pair of matching parentheses inside another pair of matching parentheses, but you cannot place one parenthesis of a pair inside another matched pair. For example, ()(()(())) is properly nested, but (() and (())) are not.</p> <p>Graphically, you can tell that an expression's parentheses are properly nested if you can draw lines connecting left and right parentheses so that every parenthesis is connected to another, all of the lines are on the same side (top or bottom) of the expression, and no lines intersect. Figure 15.1 shows that ()(()(())) is properly nested, but (() and (())) are not.</p> <p></p> <p>Figure 15.1: Lines connect matching pairs of parentheses.</p> <p>Algorithmically, it is easy to see whether parentheses are properly matched by using a counter to keep track of the number of unmatched opening parentheses. Initialize the counter to 0, and loop through the expression. When you find an opening parenthesis, add 1 to the counter. When you find a closing parenthesis, subtract 1 from the counter. If the counter ever drops below 0, the parentheses are improperly nested. When you finish checking the expression, if the counter is not 0, the parentheses are improperly nested.</p> <p>The following pseudocode shows the algorithm:</p> <pre><code>Boolean: IsProperlyNested(String: expression)\n</code></pre> <p>For example, when the algorithm scans the expression ()(()(())), the counter's values after reading each character are 1, 0, 1, 2, 1, 2, 3, 2, 1, 0. The counter never drops below 0, and it ends at 0, so the expression is nested properly.</p> <p>Some expressions contain text other than parentheses. For example, the arithmetic expression  contains numbers, operators such as \u00d7 and +, and parentheses. To see whether the parentheses are nested properly, you can use the previous <code>IsProperlyNested</code> algorithm, ignoring any characters that are not parentheses.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#evaluating-arithmetic-expressions","title":"Evaluating Arithmetic Expressions","text":"<p>You can recursively define a fully parenthesized arithmetic expression as one of the following:</p> <ul> <li>A literal value such as 4 or 1.75</li> <li>An expression surrounded by parentheses (expr) for some expression expr</li> <li>Two expressions separated by an operator, as in expr1 + expr2 or expr1 \u00d7 expr2</li> </ul> <p>For example, the expression  uses the third rule, with the two expressions 8 and 3 separated by the operator \u00d7. The values 8 and 3 are both expressions according to the first rule.</p> <p>You can use the recursive definition to create a recursive algorithm for evaluating arithmetic expressions. The following steps describe the algorithm at a high level:</p> <ol> <li>If the expression is a literal value, use your programming language's tools to parse it and return the result. (In C#, use <code>double.Parse</code>. In Python, use the <code>float</code> function.)</li> <li>If the expression is of the form (expr), then remove the outer parentheses, recursively use the algorithm to evaluate expr, and return the result.</li> <li>If the expression is of the form expr1?expr2 for expressions expr1 and expr2 and operator?, then recursively use the algorithm to evaluate expr1 and expr2, combine those values appropriately for the operator?, and return the result.</li> </ol> <p>The basic approach is straightforward. Probably the hardest part is determining which of the three cases applies and breaking the expression into two operands and an operator in case 3. You can do that by using a counter similar to the one used by the <code>IsProperlyNested</code> algorithm described in the preceding section.</p> <p>When the counter is 0, if you find an operator, case 3 applies and the operands are on either side of the operator.</p> <p>If you finish scanning the expression and you don't find an operator when the counter is 0, then either case 1 or case 2 applies. If the first character is an opening parenthesis, then case 2 applies. If the first character is not an opening parenthesis, then case 1 applies.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#building-parse-trees","title":"Building Parse Trees","text":"<p>The algorithm described in the preceding section parses arithmetic expressions and then evaluates them, but you might like to do other things with an expression after you parse it. For example, suppose that you need to evaluate an expression that contains variables such as  many times for different values of  , perhaps to draw a graph of the equation  . One approach would be to use the previous algorithm repeatedly to parse and evaluate the expression, substituting different values for  . Unfortunately, parsing text is relatively slow.</p> <p>Another approach is to parse the expression but not evaluate it right away. Then you can evaluate the preparsed expression many times with different values for  without needing to parse the expression again. You can do this using an algorithm very similar to the one described in the preceding section. Instead of making the algorithm combine the results of recursive calls to itself, however, it builds a tree containing objects that represent the expression.</p> <p>For example, to represent multiplication, the algorithm makes a node with two children, where the children represent the multiplication's operands. Similarly, to represent addition, the algorithm makes a node with two children, where the children represent the addition's operands.</p> <p>You can build a class for each of the necessary node types. The classes should provide an <code>Evaluate</code> method that calculates and returns the node's value, calling the <code>Evaluate</code> method for its child nodes if it has any.</p> <p>Having built the parse tree, you can call the root node's <code>Evaluate</code> method any number of times for different values of  .</p> <p>Figure 15.2 shows the parse tree for the expression  .</p> <p></p> <p>Figure 15.2: You can use parse trees to represent expressions such as  .</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#pattern-matching","title":"Pattern Matching","text":"<p>The algorithms described in the preceding sections are useful and effective, but they're tied to the particular application of parsing and evaluating arithmetic expressions. Parsing is a common task in computer programming, so it would be nice to have a more general approach that you could use to parse other kinds of text.</p> <p>For example, a regular expression is a string that a program can use to represent a pattern for matching in another string. Programmers have defined several different regular expression languages. To keep this discussion reasonably simple, this section uses a language that defines the following symbols:</p> <ul> <li>An alphabetic character such as A or Q represents that letter.</li> <li>The <code>+</code> symbol represents concatenation. For the sake of readability, this symbol is often omitted, so ABC is the same as  . However, it may be convenient to require the symbol to make it easier for a program to parse the regular expression.</li> <li>The <code>*</code> symbol means that the previous expression can be repeated any number of times (including zero).</li> <li>The <code>|</code> symbol means that the text must match either the previous or the following expression.</li> <li>Parentheses determine the order of operation.</li> </ul> <p>For example, with this restricted language, the regular expression  matches strings that begin with an A, contain any number of Bs, and then end with an A. That pattern would match ABA, ABBBBA, and AA.</p> <p>More generally, a program might want to find the first occurrence of a pattern within a string. For example, the string AABBA matches the previous pattern  starting at the second letter.</p> <p>To understand the algorithms described here for regular expression matching, it helps to understand deterministic finite automata and nondeterministic finite automata. The following two sections describe deterministic and nondeterministic finite automata. The section after that explains how you can use them to perform pattern matching with regular expressions.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#dfas","title":"DFAs","text":"<p>A deterministic finite automaton (DFA), also known as a deterministic finite state machine, is basically a virtual computer that uses a set of states to keep track of what it is doing. At each step, it reads some input and, based on that input and its current state, moves into a new state. One state is the initial state in which the machine starts. One or more states can also be marked as accepting states.</p> <p>If the machine ends its computation in an accepting state, then the machine accepts the input. In terms of regular expression processing, if the machine ends in an accepting state, the input text matches the regular expression.</p> <p>In some models, it's convenient for the machine to accept its input if it ever enters an accepting state.</p> <p>You can represent a DFA with a state transition diagram, which is basically a network in which circles represent states and directed links represent transitions to new states. Each link is labeled with the inputs that make the machine move into the new state. If the machine encounters an input that has no corresponding link, then it halts in a nonaccepting state.</p> <p>To summarize, there are three ways that a DFA can stop:</p> <ul> <li>It can finish reading its inputs while in an accepting state. In that case, it accepts the input. (The regular expression matches.)</li> <li>It can finish reading its inputs while in a nonaccepting state. In that case, it rejects the input. (The regular expression does not match.)</li> <li>It can read an input that does not have a link leading out of the current state node. In that case, it rejects the input. (The regular expression does not match.)</li> </ul> <p>For example, Figure 15.3 shows a state transition diagram for a DFA that recognizes the pattern  . The DFA starts in state 0. If it reads an A character, then it moves to state 1. If it sees any other character, then the machine halts in a nonaccepting state.</p> <p></p> <p>Figure 15.3: This network represents the state transitions for a DFA that recognizes the pattern  .</p> <p>Next, if the DFA is in state 1 and it reads a B, then it follows the loop and returns to state 1. If the DFA is in state 1 and reads an A, then it moves to state 2. If the DFA is in state 1 and reads any character other than A or B, then it halts in a nonaccepting state.</p> <p>State 2 is marked with a double circle to indicate that it is an accepting state. Depending on how you are using the DFA, just entering this state might make the machine return a successful match. Alternatively, it might need to finish reading its input in that state, so if the input string contains more characters, the match fails.</p> <p>For another example, consider the state transition diagram shown in Figure 15.4. This diagram represents a machine that matches a string that consists of AB repeated any number of times or BA repeated any number of times.</p> <p></p> <p>Figure 15.4: This network represents the state transitions for a DFA that recognizes the pattern  .</p> <p>Programmatically, you can implement a DFA by making an object to represent each of the states in the state transition diagram. When presented with an input, the program moves from the current object to the object that is appropriate for that input.</p> <p>Often, DFAs are implemented with a table showing the state transitions. For example, Table 15.1 shows the state transitions for the state transition diagram shown in Figure 15.3.</p> <p>Table 15.1: A State Transition Table for </p> <p>STATE</p> <p>0</p> <p>1</p> <p>1</p> <p>2</p> <p>On input</p> <p>A</p> <p>A</p> <p>B</p> <p>New state</p> <p>1</p> <p>2</p> <p>1</p> <p>Accepting?</p> <p>No</p> <p>No</p> <p>No</p> <p>Yes</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#note","title":"NOTE","text":"<p>DFAs aren't useful only for processing regular expressions. You can use them to model the state of any system where it's convenient to specify the system's rules with a transition diagram or transition table.</p> <p>For example, an order processing system might track the state of the orders in the system. You could give the states intuitive names such as Placed, Fulfilled, Shipped, Billed, Canceled, Paid, and Returned. As events occur, the order's state would change accordingly. For example, if the order is in the Placed state and the customer decides to cancel the order, the order moves to the Canceled state and stops its progress through the system.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#building-dfas-for-regular-expressions","title":"Building DFAs for Regular Expressions","text":"<p>You can translate simple regular expressions into transition diagrams and transition tables easily enough by using intuition, but for complicated regular expressions, it's nice to have a methodical approach. Then you can apply this approach to let a program do the work for you.</p> <p>To convert a regular expression into a DFA state transition table, you can build a parse tree for the regular expression and then use it to generate recursively the corresponding state transitions.</p> <p>The parse tree's leaves represent literal input characters such as A and B. The state transition diagram for reading a single input character is just a start state connected to an accepting final state with a link labeled by the required character. Figure 15.5 shows the simple state transition diagram for reading the input character B.</p> <p></p> <p>Figure 15.5: This transition diagram represents the simple regular expression B.</p> <p>The parse tree's internal nodes represent the operators <code>+</code>, <code>*</code>, and <code>|</code>.</p> <p>To implement the <code>+</code> operator, take the accepting state of the left subtree's transition diagram and make it coincide with the starting state of the right subtree's transition diagram, so the machine must perform the actions of the left subtree followed by the actions of the right subtree. For example, Figure 15.6 shows the transition diagrams for the simple literal patterns A and B on the left and the combined pattern  on the right.</p> <p></p> <p>Figure 15.6: The transition diagram on the right represents the regular expression  .</p> <p>To implement the <code>*</code> operator, make the single subexpression's accepting state coincide with the subexpression's starting state. Figure 15.7 shows the transition diagram for the pattern  on the left and the pattern  on the right.</p> <p></p> <p>Figure 15.7: The transition diagram on the right represents the regular expression  .</p> <p>Finally, to implement the <code>|</code> operator, make the starting and ending states of the left and right subexpressions' transition diagram coincide. Figure 15.8 shows the transition diagram for the patterns  and  on the left and the combined pattern  on the right.</p> <p></p> <p>Figure 15.8: The transition diagram on the right represents the regular expression  .</p> <p>This approach works in this instance, but it has a serious drawback under some conditions. What happens to the <code>|</code> operator if the two subexpressions start with the same input transitions? For example, suppose the two subexpressions are  and  . In that case, blindly following the previous discussion leads to the transition diagram on the left in Figure 15.9. It has two links labeled A that leave state 0. If the DFA is in state 0 and encounters input character A, which link should it follow?</p> <p></p> <p>Figure 15.9: These transition diagrams represent the regular expression  .</p> <p>One solution is to restructure the diagram a bit, as shown on the right in Figure 15.9, so that the diagrams for the two subexpressions share their first state (state 1). This works, but it requires some cleverness\u2014something that can be hard to build into a program. If the subexpressions were more complicated, finding a similar solution might be difficult\u2014at least for a program.</p> <p>One solution to this problem is to use an NFA instead of a DFA.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#nfas","title":"NFAs","text":"<p>A deterministic finite automaton is called deterministic because its behavior is completely determined by its current state and the input that it sees. If a DFA using the transition diagram on the right side of Figure 15.8 is in state 0 and reads the character B, it moves into state 2 without question.</p> <p>A nondeterministic finite automaton (NFA) is similar to a DFA, except that multiple links may be leaving a state for the same input, as shown on the left in Figure 15.9. When that situation occurs during processing, the NFA is allowed to guess which path it should follow to eventually reach an accepting state. It's as if the NFA were being controlled by a fortune-teller who knows what inputs will come later and can decide which links to follow to reach an accepting state.</p> <p>Of course, in practice a computer cannot really guess which state it should move into to eventually find an accepting state. What it can do is to try all of the possible paths. To do that, a program can keep a list of states it might be in. When it sees an input, the program updates each of those states, possibly creating a larger number of states.</p> <p>Another way to think of this is to regard the NFA as simultaneously being in all of the states. If any of its current states is an accepting state, the NFA as a whole is in an accepting state.</p> <p>You can make one more change to an NFA's transitions to make it slightly easier to implement. The operations shown in Figures 15.6 through 15.9 require that you make states from different subexpressions coincide\u2014and that can be awkward.</p> <p>An alternative is to introduce a new kind of null transition that occurs without any input. If the NFA encounters a null transition, it immediately follows it.</p> <p>Figure 15.10 shows how you can combine state transition machines for subexpressions to produce more-complex expressions. Here the <code>\u00d8</code> character indicates a null transition, and a box indicates a possibly complicated network of states representing a subexpression.</p> <p></p> <p>Figure 15.10: Using an NFA and null transitions makes combining subexpressions more straightforward.</p> <p>The first part of Figure 15.10 shows a set of states representing some subexpression. This could be as simple as a single transition that matches a single input, as shown in Figure 15.5, or it could be a complicated set of states and transitions. The only important feature of this construct from the point of view of the rest of the states is that it has a single input state and a single output state.</p> <p>The second part of Figure 15.10 shows how you can combine two machines,  and  , by using the <code>+</code> operator. The output state from  is connected by a null transition to the input state of  . By using a null transition, you avoid the need to make  's output state and  's input state coincide.</p> <p>The third part of Figure 15.10 shows how you can add the <code>*</code> operator to  .  's output state is connected to its input state by a null transition. The <code>*</code> operator allows whatever it follows to occur any number of times, including zero times, so another null transition allows the NFA to jump to the accept state without matching whatever is inside the M1.</p> <p>The final part of Figure 15.10 shows how you can combine two machines  and  by using the <code>|</code> operator. The resulting machine uses a new input state connected by null transitions to the input states of  and  . The output states of  and  are connected by null transitions to a final output state for the new combined machine.</p> <p>To summarize, you can follow these steps to make a regular expression parser:</p> <ol> <li>Build a parse tree for the regular expression.</li> <li>Use the parse tree to recursively build the states for an NFA representing the expression.</li> <li>Start the NFA in state 0 and use it to process the input string one character at a time.</li> </ol>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#string-searching","title":"String Searching","text":"<p>The previous sections explained how you can use DFAs and NFAs to search for patterns in a string. Those methods are quite flexible, but they're also relatively slow. To search for a complicated pattern, an NFA might need to track a large number of states as it examines each character in an input string one at a time.</p> <p>If you want to search a piece of text for a target substring instead of a pattern, there are faster approaches. The most obvious strategy is to loop over all of the characters in the text and see whether the target is at each position. The following pseudocode shows this brute-force approach:</p> <pre><code>// Return the position of the target in the text.\n</code></pre> <p>In this algorithm, variable <code>i</code> loops over the length of the text. For each value of <code>i</code>, the variable <code>j</code> loops over the length of the target. If the text has length  and the target has length  , the total run time is  . This is simpler than using an NFA, but it's still not very efficient.</p> <p>The Boyer\u2013Moore algorithm uses a different approach to search for target substrings much more quickly. Instead of looping through the target's characters from the beginning, it examines the target's characters starting at the end and works backward toward the beginning.</p> <p>The easiest way to understand the algorithm is to imagine the target substring sitting below the text at a position where a match might occur. The algorithm compares characters starting at the target's leftmost character. If it finds a position where the target and text don't match, the algorithm slides the target to the right to the next position where a match might be possible.</p> <p>For example, suppose you want to search the string <code>A man a plan a canal Panama</code> for the target string <code>Roosevelt</code>. Consider Figure 15.11.</p> <p></p> <p>Figure 15.11: Searching <code>A man a plan a canal Panama</code> for <code>Roosevelt</code> requires only three comparisons.</p> <p>The algorithm first aligns the two strings so that they line up on the left and compares the last character in the target to the corresponding character in the text. At that position, the target's last character is <code>t</code>, and the text's corresponding character is <code>p</code>. Those characters don't match, so the algorithm slides the target to the right to find the next position where a match is possible. The text's character <code>p</code> doesn't appear anywhere in the target, so the algorithm slides the target to the right all the way past its current location, nine characters to the right.</p> <p>At the new position, the target's last character is <code>t</code>, and the text's corresponding character is <code>n</code>. Again, the characters don't match, so the algorithm slides the target to the right. Again, the text's character <code>n</code> doesn't appear in the target, so the algorithm slides the target nine characters to the right.</p> <p>At the new position, the target's last character is <code>t</code>, and the text's corresponding character is <code>a</code>. The characters don't match, so the algorithm slides the target to the right. Again, the text's character <code>a</code> doesn't appear in the target, so the algorithm slides the target nine characters to the right.</p> <p>At this point, the target extends beyond the end of the text, so a match isn't possible, and the algorithm concludes that the target is not present in the text. The brute-force algorithm described earlier would have required 37 comparisons to decide that the target wasn't present, but the Boyer\u2013Moore algorithm required only three comparisons.</p> <p>Things don't always work out this smoothly. For a more complicated example, suppose that you want to search the text <code>abba daba abadabracadabra</code> for the target <code>cadabra</code>. Consider Figure 15.12.</p> <p></p> <p>Figure 15.12: Searching abba daba abadabracadabra for cadabra requires 18 comparisons.</p> <p>The algorithm starts with the two strings aligned at the left and compares the target character <code>a</code> with the text character <code>a</code>. Those characters match, so the algorithm considers the preceding characters, <code>r</code> and <code>d</code>. Those characters do not match, so the algorithm slides the target to the right. In this case, however, the text's character <code>d</code> does appear in the target, so there's a chance that the <code>d</code> is part of a match. The algorithm slides the target to the right until the last <code>d</code> in the target (shown with a dark box in Figure 15.12) aligns with the <code>d</code> in the text.</p> <p>At the new position, the target's last character is <code>a</code>, and the text's corresponding character is a space. Those characters don't match, so the algorithm slides the target to the right. The target has no space, so the algorithm moves the target its full width of seven characters.</p> <p>At the new position, the target's last character is <code>a</code> and the text's corresponding character is <code>r</code>. Those characters don't match, so the algorithm slides the target to the right. The character <code>r</code> does appear in the target, so the algorithm moves the target until its last <code>r</code> (dark) aligns with the <code>r</code> in the text.</p> <p>At the new position, the target's last character is <code>a</code>, and the text's corresponding character is <code>a</code>. These characters match, so the algorithm compares the preceding characters to see whether they match. Those characters also match, so the algorithm continues comparing characters backward through the target and text. Six characters match. Not until the algorithm considers the target's first character does it find a mismatch. Here the target's character is <code>c</code>, and the text's corresponding character is <code>b</code>.</p> <p>The target has a <code>b</code>, but it comes after the position in the target the algorithm is currently considering. To align this <code>b</code> with the one in the text, the algorithm would have to move the target to the left. All leftward positions have already been eliminated as possible locations for the match, so the algorithm doesn't do this. Instead, it shifts the target seven characters to the right to the next position where a match could occur.</p> <p>At this new position, the target's characters all match the corresponding characters in the text, so the algorithm has found a match.</p> <p>The following steps describe the basic Boyer\u2013Moore algorithm at a high level:</p> <ol> <li>Align the target and text on the left.</li> <li>Repeat until the target's last character is aligned beyond the end of the text:<ol> <li>Compare the characters in the target with the corresponding characters in the text, starting from the end of the target and moving backward toward the beginning.</li> <li>If all of the characters match, then congratulations\u2014you've found a match!</li> <li>Suppose character <code>X</code> in the text doesn't match the corresponding character in the target. Slide the target to the right until the <code>X</code> aligns with the next character with the same value <code>X</code> in the target to the left of the current position. If no such character <code>X</code> exists to the left of the position in the target, slide the target to the right by its full length.</li> </ol> </li> </ol> <p>One of the more time-consuming pieces of this algorithm is step 2c, which calculates the amount by which the algorithm slides the target to the right. You can make this step faster if you precalculate the amounts for different mismatched characters in different positions within the target.</p> <p>For example, suppose that the algorithm compares target and text characters, and the first mismatch is in position 3, where the text has the character <code>G</code>. The algorithm would then slide the text to the right to align the <code>G</code> with the first <code>G</code> that appears to the left of position 3 in the target. If you use a table to store the amounts by which you need to slide the target, then you can just look up that amount instead of calculating it during the search.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#note_1","title":"NOTE","text":"<p>Variations on the Boyer\u2013Moore algorithm use other, more complicated rules for shifting the target string efficiently. For example, suppose that the algorithm considers the following alignment:</p> <pre><code>    \u2026 what shall we draw today \u2026\n</code></pre> <p>The algorithm scans the target <code>abracadabra</code> backward. The first two characters, <code>a</code> and <code>r</code>, match. Then the text's <code>d</code> doesn't match the target's <code>b</code>. The previous algorithm would shift the target to align the text's mismatched <code>d</code> like this:</p> <pre><code>    \u2026 what shall we draw today \u2026\n</code></pre> <p>But you know that the text matched the following two characters, <code>ra</code>, so you know that the text's characters <code>dra</code> cannot match the target's characters <code>dab</code> at this point.</p> <p>Instead of shifting to align the text's mismatched <code>d</code>, you can shift to align the entire suffix that has been matched so far\u2014in this case, <code>ra</code>\u2014to an earlier occurrence of those characters in the target. In other words, you can move the target to place an earlier occurrence of the characters <code>ra</code> where the matched suffix is right now, as in the following:</p> <pre><code>    \u2026 what shall we draw today \u2026\n</code></pre> <p>This lets the algorithm shift the target further so that it can make the search run faster.</p> <p>For more information on variations on the Boyer\u2013Moore algorithm, see <code>[https://en.wikipedia.org/wiki/Boyer-Moore_string_search_algorithm](https://en.wikipedia.org/wiki/Boyer-Moore_string_search_algorithm)</code>.</p> <p>The Boyer\u2013Moore algorithm has the unusual property that it tends to be faster if the target string is longer because, when it finds a nonmatching character, it can shift the target farther.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#calculating-edit-distance","title":"Calculating Edit Distance","text":"<p>The edit distance of two strings is the minimum number of changes that you need to make to turn the first string into the second. You can define the changes that you are allowed to make in several ways. For this discussion, assume that you are only allowed to remove or insert letters. (Another common change that isn't considered here is changing one letter into another letter. You can achieve the same result by deleting the first character and then inserting the second.)</p> <p>For example, consider the words encourage and entourage. It's fairly easy to see that you can change encourage into entourage by removing the c and inserting a t. That's two changes, so the edit distance between those two words is 2.</p> <p>For another example, consider the words assent and descent. One way to convert assent into descent would be to follow these steps:</p> <ol> <li>Remove a to get ssent.</li> <li>Remove s to get sent.</li> <li>Remove s to get ent.</li> <li>Add d to get dent.</li> <li>Add e to get deent.</li> <li>Add s to get desent.</li> <li>Add c to get descent.</li> </ol> <p>This requires seven steps, so the edit distance is no more than 7, but how can you tell if this is the most efficient way to convert assent to descent? For longer words or strings (or, as you'll see later in this section, for files), it can be hard to be sure that you have found the best solution.</p> <p>One way to calculate the edit distance is to build an edit graph that represents all the possible changes that you could make to get from the first word to the second. Start by creating an array of nodes similar to the one shown in Figure 15.13.</p> <p></p> <p>Figure 15.13: This edit graph represents possible ways to convert assent to descent.</p> <p>The nodes across the top of the graph represent the letters in the first word. The nodes down the left side represent the letters in the second word. Create links between the nodes leading to their rightward and downward neighbors.</p> <p>Add diagonal links ending at any locations where the corresponding letters in both words are the same. For example, assent has an e in the fourth position, and descent has an e in its second position, so a diagonal link leads to the node below the e in assent and to the right of the first e in descent.</p> <p>Each link represents a transformation of the first word, making it more similar to the second word. A link pointing right represents removing a letter from the first word. For example, the link leading to the a on the top row represents removing the a from assent, which would make ssent.</p> <p>A link pointing down represents adding a letter to the word. For example, the link pointing to the d in the first column represents adding the letter d to the current word, which would make dassent.</p> <p>A diagonal link represents keeping a letter unchanged.</p> <p>Any path through the graph from the upper-left corner to the lower-right corner corresponds to a series of changes to convert the first word into the second. For example, the bold arrows shown in Figure 15.13 represent the changes described earlier to convert assent into descent.</p> <p>Now finding a path through the edit graph that has the least cost is fairly easy. Give each horizontal and vertical link a cost of 1, and give the diagonal links a cost of 0. Now you just need to find the shortest path through the network.</p> <p>You can use the same techniques described in Chapter 13, \u201cBasic Network Algorithms,\u201d to find the shortest path, but this network has a special structure that lets you use an easier method.</p> <p>First, set the distances for the nodes in the top row to be their column numbers. To get to the node in column 5 from the upper-left corner, you need to cross five links, so its distance is 5.</p> <p>Similarly, set the distances for the nodes in the leftmost column to be their row numbers. To get to the node in row 7, you need to cross seven links, so its distance is 7.</p> <p>Now loop over the rows and, for each row, loop over its columns. The shortest path to the node at position  comes via the node above at  , the node to the left at  , or, if a diagonal move is allowed, the node diagonally up and to the left at  . The distances to all of those nodes have already been set. You can determine what the cost would be for each of those possibilities and set the distance for the node at  to be the smallest of those.</p> <p>When you're finished looping through the rows and columns, the distance to the node in the lower-right corner gives the edit distance.</p> <p>Once you know how to find the edit distance between two words or strings, it's easy to find the edit distance between two files. You could just use the algorithm as is to compare the files character by character. Unfortunately, that could require a very large edit graph. For example, if the two files have about 40,000 characters (this chapter is in that neighborhood), then the edit graph would have about  . Building that graph would require a lot of memory, and using it would take a long time.</p> <p>Another approach is to modify the algorithm so that it compares lines in the files instead of characters. If the files each contain about  , the edit graph would hold about  . That's still a lot, but it's much more reasonable.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#phonetic-algorithms","title":"Phonetic Algorithms","text":"<p>A phonetic algorithm is one that categorizes and manipulates words based on their pronunciation. For example, suppose you are a customer service representative and a customer tells you that his name is Smith. You need to look up that customer in your database, but you don't know if the name should be spelled, Smith, Smyth, Smithe, or Smythe.</p> <p>If you enter any reasonable spelling (perhaps Smith), the computer can convert it into a phonetic form and then look for previously stored phonetic versions in the customer database. You can look through the results, ask a few questions to verify that you have the right person, and begin troubleshooting.</p> <p>Unfortunately, deducing a word's pronunciation from its spelling it difficult, at least in English. That means these algorithms tend to be long and complicated.</p> <p>The following sections describe two phonetic algorithms: Soundex and Metaphone.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#soundex","title":"Soundex","text":"<p>The Soundex algorithm was devised by Robert C. Russell and Margaret King Odell in the early 1900s to simplify the U.S. census. They first patented their algorithm in 1918, long before the first computers were created.</p> <p>The following list shows my version of the Soundex rules. They're slightly different from the rules that you'll see online. I've reformulated them slightly to make them easier to implement.</p> <ol> <li>Save the first letter of the name for later use.</li> <li>Remove w and h after the first character.</li> <li> <p>Use Table 15.2 to convert the remaining characters into codes. If a character doesn't appear in the table (w or h), leave it unchanged.</p> <p>Table 15.2: Soundex Letter Codes</p> <p>LETTER</p> <p>CODE</p> <p>a, e, I, o, u, y</p> <p>0</p> <p>b, f, p, v</p> <p>1</p> <p>c, g, j, k, q, s, x, z</p> <p>2</p> <p>d, t</p> <p>3</p> <p>l</p> <p>4</p> <p>m, n</p> <p>5</p> <p>r</p> <p>6</p> </li> <li> <p>If two or more adjacent codes are the same, keep only one of them.</p> </li> <li>Replace the first code with the original first letter.</li> <li>Remove code 0 (vowels after the first letter).</li> <li>Truncate or pad with 0s on the right so that the result has four characters.</li> </ol> <p>For example, let's walk through the steps for the name Ashcraft.</p> <ol> <li>We save the first letter, A.</li> <li>We remove w and h after the first letter to get Ascraft.</li> <li>Using Table 15.2 to convert the remaining letters into codes gives 0226013.</li> <li>Removing adjacent duplicates gives 026013.</li> <li>Replacing the first code with the original first letter gives A26013.</li> <li>Removing code 0 gives A2613.</li> <li>Truncating to four characters gives the final code A261.</li> </ol> <p>Over the years, there have been several variations on the original Soundex algorithm. Most SQL database systems use a slight variation that does not consider vowels when looking for adjacent codes. For example, in the name Alol, the two _L_s are separated by a vowel. Basic Soundex would convert them into the code, 4, and keep them both. SQL Soundex would remove the vowel, find the two adjacent 4s, and remove one of them.</p> <p>Another relatively simple variation of the original algorithm uses the character codes shown in Table 15.3.</p> <p>Table 15.3: Refined Soundex Letter Codes</p> <p>LETTER</p> <p>CODE</p> <p>b, p</p> <p>1</p> <p>f, v</p> <p>2</p> <p>c, k, s</p> <p>3</p> <p>g, j</p> <p>4</p> <p>q, x, z</p> <p>5</p> <p>d, t</p> <p>6</p> <p>l</p> <p>7</p> <p>m, n</p> <p>8</p> <p>r</p> <p>9</p> <p>Still other examples include variations designed for use with non-English names and words. The Daitch\u2013Mokotoff Soundex (D-M Soundex) was designed to represent Germanic and Slavic names better. Those kinds of variations tend to be much more complicated than the original Soundex algorithm.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#metaphone","title":"Metaphone","text":"<p>In 1990, Lawrence Philips published a new phonetic algorithm named Metaphone. It uses a more complex set of rules to represent English pronunciation more accurately. The following list shows the Metaphone rules:</p> <ol> <li>Drop duplicate adjacent letters, except for C.</li> <li>If the word starts with KN, GN, PN, AE, WR, drop the first letter.</li> <li>If the words ends with MB, drop the B.</li> <li>Convert C:<ol> <li>Convert C into K if part of SCH.</li> <li>Convert C into X if followed by IA or H.</li> <li>Convert C into S if followed by I, E, or Y.</li> <li>Convert all other C_s into _K.</li> </ol> </li> <li>Convert D:<ol> <li>Convert C into J if followed by GE, GY, or GI.</li> <li>Convert C into T otherwise.</li> </ol> </li> <li>Convert G:<ol> <li>Drop the G if part of GH unless it is at the end of the word or it comes before a vowel.</li> <li>Drop the G in GN and GNED at the end of the word.</li> <li>Convert G into J if part of GI, GE, or GY and not in GG.</li> <li>Convert all other G_s into _K.</li> </ol> </li> <li>If H comes after a vowel and not before a vowel, drop it.</li> <li>Convert CK into K.</li> <li>Convert PH into F.</li> <li>Convert Q into K.</li> <li>Convert S into X if followed by H, IO, or IA.</li> <li>Convert T:  <ol> <li>Convert T into X if part of TIA or TIO.  </li> <li>Convert TH into 0.  </li> <li>Drop the T in TCH.</li> </ol> </li> <li>Convert V into F.</li> <li>Convert WH into W if at the beginning of the word. Otherwise, drop the _W_s if not followed by a vowel.</li> <li>Convert X:  <ol> <li>Convert X into S if at the beginning of the word.  </li> <li>Otherwise convert X into KS.</li> </ol> </li> <li>Drop Y if not followed by a vowel.</li> <li>Convert Z into S.</li> <li>Drop all remaining vowels after the first character.</li> </ol> <p>Metaphone is an improvement over Soundex, but it also has several variations. For example, Double Metaphone is the second version of the original Metaphone algorithm. It is called Double Metaphone because it can generate primary and secondary codes for words to differentiate between words that have the same primary code.</p> <p>Metaphone 3 further refines Metaphone's phonetic rules and provides better results with non-English words that are common in the United States and some common names. It is available as a commercial product. There are also versions that handle Spanish and German pronunciations.</p> <p>For more information on phonetic algorithms, see the following URLs:</p> <ul> <li><code>[https://en.wikipedia.org/wiki/Phonetic_algorithm](https://en.wikipedia.org/wiki/Phonetic_algorithm)</code></li> <li><code>[https://en.wikipedia.org/wiki/Soundex](https://en.wikipedia.org/wiki/Soundex)</code></li> <li><code>[https://en.wikipedia.org/wiki/Metaphone](https://en.wikipedia.org/wiki/Metaphone)</code></li> <li><code>[http://ntz-develop.blogspot.com/2011/03/phonetic-algorithms.html](http://ntz-develop.blogspot.com/2011/03/phonetic-algorithms.html)</code></li> </ul>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#summary","title":"Summary","text":"<p>Many programs need to examine and manipulate strings. Even though programming libraries include many string manipulation tools, it's worth knowing how some of those algorithms work. For example, using a regular expression tool is much easier than writing your own, but the technique of using DFAs and NFAs to process commands is useful in many other situations. The Boyer\u2013Moore string search algorithm is a well-known algorithm that any student of algorithms should see at least once. Edit distance algorithms let you determine how close two words, strings, or even files are to each other and to find the differences between them. Finally, Soundex and other phonetic algorithms are useful for finding names or other words when you're unsure of their spelling.</p> <p>One kind of string algorithm that isn't covered in this chapter is algorithms used for encryption and decryption. The next chapter describes some of the more important and interesting algorithms used to encrypt and decrypt strings and other data.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/String%20Algorithms/#exercises","title":"Exercises","text":"<p>You can find the answers to these exercises in Appendix B. Asterisks indicate particularly difficult problems. Problems with two asterisks are exceptionally hard or time-consuming.</p> <ol> <li>Write a program that determines whether an expression entered by the user contains properly nested parentheses. Allow the expression to contain other characters as well, as in  .</li> <li>Write a program that parses and evaluates arithmetic expressions that contain real numbers and the operators <code>+</code>, <code>\u2013</code>, <code>*</code>, and <code>/</code>.</li> <li>How would you modify the program you wrote for the preceding exercise to handle the unary negation operator, as in  ?</li> <li>How would you modify the program you wrote for Exercise 2 to handle functions such as sine, as in  ?</li> <li>Write a program that parses and evaluates Boolean expressions such as  , where  means True,  means False, &amp; means AND, | means OR, and \u2013 means NOT.</li> <li> <p>**Write a program similar to the one shown in Figure 15.14. The program should build a parse tree for the expression entered by the user and then graph it. (Depending on how your program draws the graphics, the default coordinate system for the picture probably will have (0, 0) in the upper-left corner, and coordinates will increase to the right and down. The coordinate system may also use one unit in the X and Y directions per pixel, which means that the resulting graph will be fairly small. Unless you have experience with graphics programming, don't worry about scaling and transforming the result to fit the form nicely.)</p> <p></p> <p>Figure 15.14: This program, GraphExpression, builds a parse tree for an expression and then evaluates it many times to graph the expression.</p> </li> <li> <p>Build a state transition table for the DFA state transition diagram shown in Figure 15.4.</p> </li> <li>Draw a state transition diagram for a DFA to match the regular expression ((AB)|(BA))*.</li> <li>Build a state transition table for the state transition diagram you drew for the preceding exercise.</li> <li>*Write a program that lets the user type a DFA's state transitions and an input string and determines whether the DFA accepts the input string.</li> <li>Do you think it would be better for a DFA to get its state transitions from a table similar to the one shown in Table 15.1 or to use objects to represent the states? Why?</li> <li>How can you make a set of states for an NFA to see whether a pattern occurs anywhere within a string? For example, how could you determine whether the pattern ABA occurred anywhere within a long string? Draw the state transition diagram using a block to represent the pattern's machine (as done in Figure 15.10).</li> <li>Draw the parse tree for the expression  . Then draw the NFA network you get by applying the rules described in this chapter to the parse tree.</li> <li>Convert the NFA state transition diagram you drew for the preceding exercise into a simple DFA state transition diagram.</li> <li>Suppose that you want to search some text of length  for a target substring of length  . Find an example where a brute-force search requires  steps.</li> <li>Study the edit graph shown in Figure 15.13. What rule should you follow to find the least-cost path from the upper-left corner to the lower-right corner? What is the true edit distance?</li> <li>*Write a program that calculates edit distance.</li> <li> <p>*Enhance the program you wrote for the preceding exercise to display the edits required to change one string into another. Display deleted characters as crossed out and inserted characters as underlined, as shown in Figure 15.15.</p> <p></p> <p>Figure 15.15: By following the path through the edit graph, you can show exactly what edits were needed to change one string into another.</p> </li> <li> <p>Is edit distance commutative? In other words, is the edit distance between word 1 and word 2 the same as the edit distance between word 2 and word 1? Why or why not?  </p> </li> <li>*Modify the program you wrote for Exercise 17 to calculate the edit distance between two files instead of the differences between two strings.  </li> <li>*Modify the program you wrote for Exercise 18 to display the differences between two files instead of the differences between two strings.  </li> <li>Write a program that calculates Soundex encodings. When the program starts, make it verify that the names Smith, Smyth, Smithe, and Smythe all encode to S530. Also make the program verify the encoded values shown in Table 15.4.</li> </ol> <p>Table 15.4: Soundex Encodings for Example Names</p> <p>NAME</p> <p>SOUNDEX ENCODING</p> <p>Robert</p> <p>R163</p> <p>Rupert</p> <p>R163</p> <p>Rubin</p> <p>R150</p> <p>Ashcraft</p> <p>A261</p> <p>Ashcroft</p> <p>A261</p> <p>Tymczak</p> <p>T522</p> <p>Pfister</p> <p>P236</p> <p>Honeyman</p> <p>H555</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/","title":"CHAPTER 8   Hash Tables","text":"<p>The preceding chapter explained binary search, an  algorithm for locating an item in a sorted list. The algorithm repeatedly examines a test item in the middle of the part of the list where the target item must be. It compares the test item to the target item and then recursively examines the left or right half of the region, depending on whether the test item is greater than or less than the target item.</p> <p>Chapter 7 also explained interpolation search, which uses a mathematical calculation to predict where the target item will be. That algorithm has  time and is so much faster than binary search that it almost seems like magic.</p> <p>The reason why interpolation search is so much faster than binary search is that it uses the data's special structure to find values by calculation instead of by making comparisons. The countingsort, pigeonhole sort, and bucketsort algorithms described in Chapter 6 do that too.</p> <p>Hash tables also use the data's structure to locate values quickly. Instead of storing items in a sorted list, a hash table stores them in a way that lets you calculate an item's location in the table directly.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#note","title":"NOTE","text":"<p>Python's version of a hash table is a dictionary.</p> <p>In C#, you can use the <code>HashTable</code> class to store weakly typed objects with keys. The <code>Dictionary</code> class is a strongly typed hash table where the data types of the items and keys are defined. Because the objects in a <code>Dictionary</code> have a known data type, a <code>Dictionary</code> gives faster performance than a nonspecific <code>HashTable</code>.</p> <p>Dictionaries in both C# and Python allow you to look up items by using a key. The prebuilt dictionary classes work well, so feel free to use them in your programs. This chapter explains some of the methods that those classes use and how you can implement hash tables in your code.</p> <p>For a simple example of a hash table, suppose that you have a small company with 20 employees, and you want to be able to look up an employee's information by searching for that person's employee ID. One way you could store the information is to allocate an array of 100 items and then store an employee with employee ID N in position N mod 100 in the array. For example, an employee with ID 2190 would go in position 90, an employee with ID 2817 would go in position 17, and an employee with ID 3078 would go in position 78.</p> <p>To find a particular employee, you would simply calculate the ID mod 100 and look at the corresponding array entry. This is an O(1) operation that's even faster than interpolation search.</p> <p>In a real program, things aren't quite so simple. If you have enough employees, you will eventually get two with IDs that map to the same value. For example, if two employees have IDs 2817 and 1317, they both map to position 17 in the table.</p> <p>Still, this idea of mapping values into a table is a pretty good start, and it is the basic concept behind hash tables. The rest of this chapter describes hash tables more precisely and explains ways that you can implement hash tables in a program.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#hash-table-fundamentals","title":"Hash Table Fundamentals","text":"<p>A hash table maps data to locations in a data structure. Often it associates a key value such as an ID or name to a larger record such as an employee or customer record. Because hash tables associate a key to a value, they are sometimes called associative arrays or, less formally, dictionaries.</p> <p>The process of mapping a key value for use by the hash table is called hashing. Good hashing functions spread out key values so that they don't all go to the same position in the table. In particular, key values are often similar, so a good hashing function maps similar key values to dissimilar locations in the table.</p> <p>For example, suppose that you want to store customer records in a hash table and look them up by name. If two customers have the last names Richards and Richardson, ideally the hashing function should map them to two different locations.</p> <p>To achieve this, hashing functions often generate a value that looks something like gibberish, as if the key value had been chopped into hash.</p> <p>If you put enough values in a hash table, eventually you'll find two keys that hash to the same value. That's called a collision. When that occurs, you need a collision-resolution policy that determines what to do. Often the collision resolution policy maps the key to a series of new positions in the table until it finds an empty position.</p> <p>A hash table's fill percentage, the percentage of the table that contains entries, influences the chance of collisions occurring. Adding a new key to a hash table is more likely to cause a collision if the table's data structure is 95 percent full than if it's only 10 percent full.</p> <p>To summarize, a hash table needs the following:</p> <ul> <li>A data structure to hold the data</li> <li>A hashing function to map keys to locations in the data structure</li> <li>A collision-resolution policy that specifies what to do when keys collide</li> </ul> <p>To be useful, a hash table must be able to at least add new items and locate items that were previously stored. Another feature that is useful but not provided by some hash tables is the ability to remove a hashed key.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#resizing-hash-tables","title":"RESIZING HASH TABLES","text":"<p>Eventually a hash table may become completely full, or at least so full that collisions are likely and performance suffers. In that case, you need a resize algorithm to determine when and how the hash table is resized to make it larger.</p> <p>You can also have an algorithm for determining when and how to make the hash table smaller. For example, if a hash table can hold 1 million entries but currently holds only 10 entries, you might want to make it smaller to reclaim unused space.</p> <p>One simple method of resizing a hash table is to create a new hash table of the desired size and then rehash all the items in the original data structure into the new table. Some types of hash tables, such as hash tables with chaining, offer other methods, but this one should work for almost any hash table.</p> <p>Different kinds of hash tables use different methods to provide these features. The following sections describe some common methods of building hash tables.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#chaining","title":"Chaining","text":"<p>A hash table with chaining uses a collection of entries called buckets to hold key values. Each bucket is the top of a linked list holding the items that map to that bucket.</p> <p>Typically the buckets are arranged in an array, so you can use a simple hashing function to determine a key's bucket. For example, if you have N buckets and the keys are numeric, you could map the key K to bucket number K mod N.</p> <p>Figure 8.1 shows a hash table with chaining.</p> <p></p> <p>Figure 8.1: In a hash table with chaining, each bucket is the top of a linked list.</p> <p>To add a key to the hash table, you map the key to a bucket using the hash function and then add a new cell to the bucket's linked list. Hashing the key to find its bucket takes O(1) steps. Adding the value to the top of the linked list takes O(1) steps, so this operation is very fast.</p> <p>However, to be useful, a hash table cannot hold duplicate values. This means that before you can add a new item to a bucket, you should verify that it is not already present. If the hash table uses B buckets and holds a total of N items and the items are reasonably evenly distributed, each bucket's linked list holds roughly  items. If you need to verify that a key is not in the hash table, you need to examine the roughly  items in that key's bucket. All of this means that adding an item to the hash table takes a total of  steps.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#note_1","title":"NOTE","text":"<p>You can make searching for items in the hash table a little faster if the linked lists hold keys in sorted order. Then, if a key isn't present, you only need to search until you find a value greater than the target key instead of searching all the way to the end of the list. The run time is still  , but in practice it will be a bit faster.</p> <p>To find an item, you hash its key to see which bucket should hold it and then traverse that bucket's linked list until you find the item or come to the end of the list. If you get to the end of the list, you can conclude that the item isn't in the hash table. As is the case when adding an item to the hash table, this takes  steps.</p> <p>A hash table with chaining supports item removal quite well. To remove an item, hash its key as usual to find its bucket. Then remove the item from the bucket's linked list. Hashing the item takes O(1) steps and removing it takes  steps, so the total time is  .</p> <p>A hash table with chaining can expand and shrink as needed, so you don't need to resize it if you don't want to. If the linked lists become too long, however, finding and removing items will take a long time. In that case, you may want to enlarge the table to make more buckets. When you rehash the table, you know that you will not be adding any duplicate items, so you don't need to search to the end of each bucket's linked list to look for duplicates. That allows you to rehash all of the items in O(N) time.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#open-addressing","title":"Open Addressing","text":"<p>Chaining has some nice advantages, such as the fact that it can hold any number of values without changing the number of buckets, but it has some disadvantages as well. For example, if you put too many items in the buckets, then searching through the buckets can take a fair amount of time. You can reduce the search time by adding more buckets, but then you might have lots of empty buckets taking up space, and there's no way for the hash table to use those empty buckets.</p> <p>Another strategy for building hash tables is called open addressing. In open addressing, the values are stored in an array, and some sort of calculation serves as the hashing function, mapping values into positions in the array. For example, if a hash table uses an array with M entries, a simple hashing function might map the key value K into array position K mod M.</p> <p>Different variations of open addressing use different hashing functions and collision-resolution policies. In all cases, however, the collision-resolution policy produces a sequence of locations in the array for a value. If a value maps to a location that is already in use, the algorithm tries another location. If that location is also in use, the algorithm tries again. The algorithm continues trying new locations until it either finds an empty location or concludes that it cannot find one.</p> <p>The sequence of locations that the algorithm tries for a value is called the value's probe sequence. The average length of probe sequences for values that may or may not be in the hash table gives a good estimate of the efficiency of the hash table. Ideally, the average probe sequence length should be only 1 or 2. If the table becomes too full, the average probe sequence may become very long.</p> <p>Depending on the collision-resolution policy, a probe sequence might be unable to find an empty location for an item even if there are empty items in the hash table's array. If the probe sequence repeats itself before visiting every entry, some entries may remain unused.</p> <p>To locate an item in the hash table, the algorithm follows the value's probe sequence until one of three things happens. First, if the probe sequence finds the item, the job is done. Second, if the probe sequence finds an empty entry in the array, the item is not present. (Otherwise, it would have been placed in the empty position.)</p> <p>The third possibility is that the probe sequence could visit M entries, where M is the size of the array. In that case, the algorithm can conclude that the value is not present. The probe sequence might not visit every entry in the array, but after visiting M entries, you know that it has either visited every entry or that it is unlikely to find the target value. The probe sequence may even be following a loop, visiting the same positions repeatedly. In any case, the value must not be present because, if it were, it would have been added to the array using the same probe sequence.</p> <p>At a reasonable fill percentage, open addressing is extremely fast. If the average probe sequence length is only 1 or 2, then adding and locating items has run time O(1).</p> <p>Open addressing is fast, but it does have some disadvantages. The most obvious problem is that the hash table's performance degrades if its array becomes too full. In the worst case, if the array contains N items and is completely full, it takes O(N) time to conclude that an item is not present in the array. Even finding items that are present can be very slow.</p> <p>If the array becomes too full, you can resize it to make it bigger and give the hash table a smaller fill percentage. To do that, create a new array and rehash the items into it. If the new array is reasonably large, it should take O(1) time to rehash each item, for a total run time of O(N).</p> <p>The following section discusses another important problem with open addressing: removing items.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#removing-items","title":"Removing Items","text":"<p>Although open addressing lets you add and find items reasonably quickly, at least if the array isn't too full, it doesn't allow you to remove items the way chaining does. An item in the array might be part of another item's probe sequence. If you remove that item, then you will break the other item's probe sequence so you can no longer find the second value.</p> <p>For example, suppose items A and B both map to the same index  in the array. Item A is added first at index  , so when you try to add item B, it goes to the second position in its probe sequence,  .</p> <p>Now suppose you remove item A. If you then try to find item B, you initially look at index  . Because that entry is now empty, you incorrectly conclude that item B isn't present.</p> <p>One solution to this problem is to mark the item as deleted instead of resetting the array's entry to the empty value. For example, if the array holds 32-bit integers, you might use the value  to mean that an entry has no value and  to mean that the value has been deleted.</p> <p>When you search for a value, you continue searching if you find the deleted value. When you insert a new value into the hash table, you can place it in a previously deleted entry if you find one in the probe sequence.</p> <p>One drawback of this approach is that if you add and then remove many items, the table may become full of deleted entries. That will make searching for items slower. In the worst case, if the array is completely full of current and deleted items, you might have to search the entire array to find an item or to conclude that it isn't present.</p> <p>If you delete many items, you can rehash the current values and reset the deleted array locations so that they hold the special empty value. If the array contains N items and has a reasonable fill percentage, this should take O(N) time.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#linear-probing","title":"Linear Probing","text":"<p>In linear probing, the collision-resolution policy adds a constant number, called the stride and usually set to 1, to each location to generate a probe sequence. Each time the algorithm adds 1, it takes the result modulus the size of the array, so the sequence wraps around to the beginning of the array if necessary.</p> <p>For example, suppose the hash table's array contains 100 items and the hashing rule is as follows: N maps to location N mod 100. Then the probe sequence for the value 2,197 would visit locations 97, 98, 99, 0, 1, 2, and so forth.</p> <p>Figure 8.2 shows a linear probe sequence for inserting the value 71.</p> <p></p> <p>Figure 8.2: In linear probing, the algorithm adds a constant amount to locations to produce a probe sequence.</p> <p>Here the table already contains several values when you want to add item 71. This table's array has 10 entries, so 71 maps to location 71 mod  . That location already contains the value 61, so the algorithm moves to the next location in the value's probe sequence: location 2. That location is also occupied, so the algorithm moves to the next location in the probe sequence: location 3. That location is empty, so the algorithm places 71 there.</p> <p>This method has the advantages that it is very simple and that a probe sequence will eventually visit every location in the array. Therefore, the algorithm can insert an item if any space is left in the array.</p> <p>However, it has a disadvantage called primary clustering, an effect in which items added to the table tend to cluster to form large blocks of contiguous array entries that are all full. This is a problem because it leads to long probe sequences. If you try to add a new item that hashes to any of the entries in a cluster, the item's probe sequence will not find an empty location for the item until it crosses the whole cluster.</p> <p>The LinearProbing example program shown in Figure 8.3 demonstrates primary clustering. This hash table's array has 101 entries and currently holds 50 values. If the items were evenly distributed within the array, the probe sequence for every item that is in the table would have a length of 1. The probe sequences for items that are not in the table would have lengths of 1 or 2, depending on whether the initial hashing mapped an item to an occupied location.</p> <p></p> <p>Figure 8.3: Hash tables that use linear probing are subject to primary clustering.</p> <p>However, in Figure 8.3 the program shows that the hash table's average probe sequence length is 2.42, which is a bit above what you would get with an even distribution. The situation is worse with higher load factors.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#note_2","title":"NOTE","text":"<p>The program shown in Figure 8.3 is a solution to Exercise 8.3. See Appendix B for more information.</p> <p>To understand how clusters form, consider an empty hash table with N entries. If you add a random number to the table, there's a  chance that it will end up in any given position. Suppose it ends up in position K.</p> <p>Now suppose that you add another random number to the table. There's a  chance that this item will also map to position K, and in that case, linear probing will put the item in position  . There's also a  chance that the item will map directly to position  . Between the two possibilities, there's a 2/N chance that the item will end up in position  and a small cluster will form.</p> <p>Over time, more clusters will form. The larger a cluster is, the greater the probability that a new item will add to the end of the cluster. Eventually, clusters will expand until they merge and form bigger clusters. Soon the array is full of clusters and long probe sequences.</p> <p>The following two sections describe ways you can reduce the primary clustering effect.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#quadratic-probing","title":"Quadratic Probing","text":"<p>The reason linear probing produces clusters is that items that map to any location within a cluster end up at the end of the cluster, making it larger. One way to prevent that is quadratic probing. Instead of adding a constant stride to locations to create a probe sequence, the algorithm adds the square of the number of locations it has tried to create the probe sequence.</p> <p>In other words, if  is the probe sequence created by linear probing, the sequence created by quadratic probing is  \u2009.</p> <p>Now, if two items map to different positions in the same cluster, they don't follow the same probe sequences, so they don't necessarily end up adding to the cluster.</p> <p>Figure 8.4 shows an example. Initially, the table has a cluster containing five items. The value 71 has the probe sequence  , so it doesn't add to the cluster. The value 93 initially maps to the same cluster but has the probe sequence  , so it doesn't add to the cluster, either.</p> <p></p> <p>Figure 8.4: Quadratic probing reduces primary clustering.</p> <p>The QuadraticProbing example program, shown in Figure 8.5, uses quadratic probing to store random values in a hash table. If you compare this figure to Figure 8.3, you'll see that quadratic probing gives a shorter average probe sequence length than linear probing. In this example, linear probing gave an average probe sequence length of 2.42 but quadratic probing gave an average probe sequence length of only 1.92.</p> <p></p> <p>Figure 8.5: The average probe sequence length is shorter with quadratic probing than it is with linear probing.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#note_3","title":"NOTE","text":"<p>The program shown in Figure 8.5 is part of the solution to Exercise 8.4. See Appendix B for more information.</p> <p>Quadratic probing reduces primary clustering, but it can suffer from secondary clustering. In secondary clustering, values that map to the same initial position in the array follow the same probe sequence, so they create a cluster. This cluster is spread out through the array, but it still results in longer probe sequences for the items that map to the same initial position.</p> <p>Quadratic probing also has the drawback that it may fail to find an empty entry for a value even if a few empty positions are left in the table. Because of how a quadratic probe sequence jumps farther and farther through the array, it may jump over an empty position and not find it.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#pseudorandom-probing","title":"Pseudorandom Probing","text":"<p>Pseudorandom probing is similar to linear probing, except that the stride is given by a pseudorandom function of the initially mapped location. In other words, if a value initially maps to position K, its probe sequence is  \u2009, where p is determined by a pseudorandom function of K.</p> <p>Like quadratic probing, pseudorandom probing prevents primary clustering. Also like quadratic probing, pseudorandom probing is subject to secondary clustering, because values that map to the same initial position follow the same probe sequences.</p> <p>Pseudorandom probing may also skip over some unused entries and fail to insert an item even though the table isn't completely full.</p> <p>The result is similar to that of quadratic probing; you're just using a different method for building the probe sequence.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#double-hashing","title":"Double Hashing","text":"<p>The reason quadratic probing and pseudorandom probing suffer from secondary clustering is that values that map to the same initial location then follow the same probe sequence. You can reduce that effect if you make values that map to the same location follow different probe sequences.</p> <p>Double hashing is similar to pseudorandom probing. However, instead of using a pseudorandom function of the initial location to create a stride value, it uses a second hashing function to map the original value to a stride.</p> <p>For example, suppose the values A and B both initially map to position K. In pseudorandom probing, a pseudo-random function  generates a stride  . Then both values use the probe sequence  .</p> <p>In contrast, double hashing uses a pseudorandom hash function  to map the original values A and B to two different stride values  and  . The two probe sequences start at the same value K, but after that they are different.</p> <p>Double hashing eliminates primary and secondary clustering. However, like pseudorandom probing, double hashing may skip some unused entries and fail to insert an item even though the table isn't completely full.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#ordered-hashing","title":"Ordered Hashing","text":"<p>In some applications, values are hashed once and then looked up many times. For example, a program that uses a dictionary, address book, or product lookup table might follow this approach. In that case, it is more important that the program be able to find values quickly than to insert them quickly.</p> <p>A hash table with chaining can find items more quickly if its linked lists are sorted. When searching for an item, the algorithm can stop if it ever finds an item that is larger than the target item.</p> <p>Similarly, you can arrange a hash table in an ordered manner. Suppose the probe sequence for value K visits array locations with values  ,  , and so forth, where all of the  are less than K. In other words, all of the values along K's probe sequence are less than K.</p> <p>Note that the values need not be in a strictly increasing order. For example, the probe sequence for the value 71 might encounter the values 61, 32, and then 71. That's okay as long as the probe sequence for 32 doesn't follow the same path so that it visits 61 before 32.</p> <p>If you can arrange the array in this way, you can make searching for an item faster by stopping if you ever find a value greater than the target value.</p> <p>The following pseudocode shows at a high level how you can find an item in an ordered hash table:</p> <pre><code>// Return the location of the key in the array or -1 if it is\n</code></pre> <p>The exact arrangements of the hash tables described so far depend on the order in which items are added to the table. For example, suppose a hash table's array has 10 entries and the hashing function maps the value K to K mod 10. If you add the values 11, 21, 31, 41 to the hash table, they are stored in that order in positions 1 through 4. However, if you add the same items in the order 41, 31, 21, 11, they are stored in the same positions, but in reverse order.</p> <p>Suppose that you can add the values to the hash table in sorted order, smallest to largest. Then, when you add a value, if the table already holds any values in the new value's probe sequence, they must be smaller than the new value, because you're adding the values in sorted order. That means each probe sequence must be properly ordered so that you can search the table quickly.</p> <p>Unfortunately, you often cannot add the items to a hash table in sorted order because you don't know that order when you start. For example, you may only add a few items at a time to the table over a long period. Fortunately, there is a way to create an ordered hash table no matter how you add the items.</p> <p>To add an item, follow its probe sequence as usual. If you find an empty spot, insert the item and you're done. If you find a spot containing a value that is larger than the new value, replace it with the new value and then rehash the larger value.</p> <p>As you rehash the larger value, you may encounter another, even larger value. If that happens, drop the item you're hashing in the new position and rehash the larger value. Continue the process until you find an empty spot for whatever item you're currently hashing.</p> <p>The following pseudocode shows the process at a high level:</p> <pre><code>AddItem(Integer: array[], Integer: key)\n</code></pre> <p>The final step inside the <code>While</code> loop sets <code>probe</code> equal to the next location in the current key's probe sequence. For linear probing, pseudorandom probing, and double hashing, you can figure out the next item in the probe sequence even if you switched the <code>key</code> value you're hashing for a larger value. For example, with double hashing, you can apply the second hashing function to the new <code>key</code> value to find the new probe sequence's stride. You can then use the new stride to follow the new item's probe sequence from that point.</p> <p>That doesn't work for quadratic probing, because you would need to know how far the algorithm had searched the new key's probe sequence to get to that point.</p> <p>The reason this method works is that you only replace values with smaller values. If you replace a value in an ordered probe sequence with a smaller value, the probe sequence is still ordered.</p> <p>The only value that might still be in question is the new larger value you're rehashing. When you rehash that value, it ends up in a position that makes its probe sequence ordered.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#summary","title":"Summary","text":"<p>Hash tables allow you to store and locate values very quickly. If a hash table has a reasonably low fill percentage, finding an item may require only a couple calculations.</p> <p>It is important to maintain a reasonable fill percentage, however, because if a hash table becomes too full, its performance suffers. A lower fill percentage gives better performance but requires extra space that isn't used to hold data, so in some sense it is wasted. Too high a fill percentage can slow performance and increases the risk that the hash table will become full. This requires you to resize the hash table, which can take a considerable amount of time and memory.</p> <p>This is a good example of a space/time trade-off that is common in algorithms. By using extra space, you can improve an algorithm's performance.</p> <p>Ordered hashing provides another kind of trade-off. If you spend extra time up front building a hash table, later searching is much faster. When inserting a value, the program may find a value that is larger than the one it is inserting. In that case, it switches values and continues to rehash the larger one. One way to do that is recursion: making the insertion algorithm call itself. The next chapter discusses recursion in detail. It covers good and bad uses of recursion and explains how you can remove recursion from a program if deep call stacks or frequent recalculation of values cause problems.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/hash-tables/#exercises","title":"Exercises","text":"<p>You can find the answers to these exercises in Appendix B. Asterisks indicate particularly difficult problems.</p> <p>For the exercises that ask you to build a hash table, create an interface similar to Figure 8.6. The example shown in the figure sets each item's value to its key value with a <code>v</code> added in front so that you can tell it's a string. It displays an entry's value in the format <code>[key:value]</code>.</p> <p></p> <p>Figure 8.6: This interface lets you build and test hash tables.</p> <p>The Create button creates a new hash table. The Make Items button lets you add many random items to the hash table all at once. The Insert and Find buttons add or find a single item. After each change to the table or its data, display the number of keys per bucket for chaining algorithms or the fill percentage for open addressing algorithms. Also display the maximum and average probe length when you try to find all of the values between the minimum and maximum values used to fill the table.</p> <ol> <li>Write a program that implements a hash table with chaining.</li> <li>Modify the program you wrote for Exercise 1 to use sorted chains. Compare the average probe lengths of the two programs when the hash tables use 10 buckets and hold 100 items.</li> <li>Graph the average probe sequence length for the programs you built for Exercises 1 and 2 when the hash tables use 10 buckets and hold 50, 100, 150, 200, and 250 items. What can you deduce from the graph?</li> <li>Write a program that builds a hash table that uses open addressing with linear probing.</li> <li>Write a program that builds a hash table that uses open addressing with quadratic probing.</li> <li>Write a program that builds a hash table that uses open addressing with pseudorandom probing.</li> <li>Write a program that builds a hash table that uses open addressing with double hashing.</li> <li>Linear probing always finds an empty spot for a value if a spot is available, but quadratic probing, pseudorandom probing, and double hashing may all skip empty entries and conclude that the table is full when it is not. How can you pick the table size N to prevent quadratic probing, pseudorandom probing, and double hashing from concluding that the hash table is full even if it is not?</li> <li>Write a program that builds a hash table that uses open addressing with ordered quadratic hashing.</li> <li>Write a program that builds a hash table that uses open addressing with ordered double hashing.</li> <li>To see how the different open addressing algorithms compare, graph the average probe sequence length for the programs you built for Exercises 4, 5, 6, 7, 9, and 10. Use a table with 101 entries, and plot values when the table holds 50, 60, 70, 80, and 90 values. What can you deduce from the graph?</li> <li>Suppose a hash table uses buckets with sorted chaining. To insert a key, you need to search its bucket to verify that it is not present. If the table uses B buckets and contains N items, that takes roughly  steps on average. After you verify that the key is not present, you need to insert it in the correct position in its chain, which takes another  steps. Why is this faster than the  steps needed to insert an item if the chains are not sorted?</li> <li>Suppose you want to double the number of buckets used by a hash table that uses buckets with chaining. How would you split a bucket in two? What if the chains are sorted?</li> <li>Suppose that you're using a hash table with open addressing and you mark removed entries with a special value such as  . When you insert a new item, you can place it in a spot that has been marked as deleted if you find such a spot. Now suppose you add and remove many items so that the table is full of marked entries. Why does that slow down inserting new items?</li> <li>In open addressing with linear probing, what is the probability that two random values will land adjacent to each other and start a small cluster if the table is initially empty?</li> <li>When you insert an item in an ordered hash table that uses open addressing, you sometimes find a larger value along an item's probe sequence. In that case, you deposit the new item and rehash the larger value. How do you know that this process will eventually stop? What is the largest number of items that you might move during this process?</li> <li> <p>In ordered hashing, what happens if the algorithm is unable to find an empty position to add a new item even if the table isn't full?</p> </li> <li> <p>Support</p> </li> </ol>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/","title":"10.\u00a0Searching and Sorting in JS","text":"<p>Searching data and sorting through data are fundamental algorithms. Searching refers to iterating over the data structure\u2019s elements to retrieve some data. Sorting refers to putting the data structure\u2019s elements in order. The searching and sorting algorithms are different for every data structure. This chapter focuses on searching and sorting for arrays. By the end of this chapter, you will understand how to use common sorting and searching algorithms for arrays.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#searching","title":"Searching","text":"<p>As mentioned, searching is the task of looking for a specific element inside a data structure. When searching in an array, there are two main techniques depending on whether the array is sorted. In this section, you\u2019ll learn about linear and binary searching. Linear searches are especially flexible because they can be used with both sorted and unsorted data. Binary searches are specifically used with sorted data. However, a linear search has a higher time complexity than a binary search.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#linear-search","title":"Linear Search","text":"<p>A linear search works by going through each element of the array one index after another sequentially. The following code example is an implementation of a linear search that iterates through the entire array of numbers to find out whether 4 and 5 exist within the array.</p> <p>1\u00a0\u00a0\u00a0//iterate through the array and find</p> <p>2\u00a0\u00a0\u00a0function linearSearch(array,n){</p> <p>3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for(var i=0; i&lt;array.length; i++) {</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (array[i]==n) {</p> <p>5\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return true;</p> <p>6\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>8\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return false;</p> <p>9\u00a0\u00a0\u00a0}</p> <p>10\u00a0\u00a0\u00a0console.log(linearSearch([1,2,3,4,5,6,7,8,9], 6)); // true</p> <p>11\u00a0\u00a0\u00a0console.log(linearSearch([1,2,3,4,5,6,7,8,9], 10)); // false</p> <p>Time Complexity: O(n)</p> <p>As shown in Figure 10-1, when 6 is searched for, it goes through six iterations. When 10 is searched for, it must iterate through all n elements before returning false; therefore, the time complexity is O(n).</p> <p></p> <p>Figure 10-1</p> <p>Linear search</p> <p>As another example, with an array of [1,2,3,4,5] and a search term of 3, it would take three iterations to complete (1, 2, 3). The reason why this algorithm has a Big-O of O(n) is that, in the worst-case scenario, the entire array needs to be iterated. For example, if the search term is 5, it takes five iterations (1, 2, 3, 4, 5). If 6 is the search term, it goes through the entire array (1, 2, 3, 4, 5) and then returns false because it was not found.</p> <p>As noted previously, a linear search algorithm like this is great because it works whether or not the array is sorted. In a linear search algorithm, every element of the array is checked. So, you should use a linear search when the array is not sorted. If the array is sorted, you can do the search faster via a binary search.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#binary-search","title":"Binary Search","text":"<p>Binary search is a searching algorithm that works on sorted data. Unlike the linear search algorithm, in which every element of the array is checked, binary searches can check the middle value to see whether the desired value is greater or smaller than it. If the desired value is smaller, this algorithm can search through the smaller parts, or it can search through the bigger parts if the desired value is bigger.</p> <p>Figure 10-2 illustrates the process of a binary search. First, the search range is 1 to 9. Since the middle element, 5, is bigger than 3, the search range is restricted to 1 to 4. Finally, 3 is found as the middle element. Figure 10-3 illustrates searching for an item in the right half of the array.</p> <p></p> <p>Figure 10-2</p> <p>Binary search in the left half of the array</p> <p></p> <p>Figure 10-3</p> <p>Binary search in the right half of the array</p> <p>The following code implements the binary search algorithm described:</p> <p>1\u00a0\u00a0\u00a0function binarySearch(array,n){</p> <p>2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var lowIndex = 0, highIndex = array1.length-1;</p> <p>3</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0while(lowIndex&lt;=highIndex){</p> <p>5\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var midIndex = Math.floor((highIndex+lowIndex) /2);</p> <p>6\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (array[midIndex]==n) {</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return midIndex;</p> <p>8\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0} else if (n&gt;array[midIndex]) {</p> <p>9\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0lowIndex = midIndex;</p> <p>10\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0} else {</p> <p>11\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0highIndex = midIndex;</p> <p>12\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>13\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>14\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return -1;</p> <p>15\u00a0\u00a0\u00a0}</p> <p>16\u00a0\u00a0\u00a0console.log(binarySearch([1,2,3,4], 4)); // true</p> <p>17\u00a0\u00a0\u00a0console.log(binarySearch([1,2,3,4], 5)); // -1</p> <p>The binary search algorithm is fast but can be done only if the array is sorted. It checks the middle element if that is the element that is being searched for. If the search element is bigger than the middle element, the lower bound is set to the middle element plus one. If the search element is less than the middle element, the higher bound is set to the middle element minus one.</p> <p>This way, the algorithm is continuously dividing the array into two sections: the lower half and the upper half. If the element is smaller than the middle element, it should look for it in the lower half; if the element is bigger than the middle element, it should look for it in the upper half.</p> <p>Binary searches are used by humans without them even knowing. An example is a phone directory that is arranged from A to Z by last name.</p> <p>If you are given the task of finding someone with the last name of Lezer, one would first go to the L section and open it halfway through. Lizar is on that page; this means that the lower section contains L + [a to i] and the upper section contains L + [i to z] last names. You would then check the middle of the lower section. Laar appears, so you would now check the upper section. This process repeats until Lezer is found.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#sorting","title":"Sorting","text":"<p>Sorting is one of the most important topics in computer science; it is faster and easier to locate items in a sorted array than in an unsorted sorted array. You can use sorting algorithms to sort an array in memory for searching later in the program or to write to a file for later retrieval. In this section, different sorting techniques will be explored. We will start with the naive sorting algorithms and then explore efficient sorting algorithms. Efficient sorting algorithms have various trade-offs that should be considered during usage.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#bubble-sort","title":"Bubble Sort","text":"<p>Bubble sorting is the simplest sorting algorithm. It simply iterates over the entire array and swaps elements if one is bigger than the other, as shown in Figure 10-4 and Figure 10-5.</p> <p></p> <p>Figure 10-4</p> <p>First run of the bubble sort</p> <p></p> <p>Figure 10-5</p> <p>The rest of the bubble sort runs</p> <p>swap is a common function used in sorting. It simply switches two array element values and will be used as a helper function for most of the sorting algorithms mentioned.</p> <p>1\u00a0\u00a0\u00a0function swap(array, index1, index2) {</p> <p>2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var temp = array[index1];</p> <p>3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0array[index1] = array[index2];</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0array[index2] = temp;</p> <p>5\u00a0\u00a0\u00a0}</p> <p>The following bubbleSort code block illustrates the bubble sort algorithm previously described:</p> <p>1\u00a0\u00a0\u00a0function bubbleSort(array) {</p> <p>2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for (var i=0, arrayLength = array.length; i&lt;arrayLength; i++) {</p> <p>3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for (var j=0; j&lt;=i; j++) {</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (array[i] &lt; array[j]) {</p> <p>5\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0swap(array, i, j);</p> <p>6\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>8\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>9\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return array;</p> <p>10\u00a0\u00a0\u00a0}</p> <p>11\u00a0\u00a0\u00a0bubbleSort([6,1,2,3,4,5]); // [1,2,3,4,5,6]</p> <p>Time Complexity: O(n__2)</p> <p>Space Complexity: O(1)</p> <p>Bubble sort is the worst type of sort because it compares every pair possible, whereas other sorting algorithms take advantage of the presorted parts of the array. Because bubble sort uses nested loops, it has a time complexity of O(n__2).</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#selection-sort","title":"Selection Sort","text":"<p>Selection sorting works by scanning the elements for the smallest element and inserting it into the current position of the array. This algorithm is marginally better than bubble sort. Figure 10-6 shows this minimum selection process.</p> <p></p> <p>Figure 10-6</p> <p>Selection sort</p> <p>The following code implements the selection sort. In the code, there is one for loop to iterate through the array and one nested for loop to scan to get the minimum element.</p> <p>1\u00a0\u00a0\u00a0function selectionSort(items) {</p> <p>2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var len = items.length,</p> <p>3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0min;</p> <p>4</p> <p>5\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for (var i=0; i &lt; len; i++){</p> <p>6\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// set minimum to this position</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0min = i;</p> <p>8\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0//check the rest of the array to see if anything is smaller</p> <p>9\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for (j=i+1; j &lt; len; j++){</p> <p>10\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (items[j] &lt; items[min]){</p> <p>11\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0min = j;</p> <p>12\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>13\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>14\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0//if the minimum isn't in the position, swap it</p> <p>15\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (i != min){</p> <p>16\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0swap(items, i, min);</p> <p>17\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>18\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>19</p> <p>20\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return items;</p> <p>21\u00a0\u00a0\u00a0}</p> <p>22\u00a0\u00a0\u00a0selectionSort([6,1,23,4,2,3]); // [1, 2, 3, 4, 6, 23]</p> <p>Time Complexity: O(_n_2)</p> <p>Space Complexity: O(1)</p> <ul> <li>The time complexity for selection sort is still O(n__2) because of the nested for loop .</li> </ul>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#insertion-sort","title":"Insertion Sort","text":"<p>Insertion sort works similarly to selection sort by searching the array sequentially and moving the unsorted items into a sorted sublist on the left side of the array. Figure 10-7 shows this process in detail.</p> <p></p> <p>Figure 10-7</p> <p>Insertion sort</p> <p>The following code implements the insertion sort algorithm. The outer for loop iterates over the array indices, and the inner for loop moves the unsorted items into the sorted sublist on the left side of the array.</p> <p>1\u00a0\u00a0\u00a0function insertionSort(items) {</p> <p>2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var len = items.length, // number of items in the array</p> <p>3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0value,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// the value currently being compared</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0i,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// index into unsorted section</p> <p>5\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0j;\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// index into sorted section</p> <p>6</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for (i=0; i &lt; len; i++) {</p> <p>8\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// store the current value because it may shift later</p> <p>9\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0value = items[i];</p> <p>10</p> <p>11\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// Whenever the value in the sorted section is greater than the value</p> <p>12\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// in the unsorted section, shift all items in the sorted section</p> <p>13\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// over by one. This creates space in which to insert the value.</p> <p>14</p> <p>15\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for (j=i-1; j &gt; -1 &amp;&amp; items[j] &gt; value; j--) {</p> <p>16\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0items[j+1] = items[j];</p> <p>17\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>18\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0items[j+1] = value;</p> <p>19\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>20\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return items;</p> <p>21\u00a0\u00a0\u00a0}</p> <p>22\u00a0\u00a0\u00a0insertionSort([6,1,23,4,2,3]); // [1, 2, 3, 4, 6, 23]</p> <p>Time Complexity: O(_n_2)</p> <p>Space Complexity: O(1)</p> <p>Again, this sorting algorithm has a quadratic time complexity of O(_n_2) like bubble and insertion sort because of the nested for loop.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#quicksort","title":"Quicksort","text":"<p>Quicksort works by obtaining a pivot and partitioning the array around it (bigger elements on one side and smaller elements on the other side) until everything is sorted. The ideal pivot is the median of the array since it will partition the array evenly but getting the median of an unsorted array linear time to compute. Hence, a pivot is typically obtained by taking the median value of the first, middle, and last elements in the partition. This sort is a recursive one and uses the divide-and-conquer methodology to break the quadratic complexity barrier and get the time complexity down to O(nlog_2(_n)). However, with a pivot that partitions everything on one side, the time complexity is worse case: O(_n_2).</p> <p>Figure 10-8 shows the quicksort process\u2019s partitioning steps in great detail.</p> <p></p> <p>Figure 10-8</p> <p>Quicksort</p> <p>The following code shows an implementation of the quicksort algorithm:</p> <p>1\u00a0\u00a0\u00a0function quickSort(items) {</p> <p>2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return quickSortHelper(items, 0, items.length-1);</p> <p>3\u00a0\u00a0\u00a0}</p> <p>4</p> <p>5\u00a0\u00a0\u00a0function quickSortHelper(items, left, right) {</p> <p>6\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var index;</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (items.length &gt; 1) {</p> <p>8\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0index = partition(items, left, right);</p> <p>9</p> <p>10\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (left &lt; index - 1) {</p> <p>11\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0quickSortHelper(items, left, index - 1);</p> <p>12\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>13</p> <p>14\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (index &lt; right) {</p> <p>15\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0quickSortHelper(items, index, right);</p> <p>16\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>17\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>18\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return items;</p> <p>19\u00a0\u00a0\u00a0}</p> <p>20</p> <p>21\u00a0\u00a0\u00a0function partition(array, left, right) {</p> <p>22\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var pivot = array[Math.floor((right + left) / 2)];</p> <p>23\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0while (left &lt;= right) {</p> <p>24\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0while (pivot &gt; array[left]) {</p> <p>25\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0left++;</p> <p>26\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>27\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0while (pivot &lt; array[right]) {</p> <p>28\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0right--;</p> <p>29\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>30\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (left &lt;= right) {</p> <p>31\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var temp = array[left];</p> <p>32\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0array[left] = array[right];</p> <p>33\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0array[right]= temp;</p> <p>34\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0left++;</p> <p>35\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0right--;</p> <p>36\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>37\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>38\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return left;</p> <p>39\u00a0\u00a0\u00a0}</p> <p>40</p> <p>41\u00a0\u00a0\u00a0quickSort([6,1,23,4,2,3]); // [1, 2, 3, 4, 6, 23]</p> <p>Time Complexity: O(nlog_2(_n)) on average, O(n2) for worst case</p> <p>Space Complexity: O(log_2(_n))</p> <p>One downside about a quicksort algorithm is that it could potentially be O(n_2) if a bad pivot is always picked . A bad pivot is one that it does not partition the array evenly. The ideal pivot is the median element of the array. In addition, a quicksort algorithm takes a bigger space complexity of O(_log_2(_n)) compared to other sorting algorithms because of the call stack in recursion.</p> <p>Use a quicksort algorithm when the average performance should be optimal. This has to do with the fact that quicksort works better for the RAM cache.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#quickselect","title":"Quickselect","text":"<p>Quickselect is a selection algorithm to find the k_th smallest element in an unordered list. Quickselect uses the same approach as a quicksort algorithm. A pivot is chosen, and the array is partitioned. Instead of recursing both sides like quicksort, however, it recurses only the side for the element. This reduces the complexity from O(_nlog_2(_n)) to O(n).</p> <p>Quickselect is implemented in the following code:</p> <p>1\u00a0\u00a0\u00a0var array = [1,3,3,-2,3,14,7,8,1,2,2];</p> <p>2\u00a0\u00a0\u00a0// sorted form: [-2, 1, 1, 2, 2, 3, 3, 3, 7, 8, 14]</p> <p>3</p> <p>4\u00a0\u00a0\u00a0function quickSelectInPlace(A, l, h, k){</p> <p>5\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var p = partition(A, l, h);</p> <p>6\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if(p==(k-1)) {</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return A[p];</p> <p>8\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0} else if(p&gt;(k-1)) {</p> <p>9\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return quickSelectInPlace(A, l, p - 1,k);</p> <p>10\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0} else {</p> <p>11\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return quickSelectInPlace(A, p + 1, h,k);</p> <p>12\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>13\u00a0\u00a0\u00a0}</p> <p>14</p> <p>15\u00a0\u00a0\u00a0function medianQuickselect(array) {</p> <p>16\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return quickSelectInPlace(array,0,array.length-1, Math.floor(array.length/2));</p> <p>17\u00a0\u00a0\u00a0}</p> <p>18</p> <p>19\u00a0\u00a0\u00a0quickSelectInPlace(array,0,array.length-1,5); // 2</p> <p>20\u00a0\u00a0\u00a0// 2 - because it's the fifth smallest element</p> <p>21\u00a0\u00a0\u00a0quickSelectInPlace(array,0,array.length-1,10); // 7</p> <p>22\u00a0\u00a0\u00a0// 7 - because it's the tenth smallest element</p> <p>Time Complexity: O(n)</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#mergesort","title":"Mergesort","text":"<p>Mergesort works by dividing the array into subarrays until each array has one element. Then, each subarray is concatenated (merged) in a sorted order (see Figure 10-9).</p> <p></p> <p>Figure 10-9</p> <p>Mergesort</p> <p>The merge function should add all the elements from both arrays in sorted order in a \u201cresult array.\u201d To do this, the index of each array can be created to keep track of elements already compared. Once one array exhausts all its elements, the rest can be appended to the result array.</p> <p>1\u00a0\u00a0\u00a0function merge(leftA, rightA){</p> <p>2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var results= [], leftIndex= 0, rightIndex= 0;</p> <p>3</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0while (leftIndex &lt; leftA.length &amp;&amp; rightIndex &lt; rightA.length) {</p> <p>5\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if( leftA[leftIndex]&lt;rightA[rightIndex] ){</p> <p>6\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0results.push(leftA[leftIndex++]);</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0} else {</p> <p>8\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0results.push(rightA[rightIndex++]);</p> <p>9\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>10\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>11\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var leftRemains = leftA.slice(leftIndex),</p> <p>12\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0rightRemains = rightA.slice(rightIndex);</p> <p>13</p> <p>14\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// add remaining to resultant array</p> <p>15\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return results.concat(leftRemains).concat(rightRemains);</p> <p>16\u00a0\u00a0\u00a0}</p> <p>The merging function works by taking the two arrays (left and right) and merging them into one resultant array. The elements need to be compared as they get merged to preserve order.</p> <p>Now, the mergeSort function has to partition the bigger array into two separate arrays and recursively call merge.</p> <p>1\u00a0\u00a0\u00a0function mergeSort(array) {</p> <p>2</p> <p>3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if(array.length&lt;2){</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return array; // Base case: array is now sorted since it's just 1 element</p> <p>5\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>6</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var midpoint = Math.floor((array.length)/2),</p> <p>8\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0leftArray = array.slice(0, midpoint),</p> <p>9\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0rightArray = array.slice(midpoint);</p> <p>10</p> <p>11\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return merge(mergeSort(leftArray), mergeSort(rightArray));</p> <p>12\u00a0\u00a0\u00a0}</p> <p>13\u00a0\u00a0\u00a0mergeSort([6,1,23,4,2,3]); // [1, 2, 3, 4, 6, 23]</p> <p>Time Complexity: O(nlog_2(_n))</p> <p>Space Complexity: O(n)</p> <p>Mergesort has a large space complexity of O(n) because of the need to create n number of arrays to be merged later. Use mergesort when a stable sort is needed. A stable sort is one that\u2019s guaranteed not to reorder elements with identical keys. Mergesort is guaranteed to be O(nlog__2__(n)). A disadvantage of mergesort is that it uses O(n) in space.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#count-sort","title":"Count Sort","text":"<p>Count sort can be done in O(k+n) because it does not compare values. It works only for numbers and given a certain range. Instead of sorting by swapping elements, this count works by counting occurrences of each element in the array. Once occurrences of each element are counted, the new array can be created using those occurrences. This sorts the data without having to swap elements, as shown in Figure 10-10.</p> <p></p> <p>Figure 10-10</p> <p>Count sort</p> <p>Here\u2019s an implementation using a JavaScript object:</p> <p>1\u00a0\u00a0\u00a0function countSort(array) {</p> <p>2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var hash = {}, countArr= [];</p> <p>3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for(var i=0;i&lt;array.length;i++){</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if(!hash[array[i]]){</p> <p>5\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0hash[array[i]] = 1;</p> <p>6\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}else{</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0hash[array[i]]++;</p> <p>8\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>9\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>10</p> <p>11\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for(var key in hash){</p> <p>12\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// for any number of _ element, add it to array</p> <p>13\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for(var i=0;i&lt;hash[key];i++) {</p> <p>14\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0countArr.push(parseInt(key));</p> <p>15\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>16\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>17</p> <p>18\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return countArr;</p> <p>19\u00a0\u00a0\u00a0}</p> <p>20\u00a0\u00a0\u00a0countSort([6,1,23,2,3,2,1,2,2,3,3,1,123,123,4,2,3]); // [1, 2, 3, 4, 6, 23]</p> <p>Time Complexity: O(k+n)</p> <p>Space Complexity: O(k)</p> <p>Use count sort when you\u2019re sorting integers with a limited range. This will be the fastest sort for this case.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#javascripts-built-in-sort","title":"JavaScript\u2019s Built-in Sort","text":"<p>JavaScript has a built-in sort() method for an array object, which sorts elements by ascending order. To use it, there is an optional parameter that you can pass in a comparator function.</p> <p>However, the default comparator function sorts alphabetically, so it will not work for numbers.</p> <p>1\u00a0\u00a0\u00a0var array1 = [12,3,4,2,1,34,23];</p> <p>2\u00a0\u00a0\u00a0array1.sort(); // array1: [1, 12, 2, 23, 3, 34, 4]</p> <p>In the previous example, notice that numbers starting with 1 came first (1, 12), then numbers starting with 2, and so forth. This is because no comparator function was passed and JavaScript converted the elements into a string and sorted it according to the alphabet.</p> <p>To sort numbers correctly, use this:</p> <p>1\u00a0\u00a0\u00a0var array1 = [12,3,4,2,1,34,23];</p> <p>2</p> <p>3\u00a0\u00a0\u00a0function comparatorNumber(a,b) {</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return a-b;</p> <p>5\u00a0\u00a0\u00a0}</p> <p>6</p> <p>7\u00a0\u00a0\u00a0array1.sort(comparatorNumber);</p> <p>8\u00a0\u00a0\u00a0// array1: [1, 2, 3, 4, 12, 23, 34]</p> <p>a-b indicates that it should be from smallest to biggest (ascending). Descending order can be done as follows:</p> <p>1\u00a0\u00a0\u00a0var array1 = [12,3,4,2,1,34,23];</p> <p>2</p> <p>3\u00a0\u00a0\u00a0function comparatorNumber(a,b) {</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return b-a;</p> <p>5\u00a0\u00a0\u00a0}</p> <p>6</p> <p>7\u00a0\u00a0\u00a0array1.sort(comparatorNumber); // array1: [34, 23, 12, 4, 3, 2, 1]</p> <p>The sort() function can be useful when you need a quick way to sort something without implementing it yourself.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#summary","title":"Summary","text":"<p>There are two ways to search inside an array: linear search and binary search. Binary search is faster with O(log_2(_n)) time complexity, while linear search has O(n) time complexity. However, the binary search can be performed only on a sorted array.</p> <p>Table 10-1 summarizes time and space complexities of different sorting algorithms. The most efficient sorting algorithms are quicksort, mergesort, and count sort. Count sort, while the fastest, is limited to when the range of array\u2019s values are known.</p> <p>Table 10-1</p> <p>Sorting Summary</p> <p>Algorithm</p> <p>Time Complexity</p> <p>Space Complexity</p> <p>Quicksort</p> <p>O(nlog_2(_n))</p> <p>O(nlog_2(_n))</p> <p>Mergesort</p> <p>O(nlog_2(_n))</p> <p>O(nlog_2(_n))</p> <p>Bubble sort</p> <p>O(_n_2)</p> <p>O(_n_2)</p> <p>Insertion sort</p> <p>O(_n_2)</p> <p>O(_n_2)</p> <p>Selection sort</p> <p>O(_n_2)</p> <p>O(_n_2)</p> <p>Count sort</p> <p>O(k + n)</p> <p>O(k)</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#exercises","title":"Exercises","text":""},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#use-the-implement-square-root-function-for-an-integer-without-using-any-math-libraries","title":"USE THE IMPLEMENT SQUARE ROOT FUNCTION FOR AN INTEGER WITHOUT USING ANY MATH LIBRARIES","text":"<p>The first solution that may come to mind is trying every possibility from 1 to the number, as follows:</p> <p>1\u00a0\u00a0\u00a0function sqrtIntNaive(number){</p> <p>2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if(number == 0 || number == 1)</p> <p>3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return number;</p> <p>4</p> <p>5\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var index = 1, square = 1;</p> <p>6</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0while(square &lt; number){</p> <p>8\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (square == number){</p> <p>9\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return square;</p> <p>10\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>11</p> <p>12\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0index++;</p> <p>13\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0square = index*index;</p> <p>14\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>15\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return index;</p> <p>16\u00a0\u00a0\u00a0}</p> <p>17\u00a0\u00a0\u00a0sqrtIntNaive(9);</p> <p>Time Complexity: O(n)</p> <p>This is essentially a linear search since it has to linearly check one by one the value for the square root.</p> <p>The binary search algorithm can be applied to this problem. Instead of going up 1 by 1, partition the range into upper half and lower half between 1 and the given number as follows:</p> <p>1\u00a0\u00a0\u00a0function sqrtInt(number) {</p> <p>2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if(number == 0 || number == 1) return number;</p> <p>3</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var start = 1, end = number, ans;</p> <p>5</p> <p>6\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0while(start &lt;= end) {</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0let mid = parseInt((start+end)/2);</p> <p>8</p> <p>9\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (mid*mid == number)</p> <p>10\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return mid;</p> <p>11</p> <p>12\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if(mid*mid&lt;number){</p> <p>13\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0start = mid+1; // use the upper section</p> <p>14\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ans = mid;</p> <p>15\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}else{</p> <p>16\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0end = mid-1; // use the lower section</p> <p>17\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>18\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>19\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return ans;</p> <p>20\u00a0\u00a0\u00a0}</p> <p>21\u00a0\u00a0\u00a0sqrtInt(9);</p> <p>Time Complexity: O(log_2(_n))</p> <p>Bonus: Find a Square Root of a Float</p> <p>For this exercise, the only difference is using a threshold value to calculate accuracy to because the square root of a double will have decimals. Hence, the time complexity also stays the same.</p> <p>1\u00a0\u00a0\u00a0function sqrtDouble(number) {</p> <p>2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var threshold = 0.1;</p> <p>3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0//9 try middle,</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var upper = number;</p> <p>5\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var lower = 0;</p> <p>6\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var middle;</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0while(upper-lower&gt;threshold){</p> <p>8\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0middle = (upper+lower)/2;</p> <p>9\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if(middle*middle&gt;number){</p> <p>10\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0upper = middle;</p> <p>11\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}else{</p> <p>12\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0lower = middle;</p> <p>13\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>14\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>15\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return middle</p> <p>16\u00a0\u00a0\u00a0}</p> <p>17\u00a0\u00a0\u00a0sqrtDouble(9); // 3.0234375</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#find-if-two-elements-of-an-array-add-up-to-a-given-number","title":"FIND IF TWO ELEMENTS OF AN ARRAY ADD UP TO A GIVEN NUMBER","text":"<p>The simple approach to this problem is to check every other element for each element in the array.</p> <p>1\u00a0\u00a0\u00a0function findTwoSum(array, sum) {</p> <p>2</p> <p>3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for(var i=0, arrayLength = array.length; i&lt;arrayLength;i++){</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for(var j=i+1;j&lt;arrayLength;j++){</p> <p>5\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if(array[j]+array[i] == sum){</p> <p>6\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return true;</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>8\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>9\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>10\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return false;</p> <p>11\u00a0\u00a0\u00a0}</p> <p>Time Complexity: O(_n_2)</p> <p>Space Complexity: O(1)</p> <p>There is a lot of checking, and hence it takes quadratic time.</p> <p>A better approach is to store the already visited numbers and check against them. This way, it can be done in linear time.</p> <p>1\u00a0\u00a0\u00a0function findTwoSum(array, sum){</p> <p>2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var store = {};</p> <p>3</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for(var i=0, arrayLength = array.length; i&lt;arrayLength;i++){</p> <p>5\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if(store[array[i]]){</p> <p>6\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return true;</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}else{</p> <p>8\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0store[sum-array[i]] = array[i];</p> <p>9\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>10\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>11\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return false;</p> <p>12\u00a0\u00a0\u00a0}</p> <p>Time Complexity: O(n)</p> <p>Space Complexity: O(n)</p> <p>This algorithm cuts the time complexity to O(n) but takes O(n) space as well to store items into the store object.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#find-an-element-within-an-array-that-appears-only-once","title":"FIND AN ELEMENT WITHIN AN ARRAY THAT APPEARS ONLY ONCE","text":"<p>Given a sorted array in which all elements appear twice (one after one) and one element appears only once, find that element in O(l_og__2__n_) complexity. This can be done by modifying the binary search algorithm and checking the addition indices.</p> <p>Input:\u00a0\u00a0\u00a0arr = [1, 1, 3, 3, 4, 5, 5, 7, 7, 8, 8]\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Output:\u00a0\u00a04</p> <p>Input:\u00a0\u00a0\u00a0arr = [1, 1, 3, 3, 4, 4, 5, 5, 7, 7, 8]\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Output:\u00a0\u00a08</p> <p>1\u00a0\u00a0\u00a0function findOnlyOnce(arr, low, high) {</p> <p>2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (low &gt; high) {</p> <p>3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return null;</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>5\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (low == high) {</p> <p>6\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return arr[low];</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>8</p> <p>9\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var mid = Math.floor((high+low)/2);</p> <p>10</p> <p>11\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (mid%2 == 0) {</p> <p>12\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (arr[mid] == arr[mid+1]) {</p> <p>13\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return findOnlyOnce(arr, mid+2, high);</p> <p>14\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0} else {</p> <p>15\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return findOnlyOnce(arr, low, mid);</p> <p>16\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>17\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0} else {</p> <p>18\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (arr[mid] == arr[mid-1]) {</p> <p>19\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return findOnlyOnce(arr, mid+1, high);</p> <p>20\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0} else {</p> <p>21\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return findOnlyOnce(arr, low, mid-1);</p> <p>22\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>23\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>24\u00a0\u00a0\u00a0}</p> <p>25\u00a0\u00a0\u00a0function findOnlyOnceHelper(arr) {</p> <p>26\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return findOnlyOnce(arr, 0, arr.length);</p> <p>27\u00a0\u00a0\u00a0}</p> <p>28\u00a0\u00a0\u00a0findOnlyOnceHelper([ 1, 1, 2, 4, 4, 5, 5, 6, 6 ]);</p> <p>Time Complexity: O(log2_n_)</p> <p>Space Complexity: O(1)</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#create-a-javascript-sort-comparator-function-that-would-sort-string-by-length","title":"CREATE A JAVASCRIPT SORT COMPARATOR FUNCTION THAT WOULD SORT STRING BY LENGTH","text":"<p>This is fairly simple. If it is an array of strings, strings all have a property of length, which can be used to sort the array.</p> <p>1\u00a0\u00a0\u00a0var mythical = ['dragon', 'slayer','magic','wizard of oz', 'ned stark'];</p> <p>2</p> <p>3\u00a0\u00a0\u00a0function sortComparator(a,b){</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return a.length - b.length;</p> <p>5\u00a0\u00a0\u00a0}</p> <p>6\u00a0\u00a0\u00a0mythical.sort(sortComparator);</p> <p>7\u00a0\u00a0\u00a0// [\"magic\", \"dragon\", \"slayer\", \"ned stark\", \"wizard of of\"]</p> <p>Examples</p> <p>Sort string elements, putting strings with a first, as shown here:</p> <p>1\u00a0\u00a0\u00a0var mythical = ['dragon', 'slayer','magic','wizard of oz', 'ned tark'];</p> <p>2</p> <p>3\u00a0\u00a0\u00a0function sortComparator(a,b){</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return a.indexOf(\"a\") - b.indexOf(\"a\");</p> <p>5\u00a0\u00a0\u00a0}</p> <p>6</p> <p>7\u00a0\u00a0\u00a0mythical.sort(sortComparator);</p> <p>8\u00a0\u00a0\u00a0// [\"magic\", \"dragon\", \"slayer\", \"wizard of oz\", \"ned stark\"]</p> <p>Sort object elements by the number of properties, as shown here:</p> <p>1\u00a0\u00a0\u00a0var mythical=[{prop1:\", prop2:\"},{prop1:\", prop2:\", prop3:\"},{prop1:\", prop2:\"}];</p> <p>2</p> <p>3\u00a0\u00a0\u00a0function sortComparator(a,b){</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return Object.keys(a).length - Object.keys(b).length;</p> <p>5\u00a0\u00a0\u00a0}</p> <p>6</p> <p>7\u00a0\u00a0\u00a0mythical.sort(sortComparator);</p> <p>// [{prop1:\", prop2:\"},{prop1:\", prop2:\"},{prop1:\", prop2:\", prop3:\"}]</p> <p>As shown, there\u2019s a lot of flexibility with these comparators, and they can be used for sorting without needing to implement a sort yourself.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching-sorting-js/#implement-a-word-counter-list","title":"IMPLEMENT A WORD COUNTER LIST","text":"<p>Create a function that generates an object of words (as keys) and the number of times the words occur in a string ordered by highest to lowest occurrences.</p> <p>Here\u2019s some example input: practice makes perfect. get perfect by practice. just practice.</p> <p>Here\u2019s the example output: { practice: 3, perfect: 2, makes: 1, get: 1, by: 1, just: 1 }.</p> <p>1\u00a0\u00a0\u00a0function wordCount(sentence) {</p> <p>2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// period with nothing so it doesn't count as word</p> <p>3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var wordsArray = sentence.replace(/[.]/g,\"\").split(\" \"),</p> <p>4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0occurenceList = {}, answerList = {};</p> <p>5</p> <p>6\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for (var i=0, wordsLength=wordsArray.length; i&lt;wordsLength;\u00a0\u00a0i++) {</p> <p>7\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var currentWord = wordsArray[i];</p> <p>8\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// doesn't exist, set as 1st occurrence</p> <p>9\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (!occurenceList[currentWord]) {</p> <p>10\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0occurenceList[currentWord] = 1;</p> <p>11\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0} else {</p> <p>12\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0occurenceList[currentWord]++; // add occurrences</p> <p>13\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>14\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>15</p> <p>16\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var arrayTemp = [];</p> <p>17\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// push the value and key as fixed array</p> <p>18\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for (var prop in occurenceList) {</p> <p>19\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0arrayTemp.push([occurenceList[prop], prop]);</p> <p>20\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>21</p> <p>22\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0function sortcomp(a, b) {</p> <p>23\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return b[0] - a[0]; // compare the first element of the array</p> <p>24\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>25</p> <p>26\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0arrayTemp.sort(sortcomp); //sort</p> <p>27</p> <p>28\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0for (var i = 0, arrlength = arrayTemp.length; i &lt; arrlength; i++) {</p> <p>29\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0var current = arrayTemp[i];</p> <p>30\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0answerList[current[1]] = current[0]; // key value pairs</p> <p>31\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}</p> <p>32\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return answerList;</p> <p>33\u00a0\u00a0\u00a0}</p> <p>34\u00a0\u00a0\u00a0wordCount(\"practice makes perfect. get perfect by practice. just practice\");</p> <p>Time Complexity: O(nlog_2(_n))</p> <p>Space Complexity: O(n)</p> <p>Time complexity is limited by the sorting algorithm that the JavaScript engine uses. Most use either mergesort or quicksort, which are both O(nlog_2(_n)).</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching/","title":"CHAPTER 7  Searching","text":"<p>The preceding chapter explained how you can sort data. Algorithms such as quicksort and heapsort let you sort large amounts of data quickly. Algorithms such as countingsort and bucketsort let you sort data almost as quickly as a program can examine it, but only under certain special circumstances.</p> <p>One of the advantages of sorted data is that it lets you find specific items relatively quickly. For example, you can locate a particular word in a dictionary containing tens of thousands of words in just a minute or two because all the words are arranged in sorted order. (Imagine trying to find a word if the dictionary wasn't sorted!)</p> <p>This chapter explains algorithms that you can use to find a particular piece of data in a sorted array.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching/#note","title":"NOTE","text":"<p>The algorithms described in this chapter work with simple arrays, not more specialized data structures. Specialized data structures such as trees also let you quickly find an item with a specific value. Chapter 10, \u201cTrees,\u201d discusses algorithms for working with trees.</p> <p>Some programming libraries include searching tools that locate items in a sorted array. For example, the .NET Framework's <code>Array</code> class provides a <code>BinarySearch</code> method. These methods generally are fast, so in practice you may want to use those tools to save time writing and debugging the searching code.</p> <p>It's still important to understand how searching algorithms work, however, because sometimes you can do even better than the tools. For example, interpolation search is much faster than binary search when it is applicable.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching/#linear-search","title":"Linear Search","text":"<p>As you may be able to guess from its name, a linear search or exhaustive search simply loops through the items in the array, looking for the target item. Figure 7.1 shows a linear search for the value 77.</p> <p></p> <p>Figure 7.1: A linear search examines every item in the array until it finds the target item.</p> <p>Unlike binary search and interpolation search, linear search works on linked lists, where you cannot easily jump from one part of the list to another, as you can in an array.</p> <p>Linear search also works on unsorted lists. If the items are sorted, however, the algorithm can stop if it ever comes to an item with a value greater than the target value. That lets the algorithm stop early and save a little time if the target value isn't in the list.</p> <p>The following pseudocode shows the linear search algorithm for an array:</p> <pre><code>// Find the target item's index in the sorted array.\n</code></pre> <p>This algorithm may need to loop through the entire array to conclude that an item isn't there, so its worst-case behavior is O(N).</p> <p>Even in the average case, the algorithm's run time is O(N). If you add up the number of steps required to search for every item in the array, you get  . If you divide that total by N to get the average search time for all the N items, you get  , which is still O(N).</p> <p>This algorithm is much slower than binary search or interpolation search, but it has the advantage that it works on linked lists and unsorted lists.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching/#binary-search","title":"Binary Search","text":"<p>A binary search algorithm uses a divide-and-conquer strategy to narrow down quickly the part of the array that might contain the target value. The algorithm keeps track of the largest and smallest indices that the target item might have in the array. Initially, those bounds (call them <code>min</code> and <code>max</code>) are set to 0 and the largest index in the array.</p> <p>The algorithm then calculates the index halfway between <code>min</code> and <code>max</code> (call it <code>mid</code>). If the target is less than the array's value at <code>mid</code>, the algorithm resets <code>max</code> to search the left half of the array and starts over. If the target is greater than the array's value at <code>mid</code>, the algorithm resets <code>min</code> to search the right half of the array and starts over. If the target equals the array's value at <code>mid</code>, the algorithm returns the index <code>mid</code>.</p> <p>Figure 7.2 shows a binary search for the value 77.</p> <p></p> <p>Figure 7.2: A binary search repeatedly divides the part of the array that might contain the target item into two halves and then searches the appropriate half.</p> <p>The following pseudocode shows the algorithm:</p> <pre><code>// Find the target item's index in the sorted array.\n</code></pre> <p>At each step, this algorithm halves the number of items that might contain the target. If the array contains N items, then after O(log N) steps, the section of the array that might hold the target contains only one item, so the algorithm either finds the item or concludes that it isn't in the array. This means that the algorithm has O(log N) run time.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching/#interpolation-search","title":"Interpolation Search","text":"<p>At every step, binary search examines the item in the middle of the section of the array that it is considering. In contrast, interpolation search uses the value of the target item to guess where in the array it might lie and achieve much faster search times.</p> <p>For example, suppose that the array contains 1,000 items with values between 1 and 100. If the target value is 30, then it should lie about 30 percent of the way from the smallest to the largest value, so you can guess that the item may be somewhere near index 300. Depending on the distribution of the numbers in the array, this may not be exactly correct, but it should get you fairly close to the target item's position.</p> <p>Figure 7.3 shows an interpolation search for the value 77.</p> <p></p> <p>Figure 7.3: Interpolation search uses the target item's value to calculate where it should be in the remaining part of the array.</p> <p>The following pseudocode shows the algorithm at a high level:</p> <pre><code>Integer: InterpolationSearch(Data values[], Data target)\n</code></pre> <p>This high-level description leaves a couple of problems unsolved. The <code>mid</code> calculation can result in an overflow or a value of <code>mid</code> that is not between <code>min</code> and <code>max</code>. Solving those problems is left as part of Exercise 6 in this chapter.</p> <p>The trickiest part of this algorithm is the statement that calculates <code>mid</code>. The value is set to the current value of <code>min</code> plus the distance between <code>min</code> and <code>max</code> when scaled by the expected fraction of the distance between <code>values[min]</code> and <code>values[max]</code> where <code>target</code> should lie.</p> <p>For example, if <code>values[min]</code> is 100, <code>values[max]</code> is 200, and <code>target</code> is 125, then you would use the following calculation to decide where to look for the target value:</p> <pre><code>(target - values[min]) / (values[max] - values[min]) =\n</code></pre> <p>That puts the new value for <code>mid</code> one-quarter of the way from <code>min</code> to <code>max</code>.</p> <p>In the worst case, if the data is extremely unevenly distributed and you're looking for the worst possible target value, this algorithm has O(N) performance. If the distribution is reasonably uniform, the expected performance is O(log(log N)). (Proving that, however, is outside the scope of this book.)</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching/#majority-voting","title":"Majority Voting","text":"<p>Voting is basically a specialized kind of searching. The goal in the majority voting problem is to determine a sequence's majority item\u2014the item that appears more than half of the time. For example, suppose you poll 30 students and ask them whether they prefer chocolate, strawberry, or vanilla ice cream. The majority voting problem asks you to determine the majority opinion.</p> <p>Note that there may not be a majority item. For example, suppose 14 students pick chocolate, 6 pick strawberry, and 10 pick vanilla. In that case, none of the choices receives more than half of the votes, so there is no majority.</p> <p>One obvious majority voting algorithm is to loop through the list of items and keep a counter indicating the number of times each was chosen. If there are M possible values (chocolate, strawberry, and vanilla) and the list contains N items (30 students give 30 results in this example), then this algorithm takes O(N) time to scan the results and O(M) space to hold the counters.</p> <p>Each of the O(N) steps will also require some time to find the appropriate counter. For example, if you use a hash table to store the counters, then finding them will be relatively quick. If you store the counters in an array or linked list, then finding the appropriate counter to increment will be slower.</p> <p>This algorithm has the advantage of being very simple and intuitive. It can also find the mode of the votes, in case no item occurs more than half of the time. (The mode is the outcome that occurred most often.) For example, if 14 students pick chocolate, 6 pick strawberry, and 10 pick vanilla, then this algorithm can fairly easily determine that chocolate was the mode even though it didn't receive a majority of the votes.</p> <p>The Boyer-Moore majority vote algorithm is an interesting algorithm that can find the majority item in O(N) time using only O(1) space. To find the majority, the algorithm uses two variables: <code>Majority</code> to hold an outcome and <code>Count</code> to hold a counter. The following pseudocode shows how the algorithm works:</p> <pre><code>Outcome: BoyerMooreVote(List&lt;Outcome&gt; outcomes)\n</code></pre> <p>The algorithm initializes variable <code>counter</code> to 0 and then loops through the list of items. When it examines an item, if <code>counter</code> is currently 0, then the algorithm saves the current item in variable <code>majority</code> and sets <code>counter</code> to 1.</p> <p>If <code>counter</code> is not 0 when it examines an item, the algorithm compares the new item to the one stored in <code>majority</code>. If the new item matches <code>majority</code>, then the algorithm increments <code>counter</code>, essentially casting another vote for this item.</p> <p>If <code>counter</code> is not 0 and the new item is different from <code>majority</code>, then the algorithm decrements <code>count</code>, essentially removing a vote for <code>majority</code>.</p> <p>After the algorithm finishes, the variable <code>majority</code> holds the result. If there is a majority item, then the result is correct. If there is no majority item, then the algorithm returns something, but the result is not guaranteed to be the mode.</p> <p>To understand why the algorithm works, suppose that the majority item is m. During any step of the algorithm, define the value C to be the value in <code>counter</code> if <code>majority</code> currently holds m, and let C be the negative of the value in <code>counter</code> otherwise. Whenever the algorithm sees m, it increases C. When the algorithm sees some other item, it either increases or decreases C, depending on whether the new outcome matches the value currently stored in <code>majority</code>.</p> <p>Because m is the majority item, the algorithm must increase C more than it decreases C, so when the algorithm finishes, C will be positive. That happens only when <code>majority</code> holds m, so m must hold that value when the algorithm finishes.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching/#summary","title":"Summary","text":"<p>Table 7.1 shows the values of N, log N, and log(log N) for different values of N so that you can compare the speeds of linear search, binary search, and interpolation search.</p> <p>Table 7.1: Algorithm Characteristics</p> <p>N</p> <p>log2 N</p> <p>log2(log2 N)</p> <p>1,000</p> <p>10.0</p> <p>3.3</p> <p>1,000,000</p> <p>19.9</p> <p>4.3</p> <p>1,000,000,000</p> <p>29.9</p> <p>4.9</p> <p>1,000,000,000,000</p> <p>39.9</p> <p>5.3</p> <p>Linear search is useful only for relatively small arrays. Table 7.1 shows that binary search works well even for very large arrays. It can search an array containing 1 trillion items in only about 40 steps.</p> <p>Interpolation search works well for arrays of any size that you can reasonably fit on a computer. It can search an array containing 1 trillion items in only about five steps. In fact, an array would need to hold more than  items before interpolation search would require an expected number of steps greater than nine.</p> <p>However, the exact number of steps for interpolation search depends on the distribution of the values. Sometimes the algorithm gets lucky and finds the target in one or two steps. At other times, it might need four or five steps. On average, however, it is extremely fast.</p> <p>The Boyer-Moore majority voting algorithm is a particularly odd algorithm because it produces the correct result only sometimes, and it doesn't tell you whether the result is correct.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/searching/#exercises","title":"Exercises","text":"<p>You can find the answers to these exercises in Appendix B. Asterisks indicate particularly difficult problems.</p> <p>If you're not familiar with recursion, skip Exercises 2, 5, and 7 and come back to them after you read Chapter 15.</p> <ol> <li>Write a program that implements linear search.</li> <li>Write a program that implements linear search recursively. Does this version have any advantages or disadvantages compared to the nonrecursive version?</li> <li>Write a program that implements linear search with sorted linked lists.</li> <li>Write a program that implements binary search.</li> <li>Write a program that implements binary search recursively. Does this version have any advantages or disadvantages compared to the nonrecursive version?</li> <li>Write a program that implements interpolation search.</li> <li>Write a program that implements interpolation search recursively. Does this version have any advantages or disadvantages compared to the nonrecursive version?</li> <li>Which sorting algorithm described in Chapter 6, \u201cSorting,\u201d uses a technique reminiscent of the technique used by interpolation search?</li> <li>If an array contains duplicates, the binary search and interpolation search algorithms described in this chapter don't guarantee that they return the first instance of the target item. How could you modify them to return the first occurrence of the target item? What is the run time for the modified version?</li> <li>In the Boyer-Moore majority voting algorithm, what happens if outcome M occurs exactly half of the time in the list of outcomes? Can you make two example lists, one that causes the algorithm to return M and one that returns some other value?</li> <li> <p>The Boyer-Moore majority voting algorithm always returns an outcome, but if there is no majority, the result is not guaranteed to be the most common outcome in the list. How could you modify that algorithm to indicate whether the result is really a majority without changing the O(N) run time and O(1) memory characteristics?</p> </li> <li> <p>Support</p> </li> <li>Sign Out</li> </ol> <p>\u00a92022 O'Reilly Media, Inc.\u00a0</p> <ul> <li>Terms of Service</li> <li>Privacy Policy</li> </ul>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/","title":"4 Sorting and Searching","text":"<p>There are a few workhorse algorithms we use in nearly every kind of program. Sometimes these algorithms are so fundamental that we take them for granted or don\u2019t even realize our code is relying on them.</p> <p>Several methods for sorting and searching are among these fundamental algorithms. They\u2019re worth knowing because they\u2019re commonly used and beloved by algorithm enthusiasts (and the sadists who give coding interviews). The implementation of these algorithms can be short and simple, but every character matters, and since they are so commonly needed, computer scientists have striven to enable them to sort and search with mind-melting speed. So we\u2019ll also use this chapter to discuss algorithm speed and the special notation we use to compare algorithms\u2019 efficiencies.</p> <p>We start by introducing insertion sort, a simple and intuitive sorting algorithm. We discuss the speed and efficiency of insertion sort and how to measure algorithm efficiency in general. Next, we look at merge sort, a faster algorithm that is the current state of the art for searching. We also explore sleep sort, a strange algorithm that isn\u2019t used much in practice but is interesting as a curiosity. Finally, we discuss binary search and show some interesting applications of searching, including inverting mathematical functions.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#insertion-sort","title":"Insertion Sort","text":"<p>Imagine that you\u2019ve been asked to sort all the files in a filing cabinet. Each file has a number assigned to it, and you need to rearrange the files so that the file with the lowest number is first in the cabinet, the file with the highest number is last, and the files\u2019 numbers proceed in order in between.</p> <p>Whatever method you follow as you sort the filing cabinet, we can describe it as a \u201csorting algorithm.\u201d But before you even think of opening Python to code an algorithm for this, take a moment to pause and consider how you would sort such a filing cabinet in real life. This may seem like a mundane task, but allow the adventurer within you to creatively consider a broad range of possibilities.</p> <p>In this section, we present a very simple sorting algorithm called insertion sort. This method relies on looking at each item in a list one at a time and inserting it into a new list that ends up being correctly sorted. Our algorithm\u2019s code will have two sections: an insertion section, which performs the humble task of inserting a file into a list, and a sorting section, which performs insertion repeatedly until we have completed our sorting task.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#putting-the-insertion-in-insertion-sort","title":"Putting the Insertion in Insertion Sort","text":"<p>First, consider the task of insertion itself. Imagine that you have a filing cabinet whose files are already perfectly sorted. If someone hands you one new file and asks you to insert it into the right (sorted) position in the filing cabinet, how do you accomplish that? The task may seem so simple that it doesn\u2019t warrant an explanation, or even the possibility of one (just do it! you might think). But in the world of algorithms, every task, however humble, must be explained completely.</p> <p>The following method describes a reasonable algorithm for inserting one file into a sorted filing cabinet. We\u2019ll call the file we need to insert the \u201cfile to insert.\u201d We\u2019ll say that we can compare two files and call one file \u201chigher than\u201d the other one. This could mean that one file\u2019s assigned number is higher than the other\u2019s assigned number, or it could mean that it\u2019s higher in an alphabetical or other ordering.</p> <ol> <li>Select the highest file in the filing cabinet. (We\u2019ll start at the back of the cabinet and work our way to the front.)</li> <li>Compare the file you have selected with the file to insert.</li> <li>If the file you have selected is lower than the file to insert, place the file to insert one position behind that file.</li> <li>If the file you have selected is higher than the file to insert, select the next highest file in the filing cabinet.</li> <li>Repeat steps 2 to 4 until you have inserted your file or compared it with every existing file. If you have not yet inserted your file after comparing it with every existing file, insert it at the beginning of the filing cabinet.</li> </ol> <p>That method should more or less match the intuition you have for how to insert a record into a sorted list. If you prefer, you could also start at the beginning of the list, instead of the end, and follow an analogous process with the same results. Notice that we haven\u2019t just inserted a record; we\u2019ve inserted a record in the correct position, so after insertion, we\u2019ll still have a sorted list. We can write a script in Python that executes this insertion algorithm. First, we can define our sorted filing cabinet. In this case, our filing cabinet will be a Python list, and our files will simply be numbers.</p> <pre><code>cabinet = [1,2,3,3,4,6,8,12]\n</code></pre> <p>Then, we can define the \u201cfile\u201d (in this case, just a number) that we want to insert into our cabinet.</p> <pre><code>to_insert = 5\n</code></pre> <p>We proceed one at a time through every number in the list (every file in the cabinet). We\u2019ll define a variable called <code>check_location</code>. As advertised, it will store the location in the cabinet that we want to check. We start at the back of the cabinet:</p> <pre><code>check_location = len(cabinet) - 1\n</code></pre> <p>We\u2019ll also define a variable called <code>insert_location</code>. The goal of our algorithm is to determine the proper value of <code>insert_location</code>, and then it\u2019s a simple matter of inserting the file at the <code>insert_location</code>. We\u2019ll start out by assuming the <code>insert_location</code> is 0:</p> <pre><code>insert_location = 0\n</code></pre> <p>Then we can use a simple <code>if</code> statement to check whether the file to insert is higher than the file at the <code>check_location</code>. As soon as we encounter a number that\u2019s lower than the number to insert, we use its location to decide where to insert our new number. We add 1 because our insertion takes place just behind the lower number we found:</p> <pre><code>if to_insert &gt; cabinet[check_location]:\n    insert_location = check_location + 1\n</code></pre> <p>After we know the right <code>insert_location</code>, we can use a built-in Python method for list manipulation called <code>insert</code> to put the file into the cabinet:</p> <pre><code>cabinet.insert(insert_location,to_insert)\n</code></pre> <p>Running this code will not work to insert our file properly yet, however. We need to put these steps together in one coherent insertion function. This function combines all of the previous code and also adds a <code>while</code> loop. The <code>while</code> loop is used to iterate over the files in the cabinet, starting with the last file and proceeding until either we find the right <code>insert_location</code> or we have examined every file. The final code for our cabinet insertion is in Listing 4-1.</p> <pre><code>def insert_cabinet(cabinet,to_insert):\n  check_location = len(cabinet) - 1\n  insert_location = 0\n  while(check_location &gt;= 0):\n    if to_insert &gt; cabinet[check_location]:\n        insert_location = check_location + 1\n        check_location = - 1\n    check_location = check_location - 1\n  cabinet.insert(insert_location,to_insert)\n  return(cabinet)\n\ncabinet = [1,2,3,3,4,6,8,12]\nnewcabinet = insert_cabinet(cabinet,5)\nprint(newcabinet)\n</code></pre> <p>Listing 4-1: Inserting a numbered file into our cabinet</p> <p>When you run the code in Listing 4-1, it will print out <code>newcabinet</code>, which you can see includes our new \u201cfile,\u201d 5, inserted into our cabinet at the correct location (between 4 and 6).</p> <p>It\u2019s worthwhile to think for a moment about one edge case of insertion: inserting into an empty list. Our insertion algorithm mentioned \u201cproceeding sequentially through every file in the filing cabinet.\u201d If there are no files in the filing cabinet, then there is nothing to proceed through sequentially. In this case, we need to heed only the last sentence, which tells us to insert our new file at the beginning of the cabinet. Of course, this is easier done than said, because the beginning of an empty cabinet is also the end and the middle of the cabinet. So all we need to do in this case is insert the file into the cabinet without regard to position. We can do this by using the <code>insert()</code> function in Python and inserting at location 0.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#sorting-via-insertion","title":"Sorting via Insertion","text":"<p>Now that we\u2019ve rigorously defined insertion and know how to perform it, we\u2019re almost at the point where we can perform an insertion sort. Insertion sort is simple: it takes each element of an unsorted list one at a time and uses our insertion algorithm to insert it correctly into a new, sorted list. In filing cabinet terms, we start with an unsorted filing cabinet, which we\u2019ll call \u201cold cabinet,\u201d and an empty cabinet, which we\u2019ll call \u201cnew cabinet.\u201d We remove the first element of our old unsorted cabinet and add it to our new empty cabinet, using the insertion algorithm. We do the same with the second element of the old cabinet, then the third, and so on until we have inserted every element of the old cabinet into the new cabinet. Then, we forget about the old cabinet and use only our new, sorted cabinet. Since we\u2019ve been inserting using our insertion algorithm, and it always returns a sorted list, we know that our new cabinet will be sorted at the end of the process.</p> <p>In Python, we start with an unsorted cabinet and an empty <code>newcabinet</code>:</p> <pre><code>cabinet = [8,4,6,1,2,5,3,7]\nnewcabinet = []\n</code></pre> <p>We implement insertion sort by repeatedly calling our <code>insert_cabinet()</code> function from Listing 4-1. In order to call it, we\u2019ll need to have a file in our \u201chand,\u201d which we accomplish by popping it out of the unsorted cabinet:</p> <pre><code>to_insert = cabinet.pop(0)\nnewcabinet = insert_cabinet(newcabinet, to_insert)\n</code></pre> <p>In this snippet, we used a method called <code>pop()</code>. This method removes a list element at a specified index. In this case, we removed the element of <code>cabinet</code> at index 0. After we use <code>pop()</code>, <code>cabinet</code> no longer contains that element, and we store it in the variable <code>to_insert</code> so that we can put it into the <code>newcabinet</code>.</p> <p>We\u2019ll put all of this together in Listing 4-2, where we define an <code>insertion_sort()</code> function that loops through every element of our unsorted cabinet, inserting the elements one by one into <code>newcabinet</code>. Finally, at the end, we print out the result, a sorted cabinet called <code>sortedcabinet</code>.</p> <pre><code>cabinet = [8,4,6,1,2,5,3,7]\ndef insertion_sort(cabinet):\n  newcabinet = []\n  while len(cabinet) &gt; 0:\n    to_insert = cabinet.pop(0)\n    newcabinet = insert_cabinet(newcabinet, to_insert)\n  return(newcabinet)\n\nsortedcabinet = insertion_sort(cabinet)\nprint(sortedcabinet)\n</code></pre> <p>Listing 4-2: An implementation of insertion sort</p> <p>Now that we can do insertion sort, we can sort any list we encounter. We may be tempted to think that this means we have all the sorting knowledge we\u2019ll ever need. However, sorting is so fundamental and important that we want to be able to do it in the best possible way. Before we discuss alternatives to insertion sort, let\u2019s look at what it means for one algorithm to be better than another and, on an even more basic level, what it means for an algorithm to be good.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#measuring-algorithm-efficiency","title":"Measuring Algorithm Efficiency","text":"<p>Is insertion sort a good algorithm? This question is hard to answer unless we\u2019re sure about what we mean by \u201cgood.\u201d Insertion sort works\u2014it sorts lists\u2014so it\u2019s good in the sense that it accomplishes its purpose. Another point in its favor is that it\u2019s easy to understand and explain with reference to physical tasks that many people are familiar with. Yet another feather in its cap is that it doesn\u2019t take too many lines of code to express. So far, insertion sort seems like a good algorithm.</p> <p>However, insertion sort has one crucial failing: it takes a long time to perform. The code in Listing 4-2 almost certainly ran in less than one second on your computer, so the \u201clong time\u201d that insertion sort takes is not the long time that it takes for a tiny seed to become a mighty redwood or even the long time that it takes to wait in line at the DMV. It\u2019s more like a long time in comparison to how long it takes a gnat to flap its wings once.</p> <p>To fret about a gnat\u2019s wing flap as a \u201clong time\u201d may seem a little extreme. But there are several good reasons to push algorithms as close as possible to zero-second running times.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#why-aim-for-efficiency","title":"Why Aim for Efficiency?","text":"<p>The first reason to relentlessly pursue algorithm efficiency is that it can increase our raw capabilities. If your inefficient algorithm takes one minute to sort an eight-item list, that may not seem like a problem. But consider that such an inefficient algorithm might take an hour to sort a thousand-item list, and a week to sort a million-item list. It may take a year or a century to sort a billion-item list, or it may not be able to sort it at all. If we make the algorithm better able to sort an eight-item list (something that seems trivial since it saves us only a minute), it may make the difference between being able to sort a billion-item list in an hour rather than a century, which can open up many possibilities. Advanced machine-learning methods like k-means clustering and k-NN supervised learning rely on ordering long lists, and improving the performance of a fundamental algorithm like sorting can enable us to perform these methods on big datasets that would otherwise be beyond our grasp.</p> <p>Even sorting short lists is important to do quickly if it\u2019s something that we have to do many times. The world\u2019s search engines, for example, collectively receive a trillion searches every few months and have to order each set of results from most to least relevant before delivering them to users. If they can cut the time required for one simple sort from one second to half a second, they cut their required processing time from a trillion seconds to half a trillion seconds. This saves time for users (saving a thousand seconds for half a billion people really adds up!) and reduces data processing costs, and by consuming less energy, efficient algorithms are even environmentally friendly.</p> <p>The final reason to create faster algorithms is the same reason that people try to do better in any pursuit. Even though there is no obvious need for it, people try to run the 100-meter dash faster, play chess better, and cook a tastier pizza than anyone ever has before. They do these things for the same reason George Mallory said he wanted to climb Mount Everest: \u201cbecause it\u2019s there.\u201d It\u2019s human nature to push the boundaries of the possible and strive to be better, faster, stronger, and more intelligent than anyone else. Algorithm researchers are trying to do better because, among other reasons, they wish to do something remarkable, whether or not it is practically useful.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#measuring-time-precisely","title":"Measuring Time Precisely","text":"<p>Since the time required for an algorithm to run is so important, we should be more precise than saying that insertion sort takes a \u201clong time\u201d or \u201cless than a second.\u201d How long, exactly, does it take? For a literal answer, we can use the <code>timeit</code> module in Python. With <code>timeit</code>, we can create a timer that we start just before running our sorting code and end just afterward. When we check the difference between the starting time and the ending time, we find how long it took to run our code.</p> <pre><code>from timeit import default_timer as timer\n\nstart = timer()\ncabinet = [8,4,6,1,2,5,3,7]\nsortedcabinet = insertion_sort(cabinet)\nend = timer()\nprint(end - start)\n</code></pre> <p>When I ran this code on my consumer-grade laptop, it ran in about 0.0017 seconds. This is a reasonable way to express how good insertion sort is\u2014it can fully sort a list with eight items in 0.0017 seconds. If we want to compare insertion sort with any other sorting algorithm, we can compare the results of this <code>timeit</code> timing to see which is faster, and say the faster one is better.</p> <p>However, using these timings to compare algorithm performance has some problems. For example, when I ran the timing code a second time on my laptop, I found that it ran in 0.0008 seconds. A third time, I found that it ran on another computer in 0.03 seconds. The precise timing you get depends on the speed and architecture of your hardware, the current load on your operating system (OS), the version of Python you\u2019re running, the OS\u2019s internal task schedulers, the efficiency of your code, and probably other chaotic vagaries of randomness and electron motion and the phases of the moon. Since we can get very different results in each timing attempt, it\u2019s hard to rely on timings to communicate about algorithms\u2019 comparative efficiency. One programmer may brag that they can sort a list in Y seconds, while another programmer laughs and says that their algorithm gets better performance in Z seconds. We might find out they are running exactly the same code, but on different hardware at different times, so their comparison is not of algorithm efficiency but rather of hardware speed and luck.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#counting-steps","title":"Counting Steps","text":"<p>Instead of using timings in seconds, a more reliable measure of algorithm performance is the number of steps required to execute the algorithm. The number of steps an algorithm takes is a feature of the algorithm itself and isn\u2019t dependent on the hardware architecture or even necessarily on the programming language. Listing 4-3 is our insertion sort code from Listings 4-1 and 4-2 with several lines added where we have specified <code>stepcounter+=1</code>. We increase our step counter every time we pick up a new file to insert from the old cabinet, every time we compare that file to another file in the new cabinet, and every time we insert the file into the new cabinet.</p> <pre><code>def insert_cabinet(cabinet,to_insert):\n  check_location = len(cabinet) - 1\n  insert_location = 0\n  global stepcounter\n  while(check_location &gt;= 0):\n    stepcounter += 1\n    if to_insert &gt; cabinet[check_location]:\n        insert_location = check_location + 1\n        check_location = - 1\n    check_location = check_location - 1\n  stepcounter += 1\n  cabinet.insert(insert_location,to_insert)\n  return(cabinet)\n\ndef insertion_sort(cabinet):\n  newcabinet = []\n  global stepcounter\n  while len(cabinet) &gt; 0:\n    stepcounter += 1\n    to_insert = cabinet.pop(0)\n    newcabinet = insert_cabinet(newcabinet,to_insert)\n  return(newcabinet)\n\ncabinet = [8,4,6,1,2,5,3,7]\nstepcounter = 0\nsortedcabinet = insertion_sort(cabinet)\nprint(stepcounter)\n</code></pre> <p>Listing 4-3: Our insertion sort code with a step counter</p> <p>In this case, we can run this code and see that it performs 36 steps in order to accomplish the insertion sort for a list of length 8. Let\u2019s try to perform insertion sort for lists of other lengths and see how many steps we take.</p> <p>To do so, let\u2019s write a function that can check the number of steps required for insertion sort for unsorted lists of different lengths. Instead of manually writing out each unsorted list, we can use a simple list comprehension in Python to generate a random list of any specified length. We can import Python\u2019s <code>random</code> module to make the random creation of lists easier. Here\u2019s how we can create a random unsorted cabinet of length 10:</p> <pre><code>import random\nsize_of_cabinet = 10\ncabinet = [int(1000 * random.random()) for i in range(size_of_cabinet)]\n</code></pre> <p>Our function will simply generate a list of some given length, run our insertion sort code, and return the final value it finds for <code>stepcounter</code>.</p> <pre><code>def check_steps(size_of_cabinet):\n  cabinet = [int(1000 * random.random()) for i in range(size_of_cabinet)]\n  global stepcounter\n  stepcounter = 0\n  sortedcabinet = insertion_sort(cabinet)\n  return(stepcounter)\n</code></pre> <p>Let\u2019s create a list of all numbers between 1 and 100 and check the number of steps required to sort lists of each length.</p> <pre><code>random.seed(5040)\nxs = list(range(1,100))\nys = [check_steps(x) for x in xs]\nprint(ys)\n</code></pre> <p>In this code, we start by calling the <code>random.seed()</code> function. This is not necessary but will ensure that you see the same results as those printed here if you run the same code. You can see that we define sets of values for x, stored in <code>xs</code>, and a set of values for y, stored in <code>ys</code>. The x values are simply the numbers between 1 and 100, and the y values are the number of steps required to sort randomly generated lists of each size corresponding to each x. If you look at the output, you can see how many steps insertion sort took to sort randomly generated lists of lengths 1, 2, 3 . . . , all the way to 99. We can plot the relationship between list length and sorting steps as follows. We\u2019ll import <code>matplotlib.pyplot</code> in order to accomplish the plotting.</p> <pre><code>import matplotlib.pyplot as plt\nplt.plot(xs,ys)\nplt.title('Steps Required for Insertion Sort for Random Cabinets')\nplt.xlabel('Number of Files in Random Cabinet')\nplt.ylabel('Steps Required to Sort Cabinet by Insertion Sort')\nplt.show()\n</code></pre> <p>Figure 4-1 shows the output. You can see that the output curve is a little jagged\u2014sometimes a longer list will be sorted in fewer steps than will a shorter list. The reason for this is that we generated every list randomly. Occasionally our random list generation code will create a list that\u2019s easy for insertion sort to deal with quickly (because it\u2019s already partially sorted), and occasionally it will create a list that is harder to deal with quickly, strictly through random chance. For this same reason, you may find that the output on your screen doesn\u2019t look exactly like the output printed here if you don\u2019t use the same random seed, but the general shape should be the same.</p> <p></p> <p>Figure 4-1: Insertion sort steps</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#comparing-to-well-known-functions","title":"Comparing to Well-Known Functions","text":"<p>Looking beyond the superficial jaggedness of Figure 4-1, we can examine the general shape of the curve and try to reason about its growth rate. The number of steps required appears to grow quite slowly between x = 1 and about x = 10. After that, it seems to slowly get steeper (and more jagged). Between about x = 90 and x = 100, the growth rate appears very steep indeed.</p> <p>Saying that the plot gets gradually steeper as the list length increases is still not as precise as we want to be. Sometimes we talk colloquially about this kind of accelerating growth as \u201cexponential.\u201d Are we dealing with exponential growth here? Strictly speaking, there is a function called the exponential function defined by e__x, where e is Euler\u2019s number, or about 2.71828. So does the number of steps required for insertion sort follow this exponential function that we could say fits the narrowest possible definition of exponential growth? We can get a clue about the answer by plotting our step curve together with an exponential growth curve, as follows. We will also import the <code>numpy</code> module in order to take the maximum and minimum of our step values.</p> <pre><code>import math\nimport numpy as np\nrandom.seed(5040)\nxs = list(range(1,100))\nys = [check_steps(x) for x in xs]\nys_exp = [math.exp(x) for x in xs]\nplt.plot(xs,ys)\naxes = plt.gca()\naxes.set_ylim([np.min(ys),np.max(ys) + 140])\nplt.plot(xs,ys_exp)\nplt.title('Comparing Insertion Sort to the Exponential Function')\nplt.xlabel('Number of Files in Random Cabinet')\nplt.ylabel('Steps Required to Sort Cabinet')\nplt.show()\n</code></pre> <p>Just like before, we define <code>xs</code> to be all the numbers between 1 and 100, and <code>ys</code> to be the number of steps required to sort randomly generated lists of each size corresponding to each x. We also define a variable called <code>ys_exp</code>, which is e__x for each of the values stored in <code>xs</code>. We then plot both <code>ys</code> and <code>ys_exp</code> on the same plot. The result enables us to see how the growth of the number of steps required to sort a list relates to true exponential growth.</p> <p>Running this code creates the plot shown in Figure 4-2.</p> <p></p> <p>Figure 4-2: Insertion sort steps compared to the exponential function</p> <p>We can see the true exponential growth curve shooting up toward infinity on the left side of the plot. Though the insertion sort step curve grows at an accelerating rate, its acceleration does not seem to get close to matching true exponential growth. If you plot other curves whose growth rate could also be called exponential, 2_\u00d7_ or 10_\u00d7, you\u2019ll see that all of these types of curves also grow much faster than our insertion sort step counter curve does. So if the insertion sort step curve doesn\u2019t match exponential growth, what kind of growth might it match? Let\u2019s try to plot a few more functions on the same plot. Here, we\u2019ll plot _y = x, y = x_1.5, _y = x_2, and _y = _x_3 along with the insertion sort step curve.</p> <pre><code>random.seed(5040)\nxs = list(range(1,100))\nys = [check_steps(x) for x in xs]\nxs_exp = [math.exp(x) for x in xs]\nxs_squared = [x**2 for x in xs]\nxs_threehalves = [x**1.5 for x in xs]\nxs_cubed = [x**3 for x in xs]\nplt.plot(xs,ys)\naxes = plt.gca()\naxes.set_ylim([np.min(ys),np.max(ys) + 140])\nplt.plot(xs,xs_exp)\nplt.plot(xs,xs)\nplt.plot(xs,xs_squared)\nplt.plot(xs,xs_cubed)\nplt.plot(xs,xs_threehalves)\nplt.title('Comparing Insertion Sort to Other Growth Rates')\nplt.xlabel('Number of Files in Random Cabinet')\nplt.ylabel('Steps Required to Sort Cabinet')\nplt.show()\n</code></pre> <p>This results in Figure 4-3.</p> <p></p> <p>Figure 4-3: Insertion sort steps compared to other growth rates</p> <p>There are five growth rates plotted in Figure 4-3, in addition to the jagged curve counting the steps required for insertion sort. You can see that the exponential curve grows the fastest, and next to it the cubic curve scarcely even makes an appearance on the plot because it also grows so fast. The y = x curve grows extremely slowly compared to the other curves; you can see it at the very bottom of the plot.</p> <p>The curves that are the closest to the insertion sort curve are y = x_2 and _y = x_1.5. It isn\u2019t obvious which curve is most comparable to the insertion sort curve, so we cannot speak with certainty about the exact growth rate of insertion sort. But after plotting, we\u2019re able to make a statement like \u201cif we are sorting a list with _n elements, insertion sort will take somewhere between _n_1.5 and _n_2 steps.\u201d This is a more precise and robust statement than \u201cas long as a gnat\u2019s wing flap\u201d or \u201c.002-ish seconds on my unique laptop this morning.\u201d</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#adding-even-more-theoretical-precision","title":"Adding Even More Theoretical Precision","text":"<p>To get even more precise, we should try to reason carefully about the steps required for insertion sort. Let\u2019s imagine, once again, that we have a new unsorted list with n elements. In Table 4-2, we proceed through each step of insertion sort individually and count the steps.</p> <p>Table 4-2: Counting the Steps in Insertion Sort</p> <p>Description of actions</p> <p>Number of steps required for pulling the file from the old cabinet</p> <p>Maximum number of steps required for comparing to other files</p> <p>Number of steps required for inserting the file into the new cabinet</p> <p>Take the first file from the old cabinet and insert it into the (empty) new cabinet.</p> <p>1</p> <ol> <li>(There are no files to compare to.)</li> </ol> <p>1</p> <p>Take the second file from the old cabinet and insert it into the new cabinet (that now contains one file).</p> <p>1</p> <ol> <li>(There\u2019s one file to compare to and we have to compare it.)</li> </ol> <p>1</p> <p>Take the third file from the old cabinet and insert it into the new cabinet (that now contains two files).</p> <p>1</p> <p>2 or fewer. (There are two files and we have to compare between 1 of them and all of them.)</p> <p>1</p> <p>Take the fourth file from the old cabinet and insert it into the new cabinet (that now contains three files).</p> <p>1</p> <p>3 or fewer. (There are three files and we have to compare between 1 of them and all of them.)</p> <p>1</p> <p>. . .</p> <p>. . .</p> <p>. . .</p> <p>. . .</p> <p>Take the n_th file from the old cabinet and insert it into the new cabinet (that contains _n\u200a\u200a\u200a\u2013\u200a1 files).</p> <p>1</p> <p>n\u200a\u200a\u200a\u2013\u200a1 or fewer. (There are n\u200a\u200a\u200a\u2013\u200a1 files and we have to compare between one of them and all of them.)</p> <p>1</p> <p>If we add up all the steps described in this table, we get the following maximum total steps:</p> <ul> <li>Steps required for pulling files: n (1 step for pulling each of n files)</li> <li>Steps required for comparison: up to 1 + 2 + . . . + (n \u2013 1)</li> <li>Steps required for inserting files: n (1 step for inserting each of n files)</li> </ul> <p>If we add these up, we get an expression like the following:</p> <p></p> <p>We can simplify this expression using a handy identity:</p> <p></p> <p>If we use this identity and then add everything together and simplify, we find that the total number of steps required is</p> <p></p> <p>We finally have a very precise expression for the maximum total steps that could be required to perform insertion sort. But believe it or not, this expression may even be too precise, for several reasons. One is that it\u2019s the maximum number of steps required, but the minimum and the average could be much lower, and almost every conceivable list that we might want to sort would require fewer steps. Remember the jaggedness in the curve we plotted in Figure 4-1\u2014there\u2019s always variation in how long it takes to perform an algorithm, depending on our choice of input.</p> <p>Another reason that our expression for the maximum steps could be called too precise is that knowing the number of steps for an algorithm is most important for large values of n, but as n gets very large, a small part of the expression starts to dominate the rest in importance because of the sharply diverging growth rates of different functions.</p> <p>Consider the expression n_2 + _n. It is a sum of two terms: an n_2 term, and an _n term. When n = 10, n_2 + _n is 110, which is 10% higher than n_2. When _n = 100, n_2 + _n is 10,100, which is only 1% higher than n_2. As _n grows, the n_2 term in the expression becomes more important than the _n term because quadratic functions grow so much faster than linear ones. So if we have one algorithm that takes n_2+ _n steps to perform and another algorithm that takes n_2 steps to perform, as _n grows very large, the difference between them will matter less and less. Both of them run in more or less _n_2 steps.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#using-big-o-notation","title":"Using Big O Notation","text":"<p>To say that an algorithm runs in more or less n_2 steps is a reasonable balance between the precision we want and the conciseness we want (and the randomness we have). The way we express this type of \u201cmore or less\u201d relationship formally is by using _big O notation(the O is short for order). We might say that a particular algorithm is \u201cbig O of n_2,\u201d or _O(n_2), if, in the worst case, it runs in more or less _n_2 steps for large _n. The technical definition states that the function f(x) is big- O of the function g(x) if there\u2019s some constant number M such that the absolute value of f(x) is always less than M times g(x) for all sufficiently large values of x.</p> <p>In the case of insertion sort, when we look at our expression for the maximum number of steps required to perform the algorithm, we find that it\u2019s a sum of two terms: one is a multiple of n_2, and the other is a multiple of _n. As we just discussed, the term that is a multiple of n will matter less and less as n grows, and the n_2 term will come to be the only one that we are concerned with. So the worst case of insertion sort is that it is a _O(_n_2) (\u201cbig O of _n_2\u201d) algorithm.</p> <p>The quest for algorithm efficiency consists of seeking algorithms whose runtimes are big O of smaller and smaller functions. If we could find a way to alter insertion sort so that it is O(n_1.5) instead of _O(n_2), that would be a major breakthrough that would make a huge difference in runtimes for large values of _n. We can use big O notation to talk not only about time but also about space. Some algorithms can gain speed by storing big datasets in memory. They might be big O of a small function for runtime but big O of a larger function for memory requirements. Depending on the circumstances, it may be wise to gain speed by eating up memory, or to free up memory by sacrificing speed. In this chapter, we\u2019ll focus on gaining speed and designing algorithms to have runtimes that are big O of the smallest possible functions, without regard to memory requirements.</p> <p>After learning insertion sort and seeing that its runtime performance is O(n_2), it\u2019s natural to wonder what level of improvement we can reasonably hope for. Could we find some holy grail algorithm that could sort any possible list in fewer than 10 steps? No. Every sorting algorithm will require at least _n steps, because it will be necessary to consider each element of the list in turn, for each of the n elements. So any sorting algorithm will be at least O(n). We cannot do better than O(n), but can we do better than insertion sort\u2019s O(n_2)? We can. Next, we\u2019ll consider an algorithm that\u2019s known to be _O(n_log(_n)), a significant improvement over insertion sort.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#merge-sort","title":"Merge Sort","text":"<p>Merge sort is an algorithm that\u2019s much quicker than insertion sort. Just like insertion sort, merge sort contains two parts: a part that merges two lists and a part that repeatedly uses merging to accomplish the actual sorting. Let\u2019s consider the merging itself before we consider the sorting.</p> <p>Suppose we have two filing cabinets that are both sorted individually but have never been compared to each other. We want to combine their contents into one final filing cabinet that is also completely sorted. We will call this task a merge of the two sorted filing cabinets. How should we approach this problem?</p> <p>Once again, it\u2019s worthwhile to consider how we would do this with real filing cabinets before we open Python and start writing code. In this case, we can imagine having three filing cabinets in front of us: the two full, sorted filing cabinets whose files we want to merge, and a third, empty filing cabinet that we will insert files into and that will eventually contain all of the files from the original two cabinets. We can call our two original cabinets the \u201cleft\u201d and \u201cright\u201d cabinets, imagining that they are placed on our left and right.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#merging","title":"Merging","text":"<p>To merge, we can take the first file in both of the original cabinets simultaneously: the first left file with our left hand and the first right file with our right hand. Whichever file is lower is inserted into the new cabinet as its first file. To find the second file for the new cabinet, once again take the first file in the left and right cabinets, compare them, and insert whichever is lower into the last position in the new cabinet. When either the left cabinet or the right cabinet is empty, take the remaining files in the non-empty cabinet and place them all together at the end of the new cabinet. After this, your new cabinet will contain all the files from the left and right cabinets, sorted in order. We have successfully merged our original two cabinets.</p> <p>In Python, we\u2019ll use the variables <code>left</code> and <code>right</code> to refer to our original sorted cabinets, and we\u2019ll define a <code>newcabinet</code> list, which will start empty and eventually contain all elements of both <code>left</code> and <code>right</code>, in order.</p> <pre><code>newcabinet = []\n</code></pre> <p>We\u2019ll define example cabinets that we\u2019ll call <code>left</code> and <code>right</code>:</p> <pre><code>left = [1,3,4,4,5,7,8,9]\nright = [2,4,6,7,8,8,10,12,13,14]\n</code></pre> <p>To compare the respective first elements of our left and right cabinets, we\u2019ll use the following <code>if</code> statements (which won\u2019t be ready to run until we fill in the --snip-- sections):</p> <pre><code>   if left[0] &gt; right[0]:\n    --snip--\n   elif left[0] &lt;= right[0]:\n    --snip--\n</code></pre> <p>Remember that if the first element of the left cabinet is lower than the first element of the right cabinet, we want to pop that element out of the left cabinet and insert it into the <code>newcabinet</code>, and vice versa. We can accomplish that by using Python\u2019s built-in <code>pop()</code> function, inserting it into our <code>if</code> statements as follows:</p> <pre><code>if left[0] &gt; right[0]:\n    to_insert = right.pop(0)\n    newcabinet.append(to_insert)\nelif left[0] &lt;= right[0]:\n    to_insert = left.pop(0)\n    newcabinet.append(to_insert)\n</code></pre> <p>This process\u2014checking the first elements of the left and right cabinets and popping the appropriate one into the new cabinet\u2014needs to continue as long as both of the cabinets still have at least one file. That\u2019s why we will nest these <code>if</code> statements inside a <code>while</code> loop that checks the minimum length of <code>left</code> and <code>right</code>. As long as both <code>left</code> and <code>right</code> contain at least one file, it will continue its process:</p> <pre><code>while(min(len(left),len(right)) &gt; 0):\n    if left[0] &gt; right[0]:\n        to_insert = right.pop(0)\n        newcabinet.append(to_insert)\n    elif left[0] &lt;= right[0]:\n        to_insert = left.pop(0)\n        newcabinet.append(to_insert)\n</code></pre> <p>Our <code>while</code> loop will stop executing as soon as either <code>left</code> or <code>right</code> runs out of files to insert. At that point, if <code>left</code> is empty, we\u2019ll insert all the files in <code>right</code> at the end of the new cabinet in their current order, and vice versa. We can accomplish that final insertion as follows:</p> <pre><code>if(len(left) &gt; 0):\n    for i in left:\n        newcabinet.append(i)\n\nif(len(right) &gt; 0):\n    for i in right:\n        newcabinet.append(i)\n</code></pre> <p>Finally, we combine all of those snippets into our final merging algorithm in Python as shown in Listing 4-4.</p> <pre><code>def merging(left,right):\n    newcabinet = []\n    while(min(len(left),len(right)) &gt; 0):\n        if left[0] &gt; right[0]:\n            to_insert = right.pop(0)\n            newcabinet.append(to_insert)\n        elif left[0] &lt;= right[0]:\n            to_insert = left.pop(0)\n            newcabinet.append(to_insert)\n    if(len(left) &gt; 0):\n        for i in left:\n            newcabinet.append(i)\n    if(len(right)&gt;0):\n        for i in right:\n            newcabinet.append(i)\n    return(newcabinet)\n\nleft = [1,3,4,4,5,7,8,9]\nright = [2,4,6,7,8,8,10,12,13,14]\n\nnewcab=merging(left,right)\n</code></pre> <p>Listing 4-4: An algorithm to merge two sorted lists</p> <p>The code in Listing 4-4 creates <code>newcab</code>, a single list that contains all elements of <code>left</code> and <code>right</code>, merged and in order. You can run <code>print(newcab)</code> to see that our merging function worked.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#from-merging-to-sorting","title":"From Merging to Sorting","text":"<p>Once we know how to merge, merge sort is within our grasp. Let\u2019s start by creating a simple merge sort function that works only on lists that have two or fewer elements. A one-element list is already sorted, so if we pass that as the input to our merge sort function, we should just return it unaltered. If we pass a two-element list to our merge sort function, we can split that list into two one-element lists (that are therefore already sorted) and call our merging function on those one-element lists to get a final, sorted two-element list. The following Python function accomplishes what we need:</p> <pre><code>import math\n\ndef mergesort_two_elements(cabinet):\n    newcabinet = []\n    if(len(cabinet) == 1):\n        newcabinet = cabinet\n    else:\n        left = cabinet[:math.floor(len(cabinet)/2)]\n        right = cabinet[math.floor(len(cabinet)/2):]\n        newcabinet = merging(left,right)\n    return(newcabinet)\n</code></pre> <p>This code relies on Python\u2019s list indexing syntax to split whatever cabinet we want to sort into a left cabinet and a right cabinet. You can see in the lines that define <code>left</code> and <code>right</code> that we\u2019re using <code>:math.floor(len(cabinet)/2)</code> and <code>math.floor(len(cabinet)/2):</code> to refer to the entire first half or the entire second half of the original cabinet, respectively. You can call this function with any one- or two-element cabinet\u2014for example, <code>mergesort_two_elements([3,1])</code>\u2014and see that it successfully returns a sorted cabinet.</p> <p>Next, let\u2019s write a function that can sort a list that has four elements. If we split a four-element list into two sublists, each sublist will have two elements. We could follow our merging algorithm to combine these lists. However, recall that our merging algorithm is designed to combine two already sorted lists. These two lists may not be sorted, so using our merging algorithm will not successfully sort them. However, each of our sublists has only two elements, and we just wrote a function that can perform merge sort on lists with two elements. So we can split our four-element list into two sublists, call our merge sort function that works on two-element lists on each of those sublists, and then merge the two sorted lists together to get a sorted result with four elements. This Python function accomplishes that:</p> <pre><code>def mergesort_four_elements(cabinet):\n    newcabinet = []\n    if(len(cabinet) == 1):\n        newcabinet = cabinet\n    else:\n        left = mergesort_two_elements(cabinet[:math.floor(len(cabinet)/2)])\n        right = mergesort_two_elements(cabinet[math.floor(len(cabinet)/2):])\n        newcabinet = merging(left,right)\n    return(newcabinet)\n\ncabinet = [2,6,4,1]\nnewcabinet = mergesort_four_elements(cabinet)\n</code></pre> <p>We could continue writing these functions to work on successively larger lists. But the breakthrough comes when we realize that we can collapse that whole process by using recursion. Consider the function in Listing 4-5, and compare it to the preceding <code>mergesort_four_elements()</code> function.</p> <pre><code>def mergesort(cabinet):\n    newcabinet = []\n    if(len(cabinet) == 1):\n        newcabinet = cabinet\n    else:\n   1 left = mergesort(cabinet[:math.floor(len(cabinet)/2)])\n   2 right = mergesort(cabinet[math.floor(len(cabinet)/2):])\n        newcabinet = merging(left,right)\n    return(newcabinet)\n</code></pre> <p>Listing 4-5: Implementing merge sort with recursion</p> <p>You can see that this function is nearly identical to our <code>mergesort_four_elements()</code> to function. The crucial difference is that to create the sorted left and right cabinets, it doesn\u2019t call another function that works on smaller lists. Rather, it calls itself on the smaller list 12. Merge sort is a divide and conquer algorithm. We start with a large, unsorted list. Then we split that list repeatedly into smaller and smaller chunks (the dividing) until we end up with sorted (conquered) one-item lists, and then we simply merge them back together successively until we have built back up to one big sorted list. We can call this merge sort function on a list of any size and check that it works:</p> <pre><code>cabinet = [4,1,3,2,6,3,18,2,9,7,3,1,2.5,-9]\nnewcabinet = mergesort(cabinet)\nprint(newcabinet)\n</code></pre> <p>When we put all of our merge sort code together, we get Listing 4-6.</p> <pre><code>def merging(left,right):\n    newcabinet = []\n    while(min(len(left),len(right)) &gt; 0):\n        if left[0] &gt; right[0]:\n            to_insert = right.pop(0)\n            newcabinet.append(to_insert)\n        elif left[0] &lt;= right[0]:\n            to_insert = left.pop(0)\n            newcabinet.append(to_insert)\n    if(len(left) &gt; 0):\n        for i in left:\n            newcabinet.append(i)\n    if(len(right) &gt; 0):\n        for i in right:\n            newcabinet.append(i)\n    return(newcabinet)\n\nimport math\n\ndef mergesort(cabinet):\n    newcabinet = []\n    if(len(cabinet) == 1):\n        newcabinet=cabinet\n    else:\n        left = mergesort(cabinet[:math.floor(len(cabinet)/2)])\n        right = mergesort(cabinet[math.floor(len(cabinet)/2):])\n        newcabinet = merging(left,right)\n    return(newcabinet)\n\ncabinet = [4,1,3,2,6,3,18,2,9,7,3,1,2.5,-9]\nnewcabinet=mergesort(cabinet)\n</code></pre> <p>Listing 4-6: Our complete merge sort code</p> <p>You could add a step counter to your merge sort code to check how many steps it takes to run and how it compares to insertion sort. The merge sort process consists of successively splitting the initial cabinet into sublists and then merging those sublists back together, preserving the sorting order. Every time we split a list, we\u2019re cutting it in half. The number of times a list of length n can be split in half before each sublist has only one element is about log(n) (where the log is to base 2), and the number of comparisons we have to make at each merge is at most n. So n or fewer comparisons for each of log(n) comparisons means that merge sort is O(n\u00d7log(n)), which may not seem impressive but actually makes it the state of the art for sorting. In fact, when we call Python\u2019s built-in sorting function <code>sorted</code> as follows:</p> <pre><code>print(sorted(cabinet))\n</code></pre> <p>Python is using a hybrid version of merge sort and insertion sort behind the scenes to accomplish this sorting task. By learning merge sort and insertion sort, you\u2019ve gotten up to speed with the quickest sorting algorithm computer scientists have been able to create, something that is used millions of times every day in every imaginable kind of application.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#sleep-sort","title":"Sleep Sort","text":"<p>The enormous negative influence that the internet has had on humanity is occasionally counterbalanced by a small, shining treasure that it provides. Occasionally, the bowels of the internet even produce a scientific discovery that creeps into the world outside the purview of scientific journals or the \u201cestablishment.\u201d In 2011, an anonymous poster on the online image board 4chan proposed and provided code for a sorting algorithm that had never been published before and has since come to be called sleep sort.</p> <p>Sleep sort wasn\u2019t designed to resemble any real-world situation, like inserting files into a filing cabinet. If we\u2019re seeking an analogy, we might consider the task of allocating lifeboat spots on the Titanic as it began to sink. We might want to allow children and younger people the first chance to get on the lifeboats, and then allow older people to try to get one of the remaining spots. If we make an announcement like \u201cyounger people get on the boats before older people,\u201d we\u2019d face chaos as everyone would have to compare their ages\u2014they would face a difficult sorting problem amidst the chaos of the sinking ship.</p> <p>A sleep-sort approach to the Titanic lifeboats would be the following. We would announce, \u201cEveryone please stand still and count to your age: 1, 2, 3, . . . . As soon as you have counted up to your current age, step forward to get on a lifeboat.\u201d We can imagine that 8-year-olds would finish their counting about one second before the 9-year-olds, and so would have a one-second head start and be able to get a spot on the boats before those who were 9. The 8- and 9-year-olds would similarly be able to get on the boats before the 10-year-olds, and so on. Without doing any comparisons at all, we\u2019d rely on individuals\u2019 ability to pause for a length of time proportional to the metric we want to sort on and then insert themselves, and the sorting would happen effortlessly after that\u2014with no direct inter-person comparisons.</p> <p>This Titanic lifeboat process shows the idea of sleep sort: allow each element to insert itself directly, but only after a pause in proportion to the metric it\u2019s being sorted on. From a programming perspective, these pauses are called sleeps and can be implemented in most languages.</p> <p>In Python, we can implement sleep sort as follows. We will import the <code>threading</code> module, which will enable us to create different computer processes for each element of our list to sleep and then insert itself. We\u2019ll also import the <code>time.sleep</code> module, which will enable us to put our different \u201cthreads\u201d to sleep for the appropriate length of time.</p> <pre><code>import threading\nfrom time import sleep\n\ndef sleep_sort(i):\n    sleep(i)\n    global sortedlist\n    sortedlist.append(i)\n    return(i)\n\nitems = [2, 4, 5, 2, 1, 7]\nsortedlist = []\nignore_result = [threading.Thread(target = sleep_sort, args = (i,)).start() \\for i in items]\n</code></pre> <p>The sorted list will be stored in the <code>sortedlist</code> variable, and you can ignore the list we create called <code>ignore_result</code>. You can see that one advantage of sleep sort is that it can be written concisely in Python. It\u2019s also fun to print the <code>sortedlist</code> variable before the sorting is done (in this case, within about 7 seconds) because depending on exactly when you execute the <code>print</code> command, you\u2019ll see a different list. However, sleep sort also has some major disadvantages. One of these is that because it\u2019s not possible to sleep for a negative length of time, sleep sort cannot sort lists with negative numbers. Another disadvantage is that sleep sort\u2019s execution is highly dependent on outliers\u2014if you append 1,000 to the list, you\u2019ll have to wait at least 1,000 seconds for the algorithm to finish executing. Yet another disadvantage is that numbers that are close to each other may be inserted in the wrong order if the threads are not executed perfectly concurrently. Finally, since sleep sort uses threading, it will not be able to execute (well) on hardware or software that does not enable threading (well).</p> <p>If we had to express sleep sort\u2019s runtime in big O notation, we might say that it is O(max(list)). Unlike the runtime of every other well-known sorting algorithm, its runtime depends not on the size of the list but on the size of the elements of the list. This makes sleep sort hard to rely on, because we can only be confident about its performance with certain lists\u2014even a short list may take far too long to sort if any of its elements are too large.</p> <p>There may never be a practical use for sleep sort, even on a sinking ship. I include it here for a few reasons. First, because it is so different from all other extant sorting algorithms, it reminds us that even the most stale and static fields of research have room for creativity and innovation, and it provides a refreshingly new perspective on what may seem like a narrow field. Second, because it was designed and published anonymously and probably by someone outside the mainstream of research and practice, it reminds us that great thoughts and geniuses are found not only in fancy universities, established journals, and top firms, but also among the uncredentialed and unrecognized. Third, it represents a fascinating new generation of algorithms that are \u201cnative to computers,\u201d meaning that they are not a translation of something that can be done with a cabinet and two hands like many old algorithms, but are fundamentally based on capabilities that are unique to computers (in this case, sleeping and threading). Fourth, the computer-native ideas it relies on (sleeping and threading) are very useful and worth putting in any algorithmicist\u2019s toolbox for use in designing other algorithms. And fifth, I have an idiosyncratic affection for it, maybe just because it is a strange, creative misfit or maybe because I like its method of self-organizing order and the fact that I can use it if I\u2019m ever in charge of saving a sinking ship.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#from-sorting-to-searching","title":"From Sorting to Searching","text":"<p>Searching, like sorting, is fundamental to a variety of tasks in computer science (and in the rest of life). We may want to search for a name in a phone book, or (since we\u2019re living after the year 2000) we may need to access a database and find a relevant record.</p> <p>Searching is often merely a corollary of sorting. In other words, once we have sorted a list, searching is very straightforward\u2014the sorting is often the hard part.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#binary-search","title":"Binary Search","text":"<p>Binary search is a quick and effective method for searching for an element in a sorted list. It works a little like a guessing game. Suppose that someone is thinking of a number from 1 to 100 and you are trying to guess it. You may guess 50 as your first guess. Your friend says that 50 is incorrect but allows you to guess again and gives you a hint: 50 is too high. Since 50 is too high, you guess 49. Again, you are incorrect, and your friend tells you that 49 is too high and gives you another chance to guess. You could guess 48, then 47, and so on until you get the right answer. But that could take a long time\u2014if the correct number is 1, it will take you 50 guesses to get it, which seems like too many guesses considering there were only 100 total possibilities to begin with.</p> <p>A better approach is to take larger jumps after you find out whether your guess is too high or too low. If 50 is too high, consider what we could learn from guessing 40 next instead of 49. If 40 is too low, we have eliminated 39 possibilities (1\u201339) and we\u2019ll definitely be able to guess in at most 9 more guesses (41\u201349). If 40 is too high, we\u2019ve at least eliminated 9 possibilities (41\u201349) and we\u2019ll definitely be able to guess in at most 39 more guesses (1\u201339). So in the worst case, guessing 40 narrows down the possibilities from 49 (1\u201349) to 39 (1\u201339). By contrast, guessing 49 narrows down the possibilities from 49 (1\u201349) to 48 (1\u201348) in the worst case. Clearly, guessing 40 is a better searching strategy than guessing 49.</p> <p>It turns out that the best searching strategy is to guess exactly the midpoint of the remaining possibilities. If you do that and then check whether your guess was too high or too low, you can always eliminate half of the remaining possibilities. If you eliminate half of the possibilities in each round of guessing, you can actually find the right value quite quickly (O(log(n)) for those keeping score at home). For example, a list with 1,000 items will require only 10 guesses to find any element with a binary search strategy. If we\u2019re allowed to have only 20 guesses, we can correctly find the position of an element in a list with more than a million items. Incidentally, this is why we can write guessing-game apps that can correctly \u201cread your mind\u201d by asking only about 20 questions.</p> <p>To implement this in Python, we will start by defining upper and lower bounds for what location a file can occupy in a filing cabinet. The lower bound will be 0, and the upper bound will be the length of the cabinet:</p> <pre><code>sorted_cabinet = [1,2,3,4,5]\nupperbound = len(sorted_cabinet)\nlowerbound = 0\n</code></pre> <p>To start, we will guess that the file is in the middle of the cabinet. We\u2019ll import Python\u2019s math library to use the <code>floor()</code> function, which can convert decimals to integers. Remember that guessing the halfway point gives us the maximum possible amount of information:</p> <pre><code>import math\nguess = math.floor(len(sorted_cabinet)/2)\n</code></pre> <p>Next, we will check whether our guess is too low or too high. We\u2019ll take a different action depending on what we find. We use the <code>looking_for</code> variable for the value we are searching for:</p> <pre><code>if(sorted_cabinet[guess] &gt; looking_for):\n    --snip--\nif(sorted_cabinet[guess] &lt; looking_for):\n    --snip--\n</code></pre> <p>If the file in the cabinet is too high, then we\u2019ll make our guess the new upper bound, since there is no use looking any higher in the cabinet. Then our new guess will be lower\u2014to be precise, it will be halfway between the current guess and the lower bound:</p> <pre><code>looking_for = 3\nif(sorted_cabinet[guess] &gt; looking_for):\n    upperbound = guess\n    guess = math.floor((guess + lowerbound)/2)\n</code></pre> <p>We follow an analogous process if the file in the cabinet is too low:</p> <pre><code>if(sorted_cabinet[guess] &lt; looking_for):\n    lowerbound = guess\n    guess = math.floor((guess + upperbound)/2)\n</code></pre> <p>Finally, we can put all of these pieces together into a <code>binarysearch()</code> function. The function contains a while loop that will run for as long as it takes until we find the part of the cabinet we\u2019ve been looking for (Listing 4-7).</p> <pre><code>import math\nsortedcabinet = [1,2,3,4,5,6,7,8,9,10]\n\ndef binarysearch(sorted_cabinet,looking_for):\n    guess = math.floor(len(sorted_cabinet)/2)\n    upperbound = len(sorted_cabinet)\n    lowerbound = 0\n    while(abs(sorted_cabinet[guess] - looking_for) &gt; 0.0001):\n        if(sorted_cabinet[guess] &gt; looking_for):\n            upperbound = guess\n            guess = math.floor((guess + lowerbound)/2)\n        if(sorted_cabinet[guess] &lt; looking_for):\n            lowerbound = guess\n            guess = math.floor((guess + upperbound)/2)\n    return(guess)\n\nprint(binarysearch(sortedcabinet,8))\n</code></pre> <p>Listing 4-7: An implementation of binary search</p> <p>The final output of this code tells us that the number 8 is at position 7 in our <code>sorted_cabinet</code>. This is correct (remember that the index of Python lists starts at 0). This strategy of guessing in a way that eliminates half of the remaining possibilities is useful in many domains. For example, it\u2019s the basis for the most efficient strategy on average in the formerly popular board game Guess Who. It\u2019s also the best way (in theory) to look words up in a large, unfamiliar dictionary.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#applications-of-binary-search","title":"Applications of Binary Search","text":"<p>Besides guessing games and word lookups, binary search is used in a few other domains. For example, we can use the idea of binary search when debugging code. Suppose that we have written some code that doesn\u2019t work, but we aren\u2019t sure which part is faulty. We can use a binary search strategy to find the problem. We split the code in half and run both halves separately. Whichever half doesn\u2019t run properly is the half where the problem lies. Again, we split the problematic part in half, and test each half to further narrow down the possibilities until we find the offending line of code. A similar idea is implemented in the popular code version-control software Git as <code>git bisect</code> (although <code>git``bisect</code> iterates through temporally separated versions of the code rather than through lines in one version).</p> <p>Another application of binary search is inverting a mathematical function. For example, imagine that we have to write a function that can calculate the arcsin, or inverse sine, of a given number. In only a few lines, we can write a function that will call our <code>binarysearch()</code> function to get the right answer. To start, we need to define a domain; these are the values that we will search through to find a particular arcsin value. The <code>sine</code> function is periodic and takes on all of its possible values between \u2013pi/2 and pi/2, so numbers in between those extremes will constitute our domain. Next, we calculate sine values for each value in the domain. We call <code>binarysearch()</code> to find the position of the number whose sine is the number we\u2019re looking for, and return the domain value with the corresponding index, like so:</p> <pre><code>def inverse_sin(number):\n    domain = [x * math.pi/10000 - math.pi/2 for x in list(range(0,10000))]\n    the_range = [math.sin(x) for x in domain]\n    result = domain[binarysearch(the_range,number)]\n    return(result)\n</code></pre> <p>You can run <code>inverse_sin(0.9)</code> and see that this function returns the correct answer: about 1.12.</p> <p>This is not the only way to invert a function. Some functions can be inverted through algebraic manipulation. However, algebraic function inversion can be difficult or even impossible for many functions. The binary search method presented here, by contrast, can work for any function, and with its O(log(n)) runtime, it\u2019s also lightning fast.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting%20and%20searching/#summary","title":"Summary","text":"<p>Sorting and searching may feel mundane to you, as if you\u2019ve taken a break from an adventure around the world to attend a seminar on folding laundry. Maybe so, but remember that if you can fold clothes efficiently, you can pack more gear for your trek up Kilimanjaro. Sorting and searching algorithms can be enablers, helping you build newer and greater things on their shoulders. Besides that, it\u2019s worth studying sorting and searching algorithms closely because they are fundamental and common, and the ideas you see in them can be useful for the rest of your intellectual life. In this chapter, we discussed some fundamental and interesting sorting algorithms, plus binary search. We also discussed how to compare algorithms and use big O notation.</p> <p>In the next chapter, we\u2019ll turn to a few applications of pure math. We\u2019ll see how we can use algorithms to explore the mathematical world, and how the mathematical world can help us understand our own.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/","title":"Chapter 5. Sorting Without a Hat","text":"<p>In this chapter, you will learn:</p> <ul> <li> <p>How comparison-based sorting algorithms require two fundamental operations:</p> <ul> <li> <p><code>less(i,j)</code> determines whether <code>A[i]</code> &lt; <code>A[j]</code>.</p> </li> <li> <p><code>swap(i,j)</code> swaps the contents of <code>A[i]</code> and <code>A[j]</code>.</p> </li> </ul> </li> <li> <p>How to provide a comparator function when sorting; for example, you can sort integers or string values in descending order. The comparator function can also sort complex data structures with no default ordering; for example, it is not clear how to sort a collection of two-dimensional (x, y) points.</p> </li> <li> <p>How to identify inefficient O(N2) sorting algorithms, such as Insertion Sort and Selection Sort, from the structure of their code.</p> </li> <li> <p>Recursion, where a function can call itself. This fundamental computer science concept forms the basis of a divide-and-conquer strategy for solving problems.</p> </li> <li> <p>How Merge Sort and Quicksort can sort an array of N values in O(N <code>log</code> N) using divide and conquer. How Heap Sort also guarantees O(N <code>log</code> N).</p> </li> <li> <p>How Tim Sort combines Insertion Sort and functionality from Merge Sort to implement Python\u2019s default sorting algorithm in guaranteed O(N <code>log</code> N).</p> </li> </ul> <p>In this chapter, I present algorithms that rearrange the N values in an array so they are in ascending order. Organizing a collection of values in sorted order is an essential first step to improve the efficiency of many programs. Sorting is also necessary for many real-world applications, such as printing staff directories for a company with the names and phone numbers of employees, or displaying flight departure times on an airport display.</p> <p>With an unordered array, searching for a value, in the worst case, is O(N). When the array is sorted, Binary Array Search, in the worst case, can locate a target value in O(<code>log</code> N) performance.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#sorting-by-swapping","title":"Sorting by Swapping","text":"<p>Try sorting the values in the array, <code>A</code>, at the top of Figure\u00a05-1. Use a pencil to copy the values from Figure\u00a05-1 onto a piece of paper (or bring out a pen and just write on these pages!). I challenge you to sort these values in ascending order by repeatedly swapping the location of two values in the array. What is the fewest number of swaps that you need? Also, count the number of times you compare two values together. I have sorted these values with five swaps. Is it possible to use fewer?1</p> <p></p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#figure-5-1-sample-array-a-to-sort","title":"Figure 5-1. Sample array, <code>A</code>, to sort","text":"<p>While it\u2019s important to count the number of swaps, you also need to count the number of comparisons between two values. To start, you can determine that 2 is the smallest value in <code>A</code>, with just seven comparisons, something I showed in Chapter\u00a01. The smallest value is found at <code>A[3]</code>, so it is swapped with <code>A[0]</code>. This moves the smallest value to the front of the array where it belongs. In Figure\u00a05-1, I highlight values when they are swapped. I use bold borders to mark the values that are guaranteed to be in their final location; these will not be swapped again. All values outside of the bolded borders remain to be sorted.</p> <p>I scan the remaining values to find the largest value, 24, (using six comparisons) and swap <code>A[5]</code> and <code>A[7]</code> to move the largest value to the end of the array. I then locate the smallest remaining value, 5, (using five comparisons) and swap <code>A[1]</code> and <code>A[6]</code> to move 5 into its proper place. It looks like 21 is in its right spot, which takes four comparisons to validate; no need for a swap here!</p> <p>With three comparisons, I find that 15 is the smallest remaining value, and I choose to swap the second occurrence of 15, <code>A[4]</code>, with <code>A[2]</code>. With two comparisons, you can validate that 15 belongs in index position 3, which leaves just one more comparison to swap <code>A[4]</code> and <code>A[5]</code>, moving 19 into its proper spot. In the final step shown in Figure\u00a05-1, the value 20 is in the right location, since it is larger than or equal to all values to its left and is smaller than or equal to all values to its right. With five exchanges and 28 comparisons, I have sorted this array.</p> <p>I didn\u2019t follow a specific algorithm to sort this small group of values; sometimes I looked for the smallest value, while other times I looked for the largest. The number of comparisons is reduced after each swap, and there are far more comparisons than swaps. I now define a sorting algorithm that works on any array of N values and evaluate its runtime performance.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#selection-sort","title":"Selection Sort","text":"<p>Selection Sort is named because it incrementally sorts an array from left to right, repeatedly selecting the smallest value remaining and swapping it into its proper location. To sort N values, find the smallest value and swap it with <code>A[0]</code>. Now only N \u2013 1 values remain to be sorted, since <code>A[0]</code> is in its final spot. Find the location of the smallest remaining value and swap it with <code>A[1]</code>, which leaves N \u2013 2 values to sort. Repeat this process until all values are in place.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#tip","title":"Tip","text":"<p>What happens when the smallest remaining value is already in its proper place, that is, when <code>i</code> is equal to <code>min_index</code> when the <code>for</code> loop over <code>j</code> completes? The code will attempt to swap <code>A[i]</code> with <code>A[min_index]</code>, and nothing in the array will change. You might think to add an <code>if</code> statement to only swap when <code>i</code> and <code>min_index</code> are different, but it will not noticeably improve performance.</p> <p>In Listing 5-1, there is an outer <code>for</code> loop over <code>i</code> that iterates through nearly every index position in the array, from 0 to N \u2013 2. The inner <code>for</code> loop over <code>j</code> iterates through the remaining index positions in the array, from <code>i+1</code> up to N \u2013 1 to find the smallest remaining value. At the end of the <code>for</code> loop over <code>i</code>, the value at index position <code>i</code> is swapped with the smallest value found at index position <code>min_index</code>.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#listing-5-1-selection-sort","title":"Listing 5-1. Selection Sort","text":"<pre><code>def\n</code></pre> <p>Before each pass through the <code>i</code> <code>for</code> loop, you know <code>A[0 .. i-1]</code> is sorted.</p> <p></p> <p><code>min_index</code> is the index location of the smallest value in <code>A[i .. N-1]</code>.</p> <p></p> <p>If any <code>A[j]</code> &lt; <code>A[min_index]</code>, then update <code>min_index</code> to remember index location for this newly discovered smallest value.</p> <p></p> <p>Swap <code>A[i]</code> with <code>A[min_index]</code> to ensure that <code>A[0 .. i]</code> is sorted.</p> <p>At a high level, Selection Sort starts with a problem of size N and reduces it one step at a time, first to a problem of size N \u2013 1, then to a problem of size N \u2013 2, until the whole array is sorted. As shown in Figure\u00a05-2, it takes N \u2013 1 swaps to sort an array.</p> <p>After these swaps have properly placed N \u2013 1 values into their final location, the value at <code>A[N\u20131]</code> is the largest remaining unsorted value, which means it is already in its final location. Counting the number of comparisons is more complicated. In Figure\u00a05-2, it was 28, which is the sum of the numbers from 1 through 7.</p> <p>Mathematically, the sum of the numbers from 1 to K is equal to K \u00d7 (K + 1)/2; Figure\u00a05-3 shows a visualization to provide the intuition behind this formula. Number 28 is called a triangle number, from the shape formed by the arrangement of cells.</p> <p>If you make a second triangle equal in size to the first and rotate it 180 degrees, the two triangles combine to form a K by K + 1 rectangle. The count of the squares in each triangle is half the number of squares in the 7 x 8 rectangle. In this figure, K = 7. When sorting N values, K = N \u2013 1 since that is the number of comparisons in the first step to find the smallest value: the total number of comparisons is (N \u2013 1) \u00d7 N/2 or \u00bd \u00d7 N2 \u2013 \u00bd \u00d7 N.</p> <p></p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#figure-5-2-sorting-sample-array-using-selection-sort","title":"Figure 5-2. Sorting sample array using Selection Sort","text":""},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#figure-5-3-visualizing-the-formula-for-triangle-numbers-sum-of-1-through-7-is-28","title":"Figure 5-3. Visualizing the formula for triangle numbers: sum of 1 through 7 is 28","text":""},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#anatomy-of-a-quadratic-sorting-algorithm","title":"Anatomy of a Quadratic Sorting Algorithm","text":"<p>The analysis for Selection Sort shows that the number of comparisons is dominated by the N2 term, which means its performance will be O(N2) since that is the dominant operation. To explain why, look at how Selection Sort has N \u2013 1 distinct steps when sorting N values. In the first step, it finds the smallest value in N \u2013 1 comparisons, and only one value is moved into its proper location. In each of the subsequent N \u2013 2 steps, the number of comparisons will (ever so slowly) decrease until there is no work done in the final step. Can something be done to reduce the number of comparisons?</p> <p>Insertion Sort is a different sorting algorithm that also uses N \u2013 1 distinct steps to sort an array from left to right. It starts by assuming that <code>A[0]</code> is in its proper location (hey, it could be the smallest value in the array, right?). In its first step, it checks if <code>A[1]</code> is smaller than <code>A[0]</code> and swaps these two values as needed to sort in ascending order. In the second step, it tries to insert the <code>A[2]</code> value into its proper sorted location when just considering the first three values. There are three possibilities: either <code>A[2]</code> is in its proper spot, or it should be inserted between <code>A[0]</code> and <code>A[1]</code>, or it should be inserted before <code>A[0]</code>. However, since you cannot insert a value between two array positions, you must repeatedly swap values to make room for the value to be inserted.</p> <p>At the end of each step, as shown in Figure\u00a05-4, Insertion Sort repeatedly swaps neighboring out-of-order values.</p> <p></p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#figure-5-4-sorting-sample-array-using-insertion-sort","title":"Figure 5-4. Sorting sample array using Insertion Sort","text":"<p>All swapped values are highlighted, and bold borders identify the sorted values in the array. Unlike Selection Sort, values within the bold borders may continue to be swapped, as you can see in the figure. At times (like when the value 5 is inserted) there is a sequence of cascading swaps to move that value into its proper place because the value to insert is smaller than most of the already sorted values. At other times (like when 21 or 24 is inserted), no swaps are needed because the value to insert is larger than all of the already-sorted values. In this example, there are 20 comparisons and 14 swaps. For Insertion Sort, the number of comparisons will always be greater than or equal to the number of swaps. On this problem instance, Insertion Sort uses fewer comparisons than Selection Sort but more swaps. Its implementation, in Listing 5-2, is surprisingly brief.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#listing-5-2-insertion-sort","title":"Listing 5-2. Insertion Sort","text":"<pre><code>def\n</code></pre> <p>Before each pass through the <code>i</code> <code>for</code> loop, you know <code>A[0 .. i-1]</code> is sorted.</p> <p></p> <p>Decrement <code>j</code> from index location <code>i</code> back to 0 but not including 0.</p> <p></p> <p>If <code>A[j-1]</code> \u2264 <code>A[j]</code>, then <code>A[j]</code> has found its proper spot, so stop.</p> <p></p> <p>Otherwise, swap these out-of-order values.</p> <p>Insertion Sort works the hardest when each value to be inserted is smaller than all already-sorted values. The worst case for Insertion Sort occurs when the values are in descending order. In each successive step, the number of comparisons (and swaps) increases by one, summing in total to the triangle numbers mentioned earlier.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#analyze-performance-of-insertion-sort-and-selection-sort","title":"Analyze Performance of Insertion Sort and Selection Sort","text":"<p>Selection Sort will always have \u00bd \u00d7 N2 \u2013 \u00bd \u00d7 N comparisons and N \u2013 1 swaps when sorting N values. Counting the operations for Insertion Sort is more complicated because its performance depends on the order of the values themselves. On average, Insertion Sort should outperform Selection Sort. In the worst case for Insertion Sort, the values appear in descending order, and the number of comparisons and swaps is \u00bd \u00d7 N2 \u2013 \u00bd \u00d7 N. No matter what you do, both Insertion Sort and Selection Sort require on the order of N2 comparisons, which leads to the runtime performance visualized in Figure\u00a05-5. Another way to explain this poor behavior is to observe that the problem instance size 524,288 is 512 times as large as 1,024, yet the runtime performance for both Selection Sort and Insertion Sort takes about 275,000 times longer.2 Sorting 524,288 values takes about two hours for Insertion Sort and nearly four hours for Selection Sort. To solve larger problems, you would need to measure the completion times in days or weeks. This is what a quadratic, or O(N2), algorithm will do to you, and it is simply unacceptable performance.</p> <p></p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#figure-5-5-timing-results-of-insertion-sort-and-selection-sort","title":"Figure 5-5. Timing results of Insertion Sort and Selection Sort","text":"<p>What if you wanted to sort an array in descending order? Or what if the values have a complex structure and there is no default less-than operation defined? Each of the sorting algorithms in this chapter can be extended with a parameter for a comparator function to determine how values are to be ordered, as shown in Listing 5-3. For simplicity, the implementations of the remaining algorithms assume the values are sorted in ascending order.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#listing-5-3-providing-a-comparator-function-to-a-sorting-algorithm","title":"Listing 5-3. Providing a comparator function to a sorting algorithm","text":"<pre><code>def\n</code></pre> <p>Determine sorting order using a provided comparator function, <code>less</code>. If <code>less(A[x],A[y])</code> is <code>True</code>, then <code>A[x]</code> should appear before <code>A[y]</code>.</p> <p>Both Selection Sort and Insertion Sort use N \u2013 1 steps to sort an array of N values, where each step reduces the problem size by just one. A different strategy, known as divide and conquer, breaks a problem up into two sub-problems to be solved.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#recursion-and-divide-and-conquer","title":"Recursion and Divide and Conquer","text":"<p>The concept of recursion has existed in mathematics for centuries\u2014it occurs when a function calls itself.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#tip_1","title":"Tip","text":"<p>The Fibonacci series starts with two integers, 0 and 1. The next integer in the series is the sum of the two prior numbers. The next few integers in the series are 1, 2, 3, 5, 8, 13, and so on. The recursive formula for the nth integer in the series is F(n) = F(n\u20131) + F(n\u20132). As you can see, F(n) is defined by calling itself twice.</p> <p>The factorial of an integer, N, is the product of all positive integers less than or equal to N. It is written as \u201cN!\u201d; thus 5! = 5 \u00d7 4 \u00d7 3 \u00d7 2 \u00d7 1 = 120. Another way to represent this operation is to state that N! = N \u00d7 (N \u2013 1)! For example, 120 = 5 \u00d7 4!, where 4! = 24. A recursive implementation is shown in Listing 5-4.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#listing-5-4-recursive-implementation-of-factorial","title":"Listing 5-4. Recursive implementation of factorial","text":"<pre><code>def\n</code></pre> <p>Base case: return 1 for <code>fact(1)</code> or any <code>N</code> \u2264 1.</p> <p></p> <p>Recursive case: recursively compute <code>fact(N\u20131)</code> and multiply its result by <code>N</code>.</p> <p>It may seem odd to see a function calling itself\u2014how can you be sure that it will not do so forever? Each recursive function has a base case that prevents this infinite behavior. <code>fact(1)</code> will return <code>1</code> and not call itself.3 In the recursive case, <code>fact(N)</code> calls itself with an argument of N \u2013 1 and multiplies the returned computation by N to produce its final result.</p> <p>Figure\u00a05-6 visualizes the execution of the statement <code>y = fact(3)</code> as time advances downward. Each box represents an invocation of <code>fact()</code> with the given argument (whether 3, 2, or 1). Invoking <code>fact(3)</code> recursively calls <code>fact(2)</code>. When that happens, the original <code>fact(3)</code> function will be \u201cpaused\u201d (grayed out in the figure) until the value of <code>fact(2)</code> is known. When <code>fact(2)</code> is invoked, it also must recursively call <code>fact(1)</code>, so it is paused (and grayed out in the figure) until the value of <code>fact(1)</code> is known. Finally at this point, the base case stops the recursion, and <code>fact(1)</code> returns 1 as its value, shown inside a dashed circle; this resumes the paused execution of <code>fact(2)</code>, which returns 2 \u00d7 1 = 2 as its value. Finally, the original <code>fact(3)</code> resumes, returning 3 \u00d7 2 = 6, which sets the value of <code>y</code> to 6.</p> <p>During recursion, any number of <code>fact(N)</code> invocations can be paused until the base case is reached.4 Then, the recursion \u201cunwinds\u201d one function call at a time until the original invocation is complete.</p> <p>In reviewing this algorithm, it still solves a problem of size N by reducing it into a smaller problem of size N \u2013 1. What if the problem of size N could be divided into two problems of, more or less, N/2? It might seem like this computation could go on forever, since each of these two sub-problems are further subdivided into four sub-problems of size N/4. Fortunately the base case will ensure that\u2014at some point\u2014the computations will complete.</p> <p>Consider a familiar problem, trying to find the largest value in an unordered array of N values. In Listing 5-5, <code>find_max(A)</code> invokes a recursive helper function,5 <code>rmax(0,len(A)\u20131)</code>, to properly set up the initial values for <code>lo</code> = 0 and <code>hi</code> = N \u2013 1, where N is the length of <code>A</code>. The base case in <code>rmax()</code> stops the recursion once <code>lo = hi</code> because this represents looking for the largest value in a range containing just a single value. Once the largest values are determined for the left and right sub-problems, <code>rmax()</code> returns the larger of these two values as the largest value in <code>A[lo .. hi]</code>.</p> <p></p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#figure-5-6-visualizing-the-recursive-invocation-of-fact3","title":"Figure 5-6. Visualizing the recursive invocation of <code>fact(3)</code>","text":""},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#listing-5-5-recursive-algorithm-to-find-largest-value-in-unordered-list","title":"Listing 5-5. Recursive algorithm to find largest value in unordered list","text":"<pre><code>def\n</code></pre> <p>Invoke the initial recursive call with proper arguments for <code>lo</code> and <code>hi</code>.</p> <p></p> <p>Base case: when <code>lo</code> == <code>hi</code>, the range <code>A[lo .. hi]</code> contains a single value; return it as the largest value.</p> <p></p> <p>Find midpoint index location in the range <code>A[lo .. hi]</code>. Use integer division <code>//</code> in case range has odd number of values.</p> <p></p> <p><code>L</code> is the largest value in the range <code>A[lo .. mid]</code>.</p> <p></p> <p><code>R</code> is the largest value in the range <code>A[mid+1 .. hi]</code>.</p> <p></p> <p>The largest value in <code>A[lo .. hi]</code> is the maximum of <code>L</code> and <code>R</code>.</p> <p>The function <code>rmax(lo, hi)</code> solves this problem recursively by dividing a problem of size N into two problems of half the size. Figure\u00a05-7 visualizes the execution of <code>rmax(0,3)</code> on the given array, <code>A</code>, with four values. To solve this problem, it solves two sub-problems: <code>rmax(0,1)</code> finds the largest value in the left-hand side of <code>A</code>, and <code>rmax(2,3)</code> finds the largest value in the right-hand side of <code>A</code>. Since <code>rmax()</code> makes two recursive calls within its function, I introduce a new visualization to describe where, in <code>rmax()</code>, the execution is paused. I still use a gray background to show that <code>rmax()</code> is paused when it makes a recursive call: in addition, the lines highlighted with a black background will execute once the recursive call returns.</p> <p>In Figure\u00a05-7, I only have space to show the three recursive calls that complete to determine that 21 is the largest value in the left-hand side of <code>A</code>. As you can see, the final two lines in the invocation box for <code>rmax(0,3)</code> are highlighted in black to remind you that the rest of the computation will resume with the recursive call to <code>rmax(2,3)</code>. A similar sequence of three additional recursive calls would complete the right-hand sub-problem, ultimately allowing the original recursive invocation <code>rmax(0,3)</code> to return <code>max(21,20)</code> as its answer.</p> <p>Figure\u00a05-8 visualizes the full recursive behavior of <code>rmax(0,7)</code>. Similar to my explanation for <code>fact()</code>, this figure shows how the invocation of <code>rmax(0,3)</code> is paused while it recursively computes the first sub-problem, <code>rmax(0,1)</code>. The original problem is repeatedly subdivided until <code>rmax()</code> is invoked where its parameters <code>lo</code> and <code>hi</code> are equal; this will happen eight different times in the figure, since there are N = 8 values. Each of these eight cases represents a base case, which stops the recursion. As you can see in Figure\u00a05-8, the maximum value is 24, and I have highlighted the <code>rmax()</code> recursive calls that return this value.</p> <p></p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#figure-5-7-recursive-invocation-when-calling-rmax03-on-a-1521202","title":"Figure 5-7. Recursive invocation when calling <code>rmax(0,3)</code> on <code>A = [15,21,20,2]</code>","text":""},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#figure-5-8-complete-recursive-invocation-of-rmax07","title":"Figure 5-8. Complete recursive invocation of <code>rmax(0,7)</code>","text":""},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#merge-sort","title":"Merge Sort","text":"<p>Inspired by these examples, we can now ask, \u201cIs there a recursive divide-and-conquer approach to sort an array?\u201d Listing 5-6 contains the gist of an idea: to sort an array, recursively sort its left half, and recursively sort its right half; then somehow merge the partial results to ensure the whole array is sorted.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#listing-5-6-idea-for-sorting-recursively","title":"Listing 5-6. Idea for sorting recursively","text":"<pre><code>def\n</code></pre> <p>Recursive helper method to sort <code>A[lo .. hi]</code>.</p> <p></p> <p>Base case: a range with one or fewer values is already in sorted order.</p> <p></p> <p>Recursive case: sort the left half of <code>A</code> and the right half of <code>A</code>.</p> <p></p> <p>Merge both sorted halves of the array in place.</p> <p>The structure of Listing 5-6 is identical to the <code>find_max(A)</code> function described in Listing 5-5. Completing this implementation leads to Merge Sort, an in-place recursive sorting algorithm that requires extra storage but provides the breakthrough we were looking for, namely an O(N <code>log</code> N) sorting algorithm.</p> <p>The key to Merge Sort is the <code>merge</code> function that merges in place the sorted left half of an array with the sorted right half of an array. The mechanics of <code>merge()</code> might be familiar if you\u2019ve ever had two sorted stacks of paper that you want to merge into one final sorted stack, as shown in Figure\u00a05-9.</p> <p></p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#figure-5-9-merging-two-stacks-into-one","title":"Figure 5-9. Merging two stacks into one","text":"<p>To merge these two stacks into one stack, look at the topmost remaining value in each stack and choose the smallest one. In the first two steps, 2 is removed from the left stack, and then 5 is removed from the right. When faced with two values that are the same, arbitrarily take the value from the left stack, first removing 15 from the left stack, then removing 15 from the right stack. Repeat this process until one of the stacks is exhausted (which happens in the final eighth step). When only one stack remains, just take all those values as a group, since they are already sorted.</p> <p>The merge process sketched in Figure\u00a05-9 works because of the extra storage into which the values are placed. The most efficient way to implement Merge Sort is to initially allocate extra storage equal to the size of the original array being sorted, as shown in Listing 5-7.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#listing-5-7-recursive-merge-sort-implementation","title":"Listing 5-7. Recursive Merge Sort implementation","text":"<pre><code>def\n</code></pre> <p>Allocate auxiliary storage equal in size to original array.</p> <p></p> <p>Base case: with 1 or fewer values, there is nothing to sort.</p> <p></p> <p>Recursive case: sort left and right sub-arrays and then merge.</p> <p></p> <p>Copy sorted sub-arrays from <code>A</code> into <code>aux</code> to prepare for merge.</p> <p></p> <p>Set <code>left</code> and <code>right</code> to be the starting index positions of the corresponding sub-arrays.</p> <p></p> <p>When left sub-array is exhausted, take value from right sub-array.</p> <p></p> <p>When right sub-array is exhausted, take value from left sub-array.</p> <p></p> <p>When right value is smaller than left value, take value from right sub-array.</p> <p></p> <p>When left value is smaller than or equal to right value, take value from left sub-array.</p> <p></p> <p>Invoke the initial recursive call.</p> <p>Figure\u00a05-10 visualizes the dynamic behavior of <code>merge()</code>. The first step of <code>merge(lo,mid,hi)</code> is to copy the elements from <code>A[lo .. hi]</code> into <code>aux[lo .. hi]</code> since this is the sub-problem range being sorted.</p> <p>The <code>for</code> loop over <code>i</code> will execute 8 times, because that is the total size of the two sub-problems being merged. Starting in the third row of Figure\u00a05-10, the variables <code>left</code>, <code>right</code>, and <code>i</code> each keep track of specific locations:</p> <ul> <li> <p><code>left</code> is the index position of the next value in the left sub-array to be merged.</p> </li> <li> <p><code>right</code> is the index position of the next value in the right sub-array to be merged.</p> </li> <li> <p><code>i</code> is the index position in <code>A</code> where successively larger values are copied until, by the last step, all values in <code>A[lo .. hi]</code> are in sorted order.</p> </li> </ul> <p>Within the <code>for</code> loop, up to two values in <code>aux</code> (highlighted in Figure\u00a05-10) are compared to find the lower value, which is then copied into <code>A[i]</code>. With each step, <code>i</code> is incremented, while <code>left</code> and <code>right</code> advance only when the value at <code>aux[left]</code> or <code>aux[right]</code> is found to be the next smallest one to be copied into <code>A</code>. The time to complete <code>merge()</code> is directly proportional to the combined size of the sub-problems (or <code>hi \u2013 lo + 1</code>).</p> <p>Merge Sort is a great example of a divide-and-conquer algorithm that guarantees O(N <code>log</code> N) performance. If you have a problem that satisfies the following checklist, then an O(N <code>log</code> N) algorithm exists:</p> <ul> <li> <p>If you can subdivide a problem of size N into two independent sub-problems of size N/2; it is perfectly fine for one sub-problem to be slightly larger than the other.</p> </li> <li> <p>If you have a base case that either does nothing (like with Merge Sort) or performs some operations in constant time.</p> </li> <li> <p>If you have a processing step (either before the problem is subdivided or afterward as a post-processing step) that requires time directly proportional to the number of values in the sub-problem. For example, the <code>for</code> loop in <code>merge()</code> repeats a number of times equal to the size of the sub-problem being solved.</p> </li> </ul> <p></p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#figure-5-10-step-by-step-merge-of-two-sorted-sub-arrays-of-size-4","title":"Figure 5-10. Step-by-step merge of two sorted sub-arrays of size 4","text":""},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#quicksort","title":"Quicksort","text":"<p>Another sorting algorithm that follows divide-and-conquer is Quicksort, one of the most heavily studied and efficient sorting algorithms ever designed.6 It recursively sorts an array by selecting an element in <code>A</code> to use as a pivot value, <code>p</code>, and then it inserts <code>p</code> into its proper location in the final sorted array. To do this, it rearranges the contents of <code>A[lo .. hi]</code> such that there is a left sub-array with values that are \u2264 <code>p</code>, and a right sub-array with values that are \u2265 <code>p</code>. You can confirm in Figure\u00a05-11 that the partitioned array has this property.</p> <p></p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#figure-5-11-results-of-partitiona070-using-a0-as-pivot","title":"Figure 5-11. Results of <code>partition(A,0,7,0)</code> using <code>A[0]</code> as pivot","text":"<p>This amazing feat may at first seem impossible\u2014how do you know where <code>p</code> exists in the final sorted array without actually sorting the entire array? It turns out that partitioning doesn\u2019t sort all elements in <code>A</code> but rearranges just a few based on <code>p</code>. In the challenge exercises found in Chapter\u00a01, you can find the implementation of <code>partition()</code>. After <code>partition()</code> completes in Figure\u00a05-11, the left sub-array to be sorted contains two values, while the right sub-array contains five values. Each of these sub-arrays is recursively sorted using Quicksort, as shown in Listing 5-8.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#listing-5-8-recursive-quicksort-implementation","title":"Listing 5-8. Recursive Quicksort implementation","text":"<pre><code>def\n</code></pre> <p>Base case: with 1 or fewer values, there is nothing to sort.</p> <p></p> <p>Choose <code>A[lo]</code> as the pivot value, <code>p</code>.</p> <p></p> <p>Return <code>location</code> in <code>A</code> such that:</p> <ul> <li> <p><code>A[location] = p</code></p> </li> <li> <p>All values in left sub-array <code>A[lo .. location\u20131]</code> are all \u2264 <code>p</code></p> </li> <li> <p>All values in right sub-array <code>A[location+1 .. hi]</code> are all \u2265 <code>p</code></p> </li> </ul> <p></p> <p>Recursive case: sort in place left and right sub-arrays, since <code>p</code> is already in its proper sorted location, <code>A[location]</code>.</p> <p></p> <p>Invoke the initial recursive call.</p> <p>Quicksort presents an elegant recursive solution whose success depends on the partitioning function. For example, if <code>partition()</code> is invoked on a sub-array <code>A[lo .. hi]</code> containing N values and the smallest value in that sub-array is used as the pivot, then the resulting left sub-array is empty, whereas the right sub-array contains N \u2013 1 values. Reducing a sub-problem by 1 is exactly how Insertion Sort and Selection Sort performed, leading to inefficient O(N2) sorting. The top of Figure\u00a05-12 summarizes the key steps of Quicksort applied to the array from Figure\u00a05-11. The bottom of Figure\u00a05-12 shows the full recursive execution. On the right side of the figure, you can see <code>A</code>, the array being sorted, and how its values change in response to the recursive execution. For each partition of a range <code>A[lo .. hi]</code>, the selected pivot is always <code>A[lo]</code>, which is why each box reads <code>partition(lo,hi,lo)</code>. As time moves vertically down the figure, you can see how each <code>partition()</code> invocation leads to 1 or 2 recursive calls to <code>qsort()</code>. For example, <code>partition(0,7,0)</code> on <code>A</code> places 15 into its final index location (which is why it is grayed out on the right), leading to two subsequent recursive invocations: <code>qsort(0,1)</code> on the left sub-array and <code>qsort(3,7)</code> on the right sub-array. The invocation of <code>qsort(3,7)</code> does not start until <code>qsort(0,1)</code> has completed its work.</p> <p>Each time <code>partition</code> is invoked, a different value is placed into its proper index location and grayed out. When <code>qsort(lo,hi)</code> is invoked on a range where <code>lo = hi</code>, that value is in its proper location, and it is also grayed out.</p> <p>When a <code>partition(lo,hi,lo)</code> produces only a single recursive call to <code>qsort()</code>, it is because the pivot value is placed in either <code>A[lo]</code> or <code>A[hi]</code>, thus reducing the problem size by just 1. For example, given the implementation in Listing 5-8, Quicksort will degrade its performance to O(N2) when called on an array of already-sorted values! To avoid this behavior, Quicksort is often modified to choose the pivot value randomly from within the range <code>A[lo .. hi]</code> by replacing <code>pivot_idx = lo</code> in Listing 5-8 with <code>pivot_idx = random.randint(lo, hi)</code>. Decades of research have confirmed that there is always a theoretical possibility that in the worst case, Quicksort will have a runtime performance of O(N2). Despite this weakness, Quicksort is often the sorting algorithm of choice because, unlike Merge Sort, it does not require any extra storage. In reviewing the structure for Quicksort, you can see that it conforms to the checklist for O(N <code>log</code> N) algorithms.</p> <p></p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#figure-5-12-full-recursive-invocation-of-quicksort","title":"Figure 5-12. Full recursive invocation of Quicksort","text":"<p>Another way to achieve O(N <code>log</code> N) is to have N steps where the runtime performance of each step is O(<code>log</code> N). Using the heap data structure introduced in the last chapter, I now present Heap Sort, whose runtime performance is O(N <code>log</code> N).</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#heap-sort","title":"Heap Sort","text":"<p>To see why a max binary heap can help sort an array, consider Figure\u00a05-13 that presents the array storage for the heap from Figure\u00a04-17. The largest value in <code>A</code> is found in <code>A[1]</code>. When this max value is dequeued, the underlying array storage is updated to reflect the modified max binary heap containing one less value. More importantly, the index position <code>A[18]</code> is not only unused, it is exactly the index position that should contain the maximum value if the array were sorted. Simply place the dequeued value there. Perform another dequeue, and this value (the second-largest value in the heap) can be placed in index position <code>A[17]</code>, which is now unused.</p> <p></p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#figure-5-13-intuition-behind-how-a-max-binary-heap-can-be-used-for-sorting","title":"Figure 5-13. Intuition behind how a max binary heap can be used for sorting","text":"<p>To make this promising approach work, I need to address the following issues:</p> <ul> <li> <p>The heap data structure ignores the value in index position 0 to simplify its computations using an array of size N + 1 to store N values.</p> </li> <li> <p>The heap is initially empty, and new values are enqueued one at a time. When starting with N values to sort initially, there needs to be an efficient way to \u201cbulk upload\u201d all values.</p> </li> </ul> <p>Let\u2019s fix how index positions are calculated. The original heap with 18 elements (as shown in Figure\u00a05-13) was stored in an array with 19 elements. Any reference to <code>A[i]</code> uses 1-based indexing, meaning that <code>A[1]</code> stored the first value in the heap, and <code>A[N\u20131]</code> stored the last. In Listing 5-9, the <code>less(i,j)</code> and <code>swap(i,j)</code> functions all subtract 1 from <code>i</code> and <code>j</code> whenever accessing <code>A[i]</code> or <code>A[j]</code>. This allows 1-based indexing to work with 0-based array storage. The largest value in the heap is now in <code>A[0]</code>. When <code>swap(1, N)</code> appears in the <code>sort()</code> function, it actually swaps the values in <code>A[0]</code> and <code>A[N\u20131]</code>. With this small adjustment, the <code>sink()</code> method remains the same. Note that Heap Sort never uses <code>swim()</code>.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#listing-5-9-heap-sort-implementation","title":"Listing 5-9. Heap Sort implementation","text":"<pre><code>class\n</code></pre> <p>To ensure that <code>i</code> // 2 computes the parent index location for <code>i</code>, both <code>less()</code> and <code>swap()</code> subtract 1 from <code>i</code> and <code>j</code>, as if they were using 1-based indexing.</p> <p></p> <p>Convert array to be sorted, <code>A</code>, into a max binary heap in bottom-up fashion, starting at <code>N</code>//2, the highest index position that has at least one child.</p> <p></p> <p>The <code>while</code> loop continues as long as there are values to sort.</p> <p></p> <p>Dequeue maximum value by swapping with last value in heap.</p> <p></p> <p>Reduce size of heap by one for upcoming <code>sink()</code> to work.</p> <p></p> <p>Sink the newly swapped value into its proper location, which reestablishes the heap-ordered property.</p> <p>The most important step in Heap Sort is constructing the initial max binary heap from the original array to be sorted. The <code>for</code> loop in <code>HeapSort</code> completes this task, and the result is shown in Figure\u00a05-14, which required only 23 total comparisons and 5 swaps. This <code>for</code> loop constructs a heap from the bottom to the top by starting at index position <code>N</code>//2, the highest index position that has at least one child. In reverse order, the <code>for</code> loop calls <code>sink()</code> on the kth index position to ultimately ensure that all values in the array satisfy the heap-ordered property. These index positions are drawn with a bold border in Figure\u00a05-14.</p> <p>Through a rather unexpected theoretical analysis, the total number of comparisons required to convert an arbitrary array into a max binary heap is no more than 2N in the worst case. The intuition behind this result can be seen in the running total of comparisons in Figure\u00a05-14, which shows a steady, but slow, growth rate. I continue to alternatively shade the index positions within <code>A</code> by the computed level of the max binary heap to show how values are swapped between levels.</p> <p></p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#figure-5-14-converting-array-into-a-max-binary-heap","title":"Figure 5-14. Converting array into a max binary heap","text":"<p>The final row in Figure\u00a05-14 represents a max binary heap\u2014in fact, the exact same one depicted in Figure\u00a04-16, now offset by one index position to use all N index positions. The <code>sort()</code> function in Listing 5-9 now repeatedly swaps the largest value in the heap with the last value in the heap (using the trick hinted at in Figure\u00a05-13), which has the effect of placing that value in exactly its proper location in the final sorted array. <code>sort()</code> then reduces the size of the heap by one, and <code>sink()</code> properly re-establishes the heap-ordered property with runtime performance of O(<code>log</code> N), as described in Chapter\u00a04.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#performance-comparison-of-on-log-n-algorithms","title":"Performance Comparison of O(N log N) Algorithms","text":"<p>How does the runtime performance of these different sorting algorithms\u2014all classified as O(N <code>log</code> N)\u2014compare with each other? Let\u2019s start with some empirical results, as shown in Table\u00a05-1. Reading the numbers down in a column reports the timing results of an algorithm as the problem size doubles; you can see that each timing value is a bit more than twice as large as its previous value. This relative performance is the signature behavior of an O(N <code>log</code> N) algorithm.</p> <p>Table 5-1. Runtime performance (in seconds) for different sorting algorithms</p> <p>N</p> <p>Merge Sort</p> <p>Quicksort</p> <p>Heap Sort</p> <p>Tim Sort</p> <p>Python Sort</p> <p>1,024</p> <p><code>0.002</code></p> <p><code>0.002</code></p> <p><code>0.006</code></p> <p><code>0.002</code></p> <p><code>0.000</code></p> <p>2,048</p> <p><code>0.004</code></p> <p><code>0.004</code></p> <p><code>0.014</code></p> <p><code>0.005</code></p> <p><code>0.000</code></p> <p>4,096</p> <p><code>0.009</code></p> <p><code>0.008</code></p> <p><code>0.032</code></p> <p><code>0.011</code></p> <p><code>0.000</code></p> <p>8,192</p> <p><code>0.020</code></p> <p><code>0.017</code></p> <p><code>0.073</code></p> <p><code>0.023</code></p> <p><code>0.001</code></p> <p>16,384</p> <p><code>0.042</code></p> <p><code>0.037</code></p> <p><code>0.160</code></p> <p><code>0.049</code></p> <p><code>0.002</code></p> <p>32,768</p> <p><code>0.090</code></p> <p><code>0.080</code></p> <p><code>0.344</code></p> <p><code>0.103</code></p> <p><code>0.004</code></p> <p>65,536</p> <p><code>0.190</code></p> <p><code>0.166</code></p> <p><code>0.751</code></p> <p><code>0.219</code></p> <p><code>0.008</code></p> <p>131,072</p> <p><code>0.402</code></p> <p><code>0.358</code></p> <p><code>1.624</code></p> <p><code>0.458</code></p> <p><code>0.017</code></p> <p>262,144</p> <p><code>0.854</code></p> <p><code>0.746</code></p> <p><code>3.486</code></p> <p><code>0.970</code></p> <p><code>0.039</code></p> <p>524,288</p> <p><code>1.864</code></p> <p><code>1.659</code></p> <p><code>8.144</code></p> <p><code>2.105</code></p> <p><code>0.096</code></p> <p>1,048,576</p> <p><code>3.920</code></p> <p><code>3.330</code></p> <p><code>16.121</code></p> <p><code>4.564</code></p> <p><code>0.243</code></p> <p>Now in each row, the absolute runtime performance of each algorithm is different. In Chapter\u00a02, I discussed how different behaviors within a classification can vary by a multiplicative constant. This table provides evidence of this observation. Once the problem size is large enough, Quicksort is about 15% faster than Merge Sort, while Heap Sort is more than four times slower.</p> <p>The last two columns in Table\u00a05-1 report on the performance of a new sorting algorithm, Tim Sort, invented by Tim Peters for Python in 2002. This algorithm is quickly becoming the standard sorting algorithm used by major programming languages, such as Java, Python, and Swift. Column \u201cTim Sort\u201d represents the runtime performance for a simplified Tim Sort implementation, which also exhibits O(N <code>log</code> N) behavior. The final column, labeled \u201cPython Sort,\u201d represents the runtime performance using the built-in <code>sort()</code> method in the <code>list</code> data type. Because it is implemented internally, it will naturally be the most efficient\u2014as you can see, it is around 15 times faster than Quicksort. It is worthwhile to investigate Tim Sort because it mixes together two different sorting algorithms to achieve its outstanding performance.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#tim-sort","title":"Tim Sort","text":"<p>Tim Sort combines Insertion Sort and the <code>merge()</code> helper function from Merge Sort in a novel way to provide a fast sorting algorithm that outperforms other sorting algorithms on real-world data. In particular, Tim Sort dynamically takes advantage of long sequences of partially sorted data to deliver truly outstanding results.</p> <p>As shown in Listing 5-10, Tim Sort first partially sorts N/<code>size</code> sub-arrays of a computed <code>size</code>, based on <code>compute_min_run()</code>. <code>size</code> will typically be an integer between 32 and 64, which means we can treat this number as a constant that is independent of N. This stage ensures there are sequences of partially sorted data, which improves the behavior of <code>merge()</code>, the helper function from Merge Sort that merges two sorted sub-arrays into one.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#listing-5-10-basic-tim-sort-implementation","title":"Listing 5-10. Basic Tim Sort implementation","text":"<pre><code>def\n</code></pre> <p>Small arrays are sorted instead using Insertion Sort.</p> <p></p> <p>Compute <code>size</code>\u2014a value typically between 32 and 64\u2014to use for the length of the sub-arrays to be sorted.</p> <p></p> <p>Use Insertion Sort to sort each sub-array <code>A[lo .. lo+size\u20131]</code>, handling special case when final sub-array is smaller.</p> <p></p> <p><code>merge()</code> uses extra storage equal in size to the original array.</p> <p></p> <p>Compute index positions for two sub-arrays to be merged, <code>A[lo .. mid]</code> and <code>A[mid+1 .. hi]</code>. Take special care with partial sub-arrays.</p> <p></p> <p>Merge sub-arrays together to sort <code>A[lo .. hi]</code> using <code>aux</code> for auxiliary storage.</p> <p></p> <p>Once all sub-arrays of length <code>size</code> are merged with another, prepare for next iteration through <code>while</code> loop to merge sub-arrays twice as large.</p> <p>The auxiliary storage, <code>aux</code>, is allocated once and used by each invocation of <code>merge()</code>. The actual implementation of Tim Sort has more complicated logic that looks for ascending or strictly descending sub-arrays; it also has a more sophisticated merge function that can merge groups of values \u201call at once,\u201d where the <code>merge()</code> function I\u2019ve shown operates one value at a time. The simplified implementation whose behavior is shown in Figure\u00a05-15 contains the essential structure. Given the extensive study of sorting algorithms, it is rather amazing that a new sorting algorithm\u2014discovered this century\u2014has proven to be so effective when working with real-world data sets.</p> <p></p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#figure-5-15-changes-to-array-when-applying-tim-sort-with-initial-size-of-4","title":"Figure 5-15. Changes to array when applying Tim Sort with initial size of 4","text":"<p>Figure\u00a05-15 demonstrates how Tim Sort works, using a <code>min_run</code> of 4 just to make it easier to visualize. In the first step, four sub-arrays of size 4 are sorted using Insertion Sort; the final two values containing 2 and 8 are contained in a partial sub-array of length 2. These sorted sub-arrays are visualized using alternating bands of shaded and non-shaded regions. There will be N/<code>size</code> sorted sub-arrays (possibly one more, if the length of the original array is not divisible by <code>size</code>). I showed earlier that the runtime performance of sorting <code>size</code> values is directly proportional to <code>size</code> \u00d7 (<code>size</code> \u2013 1)/2\u2014since this occurs N/<code>size</code> times, the total runtime performance is directly proportional to N \u00d7 (<code>size</code> \u2013 1)/2. Because <code>size</code> can be considered a constant, this initial phase is classified as O(N).</p> <p>In the second phase, pairs of neighboring runs are merged together. The total accumulated time for the <code>merge()</code> invocations is proportional to N (as I explained earlier in Merge Sort). After the first pass through the <code>while</code> loop, the size of the sorted sub-arrays has doubled to 8, as you can see by the shaded regions in Figure\u00a05-15. In this example, there are three iterations, as <code>size</code> repeatedly doubles from 4 to 32 (which is greater than N). In general, starting with sorted sub-arrays of size <code>size</code>, the <code>while</code> loop iterates <code>k</code> times until <code>size</code> \u00d7 <code>2``k</code> &gt; N; rewrite this computation as 2<code>k</code> &gt; N/<code>size</code>.</p> <p>To find <code>k</code>, take the logarithm of both sides, which reveals that <code>k</code> &gt; <code>log</code>(N/<code>size</code>). Because <code>log</code>(<code>a</code>/<code>b</code>) = <code>log</code>(<code>a</code>) \u2013 <code>log</code>(<code>b</code>), I can say that <code>k</code> &gt; <code>log</code>(N) \u2013 <code>log</code>(<code>size</code>); since <code>size</code> is a constant, I only need to focus on the fact that <code>k</code> is equal to the smallest integer greater than or equal to <code>log</code>(N) minus a small constant value.</p> <p>To summarize, the first phase of Tim Sort\u2014which applies Insertion Sort\u2014can be classified as O(N), and the second phase\u2014which performs repeated <code>merge()</code> requests\u2014 is O(<code>k</code> \u00d7 N), where <code>k</code> is no greater than <code>log</code>(N), resulting in a total overall performance of O(N <code>log</code> N).</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#summary","title":"Summary","text":"<p>Sorting is a fundamental problem in computer science and has been extensively studied. An array containing primitive values can be sorted because these values can be compared with each other by default. More complex data types (such as strings or two-dimensional points) can be sorted using custom ordering functions to allow the same sorting algorithms to work.</p> <p>In this chapter, you learned:</p> <ul> <li> <p>How some basic sorting algorithms have O(N2) performance, making them completely unsuitable for sorting large data sets.</p> </li> <li> <p>The concept of recursion as a key strategy to solve problems by dividing them into smaller sub-problems.</p> </li> <li> <p>That Merge Sort and Heap Sort, in different ways, achieve O(N <code>log</code> N) performance.</p> </li> <li> <p>That Quicksort achieves O(N <code>log</code> N) performance without requiring additional storage, as Merge Sort does.</p> </li> <li> <p>Tim Sort, the default sorting algorithm used by Python and an increasing number of other programming languages.</p> </li> </ul>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#challenge-exercises","title":"Challenge Exercises","text":"<ol> <li> <p>Write a recursive method <code>count(A,t)</code> that returns the number of times that the value <code>t</code> appears within <code>A</code>. Your implementation must have a recursive structure, similar to <code>find_max(A)</code>.</p> </li> <li> <p>You are given an array containing a permutation of the N distinct integers from 0 to N \u2013 1. Determine the fewest number of swaps needed to sort the values in ascending order. Write a function, <code>num_swaps(A)</code>, that takes such an array as input and returns an integer value. Note that you do not actually have to sort the array; just determine the number of swaps.</p> <p>Extend the problem to work with an array of N distinct values, using the symbol table from Chapter\u00a03, and confirm that five swaps are needed for Figure\u00a05-1.</p> </li> <li> <p>What is the total number of comparisons needed for the recursive <code>find_max(A)</code> to determine the largest value in an unordered array of N values? Is this total less than (or greater than) the total number of comparisons used by <code>largest(A)</code> presented in Chapter\u00a01?</p> </li> <li> <p>In the <code>merge()</code> step in Merge Sort, it can happen that one side (left or right) is exhausted. Currently, the <code>merge()</code> function continues to iterate one step at a time. Replace this logic using Python\u2019s ability to copy entire slices of an array, like was done in <code>aux[lo:hi+1] = A[lo:hi+1]</code>. Replace the logic in the first two cases of <code>merge()</code> using slice assignment. Conduct empirical trials to try to measure the performance improvement, if any.</p> </li> <li> <p>Complete a recursive implementation, <code>recursive_two(A)</code>, that returns the two largest values in <code>A</code>. Compare its runtime performance against the other approaches from Chapter\u00a01; also compare the number of times less-than is invoked.</p> </li> <li> <p>The Fibonacci series is defined using the recursive formula FN = FN \u2013 1 + FN \u2013 2, with base cases of F0 = 0 and F1 = 1. A related series, Lucas Numbers, is defined as LN = LN \u2013 1 + LN \u2013 2, with base cases of L0 = 2 and L1 = 1. Implement <code>fibonacci(n)</code> and <code>lucas(n)</code> using a standard recursive approach and measure the time it takes to compute both FN and LN up to N = 40; depending on the speed of your computer, you might have to increase or decrease N to allow the code to terminate. Now implement a new <code>fib_with_lucas(n)</code> method that takes advantage of the following two identities:</p> <ul> <li> <p><code>fib_with_lucas(n)</code>: If you set i = n//2 and j = n-i, then Fi + j = (Fi + Lj) \u00d7 (Fj + Li)/2</p> </li> <li> <p><code>lucas_with_fib(n)</code>: LN = FN \u2013 1 + FN + 1  </p> </li> </ul> <p>Compare timing results of <code>fibonacci()</code> with <code>fib_with_lucas()</code>.</p> </li> </ol>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting-algorithms/#interactive-practice","title":"Interactive Practice","text":"<p>Get more hands-on training and test your understanding of the concepts by working through our playlist of interactive scenarios. Each step of the scenario must be completed correctly before you can move to the next step. If you get stuck, you can view the solution and learn how to complete the step.</p> <p>The following scenarios cover material from this chapter:</p> <ul> <li> <p>Sorting Algorithms: Insertion Sort</p> </li> <li> <p>Sorting Algorithms: Merge Sort</p> </li> <li> <p>Sorting Algorithms: Quicksort Variations</p> </li> </ul> <p>1 No. See the challenge exercises at the end of the chapter.</p> <p>2 275,000 is about 512 squared.</p> <p>3 To avoid crashing the Python interpreter because of infinite recursion, this code returns 1 when given any integer less than or equal to 1.</p> <p>4 In Python, the recursion limit is technically less than 1,000 to prevent crashing the Python interpreter.</p> <p>5 <code>rmax</code> stands for recursive max.</p> <p>6 Invented by Tony Hoare in 1959, Quicksort is well over 50 years old!</p> <ul> <li>Support</li> </ul>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/","title":"CHAPTER 6   Sorting","text":"<p>Sorting algorithms are usually covered in great detail in algorithms books for several reasons.</p> <ul> <li>They are interesting and demonstrate several useful techniques, such as recursion, divide and conquer, heaps, and trees.</li> <li>Sorting algorithms are well-studied and are some of the few algorithms for which exact run times are known. It can be shown that the fastest possible algorithm that uses comparisons to sort N items must use O(N log N) time. Several sorting algorithms actually achieve that performance, so in some sense they are optimal.</li> <li>Sorting algorithms are useful. Almost any data is more useful when it is sorted in various ways, so sorting algorithms play an important role in many applications.</li> </ul> <p>This chapter describes several different sorting algorithms. Some, such as insertionsort, selectionsort, and bubblesort, are relatively simple but slow. Others, such as heapsort, quicksort, and mergesort, are more complicated but much faster. Still others, such as countingsort and pigeonhole sort, don't use comparisons to sort items, so they can break the O(N log N) barrier and perform amazingly fast under the right circumstances.</p> <p>The following sections categorize the algorithms by their run-time performance.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#note","title":"NOTE","text":"<p>Many programming libraries, such as C# and Python, include sorting tools, and they usually are quite fast. In practice, you may want to use those tools to save time writing and debugging the sorting code. It's still important to understand how sorting algorithms work, however, because sometimes you can do even better than the built-in tools. For example, a simple bubblesort algorithm may beat a more complicated library routine for very small lists, and countingsort often beats the tools if the data being sorted has the right characteristics.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#algorithms","title":"Algorithms","text":"<p> algorithms are relatively slow but fairly simple. In fact, their simplicity sometimes lets them outperform faster but more complicated algorithms for very small arrays.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#insertionsort-in-arrays","title":"Insertionsort in Arrays","text":"<p>Chapter 3 described an insertionsort algorithm that sorts items in linked lists. Chapter 5 described insertionsort algorithms that use stacks and queues. The basic idea is to take an item from the input list and insert it into the proper position in a sorted output list (which initially starts empty).</p> <p>Chapter 3 explained how to do this in linked lists, but you can use the same steps to sort an array. The following pseudocode shows the algorithm for use with arrays:</p> <pre><code>Insertionsort(Data: values[])\n</code></pre> <p>As the code loops through the items in the array, the index <code>i</code> separates the items that have been sorted from those that have not. The items with an index less than <code>i</code> have already been sorted, and those with an index greater than or equal to <code>i</code> have not yet been sorted.</p> <p>As <code>i</code> goes from 0 to the last index in the array, the code moves the item at index <code>i</code> into the proper position in the sorted part of the array.</p> <p>To find the item's position, the code looks through the already sorted items and finds the first item that is greater than the new value <code>values[i]</code>.</p> <p>The code then moves <code>values[i]</code> into its new position. Unfortunately, this can be a time-consuming step. Suppose that the item's new index should be <code>j</code>. In that case, the code must move the items between indices <code>j</code> and <code>i</code>, one position to the right to make room for the item at position <code>j</code>.</p> <p>Figure 6.1 shows the algorithm's key steps. The image at the top shows the original unsorted array. In the middle image, the first four items (outlined in bold) have been sorted, and the algorithm is preparing to insert the next item (which has value 3) into the sorted part of the array. The algorithm searches through the sorted items until it determines that the value 3 should be inserted before the value 5. At the bottom of the figure, the algorithm has moved the values 5, 6, and 7 to the right to make room for value 3. The algorithm inserts value 3 and continues the <code>For</code> loop to insert the next item (which has value 2) into its correct position.</p> <p></p> <p>Figure 6.1: Insertionsort inserts items into the sorted part of the array.</p> <p>This algorithm sorts the items in the original array, so it doesn't need any additional storage (aside from a few variables to control loops and move items).</p> <p>If the array contains N items, the algorithm considers each of the N positions in the array. For each position <code>i</code>, it must search the previously sorted items in the array to find the <code>i</code>th item's new position. It must then move the items between that location and index <code>i</code> one position to the right. If the item <code>i</code> should be moved to position <code>j</code>, it takes <code>j</code> steps to find the new location <code>j</code> and then <code>i</code> \u2013 <code>j</code> more steps to move items over, resulting in a total of <code>i</code> steps. That means in total it takes <code>i</code> steps to move item <code>i</code> into its new position.</p> <p>Adding up all the steps required to position the items, the total run time is as follows:</p> <p></p> <p>This means that the algorithm has run time  . This isn't a very fast run time, but it's fast enough for reasonably small arrays (fewer than 10,000 or so items). It's also a relatively simple algorithm, so it may sometimes be faster than more complicated algorithms for very small arrays. How small an array must be for this algorithm to outperform more complicated algorithms depends on your system. Typically, this algorithm is only faster for arrays holding fewer than 5 or 10 items.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#selectionsort-in-arrays","title":"Selectionsort in Arrays","text":"<p>In addition to describing insertionsort for linked lists, Chapter 3 also described selectionsort for linked lists. Similarly, Chapter 5 described selectionsort algorithms that use stacks and queues.</p> <p>The basic idea is to search the input list for the largest item it contains and then add it to the end of a growing sorted list. The following pseudocode shows the algorithm for use with arrays:</p> <pre><code>Selectionsort(Data: values[])\n</code></pre> <p>The code loops through the array to find the smallest item that has not yet been added to the sorted part of the array. It then swaps that smallest item with the item in position <code>i</code>.</p> <p>Figure 6.2 shows the algorithm's key steps. The image at the top shows the original unsorted array. In the middle image, the first three items (outlined in bold) have been sorted, and the algorithm is preparing to swap the next item into position. The algorithm searches the unsorted items to find the one with the smallest value (3 in this case). The algorithm then swaps the item that has the smallest value into the next unsorted position. The image at the bottom of the figure shows the array after the new item has been moved to the sorted part of the array. The algorithm now continues the <code>For</code> loop to add the next item (which has value 5) to the growing sorted portion of the array.</p> <p></p> <p>Figure 6.2: Selectionsort moves the smallest unsorted item to the end of the sorted part of the array.</p> <p>Like insertionsort, this algorithm sorts the items in the original array, so it doesn't need any additional storage (aside from a few variables to control loops and move items).</p> <p>If the array contains N items, the algorithm considers each of the N positions in the array. For each position <code>i</code>, it must search the N \u2013 <code>i</code> items that have not yet been sorted to find the item that belongs in position <code>i</code>. It then swaps the item into its final position in a small constant number of steps. Adding up the steps to move all of the items gives the following run time:</p> <p></p> <p>This means that the algorithm has run time  \u2014the same run time as insertionsort.</p> <p>Like insertionsort, selectionsort is fast enough for reasonably small arrays (fewer than 10,000 or so items). It's also a fairly simple algorithm, so it may sometimes be faster than more complicated algorithms for very small arrays (typically 5 to 10 items).</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#bubblesort","title":"Bubblesort","text":"<p>Bubblesort uses the fairly obvious fact that if an array is not sorted, then it must contain two adjacent elements that are out of order. The algorithm repeatedly passes through the array, swapping items that are out of order, until it can't find any more swaps.</p> <p>The following pseudocode shows the bubblesort algorithm:</p> <pre><code>Bubblesort(Data: values[])\n</code></pre> <p>The code uses a Boolean variable named <code>not_sorted</code> to keep track of whether it has found a swap in its most recent pass through the array. As long as <code>not_sorted</code> is true, the algorithm loops through the array, looking for adjacent pairs of items that are out of order and swaps them.</p> <p>Figure 6.3 shows an example. The array on the far left is mostly sorted. During the first pass through the array, the algorithm finds that the 6/3 pair is out of order (6 should come after 3), so it swaps 6 and 3 to get the second arrangement of values. During the second pass through the array, the algorithm finds that the 5/3 pair is out of order, so it swaps 5 and 3 to get the third arrangement of values. During the third pass through the array, the algorithm finds that the 4/3 pair is out of order, so it swaps 4 and 3, giving the arrangement on the far right in the figure. The algorithm performs one final pass, finds no pairs that are out of order, and ends.</p> <p></p> <p>Figure 6.3: In bubblesort, items that are farther down than they should be slowly \u201cbubble up\u201d to their correct positions.</p> <p>The fact that item 3 seems to bubble up slowly to its correct position gives the bubblesort algorithm its name.</p> <p>During each pass through the array, at least one item reaches its final position. In Figure 6.3, item 6 reaches its final destination during the first pass, item 5 reaches its final destination during the second pass, and items 3 and 4 reach their final destinations during the third pass.</p> <p>If the array holds N items and at least one item reaches its final position during each pass through the array, then the algorithm can perform, at most, N passes. (If the array is initially sorted in reverse order, the algorithm needs all N passes.) Each pass takes N steps, so the total run time is .</p> <p>Like insertionsort and selectionsort, bubblesort is fairly slow but may provide acceptable performance for small lists (fewer than 1,000 or so items). It is also sometimes faster than more complicated algorithms for very small lists (five or so items).</p> <p>You can make several improvements to bubblesort. First, in Figure 6.3, the item with value 3 started out below its final correct position. However, consider what happens if an item starts above its final position. In that case, the algorithm finds that the item is out of position and swaps it with the following item. It then considers the next position in the array and considers the item again. If the item is still out of position, the algorithm swaps it again. The algorithm continues swapping that item down through the list until it reaches its final position in a single pass through the array. You can use this fact to speed up the algorithm by alternating downward and upward passes through the array. Downward passes quickly move items that are too high in the array, and upward passes quickly move items that are too low in the array.</p> <p>This upward and downward version of bubblesort is sometimes called cocktail shaker sort.</p> <p>To make a second improvement, notice that some items may move through several swaps at once. For example, during a downward pass, a large item (call it K) may be swapped several times before it reaches a larger item, and it stops for that pass. You can save a little time if you don't put item K back in the array for every swap. Instead, you can store K in a temporary variable and move other items up in the array until you find the spot where K stops. You then put K in that position and continue the pass through the array.</p> <p>To make a final improvement, consider the largest item (call it L) that is not in its final position. During a downward pass, the algorithm reaches that item (possibly making other swaps beforehand) and swaps it down through the list until it reaches its final position. During the next pass through the array, no item can swap past L because L is in its final position. That means the algorithm can end its pass through the array when it reaches item L.</p> <p>More generally, the algorithm can end its pass through the array when it reaches the position of the last swap that it made during the previous pass. If you keep track of the last swaps made during downward and upward passes through the array, you can shorten each pass.</p> <p>Figure 6.4 shows these three improvements. During the first pass down through the array, the algorithm swaps item 7 with items 4, 5, 6, and 3. It holds the value 7 in a temporary variable, so it doesn't need to save it back into the array until it reaches its final position.</p> <p></p> <p>Figure 6.4: Improvements make bubblesort faster, but it still has  performance.</p> <p>After placing 7 after 3, the algorithm continues moving through the array and doesn't find any other items to swap, so it knows that item 7 and those that follow are in their final positions and don't need to be examined again. If some item nearer to the top of the array were larger than 7, the first pass would have swapped it down past 7. In the middle image shown in Figure 6.4, the final items are shaded to indicate that they don't need to be checked during later passes.</p> <p>The algorithm knows that item 7 and the items after it are in their final positions, so it starts its second pass, moving upward through the array at the first item before item 7, which is item 3. It swaps that item with items 6, 5, and 4, this time holding item 3 in a temporary variable until it reaches its final position.</p> <p>Now item 3 and those that come before it in the array are in their final positions, so they are shaded in the last image in Figure 6.4.</p> <p>The algorithm makes one final downward pass through the array, starting the pass at value 4 and ending at value 6. No swaps occur during this pass, so the algorithm ends.</p> <p>These improvements make bubblesort faster in practice. (In one test sorting 10,000 items, bubblesort took 2.50 seconds without improvements and 0.69 seconds with improvements.) But it still has  performance, so there's a limit to the size of the list you can sort with bubblesort.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#algorithms_1","title":"Algorithms","text":"<p> algorithms are much faster than  algorithms, at least for larger arrays. For example, if N is 1,000,  is less than  , but  is roughly 100 times as big at  . That difference in speed makes  algorithms more useful in everyday programming, at least for large arrays.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#heapsort","title":"Heapsort","text":"<p>Heapsort uses a data structure called a heap, which also demonstrates a useful technique for storing a complete binary tree in an array.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#storing-complete-binary-trees","title":"Storing Complete Binary Trees","text":"<p>A binary tree is a tree where every node is connected to, at most, two children. In a complete tree (binary or otherwise), all of the tree's levels are completely filled, except possibly the last level, where all of the nodes are pushed to the left.</p> <p>Figure 6.5 shows a complete binary tree holding 12 nodes. The tree's first three levels are full. The fourth level contains five nodes pushed to the left side of the tree.</p> <p></p> <p>Figure 6.5: In a complete binary tree, every level is full, except possibly the last.</p> <p>One useful feature of complete binary trees is that you can easily store them in an array using a simple formula. Start by placing the root node at index 0. Then, for any node with index  , place its children at indices  and .</p> <p>If a node has index  , then its parent has index \u230a \u230b, where \u230a \u230b means to truncate the result to the next-smallest integer. In other words, round down. For example, \u230a \u230b is 2, and \u230a \u230b is also 2.</p> <p>Figure 6.6 shows the tree shown in Figure 6.5 stored in an array, with the entries' indices shown on top.</p> <p></p> <p>Figure 6.6: You can easily store a complete binary tree in an array.</p> <p>For example, the value 6 is at index 4, so its children should be at indices  and  10. Those items have values 5 and 12. If you look at the tree shown in Figure 6.5, you'll see that those are the correct children.</p> <p>If the index of either child is greater than the largest index in the array, then the node doesn't have that child in the tree. For example, the value 9 has index 5. Its right child has index  , which is beyond the end of the array. If you look at Figure 6.5, you'll see that the item with value 9 has no right child.</p> <p>For an example of calculating a node's parent, consider the item with value 12 stored at index 10. The index of the parent is \u230a(10 \u2013 1)/2\u230b = \u230a4.5\u230b = 4 . The value at index 4 is 6. If you look at the tree shown in Figure 6.5, you'll see that the node with value 12 does have as its parent the node with value 6.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#defining-heaps","title":"Defining Heaps","text":"<p>A heap, shown in Figure 6.7, is a complete binary tree where every node holds a value that is at least as large as the values in all of its children. Figure 6.5 is not a heap, however, because the root node has a value of 7 and its right child has a value of 10, which is greater.</p> <p></p> <p>Figure 6.7: In a heap, the value of every node is at least as large as the values of its children.</p> <p>You can build a heap one node at a time. Start with a tree consisting of a single node. Because the single node has no children, it satisfies the heap property.</p> <p>Now suppose you have built a heap, and you want to add a new node to it. Add the new node at the end of the tree. There is only one place where you can add this node to keep the tree a complete binary tree\u2014to the right of the nodes already in the bottom level of the tree.</p> <p>Now compare the new value to the value of its parent. If the new value is larger than the parent's, swap them. Because the tree was previously a heap, you know that the parent's value was already larger than its other child (if it has one). By swapping it with an even larger value, you know that the heap property is preserved at this point.</p> <p>However, you have changed the value of the parent node, so that might break the heap property farther up in the tree. Move up the tree to the parent node and compare its value to the value of its parent, swapping their values if necessary.</p> <p>Continue up the tree, swapping values if necessary, until you reach a node where the heap property is satisfied. At that point, the tree is again a heap.</p> <p>Figure 6.8 shows this process when you add the value 12 to the tree shown in Figure 6.7. Figure 6.9 shows the new heap.</p> <p></p> <p>Figure 6.8: To add a new value to a heap, place the value at the end of the tree and move it up as needed to restore the heap property.</p> <p></p> <p>Figure 6.9: When the value moves up to a node that already satisfies the heap property, the tree is once again a heap.</p> <p>Storing the heap in an array makes this process particularly easy because when you need to add a new item to the end of the tree, it's already in the proper position in the array. When you store a complete binary tree in an array, the next item belongs on the right, on the tree's bottom level. In the array, that's the position that comes after the last entry that is already in the tree. This means you don't need to do anything to place the next item in the tree. All you need to do is to swap it up through the tree to restore the heap property.</p> <p>The following pseudocode shows the algorithm to turn an array into a heap:</p> <pre><code>MakeHeap(Data: values[])\n</code></pre> <p>You may recall from Chapter 5, \u201cStacks and Queues,\u201d that a priority queue is a queue that returns objects in the order of their priorities. Heaps are useful for creating priority queues because the largest item in the tree is always at the root node. If you use the items' priorities to build the heap, then the item with the highest priority is at the top. To remove an item from the priority queue, you simply use the item at the root.</p> <p>Unfortunately, that breaks the heap, so it has no root and is therefore no longer a tree. Fortunately, there's an easy way to fix it: move the last item in the tree to the root.</p> <p>Doing that breaks the tree's heap property, but you can fix that by using a method similar to the one you used to build the heap. If the new root value is smaller than one of its child values, swap it with the larger child. That fixes the heap property at this node, but it may have broken it at the child's level, so move down to that node and repeat the process. Continue swapping the node down into the tree until you find a spot where the heap property is already satisfied or you reach the bottom of the tree.</p> <p>The following pseudocode shows the algorithm to remove an item from the heap and restore the heap property:</p> <pre><code>Data: RemoveTopItem (Data: values[], Integer: count)\n</code></pre> <p>This algorithm takes as a parameter the size of the tree, so it can find the location where the heap ends within the array.</p> <p>The algorithm starts by saving the value at the root node so that it later can return the highest-priority value. It then moves the last item in the tree to the root node.</p> <p>The algorithm sets the variable <code>index</code> to the index of the root node and then enters an infinite <code>While</code> loop.</p> <p>Inside the loop, the algorithm calculates the indices of the children of the current node. If either of those indices is off the end of the tree, then it is set to the current node's index. In that case, when the node's values are compared later, the current node's value is compared to itself. Because any value is greater than or equal to itself, that comparison satisfies the heap property, so the missing node does not make the algorithm swap values.</p> <p>After the algorithm calculates the child indices, it checks whether the heap property is satisfied at this point. If it is, then the algorithm breaks out of the <code>While</code> loop. (If both child nodes are missing or if one is missing and the other satisfies the heap property, then the <code>While</code> loop also ends.)</p> <p>If the heap property is not satisfied, the algorithm sets <code>swap_child</code> to the index of the child that holds the larger value and swaps the parent node's value with that child node's value. It then updates the <code>index</code> variable to move down to the swapped child node and continues down the tree.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#implementing-heapsort","title":"Implementing Heapsort","text":"<p>Now that you know how to build and maintain a heap, implementing the heapsort algorithm is easy. The algorithm builds a heap. It then repeatedly swaps the first and last items in the heap and rebuilds the heap excluding the last item. During each pass, one item is removed from the heap and added to the end of the array where the items are placed in sorted order.</p> <p>The following pseudocode shows how the algorithm works:</p> <pre><code>Heapsort(Data: values)\n</code></pre> <p>This algorithm starts by turning the array of values into a heap. It then repeatedly removes the top item, which is the largest, and moves it to the end of the heap. It reduces the number of items in the heap by one and restores the heap property, leaving the newly positioned item beyond the end of the heap in its proper sorted order.</p> <p>When it is finished, the algorithm has removed the items from the heap in largest-to-smallest order and placed them at the end of the ever-shrinking heap. That leaves the array holding the values in smallest-to-largest order.</p> <p>The space required by heapsort is easy to calculate. The algorithm stores all the data inside the original array and uses only a fixed number of extra variables for counting and swapping values. If the array holds N values, the algorithm uses  space.</p> <p>The run time required by the algorithm is slightly harder to calculate. To build the initial heap, the algorithm adds each item to a growing heap. Each time it adds an item, it places the item at the end of the tree and swaps the item upward until the tree is again a heap. Because the tree is a complete binary tree, it is up to  levels tall, so pushing the item up through the tree can take, at most,  steps. The algorithm performs this step of adding an item and restoring the heap property N times, so the total time to build the initial heap is .</p> <p>To finish sorting, the algorithm removes each item from the heap and then restores the heap property. It does that by swapping the last item in the heap with the root node and then swapping the new root down through the tree until the heap property is restored. The tree is up to  levels tall, so this can take up to  time. The algorithm repeats this step N times, so the total number of steps required is .</p> <p>Adding the time needed to build the initial heap and the time to finish sorting gives a total time of .</p> <p>Heapsort is an elegant \u201csort-in-place\u201d algorithm that takes no extra storage. It also demonstrates some useful techniques such as heaps and storing a complete binary tree in an array.</p> <p>Even though heapsort's  run time is asymptotically the fastest possible for an algorithm that sorts by using comparisons, the quicksort algorithm described in the next section usually runs slightly faster.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#quicksort","title":"Quicksort","text":"<p>The quicksort algorithm uses a divide-and-conquer strategy. It subdivides an array into two pieces and then calls itself recursively to sort the pieces. The following pseudocode shows the algorithm at a high level:</p> <pre><code>Quicksort(Data: values[], Integer: start, Integer: end)\n</code></pre> <p>For example, the top of Figure 6.10 shows an array of values to sort. In this case, I picked the first value, 6, for <code>divider</code>.</p> <p></p> <p>Figure 6.10: When the value moves up to a node that already satisfies the heap property, the tree is once again a heap.</p> <p>In the middle image, values less than <code>divider</code> have been moved to the beginning of the array, and values greater than or equal to <code>divider</code> have been moved to the end of the array. The divider item is shaded at index 6. Notice that one other item has value 6, and it comes after the <code>divider</code> in the array.</p> <p>The algorithm then calls itself recursively to sort the two pieces of the array before and after the <code>divider</code> item. The result is shown at the bottom of Figure 6.10.</p> <p>Before moving into the implementation details, let's study the algorithm's run-time behavior.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#analyzing-quicksorts-run-time","title":"Analyzing Quicksort's Run Time","text":"<p>First, consider the special case in which the dividing item divides the part of the array that is of interest into two exactly equal halves at every step. Figure 6.11 shows the situation.</p> <p></p> <p>Figure 6.11: If the divider item divides the array into equal halves, the algorithm progresses quickly.</p> <p>Each of the \u201cnodes\u201d in the tree shown in Figure 6.11 represents a call to the quicksort algorithm. The thick line in the middle of the node shows how the array was divided into two equal halves. The two arrows out of the node represent the quicksort algorithm calling itself twice to process the two halves.</p> <p>The nodes at the bottom of the tree represent calls to sort a single item. Because a list holding a single item is already sorted, those calls simply return without doing anything.</p> <p>After the calls work their way to the bottom of the tree, they begin returning to the methods that called them, so control moves back up the tree.</p> <p>If the array originally holds N items and the items divide exactly evenly, as shown in Figure 6.11, then the tree of quicksort calls is log N levels tall.</p> <p>Each call to quicksort must examine all the items in the piece of the array it is sorting. For example, a call to quicksort represented by a group of four boxes in Figure 6.11 would need to examine those four boxes to divide its values further.</p> <p>All of the items in the original array are present at each level of the tree, so each level of the tree contains N items. If you add up the items that each call to quicksort must examine at any level of the tree, you get N items. That means the calls to quicksort on any level require N steps.</p> <p>The tree is log N levels tall, and each level requires N steps, so the algorithm's total run time is .</p> <p>All of this analysis assumes that the quicksort algorithm divides its part of the array into two equal-sized pieces at every step. In practice, that would be extremely unlikely.</p> <p>Most of the time, however, the dividing item will belong somewhere more or less in the middle of the items that it is dividing. It won't be in the exact middle, but it won't be near the edges either. For example, in Figure 6.10, the dividing item 6 ended up close to but not exactly in the middle in the second image. If the dividing item is usually somewhere near the middle of the values that it is dividing, then in the expected case, the quicksort algorithm still has  performance.</p> <p>In the worst case, suppose the dividing item is less than any of the other items in the part of the array that it is dividing. That happens if the items are already sorted when the algorithm begins. (The worst case also occurs if all of the items in the array have the same value.) In that case, none of the items goes into the left piece of the array, and all of the other items (except the dividing item) go into the right piece of the array. The first recursive call returns immediately because it doesn't need to sort any items, but the second call must process almost all the items. If the first call to quicksort had to sort N items, this recursive call must sort  items.</p> <p>If the dividing item is always less than the other items in the part of the array being sorted, then the algorithm is called to sort N items, then  items, then  items, and so on. In that case, the call tree shown in Figure 6.11 is extremely tall and thin, with a height of N.</p> <p>The calls to quicksort at level <code>i</code> in the tree must examine N \u2013 <code>i</code> items. Adding up the items that all of the calls must examine gives  which is  so the algorithm's worst-case behavior is .</p> <p>In addition to examining the algorithm's run-time performance, you should consider the space it needs. This depends partly on the method you use to divide parts of the array into halves, but it also depends on the algorithm's depth of recursion. If the sequence of recursive calls is too deep, the program will exhaust its stack space and crash.</p> <p>For the tree shown in Figure 6.11, the quicksort algorithm calls itself recursively to a depth of log N calls. In the expected case, that means the program's call stack will be  levels deep. That shouldn't be a problem for most computers. Even if the array holds 1 billion items, log N is only about 30, and the call stack should be able to handle 30 recursive method calls.</p> <p>For the tall thin tree created in the worst case, however, the depth of recursion is N. Few programs will be able to build a call stack safely with 1 billion recursive calls.</p> <p>You can help avoid the worst-case scenario to make the algorithm run in a reasonable amount of time and with a reasonable depth of recursion by picking the dividing item carefully. The following section describes some strategies for doing that. The sections after that one describe two methods for dividing a section of an array into two halves. The final quicksort section summarizes issues with using quicksort in practice.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#picking-a-dividing-item","title":"Picking a Dividing Item","text":"<p>One method of picking the dividing item is simply to use the first item in the part of the array being sorted. This is quick, simple, and usually effective. Unfortunately, if the array happens to be initially sorted or sorted in reverse, the result is the worst case. If the items are randomly arranged, this worst-case behavior is extremely unlikely, but it seems reasonable that the array of items might be initially sorted or mostly sorted for some applications.</p> <p>One solution is to randomize the array before calling quicksort. If the items are randomly arranged, it is extremely unlikely that this method will pick a bad dividing item every time and result in worst-case behavior. Chapter 2, \u201cNumerical Algorithms,\u201d explains how to randomize an array in  time so that this won't add to quicksort's expected  run time, at least in Big O notation. In practice, however, it could still take a fair amount of time to randomize a large array, so most programmers don't use this approach.</p> <p>Another approach is to examine the first, last, and middle items in the part of the array being sorted and use the value that is between the other two for the dividing item. This doesn't guarantee that the dividing item isn't close to the largest or smallest in this part of the array, but it does make it less likely.</p> <p>A final approach is to pick a random index from the part of the array being sorted and then use the value at that index as the dividing item. It would be extremely unlikely that every such random selection would produce a bad dividing value and result in worst-case behavior.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#implementing-quicksort-with-stacks","title":"Implementing Quicksort with Stacks","text":"<p>After you have picked a dividing item, you must divide the items into two sections to be placed at the front and back of the array. One easy way to do this is to move items into one of two stacks, depending on whether the item you are considering is greater than or less than the dividing item. The following pseudocode shows the algorithm for this step:</p> <pre><code>Stack of Data: before = New Stack of Data\n</code></pre> <p>At this point, the algorithm is ready to recursively call itself to sort the two pieces of the array on either side of the dividing item.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#implementing-quicksort-in-place","title":"Implementing Quicksort in Place","text":"<p>Using stacks to split the items in the array into two groups as described in the preceding section is easy, but it requires you to allocate extra space for the stacks. You can save some time if you allocate the stacks at the beginning of the algorithm and then let every call to the algorithm share the same stacks instead of creating their own, but this still requires the stacks to hold  memory.</p> <p>With a little more work, you can split the items into two groups without using any extra storage. The following high-level pseudocode shows the basic approach:</p> <pre><code>&lt;Swap the dividing item to the beginning of the array.&gt;\n</code></pre> <p>This code uses the first item as the dividing item. It places that item in a temporary variable and removes it from the array, leaving a hole.</p> <p>The algorithm then searches the array from the back to the front until it finds a value that is less than the dividing item. It removes that value from its current location and moves it into the hole. Removing the item from its original location creates a new hole.</p> <p>Next, the algorithm searches from the point of the old hole (now filled with the newly moved item) toward the back of the array until it finds an item that is greater than the dividing item. It moves that item to the current hole, creating a new hole where the item was originally.</p> <p>The code continues searching back and forth through this section of the array, moving items into the holes left by previously moved items, until the two regions that it is searching meet somewhere in the middle. The algorithm deposits the dividing item in the hole, which is now between the two pieces, and recursively calls itself to sort the two pieces.</p> <p>This is a fairly confusing step, but the actual code isn't all that long. If you study it closely, you should be able to figure out how it works.</p> <pre><code>&lt;Search the array from back to front to find\n</code></pre> <p>The following pseudocode shows the entire quicksort algorithm at a low level:</p> <pre><code>// Sort the indicated part of the array.\n</code></pre> <p>This algorithm starts by checking whether the section of the array contains one or fewer items. If it does, then it is sorted, so the algorithm simply returns.</p> <p>If the section of the array contains at least two items, the algorithm saves the first item as the dividing item. You can use some other dividing item selection method if you like. Just swap the dividing item you pick to the beginning of the section so that the algorithm can find it in the following steps.</p> <p>Next the algorithm uses variables <code>lo</code> and <code>hi</code> to hold the highest index in the lower part of the array and the lowest index in the upper part of the array. It uses those variables to keep track of which items it has placed in the two halves. Those variables also alternately track where the hole is left after each step.</p> <p>The algorithm then enters an infinite <code>While</code> loop that continues until the lower and upper pieces of the array grow to meet each other.</p> <p>Inside the outer <code>While</code> loop, the algorithm starts at index <code>hi</code> and searches the array backward until it finds an item that should be in the lower piece of the array. It moves that item into the hole left behind by the dividing item.</p> <p>Next the algorithm starts at index <code>lo</code> and searches the array forward until it finds an item that should be in the upper piece of the array. It moves that item into the hole left behind by the previously moved item.</p> <p>The algorithm continues searching backward and then forward through the array until the two pieces meet. At that point, it puts the dividing item between the two pieces and recursively calls itself to sort the pieces.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#using-quicksort","title":"Using Quicksort","text":"<p>If you divide the items in place instead of by using stacks or queues, quicksort doesn't use any extra storage (beyond a few variables).</p> <p>Like heapsort, quicksort has  expected performance, although quicksort can have  performance in the worst case. Heapsort has  performance in all cases, so it is in some sense safer and more elegant. However, in practice, quicksort is usually faster than heapsort, so it is the algorithm of choice for many programmers.</p> <p>In addition to greater speed, quicksort has another advantage over heapsort: it is parallelizable. Suppose a computer has more than one processor, which is increasingly the case these days. Each time the algorithm splits a section of the array into two pieces, it can use different processors to sort the two pieces. Theoretically, a highly parallel computer could use  processors to sort the list in  time. In practice, most computers have a fairly limited number of processors (for example, two or four), so the run time would be divided by the number of processors plus some additional overhead to manage the different threads of execution. That won't change the Big O run time, but it should improve performance in practice.</p> <p>Because it has  performance in the worst case, the implementation of quicksort provided by a library may be cryptographically insecure. If the algorithm uses a simple dividing item selection strategy, such as picking the first item, an attacker might be able to create an array holding items in an order that gives worst-case performance. The attacker might be able to launch a denial-of-service (DOS) attack by passing your program that array and ruining your performance. Most programmers don't worry about this possibility, but if this is a concern, you can use a randomized dividing item selection strategy.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#mergesort","title":"Mergesort","text":"<p>Like quicksort, mergesort uses a divide-and-conquer strategy. Instead of picking a dividing item and splitting the items into two groups holding items that are larger and smaller than the dividing item, mergesort splits the items into two halves holding an equal number of items. It then recursively calls itself to sort the two halves. When the recursive calls to mergesort return, the algorithm merges the two sorted halves into a combined sorted list.</p> <p>The following pseudocode shows the algorithm:</p> <pre><code>Mergesort(Data: values[], Data: scratch[], Integer: start, Integer: end)\n</code></pre> <p>In addition to the array and the start and end indices to sort, the algorithm also takes as a parameter a scratch array that it uses to merge the sorted halves.</p> <p>This algorithm starts by checking whether the section of the array contains one or fewer items. If it does, then it is trivially sorted, so the algorithm returns.</p> <p>If the section of the array contains at least two items, the algorithm calculates the index of the item in the middle of the section of the array and recursively calls itself to sort the two halves.</p> <p>After the recursive calls return, the algorithm merges the two sorted halves. It loops through the halves, copying the smaller item from whichever half holds it into the scratch array. When one-half is empty, the algorithm copies the remaining items from the other half.</p> <p>Finally, the algorithm copies the merged items from the scratch array back into the original <code>values</code> array.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#note_1","title":"NOTE","text":"<p>It is possible to merge the sorted halves without using a scratch array, but it's more complicated and slower, so most programmers use a scratch array.</p> <p>The \u201ccall tree,\u201d shown in Figure 6.11, shows calls to quicksort when the values in the array are perfectly balanced, so the algorithm divides the items into equal halves at every step. The mergesort algorithm does divide the items into exactly equal halves at every step, so Figure 6.11 applies even more to mergesort than it does to quicksort.</p> <p>The same run-time analysis shown earlier for quicksort also works for mergesort, so this algorithm also has O(N log N) run time. Like heapsort, mergesort's run time does not depend on the initial arrangement of the items, so it always has O(N log N) run time and doesn't have a disastrous worst case like quicksort does.</p> <p>Like quicksort, mergesort is parallelizable. When a call to mergesort calls itself recursively, it can make those calls on different processors. This requires some coordination, however, because the original call must wait until both recursive calls finish before it can merge their results. In contrast, quicksort can simply tell its recursive calls to sort a particular part of the array, and it doesn't need to wait until those calls return.</p> <p>Mergesort is particularly useful when all the data to be sorted won't fit in memory at once. For example, suppose a program needs to sort 1 million customer records, each of which occupies 1 MB. Loading all that data into memory at once would require 1018 bytes of memory, or 1,000 TB, which is much more than most computers have.</p> <p>Fortunately, the mergesort algorithm doesn't need to load that much memory all at once. The algorithm doesn't even need to look at any of the items in the array until after its recursive calls to itself have returned.</p> <p>At that point, the algorithm walks through the two sorted halves in a linear fashion and merges them. Moving through the items linearly reduces the computer's need to page memory to and from disk. When quicksort moves items into the two halves of a section of an array, it jumps from one location in the array to another, increasing paging and greatly slowing down the algorithm.</p> <p>Mergesort was even more useful in the days when large data sets were stored on tape drives, which work most efficiently if they keep moving forward with few rewinds. (Sorting data that cannot fit in memory is called external sorting.) Specialized versions of mergesort were even more efficient for tape drives. They're interesting but not commonly used anymore, so they aren't described here.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#note_2","title":"NOTE","text":"<p>For some interesting background on external sorting on tape drives, see <code>[https://en.wikipedia.org/wiki/Merge_sort#Use_with_tape_drives](https://en.wikipedia.org/wiki/Merge_sort#Use_with_tape_drives)</code>. For more general information on tape drives, see <code>[https://en.wikipedia.org/wiki/Tape_drive](https://en.wikipedia.org/wiki/Tape_drive)</code>.</p> <p>A more common approach to sorting enormous data sets is to sort only the items' keys. For example, a customer record might occupy 1 MB, but the customer's name might occupy only 100 bytes. A program can make a separate index that matches names to record numbers and then sort only the names. Then, even if you have 1 million customers, sorting their names requires only about 100 MB of memory, an amount that a computer could reasonably hold. (Chapter 11, \u201cBalanced Trees,\u201d describes B-trees and B+ trees, which are often used by database systems to store and sort record keys in this manner.)</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#stable-sorting","title":"STABLE SORTING","text":"<p>A stable sorting algorithm is one that maintains the original relative positioning of equivalent values. For example, suppose that a program is sorting <code>Car</code> objects by their <code>Cost</code> properties and that <code>Car</code> objects <code>A</code> and <code>B</code> have the same <code>Cost</code> values. If object <code>A</code> initially comes before object <code>B</code> in the array, then in a stable sorting algorithm, object <code>A</code> still comes before object <code>B</code> in the sorted array.</p> <p>If the items you are sorting are value types such as integers, dates, or strings, then two entries with the same values are equivalent, so it doesn't matter if the sort is stable. For example, if the array contains two entries that have value 47, it doesn't matter which 47 comes first in the sorted array.</p> <p>In contrast, you might care if <code>Car</code> objects are rearranged unnecessarily. For example, a stable sort lets you arrange the array multiple times to get a result that is sorted on multiple keys (such as <code>Maker</code> and <code>Cost</code> for the <code>Car</code> example).</p> <p>Mergesort is easy to implement as a stable sort (the algorithm described earlier is stable). It is also easy to parallelize, so it may be useful on computers that have more than one CPU. See Chapter 18, \u201cDistributed Algorithms,\u201d for information on implementing mergesort on multiple CPUs.</p> <p>Quicksort may often be faster, but mergesort still has some advantages.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#sub-algorithms","title":"Sub  Algorithms","text":"<p>Earlier in this chapter, I said that the fastest possible algorithm that uses comparisons to sort N items must use at least  time. Heapsort and mergesort achieve that bound, and so does quicksort in the expected case, so you might think that's the end of the sorting story. The loophole is in the phrase \u201cthat uses comparisons.\u201d If you use a technique other than comparisons to sort, you can beat the  bound.</p> <p>The following sections describe some algorithms that sort in less than  time.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#countingsort","title":"Countingsort","text":"<p>Countingsort is a specialized algorithm that works well if the values you are sorting are integers that lie in a relatively small range. For example, if you need to sort 1 million integers with values between 0 and 1,000, countingsort can provide amazingly fast performance.</p> <p>The basic idea behind countingsort is to count the number of items in the array that have each value. Then it is relatively easy to copy each value, in order, the required number of times back into the array.</p> <p>The following pseudocode shows the countingsort algorithm:</p> <pre><code>Countingsort(Integer: values[], Integer: max_value)\n</code></pre> <p>The <code>max_value</code> parameter gives the largest value in the array. (If you don't pass it in as a parameter, you can modify the algorithm to figure it out by looking through the array.)</p> <p>Let M be the number of items in the counts array (so M = <code>max_value</code> + 1) and let N be the number of items in the <code>values</code> array. If your programming language doesn't automatically initialize the <code>counts</code> array so that it contains 0s, the algorithm spends M steps initializing the array. It then takes N steps to count the values in the <code>values</code> array.</p> <p>The algorithm finishes by copying the values back into the original array. Each value is copied once, so that part takes N steps. If any of the entries in the <code>counts</code> array is still 0, the program also spends some time skipping over that entry. In the worst case, if all of the values are the same so that the <code>counts</code> array contains mostly 0s, it takes M steps to skip over the 0 entries.</p> <p>That makes the total run time  . If M is relatively small compared to N, this is much smaller than the  performance given by heapsort and the other algorithms described previously.</p> <p>In one test, quicksort took 4.29 seconds to sort 1 million items with values between 0 and 1,000, but it took countingsort only 0.03 seconds. Note that this is a bad case for quicksort because the values include many duplicates. With 1 million values between 0 and 1,000, roughly 1,000 items have each value, and quicksort doesn't handle lots of duplication well.</p> <p>With similar values, heapsort took roughly 1.02 seconds. This is a big improvement on quicksort, but it is still much slower than countingsort.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#pigeonhole-sort","title":"Pigeonhole Sort","text":"<p>Like countingsort, pigeonhole sort works well when the range of possible values is limited. Countingsort counts the number of items with each given value. To do that, it uses the values as indices into the <code>counts</code> array. Unfortunately, that won't work if the items that you are sorting are not integers, so you can't use them as indices.</p> <p>Pigeonhole sort works by placing the items in pigeonholes corresponding to their key values. The pigeonhole approach makes it easier to sort more complicated items than simple numeric values. For example, suppose that you want to sort a set of words by their lengths. Countingsort would give you an array holding the number of words with each length, but it's not immediately obvious how you would convert that into the ordered list of words.</p> <p>In contrast, pigeonhole sort groups words with the same length in the same pigeonhole, so it is easier to put them in order.</p> <p>The following pseudocode shows how pigeonhole sort works. The algorithm assumes that you have defined a <code>Cell</code> class with <code>Value</code> and <code>Next</code> properties that you can use to build a linked list of values in each pigeonhole.</p> <pre><code>PigeonholeSort(Integer: values[], Integer: max)\n</code></pre> <p>The <code>values</code> parameter gives the values to sort. The <code>max</code> parameter gives the maximum value that the <code>values</code> array could hold. Here I'm assuming the values are integers starting at zero. If they include values between lower and upper bounds, you'll have to adjust the code accordingly. If the values are non-numeric, for example if they are strings, then you'll need to use some sort of algorithm to map each value to its pigeonhole.</p> <p>The algorithm first creates a pigeonhole array of pointers to <code>Cell</code> objects and initializes them to <code>null</code>. It then loops through the items and adds each to the top of its pigeonhole's linked list. The code then loops through the pigeonholes and copies the items in each linked list back into the <code>values</code> array.</p> <p>To analyze the algorithm's run time, suppose that the <code>values</code> array contains N items that span a range of M possible values. The algorithm uses  steps to initialize its pigeonhole linked lists. It then loops through the values and adds them to their pigeonholes in  steps.</p> <p>The algorithm finishes by looping through the pigeonholes again, this time moving the items back into the values array. It must spend  steps examining each linked list whether or not that list is empty. During this stage, it also must move every item back into the <code>values</code> array, and that takes  steps, so the total steps to perform this final stage is .</p> <p>That means the total run time for the algorithm is  </p> <p>If the number of values N is roughly the same as the size of the range of values M, then this becomes  and that is much faster than .</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#bucketsort","title":"Bucketsort","text":"<p>The countingsort and pigeonhole sort algorithms work well if the values include only a relatively small range. Bucketsort works even if the values span a large range.</p> <p>The bucketsort algorithm, which is also called binsort, works by dividing items into buckets. It sorts the buckets either by recursively calling bucketsort or by using some other algorithm. It then concatenates the buckets' contents back into the original array in sorted order. The following pseudocode shows the algorithm at a high level:</p> <pre><code>Bucketsort(Data: values[])\n</code></pre> <p>If the values in an array holding N items are reasonably uniformly distributed, if you use M buckets, and if the buckets divide the range of values evenly, then you should expect roughly  items per bucket.</p> <p>For example, consider the array shown at the top of Figure 6.12, which contains 10 items with values between 0 and 99. In the distribution step, the algorithm moves the items into the buckets. In this example, each bucket represents 20 values: 0 to 19, 20 to 39, and so on. In the sorting step, the algorithm sorts each bucket. The gathering step concatenates the values in the buckets to build the sorted result.</p> <p></p> <p>Figure 6.12: Bucketsort moves items into buckets, sorts the buckets, and then concatenates the buckets to get the sorted result.</p> <p>The buckets can be stacks, linked lists, queues, arrays, or any other data structure that you find convenient.</p> <p>If the original array contains N fairly evenly distributed items, then distributing them into the buckets requires N steps times whatever time it takes to place an item in a bucket. Normally this mapping can be done in constant time. For example, suppose the items are integers between 0 and 99, as in the example shown in Figure 6.12. You would place an item with value <code>v</code> in bucket number \u230a \u230b. You can calculate this number in constant time, so distributing the items takes  steps.</p> <p>If you use M buckets, sorting each bucket requires an expected  steps, where F is the run-time function of the sorting algorithm that you use to sort the buckets. Multiplying this by the number of buckets M, the total time to sort all the buckets is .</p> <p>After you have sorted the buckets, gathering their values back into the array requires N steps to move all of the values. It could require an additional  steps to skip empty buckets if many of the buckets are empty, but if  the whole operation requires  steps.</p> <p>Adding the times needed for the three stages gives a total run time of </p> <p>If M is a fixed fraction of N, then  is a constant, so  is also a constant, and this simplifies to </p> <p>In practice, M must be a relatively large fraction of N for the algorithm to perform well. If you are sorting 10 million records and you use only 10 buckets, then you need to sort buckets containing an average of 1 million items each.</p> <p>In contrast, if M equals N, then each bucket should hold only a few items and sorting them should take a small constant amount of time. In that case, the algorithm's  run time simplifies to  and the algorithm runs very quickly.</p> <p>Unlike countingsort and pigeonhole sort, bucketsort's performance does not depend on the range of the values. Instead, it depends on the number of buckets that you use.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#summary","title":"Summary","text":"<p>The sorting algorithms described in this chapter demonstrate different techniques and have different characteristics. Table 6.1 summarizes the algorithms.</p> <p>Table 6.1: Algorithm Characteristics</p> <p>ALGORITHM</p> <p>RUN TIME</p> <p>TECHNIQUES</p> <p>USEFUL FOR</p> <p>Insertionsort</p> <p></p> <p>Insertion</p> <p>Very small arrays</p> <p>Selectionsort</p> <p></p> <p>Selection</p> <p>Very small arrays</p> <p>Bubblesort/Cocktail Shaker Sort</p> <p></p> <p>Two-way passes, restricting bounds of interest</p> <p>Very small arrays, mostly sorted arrays</p> <p>Heapsort</p> <p></p> <p>Heaps, storing complete trees in an array</p> <p>Large arrays with unknown distribution</p> <p>Quicksort</p> <p> expected,  worst case</p> <p>Divide-and-conquer, swapping items into position, randomization to avoid worst-case behavior</p> <p>Large arrays without too many duplicates, parallel sorting</p> <p>Mergesort</p> <p></p> <p>Divide-and-conquer, merging, external sorting</p> <p>Large arrays with unknown distribution, huge amounts of data, parallel sorting</p> <p>Countingsort</p> <p></p> <p>Counting</p> <p>Large arrays of integers with a limited range of values</p> <p>Pigeonhole sort</p> <p></p> <p>Pigeonholes</p> <p>Large arrays of possibly noninteger values within a limited range</p> <p>Bucketsort</p> <p></p> <p>Buckets</p> <p>Large arrays with reasonably uniform value distribution</p> <p>These algorithms demonstrate an assortment of useful techniques and provide good performance for a wide variety of problems, but they're far from the end of the story. There are dozens of other sorting algorithms. Some are minor modifications of these algorithms, and others use radically different approaches. Chapter 10 discusses trees, which are also extremely useful for sorting data. Search the Internet for other algorithms.</p> <p>This chapter explained several ways to sort data, but it didn't explain why you should want to do that. Simply having data sorted often makes it more useful to a user. For example, viewing customer accounts sorted by balance makes it much easier to determine which accounts need special attention.</p> <p>Another good reason to sort data is so that you can later find specific items within it. For example, if you sort customers by their names, it's easier to locate a specific customer. The next chapter explains methods that you can use to search a sorted set of data to find a specific value.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/Algorithms/sorting/#exercises","title":"Exercises","text":"<p>You can find the answers to these exercises in Appendix B. Asterisks indicate particularly difficult problems.</p> <ol> <li>Write a program that implements insertionsort.</li> <li>The <code>For i</code> loop used by the insertionsort algorithm runs from 0 to the array's last index. What happens if it starts at 1 instead of 0? Does that change the algorithm's run time?</li> <li>Write a program that implements selectionsort.</li> <li>What change to selectionsort could you make that corresponds to the change described in Exercise 2? Would it change the algorithm's run time?</li> <li>Write a program that implements bubblesort.</li> <li>Add the first and third bubblesort improvements described in the section \u201cBubblesort\u201d (downward and upward passes and keeping track of the last swap) to the program you built for Exercise 5.</li> <li>Write a program that uses an array-based heap to build a priority queue. So that you don't need to resize the array, allocate it at some fixed size, perhaps 100 items, and then keep track of the number of items that are used by the heap. (To make the queue useful, you can't just store priorities. Use two arrays\u2014one to store string values and another to store the corresponding priorities. Order the items by their priorities.) (For more practice, use a class to store items with their priorities and wrap the priority queue in a second class.)</li> <li>What is the run time for adding items to and removing items from a heap-based priority queue?</li> <li>Write a program that implements heapsort.</li> <li>Can you generalize the technique used by heapsort for holding a complete binary tree so that you can store a complete tree of degree d? Given a node's index p, what are its children's indices? What is its parent's index?</li> <li>Write a program that implements quicksort with stacks. (You can use the stacks provided by your programming environment or build your own.)</li> <li>Write a program that implements quicksort with queues instead of stacks. (You can use the queues provided by your programming environment or build your own.) Is there any advantage or disadvantage to using queues instead of stacks?</li> <li>Write a program that implements quicksort with in-place partitioning. Why is this version faster than the version that uses stacks or queues?</li> <li>Quicksort can display worst-case behavior if the items are initially sorted, if the items are initially sorted in reverse order, or if the items contain many duplicates. You can avoid the first two problems if you choose random dividing items. How can you avoid the third problem?</li> <li>Write a program that implements countingsort.</li> <li>If an array's values range from 100,000 to 110,000, allocating a <code>counts</code> array with 110,001 entries with indices 0 through 110,000 would slow down countingsort considerably, particularly if the array holds a relatively small number of items. How could you modify countingsort to give good performance in this situation?</li> <li>Write a program that implements pigeonhole sort.</li> <li>If an array holds N items that span the range 0 to M \u2013 1, what happens to bucketsort if you use M buckets?</li> <li>Write a program that implements bucketsort. Allow the user to specify the number of items, the maximum item value, and the number of buckets.</li> <li>Explain the space/time trade-off that you should consider when picking the number of buckets used by bucketsort.</li> <li> <p>For the following data sets, which sorting algorithms would work well, and which would not?  </p> <ol> <li>10 floating-point values  </li> <li>1,000 integers  </li> <li>1,000 names  </li> <li>100,000 integers with values between 0 and 1,000  </li> <li>100,000 integers with values between 0 and 1 billion  </li> <li>100,000 names  </li> <li>1 million floating-point values  </li> <li>1 million names  </li> <li>1 million integers with uniform distribution  </li> <li>1 million integers with nonuniform distribution</li> </ol> </li> <li> <p>Support</p> </li> <li></li> </ol>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/software%20testing/testing-pyramid%20-%20Effective%20software%20testing%20book%20by%20Mauricio%20Aiche/","title":"testing pyramid   Effective software testing book by Mauricio Aiche","text":""},{"location":"05-reference%20system%20%F0%9F%A7%BE/software%20testing/testing-pyramid%20-%20Effective%20software%20testing%20book%20by%20Mauricio%20Aiche/#14-the-testing-pyramid-and-where-we-should-focus","title":"1.4 The testing pyramid, and where we should focus","text":"<p>Whenever we talk about pragmatic testing, one of the first decisions we need to make is the level at which to test the code. By a test\u00a0level, I mean the\u00a0unit,\u00a0integration, or\u00a0system\u00a0level. Let\u2019s quickly look at each of them.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/software%20testing/testing-pyramid%20-%20Effective%20software%20testing%20book%20by%20Mauricio%20Aiche/#141-unit-testing","title":"1.4.1 Unit testing","text":"<p>In some situations, the tester\u2019s goal is to test a single feature of the software, purposefully ignoring the other units of the system. This is basically what we saw in the planning poker example. The goal was to test the\u00a0<code>identifyExtremes()</code>\u00a0method and nothing else. Of course, we cared about how this method would interact with the rest of the system, and that is why we tested its contracts. However, we did not test it together with the other pieces of the system.</p> <p>When we test units in isolation, we are doing\u00a0unit testing. This test level offers the following advantages:</p> <ul> <li> <p>Unit tests are fast. A unit test usually takes just a couple of milliseconds to execute. Fast tests allow us to test huge portions of the system in a small amount of time. Fast, automated test suites give us constant feedback. This fast safety net makes us feel more comfortable and confident in performing evolutionary changes to the software system we are working on.</p> </li> <li> <p>Unit tests are easy to control. A unit test tests the software by giving certain parameters to a method and then comparing the return value of this method to the expected result. These input values and the expected result value are easy to adapt or modify in the test. Again, look at the\u00a0<code>identifyExtremes()</code>\u00a0example and how easy it was to provide different inputs and assert its output.</p> </li> <li> <p>Unit tests are easy to write. They do not require a complicated setup or additional work. A single unit is also often cohesive and small, making the tester\u2019s job easier. Tests become much more complicated when we have databases, frontends, and web services all together.</p> </li> </ul> <p>As for disadvantages, the following should be considered:</p> <ul> <li> <p>Unit tests lack reality. A software system is rarely composed of a single class. The large number of classes in a system and their interaction can cause the system to behave differently in its real application than in the unit tests. Therefore, unit tests do not perfectly represent the real execution of a software system.</p> </li> <li> <p>Some types of bugs are not caught. Some types of bugs cannot be caught at the unit test level; they only happen in the integration of the different components (which are not exercised in a pure unit test). Think of a web application that has a complex UI: you may have tested the backend and the frontend thoroughly, but a bug may only reveal itself when the backend and frontend are put together. Or imagine multithreaded code: everything may work at the unit level, but bugs may appear once threads are running together.</p> </li> </ul> <p>Interestingly, one of the hardest challenges in unit testing is to define what constitutes a unit. A unit can be one method or multiple classes. Here is a definition for unit testing that I like, given by Roy\u00a0Osherove (2009): \u201cA unit test is an automated piece of code that invokes a unit of work in the system. And a unit of work can span a single method, a whole class or multiple classes working together to achieve one single logical purpose that can be verified.\u201d</p> <p>For me, unit testing means testing a (small) set of classes that have no dependency on external systems (such as databases or web services) or anything else I do not fully control. When I unit-test a set of classes together, the number of classes tends to be small. This is primarily because testing many classes together may be too difficult, not because this isn\u2019t a unit test.</p> <p>But what if a class I want to test depends on another class that talks to, for example, a database (figure 1.5)? This is where unit testing becomes more complicated. Here is a short answer: if I want to test a class, and this class depends on another class that depends on a database, I will simulate the database class. In other words, I will create a stub that acts like the original class but is much simpler and easier to use during testing. We will dive into this specific problem in chapter 6, where we discuss mocks.</p> <p></p> <p>Figure 1.5 Unit testing. Our goal is to test one unit of the system that is as isolated as possible from the rest of the system.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/software%20testing/testing-pyramid%20-%20Effective%20software%20testing%20book%20by%20Mauricio%20Aiche/#142-integration-testing","title":"1.4.2 Integration testing","text":"<p>Unit tests focus on the smallest parts of the system. However, testing components in isolation sometimes is not enough. This is especially true when the code under test goes beyond the system\u2019s borders and uses other (often external) components. Integration testing is the test level we use to test the integration between our code and external parties.</p> <p>Let\u2019s consider a real-world example. Software systems commonly rely on database systems. To communicate with the database, developers often create a class whose only responsibility is to interact with this external component (think of Data Access Object [DAO] classes). These DAOs may contain complicated SQL code. Thus, a tester feels the need to test the SQL queries. The tester does not want to test the entire system, only the integration between the DAO class and the database. The tester also does not want to test the DAO\u00a0class in complete isolation. After all, the best way to know whether a SQL query works is to submit it to the database and see what the database returns.</p> <p>This is an example of an integration test. Integration testing aims to test multiple components of a system together, focusing on the interactions between them instead of testing the system as a whole (see figure 1.6). Are they communicating correctly? What happens if component A sends message X to component B? Do they still present correct behavior?</p> <p></p> <p>Figure 1.6 Integration testing. Our goal is to test whether our component integrates well with an external component.</p> <p>Integration testing focuses on two parts: our component and the external component. Writing such a test is less complicated than writing a test that goes through the entire system and includes components we do not care about.</p> <p>Compared to unit testing, integration tests are more difficult to write. In the example, setting up a database for the test requires effort. Tests that involve databases generally need to use an isolated instance of the database just for testing purposes, update the database schema, put the database into a state expected by the test by adding or removing rows, and clean everything afterward. The same effort is involved in other types of integration tests: web services, file reads and writes, and so on. We will discuss writing integration tests effectively in chapter 9.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/software%20testing/testing-pyramid%20-%20Effective%20software%20testing%20book%20by%20Mauricio%20Aiche/#143-system-testing","title":"1.4.3 System testing","text":"<p>To get a more realistic view of the software and thus perform more realistic tests, we should run the entire software system with all its databases, frontend apps, and other components. When we test the system in its entirety, instead of testing small parts of the system in isolation, we are doing system testing (see figure 1.7). We do not care how the system works from the inside; we do not care if it was developed in Java or Ruby, or whether it uses a relational database. We only care that, given input X, the system will provide output Y.</p> <p></p> <p>Figure 1.7 System testing. Our goal is to test the entire system and its components.</p> <p>The obvious advantage of system testing is\u00a0how realistic the tests are. Our final customers will not run the\u00a0<code>identifyExtremes()</code>\u00a0method in\u00a0isolation. Rather, they will visit a web page, submit a form, and see the results. System tests exercise the system in that precise manner. The more realistic the tests are (that is, when the tests perform actions similar to the final user), the more confident we can be about the whole system.</p> <p>System testing does, however, have its downsides:</p> <ul> <li> <p>System tests are often\u00a0slow\u00a0compared to unit tests. Imagine everything a system test has to do, including starting and running the entire system with all its components. The test also has to interact with the real application, and actions may take a few seconds. Imagine a test that starts a container with a web application and another container with a database. It then submits an HTTP request to a web service exposed by this web app. This web service retrieves data from the database and writes a JSON response to the test. This obviously takes more time than running a simple unit test, which has virtually no dependencies.</p> </li> <li> <p>System tests are also\u00a0harder to write. Some of the components (such as databases) may require a complex setup before they can be used in a testing scenario. Think of connecting, authenticating, and making sure the database has all the data required by that test case. Additional code is required just to automate the tests.</p> </li> <li> <p>System tests are more\u00a0prone to flakiness. A\u00a0flaky\u00a0test presents erratic behavior: if you run it, it may pass or fail for the same configuration. Flaky tests are an important problem for software development teams, and we discuss this issue in chapter 10. Imagine a system test that exercises a web app. After the tester clicks a button, the HTTP POST request to the web app takes half a second longer than usual (due to small variations we often do not control in real-life scenarios). The test does not expect this and thus fails. The test is executed again, the web app takes the usual time to respond, and the test passes. Many uncertainties in a system test can lead to unexpected behavior.</p> </li> </ul>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/software%20testing/testing-pyramid%20-%20Effective%20software%20testing%20book%20by%20Mauricio%20Aiche/#144-when-to-use-each-test-level","title":"1.4.4 When to use each test level","text":"<p>With a clear understanding of the different test levels and their benefits, we have to decide whether to invest more in unit testing or system testing and determine which components should be tested via unit testing and which components should be tested via system testing. A wrong decision may have a considerable impact on the system\u2019s quality: a wrong level may cost too many resources and may not find sufficient bugs. As you may have guessed, the best answer here is, \u201cIt depends.\u201d</p> <p>Some developers\u2014including me\u2014favor unit testing over other test levels. This does not mean such developers do not do integration or system testing; but whenever possible, they push testing toward the unit test level. A pyramid is often used to illustrate this idea, as shown in figure 1.8. The size of the slice in the pyramid represents the relative number of tests to carry out at each test level.</p> <p></p> <p>Figure 1.8 My version of the testing pyramid. The closer a test is to the top, the more real and complex the test becomes. At the right part you see what I test at each test level.</p> <p>Unit testing is at the bottom of the pyramid and has the largest area. This means developers who follow this scheme favor unit testing (that is, write more unit tests). Climbing up in the diagram, the next level is integration testing. The area is smaller, indicating that, in practice, these developers write fewer integration tests than unit tests. Given the extra effort that integration tests require, the developers write tests only for the integrations they need. The diagram shows that these developers favor system tests less than integration tests and have even fewer manual tests.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/software%20testing/testing-pyramid%20-%20Effective%20software%20testing%20book%20by%20Mauricio%20Aiche/#145-why-do-i-favor-unit-tests","title":"1.4.5 Why do I favor unit tests?","text":"<p>As I said, I tend to favor unit testing. I appreciate the advantages that unit tests give me. They are easy to write, they are fast, I can write them intertwined with production code, and so on. I also believe that unit testing fits very well with the way software developers work. When developers implement a new feature, they write separate units that will eventually work together to deliver larger functionality. While developing each unit, it is easy to ensure that it works as expected. Testing small units rigorously and effectively is much easier than testing a larger piece of functionality.</p> <p>Because I am also aware of the disadvantages of unit testing, I think carefully about how the unit under development will be used by the other units of the system. Enforcing clear contracts and systematically testing them gives me more certainty that things will work out when they are put together.</p> <p>Finally, given the intensity with which I test my code using (simple and cheap) unit tests, I can use integration and system tests for the parts that really matter. I do not have to retest all the functionalities again at these levels. I use integration or system testing to test specific parts of the code that I believe may cause problems during integration.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/software%20testing/testing-pyramid%20-%20Effective%20software%20testing%20book%20by%20Mauricio%20Aiche/#146-what-do-i-test-at-the-different-levels","title":"1.4.6 What do I test at the different levels?","text":"<p>I use unit tests for units that are concerned with an algorithm or a single piece of business logic of the software system. Most enterprise/business systems are used to transform data. Such business logic is often expressed by using entity classes (for example, an\u00a0<code>Invoice</code>\u00a0class and an\u00a0<code>Order</code>\u00a0class) to exchange messages. Business logic often does not depend on external services, so it can easily be tested and fully controlled through unit tests. Unit tests give us full control over the input data as well as full observability in terms of asserting that the behavior is as expected.</p> <p>NOTE\u00a0If a piece of code deals with specific business logic but cannot be tested via unit tests (for example, the business logic can only be tested with the full system running), previous design or architectural decisions are probably preventing you from writing unit tests. How you design your classes has a significant impact on how easy it is to write unit tests for your code. We discuss design for testability in chapter 7.</p> <p>I use integration tests whenever the component under test interacts with an external component (such as a database or web service). A DAO, whose sole responsibility is to communicate with a database, is better tested at the integration level: you want to ensure that communication with the database works, the SQL query returns what you want it to, and transactions are committed to the database. Again, note that integration tests are more expensive and harder to set up than unit tests, and I use them only because they are the only way to test a particular part of the system. Chapter 7 discusses how having a clear separation between business rules and infrastructure code will help you test business rules with unit tests and integration code with integration tests.</p> <p>As we know already, system tests are very costly (they are difficult to write and slow to run) and, thus, at the top of the pyramid. It is impossible to retest the entire system at the system level. Therefore, I have to prioritize what to test at this level, and I perform a simple risk analysis to decide. What are the critical parts of the software system under test? In other words, what parts of the system would be significantly affected by a bug? These are the areas where I do some system testing.</p> <p>Remember the\u00a0pesticide paradox: a single technique usually is not enough to identify all the bugs. Let me give you a real-world example from one of my previous projects. In developing an e-learning platform, one of our most important functionalities was payment. The worst type of bug would prevent users from buying our product. Therefore, we were rigorous in testing all the code related to payment. We used unit tests for business rules related to what the user bought being converted into the right product, access and permissions, and so on. Integration with the two payment gateways we supported was tested via integration testing: the integration tests made real HTTP calls to a sandbox web service provided by the payment gateways, and we tested different types of users buying products with various credit cards. Finally, our system tests represented the entire user journey in buying our product. These tests started a Firefox browser, clicked HTML elements, submitted forms, and checked that the right product was available after confirming payment.</p> <p>Figure 1.8 also includes manual testing. I\u2019ve said that every test should be automated, but I see some value in manual testing when these tests focus on exploration and validation. As a developer, it is nice to use and explore the software system you are building from time to time, both for real and via a test script. Open the browser or the app, and play with it\u2014you may gain better insight into what else to test.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/software%20testing/testing-pyramid%20-%20Effective%20software%20testing%20book%20by%20Mauricio%20Aiche/#147-what-if-you-disagree-with-the-testing-pyramid","title":"1.4.7 What if you disagree with the testing pyramid?","text":"<p>Many people disagree about the idea of a testing pyramid and whether we should favor unit testing. These developers argue for the\u00a0testing trophy: a thinner bottom\u00a0level with unit tests, a bigger middle slice with integration tests, and a thinner top with system tests. Clearly, these developers see the most value in writing integration tests.</p> <p>While I disagree, I see their point. In many software systems, most of the complexity is in integrating components. Think of a highly distributed microservices architecture: in such a scenario, the developer may feel more comfortable if the automated tests make actual calls to other microservices instead of relying on stubs or mocks that simulate them. Why write unit tests for something you have to test anyway via integration tests?</p> <p>In this particular case, as someone who favors unit testing, I would prefer to tackle the microservices testing problem by first writing lots and lots of unit tests in each microservice to ensure that they all behaved correctly, investing heavily in contract design to ensure that the microservices had clear pre- and post-conditions. Then, I would use many integration tests to ensure that communication worked as expected and that the normal variations in the distributed system did not break the system\u2014yes, lots of them, because their benefits would outweigh their costs in this scenario. I might even invest in some smart (maybe AI-driven) tests to explore corner cases I could not see.</p> <p>Another common case I see in favor of integration testing rather than unit testing involves database-centric information systems: that is, systems where the main responsibility is to store, retrieve, and display information. In such systems, the complexity relies on ensuring that the flow of information successfully travels through the UI to the database and back. Such applications often are not composed of complex algorithms or business rules. In that case, integration tests to ensure that SQL queries (which are often complex) work as expected and system tests to ensure that the overall application behaves as expected may be the way to go. As I said before and will say many times in this book, context is king.</p> <p>I\u2019ve written most of this section in the first person because it reflects my point of view and is based on my experience as a developer. Favoring one approach over another is largely a matter of personal taste, experience, and context. You should do the type of testing you believe will benefit your software. I am not aware of any scientific evidence that argues in favor of or against the testing pyramid. And in 2020, Trautsch and colleagues analyzed the fault detection capability of 30,000 tests (some unit tests, some integration tests) and could not find any evidence that certain defect types are more effectively detected by either test level. All the approaches have pros and cons, and you will have to find what works best for you and your development team.</p> <p>I suggest that you read the opinions of others, both in favor of unit testing and in favor of integration testing:</p> <ul> <li> <p>In\u00a0Software Engineering at Google\u00a0(Winters, Manshreck, and Wright, 2020), the authors\u00a0mention\u00a0that Google\u00a0often opts for unit tests, as they tend to be cheaper and execute more quickly. Integration and system tests also happen, but to a lesser extent. According to the authors, around 80% of their tests are unit tests.</p> </li> <li> <p>Ham Vocke (2018) defends the testing pyramid in\u00a0Martin Fowler\u2019s wiki.</p> </li> <li> <p>Fowler himself (2021) discusses the different test shapes (testing pyramid and testing trophy).</p> </li> <li> <p>Andr\u00e9 Schaffer (2018) discusses how\u00a0Spotify prefers integration testing over unit testing.</p> </li> <li> <p>Julia Zarechneva and Picnic, a scale-up Dutch company (2021), reason about the testing pyramid.</p> </li> </ul> <p>Test sizes rather than their scope</p> <p>Google also has an interesting definition of test\u00a0sizes, which engineers consider when designing test cases. A\u00a0small test\u00a0is a test\u00a0that can be executed in a single process. Such tests do not have access to main sources of test slowness or determinism. In other words, they are fast and not flaky. A\u00a0medium test\u00a0can span\u00a0multiple processes, use threads, and make external calls (like network calls) to localhost. Medium tests tend to be slower and flakier than small ones. Finally,\u00a0large tests\u00a0remove the localhost restriction and can thus require and make calls to multiple machines. Google reserves large tests for full end-to-end tests.</p> <p>The idea of classifying tests not in terms of their boundaries (unit, integration, system) but in terms of how fast they run is also popular among many developers. Again, what matters is that for each part of the system, your goal is to maximize the effectiveness of the test. You want your test to be as cheap as possible to write and as fast as possible to run and to give you as much feedback as possible about the system\u2019s quality.</p> <p>Most of the code examples in the remainder of this book are about methods, classes, and unit testing, but the techniques can easily be generalized to coarse-grained components. For example, whenever I show a method, you can think of it as a web service. The reasoning will be the same, but you will probably have more test cases to consider, as your component will do more things.</p>"},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/Difficult%20Conversations/","title":"Difficult Conversations","text":"<p>difficultConversation </p>","tags":["difficultConversation"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/Difficult%20Conversations/#questions-to-prepare-for-a-difficult-conversation","title":"Questions to prepare for a difficult conversation","text":"<ul> <li>What is the issue I\u2019m trying to resolve?</li> <li>What is my counterpart\u2019s view of the issue?</li> <li>What assumptions are we making about the situation and each other?</li> <li>What underlying interests are at stake for me? For my counterpart?</li> <li>What feelings does the situation trigger for me? For my counterpart?</li> <li>What do I want to achieve from the conversation?</li> <li>How can we break the impasse?</li> </ul>","tags":["difficultConversation"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/Difficult%20Conversations/#after-the-difficult-conversation","title":"After the difficult conversation","text":"<ul> <li>Do I feel proud of how I managed the conversation? Do I feel strong? Or do I feel let down, embattled, embarrassed\u2014or just happy it\u2019s over?</li> <li>Did I meet the objectives and cover the topics I outlined for myself?</li> <li>Did I present my perspective in ways that are consistent with my intentions?</li> <li>Did I show respect?</li> <li>Do I feel differently now about the person or the problem?</li> <li>Did I learn anything that changes my view of the problem?</li> </ul>","tags":["difficultConversation"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/Difficult%20Conversations/#become-a-better-communicator","title":"Become a better communicator","text":"<ul> <li>Who do I want to be?</li> <li>How do I want to behave in this situation?</li> <li>What do I want others to take away about me?</li> </ul>","tags":["difficultConversation"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/Difficult%20Conversations/#three-ways-respect-for-a-difficult-conversation","title":"Three ways respect for a difficult conversation","text":"<ul> <li>We need a simple system to handle tough conversations, and three-way respect is its basis.</li> <li>Self-respect helps us stabilize in the face of our own emotional reactions. It brings us in from the extreme emotional poles at the same time that it expands our choices for handling ourselves well.</li> <li>Respect for our counterpart is a willingness on our side to look at our counterpart\u2019s interests and concerns\u2014not necessarily agreeing with them, and not deferring to them. Respect trades asking about those interests for guessing at them, fighting them, or avoiding them.</li> <li>Self-respect and respect form a synergistic loop. Together they determine our reputation and our relationships.</li> <li>Respect for the problem places all that we\u2019re struggling with into the landscape of the conversation itself. It lets us step back and take a satellite view of the way our tough conversation is playing out. The conversation is no longer a battlefield, but a course of obstacles through which we move.</li> </ul> <p>When we\u2019re better balanced within ourselves, we stop polarizing our own behavior.</p> <p>When we\u2019re working toward balance with our counterparts, we stop simply reacting to them</p> <p>If we put our attention on working toward balance\u2014within ourselves, between the two of us in the conversation, and in the landscape of the conversation itself\u2014we stand a good chance of protecting our reputations and our relationships</p>","tags":["difficultConversation"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/Questions%20for%20new%20teams/","title":"Questions for new teams","text":"<p>teamBuilding newTeams</p>","tags":["teamBuilding","newTeams"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/Questions%20for%20new%20teams/#purpose-why-are-we-here","title":"Purpose \u2013 \u201cWhy are we here?\u201d:","text":"<ol> <li>The team has a shared understanding of its vision.</li> <li>All team members understand the key business outcomes desired to realize the team\u2019s vision, and the indicators they will look to in order to determine whether they are succeeding at realizing those outcomes.</li> <li>Team members know who their customers and partners/stakeholders are</li> <li>The team has an initial backlog of valuable work items that will help the team realize the business outcomes</li> <li>Team members have a sense of how the business value of work items is defined and where tradeoffs might be considered in meeting customer expectations.</li> </ol>","tags":["teamBuilding","newTeams"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/Questions%20for%20new%20teams/#alignment-who-are-we-and-how-will-we-work-together","title":"Alignment \u2013 \u201cWho are we and how will we work together?\u201d:","text":"<ol> <li>Team members know who is a core member of the team, and who are external contributors who they need to work with to help them deliver.</li> <li>The team has articulated its shared values</li> <li>Team members have identified simple guiding principles to help them be successful together</li> <li>The team has a working agreement outlining specific behaviours they want to support each other in so that they can work effectively together.</li> <li>The team has identified the capabilities it possesses and the capabilities it needs to develop in order to deliver reliably and with quality, and to minimize bottlenecks/single-points-of-failure.</li> </ol>","tags":["teamBuilding","newTeams"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/Questions%20for%20new%20teams/#context-whats-the-bigger-picture-how-do-we-understand-the-system-and-its-influences","title":"Context \u2013 \u201cWhat\u2019s the bigger picture? How do we understand the system and its influences?\u201d:","text":"<ol> <li>The team knows who its stakeholders/partners are, and what information/decisions/resources they need from each other.</li> <li>The team understands what decisions about the work have already been made and other constraints that will determine what/how they deliver</li> <li>The team has considered the risks and opportunities inherent in their upcoming work, and is actively considering how to mitigate risks and take advantage of opportunities for greater benefit.</li> <li>The team knows what resources are needed to deliver, and is working to get the resources it doesn\u2019t currently have in a timely fashion.</li> <li>The team has established the initial practices it will use for coordinating, collaborating and communicating its progress.</li> </ol>","tags":["teamBuilding","newTeams"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/Receiving%20challenging%20feedback/","title":"Receiving challenging feedback","text":"<p>feedback communication</p> <p>Sign up witnesses. Ask your boss or team to alert you when they observe you mastering the skills or approaches flagged in your review. It\u2019s human nature to categorize people and never change. To disrupt that pattern, ask them to look for positive evidence that you\u2019re changing. As their brains do that work, their opinion of you will change!</p>","tags":["feedback","communication"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/Receiving%20challenging%20feedback/#look-for-the-well-intended-message","title":"Look for the well-intended message.","text":"<p>Without judging yourself, find the review\u2019s message. Trust me, there\u2019s at least a grain of helpful truth in your review. You\u2019re not a horrible person. You\u2019re not the worst performer ever. You just have some growing to do.</p> <ul> <li>Face the review fresh. After your first reading or discussion, turn to another activity. Physical activity can change your emotional state. Do something that will take your mind off the injustice, insult, or condemnation until you cool down. When you\u2019re ready, take a second look. If you\u2019re still struggling, pretend that you\u2019re reading someone else\u2019s review.</li> <li>Move from blame to curiosity. It\u2019s easier to absorb a poor review when you\u2019re curious about how to improve. \u201cWhat can I learn from this?\u201d is a better question than \u201cWhat did I do wrong?\u201d Assume that everything in the review is true and that the reviewer cares deeply about you. Your boss wants you to thrive. So get curious about what more you can learn.</li> <li>Put things in perspective. The review is also a reflection of the company culture versus how you show up. It might feel like a life-and-death battle, but you\u2019re not dying. It\u2019s just a job, and you get to decide what to do about it. You might decide to adapt or move on if the cultural fit isn\u2019t right.</li> </ul> <p>Hold a second conversation with your manager. Even if you had a positive review and a great first discussion, it\u2019s worth a second one. Don\u2019t wait too long. A few days is fine; more time leaves room for you to stew and for your manager to delay. The second discussion enables you to ask follow-up questions and dig into learning.</p> <p></p>","tags":["feedback","communication"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/Receiving%20challenging%20feedback/#make-a-connection","title":"Make a connection.","text":"<p>Show that you care about what the person is saying in the moment. That doesn\u2019t mean you have to agree. Keep the lines of communication open; you\u2019ll receive more insight that way.</p> <p></p>","tags":["feedback","communication"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/Receiving%20challenging%20feedback/#stay-calm-or-withdraw","title":"Stay calm or withdraw.","text":"<p>If you\u2019re being reactive, you\u2019re no longer learning. Take a break to recenter. That\u2019s another way of saying, be a logical, rational, thinking person.</p> <p></p>","tags":["feedback","communication"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/Receiving%20challenging%20feedback/#thank-your-manager-even-if-you-feel-angry","title":"Thank your manager even if you feel angry.","text":"<p>Standing in your manager\u2019s shoes, appreciate how hard it is to give feedback. Forgive poor delivery and accept positive intention. If you strengthen the connection, you\u2019ll enlist your manager to coach you. That makes you a better manager in turn.</p> <ul> <li>Collect multiple perspectives. If you have a mentor or sponsor, schedule a discussion. Remain open, regardless of what you hear. You\u2019re asking a more experienced person to read your review, offer advice, and recommend next steps for you. Even if your mentor\u2019s view is wildly different from yours, take notes. If you can, find three different perspectives. This process gives you time and distance to understand your review, learn more about yourself, and regain your footing.</li> <li>Decide on your next steps. It\u2019s up to you to make your development plan. Make sure to close the loop with your boss and the individuals you\u2019ve reached out to. Align on what success looks like and how to measure your progress.</li> </ul>","tags":["feedback","communication"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/dealing%20with%20a%20coleric%20person/","title":"Dealing with a coleric person","text":"<p>peopleTool difficultConversations communication</p> <p>I'd like to ask you to sleep on it. I am happy to discuss in the future how we can collaborate more. Feedback is a gift, you dont need to keep it, but hold on to it a bit to see if it resonates with you.</p>","tags":["peopleTool","difficultConversations","communication"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/dealing%20with%20a%20coleric%20person/#dealing-with-a-person-in-a-strong-emotional-state","title":"Dealing with a person in a strong emotional state:","text":"<ul> <li>Sending the person for a timeout, to calm down</li> <li>Remember this has nothing to do with me</li> <li>Stay calm. \"You seem very emotional, lets take a breather\"</li> <li>If he stays screaming:<ul> <li>I am happy to continue the conversation when you are again in a calm space. This is not me being passive aggressive, I really want to sort this out, and understand you, and that can happen when we both are in a calm space, so that the conversation can keep being a dignifying experience for both of us.</li> </ul> </li> </ul>","tags":["peopleTool","difficultConversations","communication"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/dealing%20with%20a%20coleric%20person/#preventing-anger-explosions-to-use-when-you-sense-a-bit-of-frustration-building-up","title":"Preventing anger explosions (To use when you sense a bit of frustration building up)","text":"<p>Build up: not feeling understood.</p> <p>Ask: Let's slow down for me to ask you questions so that I understand: 1. Can you give me an example of what you mean? What your context is? why do you think this? What are your assumptions? Do you have a previous experience where this happens? 2. Just for you to understand, these are my assumptions. But I understand you 3. What is the outcome that you would like to see?. My ideal way forward is__. Why do you want to do that? What are you optimising for?</p>","tags":["peopleTool","difficultConversations","communication"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/dealing%20with%20a%20coleric%20person/#if-person-loses-patience","title":"If person loses patience:","text":"<p>I am trying to understand, and if you dont have the time or patience right now, we can do it in other time when you have more time. Whenever you have time, reach out, I am here.</p> <p>If you are being emotional/when you are emotional, you are not being rational, and It makes it very hard for me to understand you.</p>","tags":["peopleTool","difficultConversations","communication"]},{"location":"05-reference%20system%20%F0%9F%A7%BE/tools-Difficult%20situations/solving%20tech%20conflict/","title":"Solving tech conflict","text":"<p>conflictResolution difficultSituations</p> <ul> <li>How does your/their solution improve the situation? In what ways does it improve the situation?</li> <li>What problem are you trying to solve? What problem do you think they are trying to solve?</li> <li>What are you trying to optimise for and what trade-offs are you accepting with your solution? What about their perspective?</li> <li>Are you sharing the same assumptions about these trade-offs?</li> </ul> <p>(Patrick Kua)</p>","tags":["conflictResolution","difficultSituations"]},{"location":"07-today-I-learned/00-Learning%20wishlist/","title":"00 Learning wishlist","text":""},{"location":"07-today-I-learned/00-Learning%20wishlist/#tech","title":"Tech","text":"<ul> <li>Cloud architectures</li> <li>Microservices</li> <li>Backend programming: kotlin, Cojure</li> <li>Containerisation</li> <li>Serverless</li> <li>Architecture documentation, trade offs etc. --- WIP ---</li> <li>Field: AI/ML</li> <li>Databases</li> </ul>"},{"location":"07-today-I-learned/00-Learning%20wishlist/#improve","title":"Improve","text":"<ul> <li>Functional programming - Clojure</li> <li>Design patterns</li> <li>Algorithmic/Mathematical thinking --- WIP ---</li> </ul>"},{"location":"07-today-I-learned/00-Learning%20wishlist/#philosophy","title":"Philosophy","text":"<ul> <li>Foucault on power</li> </ul>"},{"location":"07-today-I-learned/00-Learning%20wishlist/#theater","title":"Theater","text":"<ul> <li>Read out loud poems and monologues</li> </ul>"},{"location":"07-today-I-learned/00-Learning%20wishlist/#finance","title":"Finance","text":"<ul> <li>Finish finance for people</li> <li>Trading, investments, budgeting</li> </ul>"},{"location":"07-today-I-learned/2023-01-18%20TIL%20-%20domain%20architecture%20isomorphism/","title":"2023 01 18 TIL   domain architecture isomorphism","text":"<p>architecture basicConcepts systemDesign</p> <p>How an architecture maps to the business domain..</p> <p>If the business has a lot of interconnected processes, micro-services might not be good for it.</p> <p>Original author: Mark Richards Video with explanation: https://learning.oreilly.com/videos/software-architecture-superstream/0636920814764/0636920814764-video342451/</p>","tags":["architecture","basicConcepts","systemDesign"]},{"location":"07-today-I-learned/2023-02-01%20-%20Coupling%20%20%26%20evolve%20systems/","title":"2023 02 01   Coupling  & evolve systems","text":"<p>architecture principles</p> <p>The more coupling there is, the less evolvability there will be in the system</p> <p>From: Foundations Forum Friday QA with Neal Ford &amp; Mark Richards https://www.developertoarchitect.com/foundations-friday-forum.html</p>","tags":["architecture","principles"]},{"location":"07-today-I-learned/2023-02-06%20-%20Differences%20EDA%20vs%20MSA/","title":"2023 02 06   Differences EDA vs MSA","text":"<p>architecture eventDriven microservice </p>","tags":["architecture","eventDriven","microservice"]},{"location":"07-today-I-learned/2023-02-06%20-%20Differences%20EDA%20vs%20MSA/#key-differences","title":"Key differences","text":"Differentiators EDA MSA Service granularity Not constrained. Can be any size Constrained to single responsibility principle Data granularity Not constrained. Can be 1 monolith database all the way to 1 DB per event processor Constrained 1 BD per service Bounded context (1) Doesn't constrain the design Constrains the service design <p>EDA has no constrains on any of the main differentiators, we can define an EDA system with similar constrains as an MSA system has, where each event processor has its own data attached, and small enough to fulfil the single responsibility principle. However this is not a must</p>","tags":["architecture","eventDriven","microservice"]},{"location":"07-today-I-learned/2023-02-06%20-%20Differences%20EDA%20vs%20MSA/#hybrids","title":"Hybrids","text":"<p>We can also create hybrids of these two architectures, for example:</p> <ul> <li>An EDA where the event processors are as well micro services</li> <li>A MSA where there are event processors within the system</li> </ul>","tags":["architecture","eventDriven","microservice"]},{"location":"07-today-I-learned/2023-02-06%20-%20Differences%20EDA%20vs%20MSA/#further-differentiation","title":"Further differentiation","text":"<p>A microservice can contain an event processor as part of its implementation, but an event processor is not necessarily a microservice. </p> <p>An event processor is a component that is more focused on handling events.</p> <p>A microservice is a more general-purpose component that can contain multiple event processors, as well as other types of functionality.</p>","tags":["architecture","eventDriven","microservice"]},{"location":"07-today-I-learned/2023-02-06%20-%20Differences%20EDA%20vs%20MSA/#related-terms","title":"Related terms","text":"<ul> <li>Bounded context web link or obsidian link</li> <li>Microservice web link - obsidian link</li> <li>Event processor web link - obsidian link</li> </ul> <p>Learned from: Lesson 131 - Microservices vs. Event-Driven Architecture (posted January 31, 2022)</p>","tags":["architecture","eventDriven","microservice"]},{"location":"07-today-I-learned/2023-02-27%20deploying%20to%20dev%20backstage/","title":"2023 02 27 deploying to dev backstage","text":"<p>You just have to grab the last commit hash, and put it in a yml in infra</p>"},{"location":"07-today-I-learned/2023-02-28%20-%20Build%20a%20component%20library%20with%20vue%20ts%20and%20vite/","title":"2023 02 28   Build a component library with vue ts and vite","text":"<p>got to configure package.json </p> <pre><code>\"main\": \"../../dist/libs/my-library/ui-component-library.es.js\",\n\"module\": \"../../dist/libs/my-library/ui-component-library.es.js\",\n\"types\": \"../../dist/libs/my-library/main.d.ts\",\n\n\"exports\": {\n\".\": {\n\n\"import\": \"../../dist/libs/my-library/ui-component-library.es.js\"\n\n},\n\n-&gt; this is: when you do in the pacakge that implements the library. \nyou tell it where to find the styles\nimport \"styles\" from \"my-library/styles.css\"\n\"./styles.css\": {\n\n\"import\": \"../../dist/libs/my-library/styles.css\"\n\n}\n\n},\n</code></pre> <p>You declare your components as usual, and export them like this:</p> <pre><code>import type { App } from 'vue';\n\n//add components to export\nimport { BaseLayout } from \"./components\";\n\n// add all css here.\nimport './styles/main.scss'\n\n\n// not sure what is this for. Will test removing it\nexport default {\ninstall: (app: App) =&gt; {\n//@ts-ignore\napp.component('BaseLayout', BaseLayout);\n}\n};  \n\nexport { BaseLayout };\n</code></pre> <p>In vite:</p> <pre><code>lib: {\n\nentry: resolve(__dirname, 'src/main.ts'),\n\nname: 'uiComponentLibrary',\n\nformats: [\"es\"],\n\n/**\n\n* Name of the main import file that will be placed in\n\n* the folder specified in project.json &gt; \"build\".\"options\".\"outputPath\"\n\n* That united with this needs to be added to module of package.json\n\n* in this example: ../../dist/libs/my-library/ui-component-library.js\n\n*/\n\nfileName: (format) =&gt; `ui-component-library.${format}.js`,\n\n},\n\nrollupOptions: {\n\n// make sure to externalize deps that shouldn't be bundled\n\n// into your library\n\nexternal: ['vue'],\n\noutput: {\n\nassetFileNames: (assetInfo) =&gt; {\n// this is to expose the css with the name of the library\nif (assetInfo.name === 'main.css') return 'ui-component-library.css';\n\nreturn assetInfo.name;\n\n},\n\n},\n\n},\n\n},\n</code></pre> <p>Then in the packate that consumes the library, in the main.ts</p> <pre><code>import { createApp } from 'vue';\n\nimport uiComponentLibrary from 'my-library'\n\n\n\nimport App from './App.vue';\n\n// add this\nimport 'my-library/ui-component-library.css'\n\nimport router from './router';\n\n\n\nconst app = createApp(App);\n// you have to do this\napp.use(uiComponentLibrary)\n\napp.use(router)\n\napp.mount('#app');\n</code></pre> <p>Then you can use the components as usual</p>"},{"location":"07-today-I-learned/2023-03-31%20-%20Docker%20commands/","title":"2023 03 31   Docker commands","text":"<ul> <li>See running images: <code>docker ps</code></li> <li>See the logs of a container: <code>docker logs &lt;name-of-container&gt;</code></li> <li>Connect to a DB in docker with command line: <code>docker exec -it container-name psql -U postgres</code></li> <li>Seeing the networks of the containers: <code>docker network ls</code></li> <li>Inspecting the containers attached to each network: <code>docker network inspect</code></li> </ul>"}]}